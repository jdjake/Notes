%LaTeX template for Summer Schools
%
% !!!!!!!!!!!!   INSTRUCTIONS  !!!!!!!!!!!!!!

% 0) Submit your work in tex format (not pdf). It will be pasted into the proceedings file.
%
% 1) please name your file yourlastname.tex, e.g. thiele.tex.
%
% As several files will be concatenated, please 
% use some discipline as to the following:
%
% 2) Whenever you use \label{} to get automatic cross references
% through \ref{} (this is the preferred option for cross references)
% please add your initials to the label such as 
% \label{SLEct} for the Stochastic Loewner equation
% with initials of author Christoph Thiele
% Same with other citations such as in bibitem.
%
% 3) Please STRONGLY avoid using \def or \newcommand unless really necessary.
% We do have macros for black board bold. If you use your favorite
% macros while preparing your summary, please expand them
% (replace by the original definition) everywhere in your file.
% This will save me the work of doing the very same thing.
% Thank you! If you have to use \def, please also add your
% initials to the definition.
%
% 4) if you want to compile the header of the document, 
% uncomment remove the corresponding paragraph signs below
%
% 5) There is a sample lecture below. For the header 
% it is best to keep most of the
% commands and just change the name, title, text. etc
%
% 6) Please follow the conventions below in terms of capitalization of 
% headings etc:
% Only the beginning of a sentence and names are capitalized.


\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{esint}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{comment}
\usepackage{bbm,dsfont}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{proposition}[theorem]{Proposition}

\newcommand{\talktitle}[1]{\section{#1}}
\newcommand{\talkafter}[1]{\textbf{After #1} \addcontentsline{toc}{subsection}{after #1}}
\newcommand{\talkspeaker}[2]{\begin{center}
\textit{A summary written by #1}
\end{center}
\addcontentsline{toc}{subsection}{#1, #2}
}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[hidelinks]{hyperref}


\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\Q}{\mathbb{Q}}
\def\C{\mathbb{C}}
\newcommand*{\N}{\mathbb{N}}
\newcommand*{\R}{\mathbb{R}}

\newcommand*{\F}{\mathbf{F}}

% Absolute values and norms using mathtools.
% \\[lr][vV]ert produces correct spacing, as opposed to | and \|.
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\title{Reversing a Philosophy}

% \author{Summer School, Kopp}
% \thanks{supported by Hausdorff Center for Mathematics, Bonn}

% \date{October 2022}



\begin{document}

% \maketitle

% {
% \center{Organizers:}
% \center{
% Christoph Thiele, Universit\"at Bonn}
% \center{
% Olli Saari, Universit\"at Bonn}
% \center{$\ $}
% }
% \newpage
% \tableofcontents

% \newpage
\talktitle{Reversing a Philosophy}
\talkafter{Gressman, Guo, Pierce, Roos, and Yung \cite{dujdjf}}
\talkspeaker{Jacob Denson}{University of Edinburgh}

\setcounter{equation}{0}
\setcounter{theorem}{0}

\begin{abstract}
{ After Gressman, Guo, Pierce, Roos, and Yung, we discuss methods that take control on the solutions to a Vinogradov-type equation of the form $\phi(x_1) + \cdots + \phi(x_s) = \phi(y_1) + \cdots + \phi(y_s)$, for a function $\phi: [0,1] \to \mathbb{R}^n$ and use this control to obtain square-function estimates on the extension operator associated with $\phi$ in $L^{2s}(\mathbb{R}^n)$, for $1 \leq s \leq n$.}
\end{abstract}

\subsection{Introduction}

A classical technique to estimate the number of solutions to equations in additive number theory is to utilize orthogonality to reduce such estimates to the study of exponential sums and oscillatory integrals. In recent years, this technique has been most strikingly applied to prove the Vinogradov Mean Value theorem. Let $J_{s,n}(\mathcal{S})$ denote the number of solutions to the equations
%
\begin{equation} \label{aoiwdjaowidjoia21213}
\begin{split}
    j_1 + \cdots + j_s &= k_1 + \cdots + k_s\\
    j_1^2 + \cdots + j_s^2 &= k_1^2 + \cdots + k_s^2\\
    &\shortvdotswithin{=}
    j_1^n + \cdots + j_s^n &= k_1^n + \cdots + k_s^n
\end{split}
\end{equation}
where $j_1,\dots, j_s, k_1,\dots,k_s \in \mathcal{S}$, for some set $\mathcal{S}$ of integers. Define exponentials $e_\xi: [0,1]^n \to \mathbb{C}$ for $\xi \in \mathbb{Z}^n$ by setting $e_\xi(x) = e^{2 \pi i \xi \cdot x}$, and define the moment curve $\phi(t) = (t,t^2,\cdots,t^n)$. Then orthogonality implies
%
\begin{equation}
    J_{s,n}(\mathcal{S}) = \int_{[0,1]^n} \left| \sum\nolimits_{a \in S} e_{\phi(a)}(x) \right|^{2s}.
\end{equation}
%\begin{align*}
%    J_{s,n}(\mathcal{S}) &= \sum\nolimits_{j,k \in \mathcal{S}^s} \prod\nolimits_m \mathbf{I}(j_1^m + \cdots + j_s^m = k_1^m + \cdots + k_s^m)\\
%    &= \sum\nolimits_{j,k \in \mathcal{S}^s} \int_{[0,1]^n} \prod\nolimits_l e_{\phi(j_l)}(x) \overline{e_{\phi(k_l)}(x)}\; dx\\
%    &= \int_{[0,1]^n} \sum\nolimits_{j,k \in \mathcal{S}^s} \prod\nolimits_l e_{\phi(j_l)}(x) \overline{e_{\phi(k_l)}(x)}\; dx\\
%    &= \int_{[0,1]^n} \left| \sum\nolimits_{a \in S} e_{\phi(a)}(x) \right|^{2s}.
%\end{align*}
%
A discrete decoupling estimate of the form
%
\begin{equation} \label{aiodjqj41412qfq}
    \left\| \sum\nolimits_{1 \leq a \leq N} c_a e_{\phi(a)} \right\|_{L^{2s}[0,1]^n} \lesssim \left( \sum |c_a|^2 \right)^{1/2},
\end{equation}
%
applied with $c_a = \mathbf{I}(a \in \mathcal{S})$, imply the bounds $J_{s,n}(\mathcal{S}) \lesssim |\mathcal{S}|^s$, which is sharp up to the implicit constant, since we always have $\Theta ( |\mathcal{S}|^s )$ \emph{diagonal solutions} to the system \eqref{aoiwdjaowidjoia21213} by setting $j$ and $k$ to be permutations of one another. More generally, given an arbitrary function $\phi: \mathbb{N} \to \mathbb{Z}^n$, a discrete decoupling estimate of the form \eqref{aiodjqj41412qfq} would imply estimates on the count on the set  $J_{s,\phi}(\mathcal{S})$ of solutions to the vector equation $\phi(j_1) + \cdots + \phi(j_s) = \phi(k_1) + \cdots + \phi(k_s)$.

The paper \cite{dujdjf} describes a method of \emph{reversing this philosophy}. They show bounds on $J_{s,\phi}(\mathcal{S})$ imply discrete decoupling estimates.

\begin{theorem}
    Let $\phi: \mathbb{N} \to \mathbf{Z}^n$ be a function, and suppose that there exists $\theta \in [s,2s)$ so that $J_{s,\phi}(\mathcal{S}) \lesssim |\mathcal{S}|^\theta$, for any $\mathcal{S} \subset \{ 1, \dots, N \}$. Then for any sequence $\{ c_a: 1 \leq a \leq N \}$,
    % p = 2s/theta
    % 1/p = theta / 2s
    % 1 - 1/p = 1 - theta / 2s
    \[ \left\| \sum\nolimits_{1 \leq a \leq N} c_a e_{\phi(a)} \right\|_{L^{2s}[0,1]^n} \lesssim \log(N)^{1 - \theta / 2s} \left( \sum\nolimits_{1 \leq a \leq N} |c_a|^{2s/\theta} \right)^{\theta/2s}. \]
\end{theorem}

The theorem follows from standard methods in harmonic analysis for obtaining bounds for operators given \emph{restricted-type} control on the operator (bounds for the operator when the input is an indicator function).

Under a much stronger assumption on a function $\phi: [0,1] \to \mathbf{Z}^n$, that only \emph{near solutions} to the equation are \emph{near diagonal}, the paper shows how one can obtain square-function estimates on the extension operator
%
\begin{equation}
    E_\phi f(x) = \int_{[0,1]} f(t) e_{\phi(t)}(x)\; dt.
\end{equation}
%
More precisely, we assume the following property holds:

\vspace{0.5em}
\noindent \fbox{\parbox{\textwidth}{\textbf{Assumption A}: There exists $C > 0$ and $\delta > 0$ so that if $\mathcal{I}$ is any set of length $1/R$ intervals which is \emph{$C/R$ separated} and \emph{has diameter at most $\delta$}, and if $I_1,\dots,I_s,J_1,\dots,J_s \in \mathcal{I}$ are selected so that $(I_1,\dots,I_s)$ is not a permutation of $(J_1,\dots,J_s)$, then
%
\[ \Big| [\phi(a_1) + \cdots + \phi(a_s)] - [\phi(b_1) + \cdots + \phi(b_s)] \Big| \geq R^{-n} \quad \text{for $a_l \in I_l, b_l \in J_l$}. \]}}

\vspace{0.5em}
By the family $\mathcal{I}$ being $C/R$ separated and having diameter at most $\delta$ we mean that for any distinct $I,J \in \mathcal{I}$, $C R^{-1} \leq d(I,J) \leq \delta$.

In order to state the result, we fix $E > n$. For a function $f: \mathbb{R} \to \mathbb{C}$ and an interval $I$ we let $f_I = \chi_I f$, where  $\chi_I(t) = \mathbb{I}(t \in I)$ is a cutoff function, and for a ball $B$, define the weight function $w_B(x) = (1 + d(x,B) / R)^{-E}$, for any $E > n$ fixed throughout the argument.

\begin{theorem} \label{thm:2}
    Suppose {\normalfont \textbf{Assumption A}} holds for a function $\phi: [0,1] \to \mathbf{R}^n$. Then for any integer $1 \leq s \leq n$, and any ball $B$ of radius at least $R^n$,
    %
    \[ \| E_\phi f \|_{L^{2s}(w_B)} \lesssim \left\| \left( \sum\nolimits_I | E_\phi f_I |^2 \right)^{1/2} \right\|_{L^{2s}(w_B)}, \]
    %
    where $I$ ranges over a family of almost-disjoint intervals of length $1/R$.
\end{theorem}

Square function estimates are stronger than decoupling estimates (the $L^p l^2$ norm of a function is in general smaller than the $l^2 L^p$ norm for $p \geq 2$), so this bound is stronger than a decoupling inequality. However, the result obtained holds for a much more limited range of $L^p$ than the decoupling range $2 \leq p \leq n(n+1)$ obtained for the moment curve in \cite{uiwadawoidjwaoi}.

The proof of Theorem \ref{thm:2} is remarkably simple. Let $\mathcal{I}$ be a family of $C/R$ separated intervals with diameter at most $\delta$. Choose a non-negative function $\varphi$ with $\varphi(x) \geq 1$ for $|x| \leq 1$, and with $\widehat{\varphi}(\xi) = 0$ for $|\xi| \leq 1$. Define $\varphi_R(x) = \varphi(x/R^n)$. We expand
%
\begin{equation}
\begin{split}
    &\int \varphi_R(x) \left|\sum\nolimits_{I \in \mathcal{I}} E_\phi f_I(x) \right|^{2s}\\
    &\quad\quad = \sum_{I,J \in \mathcal{I}^s} \int \varphi_R(x) E_\phi f_{I_1}(x) \cdots E_\phi f_{I_s}(x) \overline{E_\phi f_{J_1}(x) \cdots E_\phi f_{J_s}(x)}\; dx.
\end{split}
\end{equation}
%
For each $I,J \in \mathcal{S}$, we can interchange integrals to write
%
\begin{equation}
\begin{split}
    &\int \varphi_R(x) E_\phi f_{I_1}(x) \cdots E_\phi f_{I_s}(x) \overline{E_\phi f_{J_1}(x) \cdots E_\phi f_{J_s}(x)}\; dx\\
    &\quad\quad = \int_{I \times J} \widehat{\varphi}_R \left( \sum \phi(a_j) - \phi(b_j) \right) f(a_1) \cdots f(a_s) \overline{f(b_1) \cdots f(b_s)}\; da\; db.
\end{split}
\end{equation}
%
Because of \textbf{Assumption A}, the integrand that occurs here is uniformly zero unless $I$ and $J$ are permutations of one another. And if $I$ and $J$ are permutations of one another, then
%
\begin{equation}
\begin{split}
    &\int \varphi_R(x) E_\phi f_{I_1}(x) \cdots E_\phi f_{I_s}(x) \overline{E_\phi f_{J_1}(x) \cdots E_\phi f_{J_s}(x)}\; dx\\
    &\quad\quad = \int \varphi_R(x) |E_\phi f_{I_1}(x)|^2 \cdots |E_\phi f_{I_s}(x)|^2\; dx.
\end{split}
\end{equation}
%
For each $I \in \mathcal{I}^s$, there are $s!$ such $J$ obtained by a permutation of $I$, and so summing over $J$, and then over $I$ gives that
%
\begin{equation}
    \left\| \sum\nolimits_{I \in \mathcal{I}} E_\phi f_I \right\|_{L^{2s}(\varphi_R)}^{2s} = s! \int \varphi_R(x) \left( \sum\nolimits_I |E_\phi f_I(x)|^2 \right)^s\; dx.
\end{equation}
%
Taking both sides to a power of $1/2s$ gives that if $B$ is the ball of radius $R$ centered at the origin,
%
\begin{equation}
    \left\| \sum\nolimits_{I \in \mathcal{I}} E_\phi f_I \right\|_{L^{2s}(B)} \lesssim \| E_\phi f \|_{L^{2s}(\varphi_R)} = s! \left\| \left( \sum\nolimits_I |E_\phi f_I|^2 \right)^{1/2} \right\|_{L^{2s}(\varphi_R)}.
\end{equation}
%
We can cover $[0,1]$ by the union of $O(1)$ families $\mathcal{I}$ which are $C/R$ separated and with diameter at most $\delta$, and the triangle inequality then implies
%
\begin{equation} \label{d3eu1293dj2iucnewiuov}
    \| E_\phi f \|_{L^{2s}(B)} \lesssim \left\| \left( \sum\nolimits_I |E_\phi f_I|^2 \right)^{1/2} \right\|_{L^{2s}(\varphi_R)}.
\end{equation}
%
By translation invariance, an analogue of \eqref{d3eu1293dj2iucnewiuov} holds for any ball, i.e. if $B$ is a ball with center $c(B)$, and we define $\varphi_{R,c(B)}(x) = \varphi(x - c(B))$, then
%
\begin{equation}
    \| E_\phi f \|_{L^{2s}(B)} \lesssim \left\| \left( \sum\nolimits_I |E_\phi f_I|^2 \right)^{1/2} \right\|_{L^{2s}(\varphi_{R,c(B)})}.
\end{equation}
%
Covering $\mathbb{R}^d$ by a family of radius $R$ balls $\{ B' \}$ with the finite overlap property, the two pointwise bounds $w_B \lesssim \sum\nolimits_{B'} (1 + d(B,B'))^{-E} \chi_{B'}$ and $\sum\nolimits_{B'} (1 + d(B,B'))^{-E} \varphi_{R,c(B')} \lesssim w_{B}$ imply that
%
\begin{equation}
\begin{split}
    \| E_\phi f \|_{L^{2s}(w_B)} &= \sum (1 + d(B,B'))^{-E} \| E_\phi f \|_{L^{2s}(B')}\\
    &\lesssim \sum (1 + d(B,B'))^{-E} \left\| \left( \sum\nolimits_I |E_\phi f_I|^2 \right)^{1/2} \right\|_{L^{2s}(\varphi_{R,c(B')})}\\
    &\lesssim \left\| \left( \sum\nolimits_I |E_\phi f_I|^2 \right)^{1/2} \right\|_{L^{2s}(w_{B'})},
\end{split}
\end{equation}
which completes the proof.

In the talk associated with this summary, we will also discuss how one might prove \textbf{Assumption A} when $\phi$ is a \emph{non-degenerate} curve in $\mathbb{R}^n$, i.e. such that $\phi', \phi'', \dots, \phi^{n}$ is linearly independent in $\mathbb{R}^n$. The method of proof involves a more robust generalization of the cross-product identity
%
\begin{equation}
    \phi'(t_1) \times \phi'(t_2) \times \cdots \times \phi'(t_n) = \prod\nolimits_{i < j} (t_j - t_i),
\end{equation}
%
which holds when $\phi(t) = (t,t^2,\cdots,t^n)$ is the moment curve.

\begin{thebibliography}{03}

\bibitem[GGPRY]{dujdjf} Philip T. Gressman, Shaoming Guo, Lillian B. Pierce, Joris Roos, Po-Lam Yung,
\emph{ Reversing a Philosophy: From Counting to Square Functions and Decoupling} 
J. Geom. Anal., 31, 7075-7095 (2021).

\bibitem[BDG]{uiwadawoidjwaoi} Jean Bourgain, Ciprian Demeter, Larry Guth,
\emph{Proof of the main conjecture in Vinogradov’s Mean Value Theorem for degrees higher than three}
Ann. Math. (2) 184(2), 633–682 (2016).




\end{thebibliography}

\noindent \textsc{Jacob Denson, University of Edinburgh}\\
\textit{email:} \texttt{denson@ualberta.ca}.

%\newpage

\end{document}