\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1.0in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

\usepackage{tikz}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

%\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{hyperref}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbb{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbb{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbb{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbb{MB}}}

\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\QQ}{\mathbb{Q}}
\DeclareMathOperator{\TT}{\mathbb{T}}
\DeclareMathOperator{\CC}{\mathbb{C}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}[theorem]{Remarks}
\newtheorem*{remarksaboutresults}{Remarks About The Results Stated}
%\newtheorem*{concludingremarks}{Concluding Remarks}

\DeclareMathOperator{\EE}{\mathbb{E}}
\DeclareMathOperator{\PP}{\mathbb{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{High Codimension Curves Can't Be Salem}
% \author{Jacob Denson\footnote{University of Madison Wisconsin, Madison, WI, jcdenson@wisc.edu}}

\begin{document}

\maketitle

\section{New Strategies}

Let $U \subset \RR^k$ be an open set, and consider a smooth immersion $\gamma: U \to \RR^d$. For a Borel probability measure $\mu$ supported on $U$, and $\xi \in \RR^d$, we let
%
\[ I(\mu,\xi) = \int_U e^{2 \pi i \xi \cdot \gamma(x)}\; d\mu(x) = \widehat{\gamma_* \mu}(\xi). \]
%
Our goal is to prove the following Lemma.

TODO: By a translation argument, we may assume that $\gamma: 2Q \to \RR^d$

\begin{lemma}
    Let $Q$ be a closed, axis-oriented cube, such that $2Q \subset U$. Suppose that there exists a Borel probability measure $\mu$ supported on $Q$ such that
    %
    \[ \sup_{\xi \in \RR^d} |\xi|^{s/2} |\widehat{\gamma_* \mu}(\xi)| < \infty. \]
    %
    Then there exists a non-negative smooth function $\phi$, supported in $2Q$, such that
    %
    \[ \int_U \phi(x)\; dx = 1, \]
    %
    i.e. such that the measure $\mu_\phi = \phi\; dx$ is a probability measure, and such that
    %
    \[ \sup_{\xi \in \RR^d} |\xi|^{s/2} |\widehat{\gamma_* \mu_\phi}(\xi)| < \infty. \]
\end{lemma}
\begin{proof}
    % A compactness argument shows that there exists $\delta > 0$ such that $\gamma(2Q) + t \xi_0$ is disjoint from $\gamma(2Q)$ for $|t| < \delta$. 

    Since $x \mapsto \gamma(x)$ is an immersion, for any fixed $x_0$, there exists a coordinate system $z$, defined in a neighborhood of $\gamma(x)$, such that
    %
    \[ z(\gamma(x)) = (x,0). \]
    %
    Then $\{ dz^1, \dots, dz^k, \xi_0 dx \}$ are linearly independent covector fields in a neighborhood of $\gamma(x_0)$, and thus there exists a coordinate system $w$, defined in a neighborhood of $\gamma(x_0)$, such that $(w^1,\dots,w^k) = (z^1,\dots,z^k)$, and $dw^{k+1} = \xi_0 \cdot dx$. Now, for each $v \in \RR^k$ with $|v| < \delta$, we define a diffeomorphism $A_v$ in a neighborhood of $\gamma(x_0)$ by setting
    %
    \[ (w \circ A_v \circ w^{-1})(w^1,\dots,w^k) = (w^1,\dots,w^k) + (v,0). \]
    %
    These diffeomorphisms are chosen precisely so that, for each $x$ in a neighborhood of $\gamma(x_0)$,
    %
    \[ A_v( \gamma(x) ) = \gamma(x + v), \]
    %
    because $w(\gamma(x)) = (x,0)$ and $w(\gamma(x + v)) = (x+v,0)$, and so
    %
    \[ w(A_v(\gamma(x))) = (x+v,0) = w(A_v(\gamma(x+v))). \]
    %
    and also, for $|v| < \delta$,
    %
    \[ DA_v(y)^T(\xi_0) = \xi_0, \]

    % nabla_y [ xi_0 * A_v(y) - eta * y ]
    %  = A_v(y)^T xi_0 - eta

    % nabla_y [ xi_0 * A_v(y) ] = xi_0
    % But this would imply that
    % xi_0 * A_v(gamma(x0 + tx))
    %       = xi_0 * A_v(gamma(x_0) + t Dgamma(x_0) x)
    %       = xi_0 * A_v(gamma(x_0)) + t[ xi_0 * Dgamma(x_0) x ]
    % But also
    % xi_0 * A_v(gamma(x0 + tx))
    %       = xi_0 * gamma(x0 + v + tx)
    %       = xi_0 * A_v(gamma(x_0 + t)) + t [ xi_0 * Dgamma(x0 + v) x ]
    % Whatever DA_v(x)^T xi_0 is,
    % it must relate to Dgamma(x + v)^T xi_0
    % xi_0 * A_v(x0 + t dw^{k+1}) = xi_0 * gamma(x0 + v) + t 
    %   DA_v(gamma(x0))^T

    % Ignoring the zeroeth order terms, if first order terms are equal then
    % we must have Dgamma(x0 + v)^T xi_0 = Dgamma(x0)^T xi_0
    % for all v, which is simply impossible given that Dgamma(0)^T xi_0 = 0.
    % But we *can* make all but n-k-1 of the other coordinates orthogonal to xi_0,
    % so that the stationary points in the integral below do form a k dimensional set.



    % If the stationary set is k dimensional set S, then the integral should decay
    % using integration by parts by O_N( R^{-N} d(eta, S)^{-N} )
    % So for the integral over d(eta,S) ~ 2^{-j} is
    
    % O_N( R^{d-N} 2^{j(N+k-d)}  )
    % We want to make this O( R^{-s/2} )
    % so we can sum up to j = (-s/2 + N - d) / (N+k-d) = 1 - o(1)
    % so we can sum up to 1/R^{1 + e} for any e.

    % But then the integral over d(eta,S) ~ 1/R^{1 + e}
    % is R^d (1/R)^{(d-k)(1 + e)} * R^{-s/2}
    %       = R^{-s/2 + k(1 + e)}
    % If we had some guarantee of nonstationarity,
    % we can add at O(R^{-k/2}) to the integral above,
    % but that would be enough to cancel out the required values.

    which can be verified in the language of differential forms by noting that
    %
    \[ A_v^*( \xi_0 dx ) = A_v^*(dw^{k+1}) = d( w^{k+1} \circ A_v ) = d w^{k+1} = \xi_0 dx, \]
    %
    i.e. so that the covector field $\xi_0 dx$ is preserved by the diffeomorphisms $\{ A_v \}$.

    Consider a smooth, non-negative bump function $\psi$ on $\RR^d$, which is equal to one on a neighborhood of $\gamma(x_0)$. For small $v$, consider the measure $\mu_v = \text{Trans}_v \mu$. We calculate using the multiplication formula that
    %
    \begin{align*}
        \widehat{\gamma_* \mu_v}(\lambda \xi_0) &= \int_U e^{2 \pi i \lambda \xi_0 \cdot \gamma(x + v)}\; d \mu(x)\\
        &= \int_U e^{2 \pi i \lambda \xi_0 \cdot A_v(\gamma(x))}\; d\mu(x)\\
        &= \int_{\RR^d_y} e^{2 \pi i \lambda \xi_0 \cdot A_v(y)}\; d(\gamma_* \mu)(y).
    \end{align*}
    %
    Note that $\nabla_y \{ \xi_0 \cdot A_v(y) \} = A_v(y)^T \xi_0 = \xi_0$, so that
    %
    \begin{align*}
        \xi_0 \cdot A_v(y) &= \xi_0 \cdot A_v(\gamma(x_0)) + \xi_0 \cdot (y - \gamma(x_0))\\
        &= \xi_0 \cdot [\gamma(x_0 + v) - \gamma(x_0)] + \xi_0 \cdot y.
    \end{align*}
    %
    Thus
    %
    \[ \widehat{\gamma_* \mu_v}(\lambda \xi_0) = e^{2 \pi i \lambda \xi_0 \cdot [\gamma(x_0 + v) - \gamma(x_0)]} \widehat{\gamma_* \mu}(\lambda \xi_0). \]



%  &= \int_{\RR^d_y} \psi(y) e^{2 \pi i \lambda \xi_0 \cdot A_v(y)}\; d(\gamma_* \mu)(y).
%        &= \lambda^d \int_{\RR^d} \left( \int_{\RR^d_y} \psi(y) e^{2 \pi i \lambda [\xi_0 \cdot A_v(y) - \eta \cdot y]}\; dy \right) \widehat{\gamma_* \mu}(\lambda \eta)\; d\eta\\
%        &= \lambda^d \int_{\RR^d} I(y,\lambda,\nu) \widehat{\gamma_* \mu}(\lambda \eta)\; d\eta.
%    \end{align*}
    %
    Write $\phi = \xi_0 \cdot A_v(y) - \eta \cdot y$. Then
    %
    \[ \nabla_y \phi = DA_v(y)^T \xi_0 - \eta = \xi_0 - \eta \]
    %
    is independent of $y$. Thus we can write
    %
    \[ \phi = c(\xi_0,v,\eta) + (\xi_0 - \eta) \cdot y. \]
    %
    Then
    % xi_0 * A_v(y) - xi_0 * y
    \[ |I(y,\lambda,\nu)| |\widehat{\psi}(\eta - \xi_0)| \]

    We can upper bound the magnitude of $I$ using nonstationary phase, i.e. because we can write
    %
    \[ I(\eta,v,\lambda) = \int_{\RR^d_y} \psi(y) e^{2 \pi i \lambda \phi(y,\eta,v)}\; dy, \]
    %
    where
    %
    \[ \phi(y,\eta,v) = [\xi_0 \cdot A_v(y) - \eta \cdot y]. \]
    %
    Then $\nabla_y \phi(y,\eta,v) = DA_v(y)^T \xi_0 - \eta = \xi_0 - \eta$, i.e. so that we actually have
    %
    \[ \phi(y,\eta,v) = c(\xi_0,v) + (\xi_0 - \eta) \cdot y. \]
    %
    But this means that
    %
    \[ I(\eta,v,\lambda) = c(\xi_0,v) \widehat{\psi} \]

    where
    %
    \[ I(\eta,v,\lambda) = \int_{\RR^d_y} \psi(y) e^{2 \pi i \lambda [\xi_0 \cdot A_v(y) - \eta \cdot y]}\; dy = \int_{\RR^d_y} \psi(y) e^{2 \pi i \lambda \phi(y; \eta, v)}\; dy. \]
    %
    We calculate that
    %
    \[ \nabla_y \phi(y; \eta, \lambda, v) = DA_v(y)^T \xi_0 - \eta. \]
    %
    Our choice of diffeomorphisms $\{ A_v \}$ implies that $DA_v(y)^T \xi_0 = \xi_0$ for all $y$. Thus
    %
    \[ \nabla_y \phi(y; \eta, \lambda, v) = \xi_0 - \eta. \]
    %
    Thus we can apply integration by parts to conclude that
    %
    \[ |I(\eta,v,\lambda)| \lesssim_N \lambda^{-N} |\xi_0 - \eta|^{-N}. \]
    %
    Thus we conclude that
    %
    \begin{align*}
        \lambda^d \int_{|\eta - \xi_0| \geq \lambda^{-\alpha}} I(\eta, v,\lambda) & \widehat{\gamma_* \mu}(\lambda \eta)\; d\eta\\
        &\lesssim_N \lambda^{d - N} \int_{|\eta - \xi_0| \geq \lambda^{-\alpha}} |\xi_0 - \eta|^{-N} \lesssim 1\\
        &= \lambda^{d-N} \int_{\lambda^{-\alpha}}^\infty t^{d-1-N}\; dt\\
        &\lesssim \lambda^{(1 - \alpha)(d-N)}.
    \end{align*}
    %
    If $\alpha = 1 - [ s / 2(N-d) ]$, we obtain that this integral is $O(\lambda^{-s/2})$. Taking $N$ arbitrarily large allows us to pick $\alpha$ arbitrarily close to one. Then
    %
    \begin{align*}
        \lambda^d \int_{|\eta - \xi_0| \leq \lambda^{1-\varepsilon / d}} I(\eta,v,\lambda) & \widehat{\gamma_* \mu}(\lambda \eta)\; d\eta\\
        &\leq \lambda^d \int_{|\eta - \xi_0| \leq \lambda^{1-\varepsilon / d}} \lambda^{-s/2}\\
        &= \lambda^{d - (1 - \varepsilon / d) d - s/2} = \lambda^{\varepsilon - s/2}.
    \end{align*}
    %
    Combining these calculations allows us to conclude that
    %
    \[ |\widehat{\gamma_* \mu_v}(\lambda \xi_0)| \lesssim_\varepsilon \lambda^{\varepsilon - s/2}. \]
    %    



    We start with some basic techniques from the study of differential manifolds. Write the standard coordinates of $\RR^k$ by $(x^1,\dots,x^k)$, and the standard coordinates of $\RR^d$ by $(y^1,\dots,y^d)$. Applying implicit function theorem type techniques (see Theorem 10 of Spivak, Vol 1, Chapter 2), for any $x_0 \in \RR^k$, we can find a coordinate system $z$ defined in a neighborhood of $\gamma(x_0)$ such that
    %
    \[ z(\gamma(x)) = (x,0). \]
    %
    Set $w^j(x) = z^j(x)$ for $1 \leq j \leq k$, and let $w^{k+1}(x) = x \cdot \xi_0$. Then $dw^{k+1} = \xi_0 dx$, and $\{ dw^1,\dots, dw^{k+1} \}$ are linearly independent at $\gamma(x_0)$, so we can extend these functions to a coordinate system $w$ defined in a neighborhood of $\gamma(x_0)$. Now we consider a family of diffeomorphisms $\{ A_v \}$ defined in a neighborhood of $\gamma(x_0)$, and for small $v \in \RR^k$, such that
    %
    \[ (w \circ A_v \circ w^{-1})(w^1,\dots,w^d) = (w^1,\dots,w^d) + (v, 0). \]
    %
    Then $\{ A_v \}$ is chosen precisely so that for $x$ in a neighborhood of $x_0$,
    %
    \[ A_v(\gamma(x)) = \gamma(x + v), \]
    %
    and also,
    %
    \[ A_v^*( \xi_0 dx ) = A_v^*( dw^{k+1} ) = d( w^{k+1} \circ A_v ) = d w^{k+1} = \xi_0 dx. \]
    %
    Thus the covector field $\xi_0 dx$ is preserved by the family of diffeomorphisms $\{ A_v \}$.

    


    \begin{comment}


    Fix $\delta > 0$ such that for $v \in \RR^k$ with $|v| \leq \delta$,
    %
    \[ v + Q \subset 1.5\; Q. \]
    %
    We can then find an open set $W$, compactly contained in $V$, such that $F(W) + (v,0) \subset V$ for all $v \in \RR^k$ with $|v| \leq \delta$. We can now consider the smooth family of diffeomorphisms $A_v: W \to \RR^d$ for each $v \in \RR^k$ with $|v| \leq \delta$ given by
    %
    \[ A_v(x) = F^{-1} \Big( F(y) + (v, 0) \Big). \]
    %
    These diffeomorphisms are constructed precisely so that they have the property that for $x \in Q$,
    %
    \[ \gamma(x + v) = A_v(\gamma(x)). \]
    %
    Consider a smooth, non-negative bump function $\psi$ on $\RR^d$, which is equal to one on a neighborhood of $\gamma(Q)$. For $|v| \leq \delta$, consider the measure $\mu_v = \text{Trans}_v \mu$. We calculate using the multiplication formula for the Fourier transform that
    %
    \begin{align*}
        \widehat{\gamma_* \mu_v}(\xi) &= \int_U e^{2 \pi i \xi \cdot \gamma(x + v)}\; d \mu(x)\\
        &= \int_U e^{2 \pi i \xi \cdot A_v(\gamma(x))}\; d\mu(x)\\
        &= \int_{\RR^d_y} e^{2 \pi i \xi \cdot A_v(y)}\; d(\gamma_* \mu)(y)\\
        &= \int_{\RR^d_y} \psi(y) e^{2 \pi i \xi \cdot A_v(y)}\; d(\gamma_* \mu)(y)\\
        &= \int_{\RR^d_\xi} I_{v,\xi}(\eta) \widehat{\gamma_* \mu}(\eta)\; d\eta,
    \end{align*}
    %

    where
    %
    \[ I_{v,\xi}(\eta) = \int_{\RR^d_y} \psi(y) e^{2 \pi i \xi \cdot A_v(y) - \eta \cdot y}\; dy = \int_{\RR^d_y} \psi(y) e^{2 \pi i \phi_{v,\xi,\eta}(y)}\; dy. \]
    %
    We can now apply the theory of stationary phase. The phase here satisfies
    %
    \[ \nabla_y \phi_{v,\xi,\eta}(y) = DA_v(y)^T \xi - \eta. \]
    %
    Since the family of functions $\{ A_v \}$ are uniformly diffeomorphisms, we can find a constant $C > 0$ such that
    %
    \[ (1/C) |\xi| \leq |DA_v(y)^T \xi| \leq C |\xi|, \]
    %
    uniformly in $v$. Thus for $|\eta| \leq (1/2C) |\xi|$, we get that
    %
    \[ |DA_v(y)^T \xi - \eta| \geq (1/C) |\xi| - |\eta| \geq (1/2C) |\xi| \]
    %
    and for $|\eta| \geq 2 C |\xi|$, we get that
    %
    \[ |DA_v(y)^T \xi - \eta| \geq |\eta| - C |\xi| \geq |\eta| / 2. \]
    %
    Thus we conclude that for $|\eta| \leq (1/2C) |\xi|$,
    %
    \[ |I_{v,\xi}(\eta)| \lesssim_N |\xi|^{-N} \]
    %
    and for $|\eta| \geq 2 C |\xi|$,
    %
    \[ |I_{v,\xi}(\eta)| \lesssim_N |\eta|^{-N}. \]
    %
    Together with our bound for the Fourier transform of $\gamma_* \mu$, we conclude that
    %
    \[ \left| \int_{|\eta| \leq (1/2C) |\xi|} I_{v,\xi}(\eta) \widehat{\gamma_* \mu}(\eta)\; d\eta \right| \lesssim_N |\xi|^{-N} \int_{|\eta| \leq (1/2C) |\xi|} \langle \eta \rangle^{-s/2}\; d\eta \lesssim |\xi|^{1-s/2-N} \]
    %
    and
    %
    \[ \left| \int_{|\eta| \geq 2 C |\xi|} I_{v,\xi}(\eta) \widehat{\gamma_* \mu}(\eta)\; d\eta \right| \lesssim_N \int_{|\eta| \geq 2 C |\xi|} \langle \eta \rangle^{-N-s/2} \lesssim |\xi|^{1-s/2-N}. \]
    %
    Let $|\xi| = R$. Our goal is to analyze $I_{v,\xi}(\eta)$, where $|\eta| \sim R$. If we write $\xi_0 = \xi / R$ and $\eta_0 = \eta / R$, then we can write
    %
    \[ I_{v,\xi}(\eta) = \int \psi(y) e^{2 \pi i R \phi_{v,\xi_0,\eta_0}(y)}\; dy. \]
    %
    The stationary points for this integral occur when $\eta_0 = DA_v(y)^T \xi_0$ for some $y$ on the support of $\phi$, i.e. when $\eta_0 = A_v^*((y,\xi_0))$. Let us suppose that we can perturb $A_v$ such that $DA_v(y)^T \xi_0 = \xi_0$ for all $y$. Then $I_{v,\xi}$ will have magnitude $O(1)$
    % xi - eta
    % O_N( |xi - eta|^{-N} )
    % So integral should be trivial outside of a O(1) neighborhood of xi, where mu^ has magnitude |xi|^{-s/2}. Provided that xi_0 never lies in the direction of


    %



    Then we conclude that $I_{v,\xi}(\eta)$ has magnitude $O(R^{-d/2})$ in a radius $O(R^{1/2})$ neighborhood of $DA_v(y)^T \xi$, and so the integral over this neighborhood is
    %
    \[ O(R^{d/2}) O(R^{-d/2}) R^{-s/2} = R^{- s/2}. \]
    %
    Outside of this radius $O(R^{1/2})$ neighborhood, we have that
    %
    \[ | \eta - DA_v(y)^T \xi | \geq R^{-1/2} \]


    % | eta_0 - DA_v(y)^T xi_0 | >= 1
    %
    \[ |I_{v,\xi}(\eta)| \lesssim R^{-d/2}. \]



    Let
    %
    \[ I_{v,\xi}(\eta) = \int_U \psi(x) e^{2 \pi i \xi \cdot A_v(\gamma(x)) - \eta \cdot \gamma(x)}\; dx. \]
    %
    The stationary points occur when there exists a point $x \in Q$ such that
    %
    \[ D\gamma(x)^T \left[ DA_v(\gamma(x))^T \xi - D\gamma(x)^T \eta \right] = 0. \]

    % We can assume that xi points in the direction perfectly normal to 

    % NOTE: CAN WE CHOOSE A_v in a smarter way such that
    %       A_v^*((y,xi_0))
    % is of finite type?

    % As y varies, the stationary points either concentrate in a small region because the function y -> DA_v(y)^T xi_0 vanishes to high order in many directions, or they are dispersed because the function y -> DA_v(y)^T xi_0 does not vanish in many directions.

    % I_v(xi,eta) = int psi(y) e^{2 pi i xi * A_v(y) - eta * y} dy
    % Oscillatory Integral Distribution,
    % of order -infty, associated with the canonical relation
    % { (xi, eta, y): DA_v(y)^T xi = eta }
    % If DA_v(y0)^T xi = eta
    % Then xi * A_v(y0 + dy) - eta * (y0 + dy)
    %           = xi * [ A_v(y0) + DA_v(y0) dy + < dy, HA_v(y0) dy > + O(dy^3) ] - eta * y0 - eta * dy
    %           = [xi * A_v(y0) - eta * y0] + < dy, HA_v(y0) dy > + O(dy^3)
    % sum partial_{i,j}

    \[ I_{v,\xi}(\eta) = \int_U \psi(y) e^{2 \pi i \xi \cdot A_v(\gamma(x)) - \eta \cdot \gamma(x)}\; dx \]
    % If G(x) = Dgamma(x), and A(x) = DA_v(gamma(x))
    % then the x derivative of the phase is
    %       G(x)^T A(x)^T xi - G(x)^T eta 
    % This is equal to zero when A(x)^T xi - eta lies on the
    % conormal bundle associated with the image of gamma at gamma(x).



    Finally, we conclude that
    %
    \[ \left| \int_{(1/2C) |\xi| \leq |\eta| \leq 2C |\xi|} I_{v,\xi}(\eta) \widehat{\gamma_* \mu}(\eta)\; d\eta \right| \lesssim |\xi|^{d-1-s/2} \]

    Thus unless $|\xi| \sim |\eta|$, we obtain that
    %
    \[ |I_v(\eta)| \lesssim_N ||\xi| - |\eta||^{-N} \]
    %
    for all $N > 0$. When $|\xi| \sim |\eta|$, we just use the bound
    %
    \[ |I_v(\eta)| \lesssim 1. \]
    %
    s

    \end{comment}
\end{proof}



if and only if there exists a smooth function $\phi:U \to \RR$, supported on a compact subset of $U$, such that if $\nu = \gamma_*( \phi\; dx)$, then
%
\[ |\widehat{\nu}(\xi)| \lesssim |\xi|^{-s/2}. \]
%
We do this by using stationary phase to show that `translates' of $\mu$ continue to have good FOurier decay estimates, which allows us to show that a convolution of $\mu$ with a smooth, compactly supported

\section{Old Strategy}

Let $\gamma: I \to \RR^3$ be a smooth, parametric curve defined on an interval $I \subset \RR$, and let $\Gamma = \gamma(I)$ denote the parametric curve's trace. The Hausdorff dimension of $\Gamma$ is equal to one, being the image of an interval under a diffeomorphism. We claim that the Fourier dimension of $\Gamma$ is $2/3$, so that $\Gamma$ is never a Salem set. Marstrand projection theorem variants for Fourier dimension imply that the Fourier dimension of any curve in $\RR^d$ for $d \geq 3$ has Fourier dimension at most $2/3$, though I imagine similar techniques to those described here can prove the Fourier dimension of such a curve is equal to $2/d$.

Let us make the simplifying assumption that $\gamma'$, $\gamma''$, and $\gamma'''$ are all nonvanishing on $I$, and moreover, are linearly independent\footnote{We can probably use Sard's Theorem, or something similar, to reduce the study of any curve to one satisfying this assumption, but let's not get ahead of ourselves.}. There exists a unique, smooth family of unit vectors $\{ \xi_0(t) : t \in I \}$ in $\RR^d$ such that
%
\[ \xi_0(t) \cdot \gamma'(t) = \xi_0(t) \cdot \gamma''(t) = 0 \quad\text{for all $t \in I$}, \]
%
and with
%
\[ \xi_0(t) \cdot \gamma'''(t) > 0 \quad \text{for all $t \in I$}. \]
%
It follows by taking a Taylor series in the $t$ variable that we can guarantee that there exists $\varepsilon > 0$ such that for $0 < |t - s| < \varepsilon$, we have
%
\[ \frac{\xi_0(t) \cdot \gamma'(s)}{(s - t)^{d-1}} > 0. \]
%
If we break up $I$ into a finite union of almost disjoint union of intervals $\{ I_j \}$, each with length less than $\varepsilon / 3$, and set $\Gamma_j = \gamma(I_j)$, then it follows from (Ekstr\"{o}m, Persson, Schmeling, 2015) that
%
\[ \fordim(\Gamma) = \max_j \fordim(\Gamma_j). \]
%
We can therefore choose some $j$ such that $\fordim(\Gamma_j) = 1$. Swapping out $I$ for $I_j$, and $\Gamma$ for $\Gamma_j$, we will assume in what follows that for all distinct $t,s \in I$, the smooth function $\nu$ agreeing with
%
\[ \frac{\xi_0(t) \cdot \gamma'(s)}{(s - t)^{d-1}} \]
%
for distinct $t,s \in I$ is positive. Taking a Taylor series in the $s$ variable, and then letting $s \to 0$ allows us to conclude that $\nu(t,t) = \xi_0(t) \cdot \gamma'''(t)$. We also consider the smooth, positive function $a(t) = (\xi_0(t) \cdot \gamma'''(t))^{1/3}$.

For a measure $\mu$ on $I$, a function $\gamma: I \to \RR^3$, and $\xi \in \RR^3$, let
%
\[ I_\gamma(\mu,\xi) = \int e^{i \xi \cdot \gamma(t)} d\mu(t). \]
%
Our goal is to show that for any probability measure $\mu$ on $I$, and any $\varepsilon > 0$,
%
\[ \limsup_{\xi \to \infty} |\xi|^{1/3 + \varepsilon} I_\gamma(\mu,\xi) = \infty, \]
%
which is equivalent to proving that $\fordim(\Gamma) \leq 2/3$.

The following stationary phase result will be useful.

\begin{lemma}
    There exists a constant $\Gamma$ such that if $f$ is a $C^1$ function supported on $[-10,+10]$, then for $t \in I$, and $\lambda > 0$,
    %
    \[ I_\gamma(f, \lambda \xi_0(t)) = C\; a(t) f(t) e^{i \lambda \xi_0(t) \cdot \gamma(t)} \lambda^{-1/d} + O(\lambda^{-2/d}), \]
    % C_d in higher dimensions
    %
    where the implicit constant is upper bounded by a constant multiple of $\| f \|_{L^\infty} + \| f' \|_{L^\infty}$.
\end{lemma}
\begin{proof}
    This follows from one-dimensional stationary phase methods (see Erdelyi, in the discussion of Equation (4) of Section 2.9), because we have made the assumption that the function $\nu$ above is positive.
\end{proof}

Conversely, we can also apply the principle of nonstationary phase.

\begin{lemma}
    Suppose that if $f$ is a $C^1$ function supported on an interval of length $L$, $\xi$ is a unit vector in $\RR^d$, and and $|\xi \cdot \gamma'(t)| \geq \varepsilon$ for all $t \in I$. Then
    %
    \[ I_\gamma(f, \lambda \xi) \lesssim_\gamma \frac{L}{\lambda} \left( \frac{\| f' \|_{L^\infty}}{\varepsilon} + \frac{\| f \|_{L^\infty}}{\varepsilon^2} \right). \]
\end{lemma}
\begin{proof}
    We integrate by parts, calculating that
    %
    \begin{align*}
        \left| \int e^{i \lambda \xi \cdot \gamma(t)} f(t)\; dt \right| &= \frac{1}{\lambda} \left| \int \frac{d}{dt} \left\{ e^{i \lambda \xi \cdot \gamma(t)} \right\} \frac{f(t)}{\xi \cdot \gamma'(t)}\; dt \right|\\
        &= \frac{1}{\lambda} \left| \int e^{i \lambda \xi \cdot \gamma(t)} \left( \frac{f'(t)}{\xi \cdot \gamma'(t)} - \frac{f(t)}{(\xi \cdot \gamma'(t))^2} (\xi \cdot \gamma''(t)) \right)\; dt \right|\\
        &\lesssim_\gamma \frac{L}{\lambda} \left( \frac{\| f' \|_{L^\infty}}{\varepsilon} + \frac{\| f \|_{L^\infty}}{\varepsilon^2} \right). \qedhere
    \end{align*}
\end{proof}


\begin{lemma}
    Let $\gamma_M(t) = (t,t^2,t^3)$ be the parameterization of the moment curve $\Gamma_M = \gamma_M(\RR)$. For any $\varepsilon \in (0, 1/100)$, if $t_0$ is a fixed time, $\xi_0$ is one of the vectors orthogonal to both $\gamma_M'(t_0)$ and $\gamma_M''(t_0)$, $\lambda \gtrsim_\varepsilon 1$, then
    %
    \[ \sup_{|\xi - \lambda \xi_0| \leq \varepsilon \lambda} |\xi|^{1/3} |I_{\gamma_M}(\mu, \lambda \xi)| \lesssim_\varepsilon 1. \]
%    There exists constants $C_0,C_1 > 0$ such that if $\varepsilon \in (0, 1/100)$, and $\mu$ is any probability measure on $\RR$, such that $\mu$ satisfies a Frostman condition of the form $\mu(I) \leq B l(I)^s$. If $\xi_0$ is one of the two unit vectors orthogonal to both $\gamma_M'(t_0)$ and $\gamma_M''(t_0)$, then for any $\lambda \geq 1$, and any $\xi$ with $|\xi - \lambda \xi_0| \leq \varepsilon \lambda$,
    %
%    \[ |I_{\gamma_M}(\mu, \xi)| \geq \Big[ C_0 \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) - C_1 B \varepsilon^{s-2} \lambda^{-1/3} \Big] |\xi|^{-1/3}. \]
\end{lemma}
\begin{proof}
    Fix $\delta > 0$ and $\lambda \geq 1$, and suppose there was a probability measure $\mu$ compactly supported on some interval $I$ such that
    %
    \[ \sup_{|\xi - \lambda \xi_0| \leq \lambda \varepsilon} |\xi|^{1/3} |I_{\gamma_M}(\mu,\xi)| \leq \delta. \]
    %
    Define a linear transformation
    %
    \[ A_h = \begin{pmatrix} 1 & 0 & 0 \\ 2h & 1 & 0 \\ 3h^2 & 3h & 1 \end{pmatrix}. \]
    % gamma(t + h) = (t + h, (t + h)^2, (t + h)^3) = A_h gamma(t) + (h, h^2, h^3)
    Then $A_h \gamma_M(t) = \gamma_M(h) + \gamma_M(t + h)$ for all $t,h \in \RR$. If $\gamma_{M,h}(t) = \gamma_M(t + h)$, we thus have
    %
    \begin{align*}
        I_{\gamma_{M,h}}(\mu,\xi) &= \int e^{i \xi \cdot \gamma(t + h)} d\mu(t)\\
        &= e^{-i \xi \cdot \gamma(h)} \int e^{i \xi \cdot A_h \gamma(t)} d\mu(t)\; dt\\
        &= e^{-i \xi \cdot \gamma(h)} \int e^{i (A_h^T \xi) \cdot \gamma(t)} d\mu(t)\; dt\\
        &= e^{-i \xi \cdot \gamma(h)} I_{\gamma_M}(\mu,A_h^T \xi).
    \end{align*}
    %
    If we consider an $L^1$ normalized smooth bump function $\phi: \RR \to \RR$ adapted to $\{ |h| \leq \varepsilon/2 \}$, and define a smooth function $f = \phi * \mu$, then
    %
    \[ I_{\gamma_M}(f, \lambda \xi_0) = \int \phi(h) I_{\gamma_{M,h}}(\mu, \lambda \xi_0)\; dh = \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\mu, \lambda A_h^T \xi_0)\; dh. \]
    %
    Then the $L^\infty$ norm of $f$ and $f'$ is $O_\varepsilon(1)$, and $f(t_0) \gtrsim_\varepsilon 1$, so we conclude that
%
%    Then for any $t$,
    %
%    \[ \frac{\mu([t - \varepsilon / 4, t + \varepsilon / 4])}{\varepsilon} \lesssim f(t) \lesssim \frac{\mu([t - \varepsilon/2, t + \varepsilon/2])}{\varepsilon}. \]
    %
%    and
    %
%    \[ f'(t) \lesssim \frac{\mu([t - \varepsilon/2, t + \varepsilon/2])}{\varepsilon^2}. \]
%    %
%    Thus
    %
    \[ I_{\gamma_M}(f, \lambda \xi_0) = C\; a(t_0) f(t_0) e^{i \lambda \xi_0} \lambda^{-1/3} + O_\varepsilon( \lambda^{-2/3}). \]
    %
    In particular, we conclude that for $\lambda \gtrsim_\varepsilon 1$,
    %
    \[ |I_{\gamma_M}(f,\lambda \xi_0)| \gtrsim C_\varepsilon \lambda^{-1/3}. \]
    %
    Now $|A_h^T \xi_0 - \xi_0| \leq 4 h |\xi_0|$ for $|h| \leq 1 / 100$, we know by assumption that $|I(\mu, \lambda A_h^T \xi_0)| \leq \delta \lambda^{-1/3}$. But this means we conclude that
    %
    \[ \lambda^{-1/3} \lesssim_\varepsilon \delta \lambda^{-1/3}, \]
    %
    and thus that $\delta \gtrsim_\varepsilon 1$, completing the proof.
%
%    \[ \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) \cdot \lambda^{-1/3} - C \varepsilon^{s-2} \lambda^{-2/3} \lesssim \delta \lambda^{-1/3}, \]
    %
%    i.e.
    %
%    \[ \delta \gtrsim \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) - C \varepsilon^{s-2} \lambda^{-1/3}. \qedhere \]
    %
    %We therefore conclude that $\delta \gtrsim_{c,\varepsilon} 1$, which proves the existence of $C_0$.
    %Since $|A_h^T \xi - \xi| \leq 4h |\xi|$ for $|h| \leq 1 / 100$, we have that $|I(\mu,A_h^T \xi)| \lesssim |\xi|^{-1/3-\varepsilon}$ for all $|h| \leq 1 / 100$. But we have $|I_\gamma(f,\xi)| \gtrsim |\xi|^{-1/3}$, so we conclude that $|\xi|^{-1/3} \lesssim |\xi|^{-1/3-\varepsilon}$, which gives a contradiction if $\xi$ is made suitably large. Thus $\fordim(\gamma_M(\RR)) = 2/3$.
    %For the moment curve, we have
    %
    %\[ \xi_0 = \frac{1}{(36t^4 + 36t^2 + 4)^{1/2}} (6t^2, -6t, 2). \]
    %
    %Thus
    %
    %\[ \xi_0 \cdot \gamma'''(t) = \frac{12}{(36t^4 + 36t^2 + 4)^{1/2}}, \]
    %
    %and so
    %
    %\[ a(t) = \frac{(12)^{1/3}}{(36t^4 + 36t^2 + 4)^{1/6}}. \]
    %
    %
    %Thus, if we consider any smooth, compactly supported function $\phi: \RR_h \to \RR$, and define a smooth function $g = f * \phi$, then
    %
    %\[ I(g,\xi) = \int \phi(h) I(f,A_h^T \xi)\; dt. \]
    %
    %Thus if $|I(f,\eta)| \lesssim |\eta|^{-1/2}$, then we get that $|I(g,\xi)| \lesssim |\xi|^{-1/2}$, uniformly in $\xi$, which gives a contradiction by the method above.
\end{proof}

% Let mu be a measure,
% define mu_t(E) = mu(E / t).
% Then int f(x) d (Dil_t mu) = int f(t x) dmu.

For any measure $\mu$ on $I$, we fix $\delta > 0$, and consider a family of $O(\delta^{-1})$ points $\mathcal{T}$ such that the length $\delta$ intervals $\{ I_t : t \in \mathcal{X}_\delta \}$ with center $t$ cover $[0,1]$, and for each $t$, the middle third of the interval $I_t$ is disjoint from $I_{t'}$ for $t \neq t'$. Consider a smooth partition of unity $\{ \chi_t \}$ adapted to these intervals. For each $t \in \mathcal{T}$, define $\mu_t = \chi_t \mu$. For any $t \in \mathcal{T}$, consider the degree three polynomial curve $\gamma_t: \RR \to \RR^d$ given by
%
\[ \gamma_t(s) = \gamma(t) + \gamma'(t) (s - t) + \frac{\gamma''(t)}{2} (s - t)^2 + \frac{\gamma'''(t)}{6} (s - t)^3. \]
%
then for any $t' \in I_t$, $|\gamma(t') - \gamma_t(t')| \lesssim \delta^4$. This means that the deviations between $\gamma$ and $\gamma_t$, once localized to a $\delta$ neighborhood of $t$, should be undetectable for frequencies with magnitude $O(\delta^{-4})$, i.e. for $|\xi| \lesssim \delta^{-4}$, we should expect to have
%
\[ I_\gamma(\mu,\xi) \approx \sum_t I_{\gamma_t}(\mu_t, \xi). \]
%
If we let $B_t$ be the matrix with columns $\delta^{-1} \gamma'(t)$, $\delta^{-2} \gamma''(t) / 2$, and $\delta^{-3} \gamma'''(t) / 6$, then
%
\[ \gamma_t(s) - \gamma(t) = B_t \gamma_M(\delta (s - t)). \]
%
Thus if $\nu_t$ is the dilation of $\text{Trans}_{-t} \mu_t$ by a factor $1/\delta$, then
% nu_t(x) = mu_t(delta (x + t))
\begin{align*}
    I_{\gamma_t}(\mu_t,\xi) &= \int e^{i \xi \cdot \gamma_t(s)} d\mu_t(s)\\
    &= \int e^{i \xi \cdot [\gamma(t) + B_t \gamma_M((s - t) / \delta)]}\; d\mu_t(s)\\
    &= e^{i \xi \cdot \gamma(t)} \int e^{i (B_t^T \xi) \cdot \gamma_M((s - t) / \delta)} d\mu_t(s)\\
    &= e^{i \xi \cdot \gamma(t)} I_{\gamma_M}(\nu_t, B_t^T \xi ).
\end{align*}
% For each $t \in \mathcal{T}$, consider the matrix $B_t$ with columns $\gamma'(t)$, $\gamma''(t) / 2$, and $\gamma'''(t) / 6$. Then $\gamma(t) + B_t \gamma_M(t' - t) = \gamma_t(t')$. If $\nu_t = \text{Trans}_{-t} \mu_t$, then
Thus we get
%
\[ I_\gamma(\mu,\xi) \approx \sum_t e^{i \xi \cdot \gamma(t)} I_{\gamma_M}(\nu_t, B_t^T \xi). \]
%
for $|\xi| \ll \delta^{-4}$. We now consider an $L^1$ normalized, smooth bump function $\phi$ supported on a width $\delta$ interval about the origin, and define $f_t = \nu_t * \phi$. We have seen that
%
\[ I_{\gamma_M}(f_t, B_t^T \xi) = \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\nu_t,A_h^T B_t^T \xi)\; dh. \]
%
Suppose (THIS IS THE CHEAT) we can find a matrix $C_h$ such that $A_h^T B_t^T \xi = B_t^T C_h \xi$. Then
% B_t^{-T} A_h^T B_t^T xi depends only on h
%
\[ \sum_t I_{\gamma_M}(f_t, B_t^T \xi) = \sum_t \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\nu_t, B_t^T C_h \xi) \approx \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I_\gamma(\mu, C_h \xi)\; dh. \]
%
Then $C_0$ is the identity matrix, and so we can imagine that $|C_h \xi| \sim |\xi|$ for small $h$.

We can now argue that $\fordim(\Gamma) \leq 2/3$. Suppose that instead, we could choose $\mu$ such that
%
\[ \limsup_{\xi \to \infty} |\xi|^{2/3 + \varepsilon} |I_\gamma(\mu, \xi)| < \infty. \]
%
Then for any $\xi \in \RR^d$, the right hand side of the identity above satisfies estimates of the form
%
\[ \left| \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I_\gamma(\mu, C_h \xi)\; dh \right| \lesssim |\xi|^{-1/3 - \varepsilon}. \]
%
For $|\xi| \sim \delta^{-4}$, we get that this quantity is $\lesssim \delta^{4/3 + \varepsilon}$. On the other hand, the left hand side is a sum of quantities to which we can apply stationary and nonstationary phase. If we choose $c > 0$ small enough, depending on $\gamma$, then because of the linear independence of $\gamma'$, $\gamma''$, and $\gamma'''$, if, for $t_0 \in \mathcal{T}$, we set $\xi = \xi_0(t_0)$, then for any $t \neq t_0$, and any $t' \in I_t$, $|\xi \cdot \gamma'(t')| \geq c \delta$. This implies that the principle of nonstationary phase can be applied to the quantity $I_\gamma(\nu_t, B_t^T \xi)$. For each $t_0$, the function $f_{t_0}$ has $L^\infty$ norm at most $O(\delta^{-1} \nu_{t_0}(\RR))$, and $f_{t_0}'$ has $L^\infty$ norm bounded by $O(\delta^{-2} \nu_{t_0}(\RR))$. Applying the principle of nonstationary phase, for $t \neq t_0$ we conclude that
%
\[ |I_{\gamma_M}(f_t, B_t^T \xi)| \lesssim \delta^{-2} \nu_{t_0}(\RR) |\xi|^{-1}. \]
%
Summing over $t \neq t_0$ gives that
%
\[ \sum_{t \neq t_0} |I_{\gamma_M}(f_t, B_t^T \xi)| \lesssim \delta^{-2} |\xi|^{-1}. \]
%
If we take $|\xi| \sim \delta^{-4}$, this quantity is $O(\delta^2)$. On the other hand, we have $f_{t_0}(t_0) \gtrsim \delta^{-1} \nu_{t_0}(\RR)$, and so the principle of stationary phase we calculated at the beginning of our argument shows that
%
\[ |I_{\gamma_M}(f_{t_0}, B_{t_0}^T \xi)| \gtrsim \delta^{-1} \nu_{t_0}(\RR) |\xi|^{-1/3} \]
%
so for $|\xi| \sim \delta^{-4}$, we get that this quantity is $\gtrsim \delta^{1/3} \nu_{t_0}(\RR)$. Since $\sum_t \nu_t(\RR) = \mu(\RR) = 1$, the pigeonhole principle implies we can pick some $t_0$ such that $\nu_{t_0}(\RR) \gtrsim \delta$. But then the quantity above is $\gtrsim \delta^{4/3}$. But putting these bounds together gives that
%
\[ |\sum_t I_{\gamma_M}(f_t, B_t^T \xi)| \geq |I_{\gamma_M}(f_{t_0}, B_{t_0}^T \xi)| - \sum_{t \neq t_0} |I_{\gamma_M}(f_t, B_t^T \xi)| \gtrsim \delta^{4/3}. \]
%
But we therefore conclude that $\delta^{4/3} \lesssim \delta^{4/3 + \varepsilon}$, which gives a contradiction if $\delta$ is taken appropriately small.

%Recall that
%
%\[ \nu_{t_0}(\RR) = \mu_{t_0}(\RR) = \int \chi_t(t') d \mu(t'). \]
%
%Since
%
%\[ \limsup_{\xi \to \infty} |\xi|^{2/3 + \varepsilon} |I_\gamma(\mu, \xi)| < \infty, \]
%
%the measure $\mu$ satisfies a Frostman measure condition, i.e. for all $t$, $\int \chi_t(t') d\mu(t') \lesssim \delta^{1/3}$


%Let $S = \{ t \in I: \gamma'(t) = 0 \}$. Then $S$ is closed, and so it's complement can be broken up into a countable union of almost disjoint, closed intervals $\{ I_j \}$. If $C_j = \gamma(I_j)$, it follows from (Ekstr\"{o}m, Persson, Schmeling, 2015) that
%
%\[ \fordim(C) = \max \left( \fordim(\gamma(S)), \sup_j \fordim(C_j) \right). \]
%
%Sard's theorem tells us that $\gamma(S)$ has Hausdorff dimension zero. Thus if $\fordim(C) = 1$, we can select $j$ such that $\fordim(C_j)$ is arbitrarily close to one. Without loss of generality, in the following argument we will thus assume that $\gamma'$ is non-vanishing on $I$, and in particular, by reparameterizing by arclength, that $\gamma'$ is always a unit vector.

%Let $S = \{ t \in I : \gamma''(t) = 0 \}$. Then by Sard's theorem, $\gamma'(S)$ has Hausdorff dimension zero.

% TODO: Can we assume without loss of generality that $\gamma''$ and $\gamma'''$ also are non-vanishing on $I$?





\end{document}
