\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1.0in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

\usepackage{tikz}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

%\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{hyperref}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbb{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbb{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbb{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbb{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbb{MB}}}

\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\QQ}{\mathbb{Q}}
\DeclareMathOperator{\TT}{\mathbb{T}}
\DeclareMathOperator{\CC}{\mathbb{C}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}[theorem]{Remarks}
\newtheorem*{remarksaboutresults}{Remarks About The Results Stated}
%\newtheorem*{concludingremarks}{Concluding Remarks}

\DeclareMathOperator{\EE}{\mathbb{E}}
\DeclareMathOperator{\PP}{\mathbb{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{High Codimension Curves Can't Be Salem}
% \author{Jacob Denson\footnote{University of Madison Wisconsin, Madison, WI, jcdenson@wisc.edu}}

\begin{document}

\maketitle

Let $\gamma: I \to \RR^3$ be a smooth, parametric curve defined on an interval $I \subset \RR$, and let $\Gamma = \gamma(I)$ denote the parametric curve's trace. The Hausdorff dimension of $\Gamma$ is equal to one, being the image of an interval under a diffeomorphism. We claim that the Fourier dimension of $\Gamma$ is $2/3$, so that $\Gamma$ is never a Salem set. Marstrand projection theorem variants for Fourier dimension imply that the Fourier dimension of any curve in $\RR^d$ for $d \geq 3$ has Fourier dimension at most $2/3$, though I imagine similar techniques to those described here can prove the Fourier dimension of such a curve is equal to $2/d$.

Let us make the simplifying assumption that $\gamma'$, $\gamma''$, and $\gamma'''$ are all nonvanishing on $I$, and moreover, are linearly independent\footnote{We can probably use Sard's Theorem, or something similar, to reduce the study of any curve to one satisfying this assumption, but let's not get ahead of ourselves.}. There exists a unique, smooth family of unit vectors $\{ \xi_0(t) : t \in I \}$ in $\RR^d$ such that
%
\[ \xi_0(t) \cdot \gamma'(t) = \xi_0(t) \cdot \gamma''(t) = 0 \quad\text{for all $t \in I$}, \]
%
and with
%
\[ \xi_0(t) \cdot \gamma'''(t) > 0 \quad \text{for all $t \in I$}. \]
%
It follows by taking a Taylor series in the $t$ variable that we can guarantee that there exists $\varepsilon > 0$ such that for $0 < |t - s| < \varepsilon$, we have
%
\[ \frac{\xi_0(t) \cdot \gamma'(s)}{(s - t)^{d-1}} > 0. \]
%
If we break up $I$ into a finite union of almost disjoint union of intervals $\{ I_j \}$, each with length less than $\varepsilon / 3$, and set $\Gamma_j = \gamma(I_j)$, then it follows from (Ekstr\"{o}m, Persson, Schmeling, 2015) that
%
\[ \fordim(\Gamma) = \max_j \fordim(\Gamma_j). \]
%
We can therefore choose some $j$ such that $\fordim(\Gamma_j) = 1$. Swapping out $I$ for $I_j$, and $\Gamma$ for $\Gamma_j$, we will assume in what follows that for all distinct $t,s \in I$, the smooth function $\nu$ agreeing with
%
\[ \frac{\xi_0(t) \cdot \gamma'(s)}{(s - t)^{d-1}} \]
%
for distinct $t,s \in I$ is positive. Taking a Taylor series in the $s$ variable, and then letting $s \to 0$ allows us to conclude that $\nu(t,t) = \xi_0(t) \cdot \gamma'''(t)$. We also consider the smooth, positive function $a(t) = (\xi_0(t) \cdot \gamma'''(t))^{1/3}$.

For a measure $\mu$ on $I$, a function $\gamma: I \to \RR^3$, and $\xi \in \RR^3$, let
%
\[ I_\gamma(\mu,\xi) = \int e^{i \xi \cdot \gamma(t)} d\mu(t). \]
%
Our goal is to show that for any probability measure $\mu$ on $I$, and any $\varepsilon > 0$,
%
\[ \limsup_{\xi \to \infty} |\xi|^{1/3 + \varepsilon} I_\gamma(\mu,\xi) = \infty, \]
%
which is equivalent to proving that $\fordim(\Gamma) \leq 2/3$.

The following stationary phase result will be useful.

\begin{lemma}
    There exists a constant $\Gamma$ such that if $f$ is a $C^1$ function supported on $[-10,+10]$, then for $t \in I$, and $\lambda > 0$,
    %
    \[ I_\gamma(f, \lambda \xi_0(t)) = C\; a(t) f(t) e^{i \lambda \xi_0(t) \cdot \gamma(t)} \lambda^{-1/d} + O(\lambda^{-2/d}), \]
    % C_d in higher dimensions
    %
    where the implicit constant is upper bounded by a constant multiple of $\| f \|_{L^\infty} + \| f' \|_{L^\infty}$.
\end{lemma}
\begin{proof}
    This follows from one-dimensional stationary phase methods (see Erdelyi, in the discussion of Equation (4) of Section 2.9), because we have made the assumption that the function $\nu$ above is positive.
\end{proof}

Conversely, we can also apply the principle of nonstationary phase.

\begin{lemma}
    Suppose that if $f$ is a $C^1$ function supported on an interval of length $L$, $\xi$ is a unit vector in $\RR^d$, and and $|\xi \cdot \gamma'(t)| \geq \varepsilon$ for all $t \in I$. Then
    %
    \[ I_\gamma(f, \lambda \xi) \lesssim_\gamma \frac{L}{\lambda} \left( \frac{\| f' \|_{L^\infty}}{\varepsilon} + \frac{\| f \|_{L^\infty}}{\varepsilon^2} \right). \]
\end{lemma}
\begin{proof}
    We integrate by parts, calculating that
    %
    \begin{align*}
        \left| \int e^{i \lambda \xi \cdot \gamma(t)} f(t)\; dt \right| &= \frac{1}{\lambda} \left| \int \frac{d}{dt} \left\{ e^{i \lambda \xi \cdot \gamma(t)} \right\} \frac{f(t)}{\xi \cdot \gamma'(t)}\; dt \right|\\
        &= \frac{1}{\lambda} \left| \int e^{i \lambda \xi \cdot \gamma(t)} \left( \frac{f'(t)}{\xi \cdot \gamma'(t)} - \frac{f(t)}{(\xi \cdot \gamma'(t))^2} (\xi \cdot \gamma''(t)) \right)\; dt \right|\\
        &\lesssim_\gamma \frac{L}{\lambda} \left( \frac{\| f' \|_{L^\infty}}{\varepsilon} + \frac{\| f \|_{L^\infty}}{\varepsilon^2} \right). \qedhere
    \end{align*}
\end{proof}


\begin{lemma}
    Let $\gamma_M(t) = (t,t^2,t^3)$ be the parameterization of the moment curve $\Gamma_M = \gamma_M(\RR)$. For any $\varepsilon \in (0, 1/100)$, if $t_0$ is a fixed time, $\xi_0$ is one of the vectors orthogonal to both $\gamma_M'(t_0)$ and $\gamma_M''(t_0)$, $\lambda \gtrsim_\varepsilon 1$, then
    %
    \[ \sup_{|\xi - \lambda \xi_0| \leq \varepsilon \lambda} |\xi|^{1/3} |I_{\gamma_M}(\mu, \lambda \xi)| \lesssim_\varepsilon 1. \]
%    There exists constants $C_0,C_1 > 0$ such that if $\varepsilon \in (0, 1/100)$, and $\mu$ is any probability measure on $\RR$, such that $\mu$ satisfies a Frostman condition of the form $\mu(I) \leq B l(I)^s$. If $\xi_0$ is one of the two unit vectors orthogonal to both $\gamma_M'(t_0)$ and $\gamma_M''(t_0)$, then for any $\lambda \geq 1$, and any $\xi$ with $|\xi - \lambda \xi_0| \leq \varepsilon \lambda$,
    %
%    \[ |I_{\gamma_M}(\mu, \xi)| \geq \Big[ C_0 \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) - C_1 B \varepsilon^{s-2} \lambda^{-1/3} \Big] |\xi|^{-1/3}. \]
\end{lemma}
\begin{proof}
    Fix $\delta > 0$ and $\lambda \geq 1$, and suppose there was a probability measure $\mu$ compactly supported on some interval $I$ such that
    %
    \[ \sup_{|\xi - \lambda \xi_0| \leq \lambda \varepsilon} |\xi|^{1/3} |I_{\gamma_M}(\mu,\xi)| \leq \delta. \]
    %
    Define a linear transformation
    %
    \[ A_h = \begin{pmatrix} 1 & 0 & 0 \\ 2h & 1 & 0 \\ 3h^2 & 3h & 1 \end{pmatrix}. \]
    % gamma(t + h) = (t + h, (t + h)^2, (t + h)^3) = A_h gamma(t) + (h, h^2, h^3)
    Then $A_h \gamma_M(t) = \gamma_M(h) + \gamma_M(t + h)$ for all $t,h \in \RR$. If $\gamma_{M,h}(t) = \gamma_M(t + h)$, we thus have
    %
    \begin{align*}
        I_{\gamma_{M,h}}(\mu,\xi) &= \int e^{i \xi \cdot \gamma(t + h)} d\mu(t)\\
        &= e^{-i \xi \cdot \gamma(h)} \int e^{i \xi \cdot A_h \gamma(t)} d\mu(t)\; dt\\
        &= e^{-i \xi \cdot \gamma(h)} \int e^{i (A_h^T \xi) \cdot \gamma(t)} d\mu(t)\; dt\\
        &= e^{-i \xi \cdot \gamma(h)} I_{\gamma_M}(\mu,A_h^T \xi).
    \end{align*}
    %
    If we consider an $L^1$ normalized smooth bump function $\phi: \RR \to \RR$ adapted to $\{ |h| \leq \varepsilon/2 \}$, and define a smooth function $f = \phi * \mu$, then
    %
    \[ I_{\gamma_M}(f, \lambda \xi_0) = \int \phi(h) I_{\gamma_{M,h}}(\mu, \lambda \xi_0)\; dh = \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\mu, \lambda A_h^T \xi_0)\; dh. \]
    %
    Then the $L^\infty$ norm of $f$ and $f'$ is $O_\varepsilon(1)$, and $f(t_0) \gtrsim_\varepsilon 1$, so we conclude that
%
%    Then for any $t$,
    %
%    \[ \frac{\mu([t - \varepsilon / 4, t + \varepsilon / 4])}{\varepsilon} \lesssim f(t) \lesssim \frac{\mu([t - \varepsilon/2, t + \varepsilon/2])}{\varepsilon}. \]
    %
%    and
    %
%    \[ f'(t) \lesssim \frac{\mu([t - \varepsilon/2, t + \varepsilon/2])}{\varepsilon^2}. \]
%    %
%    Thus
    %
    \[ I_{\gamma_M}(f, \lambda \xi_0) = C\; a(t_0) f(t_0) e^{i \lambda \xi_0} \lambda^{-1/3} + O_\varepsilon( \lambda^{-2/3}). \]
    %
    In particular, we conclude that for $\lambda \gtrsim_\varepsilon 1$,
    %
    \[ |I_{\gamma_M}(f,\lambda \xi_0)| \gtrsim C_\varepsilon \lambda^{-1/3}. \]
    %
    Now $|A_h^T \xi_0 - \xi_0| \leq 4 h |\xi_0|$ for $|h| \leq 1 / 100$, we know by assumption that $|I(\mu, \lambda A_h^T \xi_0)| \leq \delta \lambda^{-1/3}$. But this means we conclude that
    %
    \[ \lambda^{-1/3} \lesssim_\varepsilon \delta \lambda^{-1/3}, \]
    %
    and thus that $\delta \gtrsim_\varepsilon 1$, completing the proof.
%
%    \[ \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) \cdot \lambda^{-1/3} - C \varepsilon^{s-2} \lambda^{-2/3} \lesssim \delta \lambda^{-1/3}, \]
    %
%    i.e.
    %
%    \[ \delta \gtrsim \varepsilon^{-1} \mu([t_0 - \varepsilon / 4, t_0 + \varepsilon / 4]) - C \varepsilon^{s-2} \lambda^{-1/3}. \qedhere \]
    %
    %We therefore conclude that $\delta \gtrsim_{c,\varepsilon} 1$, which proves the existence of $C_0$.
    %Since $|A_h^T \xi - \xi| \leq 4h |\xi|$ for $|h| \leq 1 / 100$, we have that $|I(\mu,A_h^T \xi)| \lesssim |\xi|^{-1/3-\varepsilon}$ for all $|h| \leq 1 / 100$. But we have $|I_\gamma(f,\xi)| \gtrsim |\xi|^{-1/3}$, so we conclude that $|\xi|^{-1/3} \lesssim |\xi|^{-1/3-\varepsilon}$, which gives a contradiction if $\xi$ is made suitably large. Thus $\fordim(\gamma_M(\RR)) = 2/3$.
    %For the moment curve, we have
    %
    %\[ \xi_0 = \frac{1}{(36t^4 + 36t^2 + 4)^{1/2}} (6t^2, -6t, 2). \]
    %
    %Thus
    %
    %\[ \xi_0 \cdot \gamma'''(t) = \frac{12}{(36t^4 + 36t^2 + 4)^{1/2}}, \]
    %
    %and so
    %
    %\[ a(t) = \frac{(12)^{1/3}}{(36t^4 + 36t^2 + 4)^{1/6}}. \]
    %
    %
    %Thus, if we consider any smooth, compactly supported function $\phi: \RR_h \to \RR$, and define a smooth function $g = f * \phi$, then
    %
    %\[ I(g,\xi) = \int \phi(h) I(f,A_h^T \xi)\; dt. \]
    %
    %Thus if $|I(f,\eta)| \lesssim |\eta|^{-1/2}$, then we get that $|I(g,\xi)| \lesssim |\xi|^{-1/2}$, uniformly in $\xi$, which gives a contradiction by the method above.
\end{proof}

% Let mu be a measure,
% define mu_t(E) = mu(E / t).
% Then int f(x) d (Dil_t mu) = int f(t x) dmu.

For any measure $\mu$ on $I$, we fix $\delta > 0$, and consider a family of $O(\delta^{-1})$ points $\mathcal{T}$ such that the length $\delta$ intervals $\{ I_t : t \in \mathcal{X}_\delta \}$ with center $t$ cover $[0,1]$, and for each $t$, the middle third of the interval $I_t$ is disjoint from $I_{t'}$ for $t \neq t'$. Consider a smooth partition of unity $\{ \chi_t \}$ adapted to these intervals. For each $t \in \mathcal{T}$, define $\mu_t = \chi_t \mu$. For any $t \in \mathcal{T}$, consider the degree three polynomial curve $\gamma_t: \RR \to \RR^d$ given by
%
\[ \gamma_t(s) = \gamma(t) + \gamma'(t) (s - t) + \frac{\gamma''(t)}{2} (s - t)^2 + \frac{\gamma'''(t)}{6} (s - t)^3. \]
%
then for any $t' \in I_t$, $|\gamma(t') - \gamma_t(t')| \lesssim \delta^4$. This means that the deviations between $\gamma$ and $\gamma_t$, once localized to a $\delta$ neighborhood of $t$, should be undetectable for frequencies with magnitude $O(\delta^{-4})$, i.e. for $|\xi| \lesssim \delta^{-4}$, we should expect to have
%
\[ I_\gamma(\mu,\xi) \approx \sum_t I_{\gamma_t}(\mu_t, \xi). \]
%
If we let $B_t$ be the matrix with columns $\delta^{-1} \gamma'(t)$, $\delta^{-2} \gamma''(t) / 2$, and $\delta^{-3} \gamma'''(t) / 6$, then
%
\[ \gamma_t(s) - \gamma(t) = B_t \gamma_M(\delta (s - t)). \]
%
Thus if $\nu_t$ is the dilation of $\text{Trans}_{-t} \mu_t$ by a factor $1/\delta$, then
% nu_t(x) = mu_t(delta (x + t))
\begin{align*}
    I_{\gamma_t}(\mu_t,\xi) &= \int e^{i \xi \cdot \gamma_t(s)} d\mu_t(s)\\
    &= \int e^{i \xi \cdot [\gamma(t) + B_t \gamma_M((s - t) / \delta)]}\; d\mu_t(s)\\
    &= e^{i \xi \cdot \gamma(t)} \int e^{i (B_t^T \xi) \cdot \gamma_M((s - t) / \delta)} d\mu_t(s)\\
    &= e^{i \xi \cdot \gamma(t)} I_{\gamma_M}(\nu_t, B_t^T \xi ).
\end{align*}
% For each $t \in \mathcal{T}$, consider the matrix $B_t$ with columns $\gamma'(t)$, $\gamma''(t) / 2$, and $\gamma'''(t) / 6$. Then $\gamma(t) + B_t \gamma_M(t' - t) = \gamma_t(t')$. If $\nu_t = \text{Trans}_{-t} \mu_t$, then
Thus we get
%
\[ I_\gamma(\mu,\xi) \approx \sum_t e^{i \xi \cdot \gamma(t)} I_{\gamma_M}(\nu_t, B_t^T \xi). \]
%
for $|\xi| \ll \delta^{-4}$. We now consider an $L^1$ normalized, smooth bump function $\phi$ supported on a width $\delta$ interval about the origin, and define $f_t = \nu_t * \phi$. We have seen that
%
\[ I_{\gamma_M}(f_t, B_t^T \xi) = \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\nu_t,A_h^T B_t^T \xi)\; dh. \]
%
Suppose (THIS IS THE CHEAT) we can find a matrix $C_h$ such that $A_h^T B_t^T \xi = B_t^T C_h \xi$. Then
% B_t^{-T} A_h^T B_t^T xi depends only on h
%
\[ \sum_t I_{\gamma_M}(f_t, B_t^T \xi) = \sum_t \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I(\nu_t, B_t^T C_h \xi) \approx \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I_\gamma(\mu, C_h \xi)\; dh. \]
%
Then $C_0$ is the identity matrix, and so we can imagine that $|C_h \xi| \sim |\xi|$ for small $h$.

We can now argue that $\fordim(\Gamma) \leq 2/3$. Suppose that instead, we could choose $\mu$ such that
%
\[ \limsup_{\xi \to \infty} |\xi|^{2/3 + \varepsilon} |I_\gamma(\mu, \xi)| < \infty. \]
%
Then for any $\xi \in \RR^d$, the right hand side of the identity above satisfies estimates of the form
%
\[ \left| \int \phi(h) e^{-i \xi \cdot \gamma_M(h)} I_\gamma(\mu, C_h \xi)\; dh \right| \lesssim |\xi|^{-1/3 - \varepsilon}. \]
%
For $|\xi| \sim \delta^{-4}$, we get that this quantity is $\lesssim \delta^{4/3 + \varepsilon}$. On the other hand, the left hand side is a sum of quantities to which we can apply stationary and nonstationary phase. If we choose $c > 0$ small enough, depending on $\gamma$, then because of the linear independence of $\gamma'$, $\gamma''$, and $\gamma'''$, if, for $t_0 \in \mathcal{T}$, we set $\xi = \xi_0(t_0)$, then for any $t \neq t_0$, and any $t' \in I_t$, $|\xi \cdot \gamma'(t')| \geq c \delta$. This implies that the principle of nonstationary phase can be applied to the quantity $I_\gamma(\nu_t, B_t^T \xi)$. For each $t_0$, the function $f_{t_0}$ has $L^\infty$ norm at most $O(\delta^{-1} \nu_{t_0}(\RR))$, and $f_{t_0}'$ has $L^\infty$ norm bounded by $O(\delta^{-2} \nu_{t_0}(\RR))$. Applying the principle of nonstationary phase, for $t \neq t_0$ we conclude that
%
\[ |I_{\gamma_M}(f_t, B_t^T \xi)| \lesssim \delta^{-2} \nu_{t_0}(\RR) |\xi|^{-1}. \]
%
Summing over $t \neq t_0$ gives that
%
\[ \sum_{t \neq t_0} |I_{\gamma_M}(f_t, B_t^T \xi)| \lesssim \delta^{-2} |\xi|^{-1}. \]
%
If we take $|\xi| \sim \delta^{-4}$, this quantity is $O(\delta^2)$. On the other hand, we have $f_{t_0}(t_0) \gtrsim \delta^{-1} \nu_{t_0}(\RR)$, and so the principle of stationary phase we calculated at the beginning of our argument shows that
%
\[ |I_{\gamma_M}(f_{t_0}, B_{t_0}^T \xi)| \gtrsim \delta^{-1} \nu_{t_0}(\RR) |\xi|^{-1/3} \]
%
so for $|\xi| \sim \delta^{-4}$, we get that this quantity is $\gtrsim \delta^{1/3} \nu_{t_0}(\RR)$. Since $\sum_t \nu_t(\RR) = \mu(\RR) = 1$, the pigeonhole principle implies we can pick some $t_0$ such that $\nu_{t_0}(\RR) \gtrsim \delta$. But then the quantity above is $\gtrsim \delta^{4/3}$. But putting these bounds together gives that
%
\[ |\sum_t I_{\gamma_M}(f_t, B_t^T \xi)| \geq |I_{\gamma_M}(f_{t_0}, B_{t_0}^T \xi)| - \sum_{t \neq t_0} |I_{\gamma_M}(f_t, B_t^T \xi)| \gtrsim \delta^{4/3}. \]
%
But we therefore conclude that $\delta^{4/3} \lesssim \delta^{4/3 + \varepsilon}$, which gives a contradiction if $\delta$ is taken appropriately small.

%Recall that
%
%\[ \nu_{t_0}(\RR) = \mu_{t_0}(\RR) = \int \chi_t(t') d \mu(t'). \]
%
%Since
%
%\[ \limsup_{\xi \to \infty} |\xi|^{2/3 + \varepsilon} |I_\gamma(\mu, \xi)| < \infty, \]
%
%the measure $\mu$ satisfies a Frostman measure condition, i.e. for all $t$, $\int \chi_t(t') d\mu(t') \lesssim \delta^{1/3}$


%Let $S = \{ t \in I: \gamma'(t) = 0 \}$. Then $S$ is closed, and so it's complement can be broken up into a countable union of almost disjoint, closed intervals $\{ I_j \}$. If $C_j = \gamma(I_j)$, it follows from (Ekstr\"{o}m, Persson, Schmeling, 2015) that
%
%\[ \fordim(C) = \max \left( \fordim(\gamma(S)), \sup_j \fordim(C_j) \right). \]
%
%Sard's theorem tells us that $\gamma(S)$ has Hausdorff dimension zero. Thus if $\fordim(C) = 1$, we can select $j$ such that $\fordim(C_j)$ is arbitrarily close to one. Without loss of generality, in the following argument we will thus assume that $\gamma'$ is non-vanishing on $I$, and in particular, by reparameterizing by arclength, that $\gamma'$ is always a unit vector.

%Let $S = \{ t \in I : \gamma''(t) = 0 \}$. Then by Sard's theorem, $\gamma'(S)$ has Hausdorff dimension zero.

% TODO: Can we assume without loss of generality that $\gamma''$ and $\gamma'''$ also are non-vanishing on $I$?





\end{document}
