\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1.0in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{tikz, tkz-berge, tkz-graph}
\usetikzlibrary{patterns,arrows,decorations.pathreplacing}

\usepackage{color,xcolor}
\definecolor{crimsonred}{RGB}{132,22,23}
\definecolor{darkblue}{RGB}{72,61,139}

\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem*{example}{Example}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{remarks}{Remarks}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\Prob}{\mathbf{P}}
\DeclareMathOperator{\Expect}{\mathbf{E}}

\DeclareMathOperator{\B}{\mathcal{B}}









\title{Large Sets Avoiding Rough Patterns}
\author{Jacob Denson\thanks{University of British Columbia, Vancouver BC, \{denson, malabika, jzahl\}@math.ubc.ca.} \and Malabika Pramanik\footnotemark[1] \and Joshua Zahl\footnotemark[1]}

\begin{document}

\maketitle

\begin{abstract}
	The pattern avoidance problem seeks to construct a set $X\subset \RR^d$ with large dimension that avoids a prescribed pattern. Examples of such patterns include three-term arithmetic progressions (solutions to $x_1 - 2x_2 + x_3 = 0$), or more general patterns of the form $f(x_1, \dots, x_n) = 0$. Previous work on the subject has considered patterns described by polynomials, or by functions $f$ satisfying certain regularity conditions. We consider the case of `rough' patterns, not prescribed by functional zeros.

	There are several problems that fit into the framework of rough pattern avoidance. As a first application, if $Y \subset \RR^d$ is a set with Minkowski dimension $\alpha$, we construct a set $X$ with Hausdorff dimension $1-\alpha$ such that $X+X$ is disjoint from $Y$. As a second application, if $C$ is a Lipschitz curve, we construct a set $X \subset C$ of dimension $1/2$ that does not contain the vertices of an isosceles triangle.
\end{abstract}








A major question in modern geometric measure theory is whether sufficiently large sets are forced to contain copies of certain patterns. Intuitively, one expects the answer to be yes, and many results in the literature support this intuition. For example, the Lebesgue density theorem implies that a set of positive Lebesgue measure contains an affine copy of any finite set.
% CHANGE: Changed this next sentence so that the functional perspective is hidden.
And any set $X \subset \RR^d$ with Hausdorff dimension exceeding one must contain three colinear points (a simple consequence of Theorem 6.8 of \cite{Matilla}). On the other hand, there are a family of results challenging this intuition.
% CHANGE: Changed next sentence so functional perspective is hidden.
Keleti \cite{KeletiDimOneSet} constructs a set $X \subset \RR$ with full Hausdorff dimension not containing any nontrivial three term arithmetic progressions. Maga \cite{Maga} constructs a set $X \subset \RR^2$ of full Hausdorff dimension such that no four points in $X$ form the vertices of a parallelogram. The pattern avoidance problem (informally stated) asks: for a given pattern, how large can the dimension of a set $X \subset \RR^d$ be before it is forced to contain a copy of this pattern? 

A natural way to formalize the notion of a pattern is as a set $Z \subset \RR^{dn}$ for some integers $d \geq 1$ and $n \geq 2$. We say a set $X \subset \RR^d$ avoids a pattern $Z$ if for every collection of $n$ {\it distinct} points $x_1, \dots, x_n \in X$, the $n$-tuple $(x_1, \dots, x_n)$ is not an element of $Z$. For example, a set $X \subset \RR^d$ does not contain three collinear points if and only if it avoids the pattern
%
% CHANGE: Avoid the wedge product, because not everyone will know the wedge product, and we don't really need it in the rest of our proof.
% CHANGE: $$ is an obselete command, and modifies vertical spacing in weird ways, so should only be used in TeX, not LaTeX.
% CHANGE: Use : instead of \colon here, because the : symbol is not a punctuation symbol of the left hand side, but is a separator between the left and right.
\[ Z_0 = \{ (x_1,x_2,x_3) \in \RR^{3d} : \text{there is}\ \lambda\ \text{such that}\ (x_3 - x_1) = \lambda (x_2 - x_1) \}. \]
%
Similarly, a set $X \subset \RR^2$ avoids the pattern 
%
% CHANGE: Avoided wedge product again.
\[ Z_1 = \{ (x_1,x_2,x_3,x_4) \in \RR^8 : x_1 + x_4 = x_2 + x_3, (x_1,x_2,x_3) \not \in Z_0 \} \]
%
if and only if no four points in $X$ form the vertices of a parallelogram.

A number of recent articles have established pattern avoidance results for increasingly general patterns. In \cite{Mathe}, M\'{a}th\'{e} constructs a set $X\subset\RR^d$ that avoids a pattern specified by a countable union of algebraic varieties of controlled degree. In \cite{MalabikaRob}, Fraser and the second author consider the pattern avoidance problem for countable unions of $C^1$ manifolds.
% Change: Moved this sentence to last paragraph to continue the `flow', so our development fits into past developments..
In this paper, we continue these developments by considering the pattern avoidance problem for an even more general class of `rough' patterns $Z \subset \RR^{dn}$, that are the countable union of sets with controlled lower Minkowski dimension.

\begin{theorem}\label{mainTheorem}
	% CHANGE: Switch from an inequality in alpha to a specification of the interval alpha lies to make things more gramatically clear, and emphasize alpha is the parameter.
	%
	Fix $\alpha \in [d,dn]$, and let $Z \subset \RR^{nd}$ be a countable union of bounded sets, each with lower Minkowski at most $\alpha$. Then there exists a set $X \subset [0,1)^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1)$ avoiding $Z$.
\end{theorem}

% CHANGE: Using an amsthm environment leads to a more uniform structure to the LaTeX document.
% DISCUSS: Should all these remarks really be remarks?
\begin{remarks}
	\ 
	\begin{enumerate}[1.]
		\item When $\alpha < d$, the pattern avoidance problem is trivial, since $X = [0,1)^d - \pi(Z)$ is full dimensional and solves the pattern avoidance problem, where $\pi(x_1, \dots, x_n) = x_1$ is a projection map from $\RR^{dn}$ to $\RR^d$.

		\item Theorem \ref{mainTheorem} is trivial when $\alpha = dn$, since we can set $X = \emptyset$.
		% CHANGE: Added \alpha = dn into the statement of Theorem 1, then showed that this endpoint case is trivial.
		We will therefore assume that $\alpha < dn$ in our proof of the theorem, without loss of generality.

		\item When $Z$ is a countable union of smooth manifolds in $\mathbb R^{nd}$ of co-dimension $m$, we have $\alpha = nd - m$. In this case Theorem \ref{mainTheorem} yields a set $X \subset \mathbb R^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1) = m/(n-1)$. This recovers Theorem 1.1 and 1.2 from \cite{MalabikaRob}, making Theorem \ref{mainTheorem} a generalization of these results.

		\item Since Theorem \ref{mainTheorem} does not require any regularity assumptions on the set $Z$, it can be applied in contexts that cannot be addressed using previous methods. Two such applications, new to the best of our knowledge, have been recorded in Section \ref{applications}; see Theorems \ref{sumset-application} and \ref{C1IsoscelesThm} there.

		\item\label{remarkSolutionDescription} The set $X$ in Theorem \ref{mainTheorem} is obtained by constructing a sequence of approximations to $X$, each of which avoids the pattern $Z$ at different scales. For lengths $l_k \searrow 0$, we construct a decreasing nested family of sets $\{ X_k \}$, where $X_k$ is a union of cubes of sidelength $l_k$ that avoids $Z$ at scales close to $l_k$. The set $X = \bigcap X_k$ then avoids $Z$. While this proof strategy is not new, our method for constructing the sets $\{X_k\}$ has several innovations that simplify the analysis of the resulting set $X=\bigcap X_k$. In particular, through a probabilistic selection process we are able to avoid the complicated queuing techniques used in \cite{KeletiDimOneSet} and \cite{MalabikaRob}, that required storage of data from each step of the iterated construction, to be retrieved at a much later stage of the construction process.

		At the same time, our construction continues to share certain features with \cite{MalabikaRob}. For example, between each pair of scales $l_{k-1}$ and $l_{k}$, we carefully select an intermediate scale $r_{k}$. The set $X_{k}\subset X_{k-1}$ avoids $Z$ at scale $l_{k}$, and it is `evenly distributed' at scale $r_k$:
		% DISCUSS: This seems like a weird statement to make.
		the set $X_{k}$ is a union of intervals of length $l_{k}$ whose midpoints resemble (a large subset of) an arithmetic progression of step size $r_k$. The details of a single step of this construction are described in Section \ref{discretesection}. In Section \ref{discretizationsection}, we explain how the length scales $l_k$ and $r_k$ for $X$ are chosen, and prove its avoidance property. In Section \ref{dimensionsection} we analyze the size of $X$ and show that it satisfies the conclusions of Theorem \ref{mainTheorem}.
	\end{enumerate}
\end{remarks}










\section{Frequently Used Notation and Terminology}\label{notationSection}

\begin{enumerate}
	\item\label{defDyadicLength} A {\it dyadic length} is a number $l$ equal to $2^{-k}$ for some non-negative integer $k$.

	\item\label{defDyadicGrid} Given a length $l > 0$, we let $\B^d_l$ denote the family of all half open cubes in $\RR^d$ with sidelength $l$ and corners on the lattice $(l \cdot \ZZ)^d$, i.e.
	%
	\[ \B^d_l = \{ [a_1, a_1 + l) \times \cdots \times [a_d, a_d+l) : a_k \in l \cdot \ZZ \}. \]
	%
	If $E \subset \RR^d$, $\B^d_l(E)$ is the family of cubes in $\B^d_l$ intersecting $E$, i.e.
	%
	\[ \B^d_l(E) = \{ I \in \B^d_l: I \cap E = \emptyset \}. \]

	% DISCUSS: Remove upper Minkowski dimension?	
	\item\label{defMinkowskiDim} The {\it lower} and {\it upper Minkowski dimension} of a compact set $Z \subset \RR^d$ are defined as
	%
	\[ \lowminkdim(Z) = \liminf_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}\quad \text{and}\quad \upminkdim(Z) = \limsup_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}. \]

	\item\label{defHausdorffDim} If $\alpha \in (0,\infty)$ and $\delta \in (0,\infty)$, we define the dyadic Hausdorff content of a set $E\subset\RR^d$ as 
		%
	\[ H^\alpha_\delta(E) = \inf \left\{ \sum_{k = 1}^m l_k^\alpha : E \subset \bigcup_{k = 1}^m I_k\ \text{and}\ I_k \in \B^d_{l_k}, l_k \leq \delta\ \text{for all $k$} \right\}. \]
	%
	The $\alpha$-dimensional dyadic Hausdorff measure $H^\alpha$ on $\RR^d$ is $H^\alpha(E) = \lim_{\delta \to 0} H_\delta^\alpha(E)$, and the {\it Hausdorff dimension} of a set $E$ is $\hausdim(E) = \inf \{ \alpha \geq 0 : H^\alpha(E) = 0 \}$.

	\item\label{defStronglyNonDiagonal} Given $I \in \B^{dn}_l$, we can decompose $I$ as $I_1 \times \cdots \times I_n$ for unique cubes $I_1, \dots, I_n \in \B_l^d$. We say $I$ is {\it strongly non-diagonal} if the cubes $I_1, \dots, I_n$ are distinct. Strongly non-diagonal cubes will play an important role in Section \ref{discretesection}, when we solve a discrete version of Theorem \ref{mainTheorem}.

	\item\label{defStrongCover} Adopting the terminology of \cite{KatzTao}, we say a collection of sets $\{ U_k \}$ is a {\it strong cover} of a set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$. This idea will be useful in Section \ref{discretizationsection}.  

	\item\label{defFrostmanItem} A {\it Frostman measure} of dimension $\alpha$ is a non-zero compactly supported probability measure $\mu$ on $\RR^d$ such that for every cube $I$ of sidelength $l$, $\mu(I) \lesssim l^\alpha$. Note that a measure $\mu$ satisfies this inequality for every cube $I$ if and only if it satisfies the inequality for cubes whose sidelengths are dyadic lengths. {\it Frostman's lemma} says that
	%
	% CHANGE: Using an aligned environment here gives weird spacing between lines which is unnecessary and doesn't look very good.
	\[ \hausdim(E) = \sup \left\{ \alpha:
		\begin{array}{c}
			\text{there is a Frostman measure of}\\
			\text{dimension $\alpha$ supported on $E$}
		\end{array} \right\}. \]
\end{enumerate}









\section{Avoidance at Discrete Scales}\label{discretesection}

In this section we describe a method for avoiding $Z$ at a single scale. We apply this technique in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. This single scale avoidance technique is the core building block of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem}.

% Change: Using B_s^{dn}(Z) is not correct here, i.e if Z is a dense set.
At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic lengths $l > s$. In this discrete setting, $Z$ is replaced by a discretized version of itself as the dyadic length $s$, i.e. a union of cubes in $\B^{dn}_s$, denoted by $Z_s$. Given a set $X_l$, which is a union of cubes in $\B_l^d$, our goal is to construct a set $X_s \subset X_l$ that is a union of cubes in $\B_s^d$, and $X_s^n$ is disjoint from strongly non-diagonal cubes in $\B^{dn}_s(Z_s)$. Using the setup introduced in Remark \ref{remarkSolutionDescription} to Theorem \ref{mainTheorem}, we will later choose $l = l_k$, $s = l_{k+1}$, and $X_l = X_k$. The set $X_{k+1}$ will be defined as the set $X_s$ we construct.
%(see Definition \ref{defStronglyNonDiagonal}).
% DISCUSS: Don't we want to reference definitions when we first use them?

% DISCUSS: Your new version of this paragraph avoids the intuition established in the previous version.
In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $X_s$ is uniformly distributed over $X_l$. We achieve this by decomposing $X_l$ into sub-cubes in $\B_r^d$ for some intermediate scale $r \in [s,l]$, and distributing $X_s$ as evenly among these intermediate sub-cubes as possible. Assuming a mild regularity condition on the volume of $X_s$, this is possible.

\begin{lemma}\label{discretelemma}
	Fix two dyadic lengths $l > s$. Let $X_l \subset [0,1)^d$ be a nonempty union of cubes in $\B^d_l$, and let $Z_s$ be a union of cubes in $\B^d_s$ such that $\# \B^{dn}(Z_s) \leq 0.5 \cdot (l/s)^{dn}$. Then there exists a dyadic length $r \in [s,l]$ such that
	%
	\begin{equation} \label{rBound}
		A_l |Z_s|^{1/d(n-1)} \leq r \leq \max(s, 2 A_l |Z_s|^{1/d(n-1)})\quad \text{where}\quad A_l = (2^{1/d}/l)^{1/(n-1)}.
	\end{equation}
	%
	For this scale, there exists a set $F \subset E$, which is a nonempty union of cubes in $\B^d_s$, satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any distinct $J_1, \dots, J_n \in \B^d_s(F)$, $J_1 \times \dots \times J_n \not \in \B_s^{dn}(Z_s)$.
		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For any $I \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I$.
		\item\label{largeSizeItem} \emph{Large Size}: For any $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
	%
	In other words, $F$ avoids strongly non-diagonal cubes in $Z_s$, and contains a single sidelength $s$ portion of more than half of the sidelength $r$ cubes contained in any sidelength $l$ cube in $E$.
\end{lemma}
\begin{proof}
	Let $r$ be the smallest dyadic length larger than than $s$ and $A_l |Z_s|^{1/d(n-1)}$, so that \eqref{rBound} is satisfied. The assumption that $|Z_s| \leq l^{dn}/2$ implies
	%
	\[ A_l |Z_s|^{1/d(n-1)} \leq A_l l^{n/(n-1)} / 2^{1/d(n-1)} = l. \]
	%
	Thus we have gauranteed that $r \in [s,l]$. For each $I \in B_r^d(E)$, let $J_I$ be a random element of $\B^d_s(I)$ chosen uniformly at random, independantly from the other random variables $J_{I'}$ with $I \neq I'$. Define a random set
	%
	%\begin{equation} \label{Udefinition}
	\[ 	U = \bigcup \{ J_I : I \in \B^d_s(I) \}, \]
	%\end{equation}
	%
	and for each $U$, set
	%
	\[ \mathcal{K}(U) = \{ K \in \B^{dn}_s(Z_s) : K \in U^n, \text{$K$ strongly non-diagonal} \} \]
	%
	Then set
	%
	\begin{equation} \label{defOfF}
		F_U = U - \{ \pi(K): K \in \mathcal{K}(U), K\ \text{is strongly diagonal} \},
	\end{equation}
	%
	where $\pi: \RR^{dn} \to \RR^d$ maps $K_1 \times \dots \times K_n$ to $K_1$ for each $K_i \in \RR^d$. Given any strongly non-diagonal cube $J_1 \times \cdots \times J_n \in \B_s^{dn}(Z_s)$, either $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(U^n)$, or $J_1 \times \cdots \times J_n \in \B_s^{dn}(U^n)$. If the former occurs then $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$ since $F_U \subset U$, while if the latter occurs then $K \in \mathcal{K}(U)$, so $J_1 \not \in \B_s^d(F_U)$. In either case, $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$, so $F_U$ satisfies Property \ref{avoidanceItem}. By construction, $U$ contains at most one subcube $J \in \B^{dn}_s$ for each $I \in \B^{dn}_l(E)$. Since $F_U \subset U$, $F_U$ satisfies Property \ref{nonConcentrationItem}. These properties are satisfied for any instance of $U$, but it is not true that Property \ref{largeSizeItem} holds for each $F_U$. The remainder of this proof is devoted to showing this property holds for $F_U$ with non-zero probability, guaranteeing the existence of the required set $F$ satisfying the properties of the lemma.

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I \in \B_r^d(E)$ such that $J \subset I$. Since $I$ contains $(r/s)^d$ elements of $\B^d_s(E)$, and $J_I$ is chosen uniformly at random from $\B^d_s(I)$,
	%
%	\begin{equation} \label{singleCubeProb}
	\[ \Prob(J \subset U) = \Prob(J_I = J) = (s/r)^d. \]
%	\end{equation}
	%
	%Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}.
	The cubes $J_I$ are chosen independantly, so if $J_1, \dots, J_k$ are distinct cubes in $\B^d_s(E)$, then the last calculation combined with Property \ref{nonConcentrationItem} shows that
	%
%	\begin{equation}\label{jointprob}
\[ 		\Prob(J_1, \dots, J_k \in U) = \begin{cases} (s/r)^{dk} &: \text{if $J_1, \dots, J_k$ have distinct parents} \\ 0 &: \text{otherwise} \end{cases} \]
%	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(Z_s)$ be a strongly non-diagonal cube. Then cubes $J_1, \dots, J_n$ are distinct, so the calculation we just performed implies
	%
	%\begin{equation}\label{probaKSubsetUn}
	\[	\Prob(K \subset U^n) = \Prob(J_1, \dots, J_k \in U) \leq (s/r)^{dn}. \]
	%\end{equation}
	%
	Together with linearity of expectation, and $\eqref{rBound}$, if $K$ ranges over the strongly non-diagonal cubes of $\B^{dn}_s(Z_s)$, we find
	%
%	\begin{equation}\label{expectedNumberOfCubes}
	\begin{align*}
		\Expect(\# \mathcal{K}(U)) &= \sum_K \Prob(K \subset U^n) \leq \# \B_s^{dn}(Z_s) \cdot (s/r)^{dn} = |Z_s| r^{-dn}\\
		&= \left[ |Z_s| r^{-d(n-1)} \right] r^{-d} \leq \left[ |Z_s| (A_l |Z_s|^{1/d(n-1)})^{-d(n-1)} \right] r^{-d} = \left[ l^d/2 \right] r^{-d} = (l/r)^d /2.
	\end{align*}
	%	\end{equation}
	%
%	On the other hand, if $A_l |Z_s|^{1/d(n-1)} \leq s$, $|Z_s| \leq s^{d(n-1)} / A_l^{d(n-1)}$, then
	%
%	\[ \Expect(\# \mathcal{K}(U)) \leq |Z_s| r^{-dn} \leq s^{d(n-1)} r^{-dn} / (2/l^d) = (l/r)^d/2 \cdot (s/r)^{d(n-1)} \leq (l/r)^d/2 \]
	%
	Thus there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \Expect(\# \mathcal{K}(U)) \leq (l/r)^d/2.
	\end{equation}
	%
	This means that the resultant set $F_{U_0}$ is obtained by removing at most $(l/r)^d/2$ cubes in $\B^d_s$ from $U_0$. Since $U_0$ contains $(l/r)^d$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, $F_{U_0}$ contains at least $(l/r)^d/2$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, so $F_{U_0}$ satisfies Property \ref{largeSizeItem}. Setting $F = F_{U_0}$ completes the proof.
\end{proof}

\begin{remark}
	While the existence of the set $F$ in Lemma \ref{discretelemma} was obtained by probabilistic techniques, we emphasize that it's existence is a purely deterministic statement. One can find a candidate $F$ constructively by checking all of the finitely many possible choice of $U$ to find one particular choice $U_0$ which satisfies $\eqref{KU0Small}$, and then defining $F$ by \eqref{defOfF}.
	%The advantage of the probabilistic argument is that we are able to find an explicit bound for the minimal cardinality of $\mathcal{K}(U)$. 
	Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.
\end{remark}

Our inability to select almost every cube in Lemma \ref{discretelemma} means that repeated applications of the result will lead to a loss in Hausdorff dimension. In fact, in the worst case, applying the lemma causes us to lose as much Hausdorff dimension as is permitted by Theorem 1. Note that the value $r$ specified in Theorem \ref{discretelemma} is always bounded below by $|Z_s|$. We will later see that if $Z$ is the countable union of sets with lower Minkowski dimension $\alpha$, the scale $s$ discretization $Z_s$ satisfies $|Z_s| \leq s^{dn - \alpha - \varepsilon}$, for some small positive $\varepsilon$ converging to zero as $s \to 0$. But we can certainly find sets $Z$ with lower Minkowski dimension $\alpha$ satisfying $|Z_s| \geq s^{dn - \alpha}$ for all $s$. In this situation, \eqref{rBound} shows
%
\begin{equation} \label{rWorstCase}
	r \geq A_l |Z_s|^{1/d(n-1)} \geq A_l s^{(dn - \alpha)/d(n-1)} \geq s^{(dn - \alpha)/d(n-1)}
\end{equation}
%
If we combine this inequality with Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, we conclude
%
%\begin{equation} \label{boxCountingBound}
\[	\frac{\log \# \B^d_s(F)}{\log(1/s)} \leq \frac{\log \# \B^d_r(E)}{\log(1/s)} = \frac{\log |E| r^{-d}}{\log(1/s)} = \frac{d \log(1/r) - \log |E|^{-1}}{\log(1/s)} \leq \frac{dn - \alpha}{n - 1}. \]
%\end{equation}
%
Given a set $F = \bigcap F_k$, where $\{ F_k \}$ are infinitely many sets obtained from an application of Lemma \ref{discretelemma} at a sequence of scales $\{ s_k \}$ with $s_k \to 0$ as $k \to \infty$, and where $|Z_{s_k}| \geq s_k^{dn - \alpha}$, then the last computation shows% \eqref{boxCountingBound} shows
%
%\begin{equation} \label{badDimension}
\[	\hausdim(F) \leq \upminkdim(F) \leq \lim_{s_k \to 0} \frac{\log \# \B^d_{s_k}(F_k)}{\log(1/s_k)} \leq \frac{dn - \alpha}{n-1}. \]
%\end{equation}
%
This is why we can only lower the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem} by $(dn - \alpha)/(n-1)$. Furthermore, we see that we must be very careful to ensure applications of the discrete lemma are the only place in our proof where dimension is lost.

\begin{remark}
	Lemma \ref{discretelemma} is the core method in our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve the result of Lemma \ref{discretelemma} so that $r$ is chosen on the order of $s^{\beta/d}$, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with Hausdorff dimension $\beta$, as in Theorem \ref{mainTheorem}. The last paragraph shows that when $|Z_s| \geq s^{dn - \alpha}$, which is certainly possible given the hypothesis of Theorem \ref{discretelemma}, the length $r$ is chosen on the order of $s^{(dn-\alpha)/d(n-1)}$, as we saw in \eqref{rWorstCase}, which is why we obtain a Hausdorff dimension $(dn - \alpha)/(n-1)$ set.
\end{remark}










\section{Fractal Discretization}\label{discretizationsection}
In this section we will construct the set $X$ by applying Lemma \ref{discretelemma} at many scales. Since $Z$ is a countable union of compact sets with Minkowski dimension at most $\alpha$, there exists a strong cover (see Definition \ref{defStrongCover}) of $Z$ by cubes restricted to a sequence of dyadic lengths $\{ l_k \}$. We will select this strong cover so that the scales $l_k$ converge to 0 very quickly.

\begin{lemma} \label{coveringlemma}
	Let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Let $\{ \varepsilon_k \}$ be a sequence of positive numbers and let $\{ f_k \}$ be a sequence of functions such that $f_k \colon (0,\infty) \to (0,\infty)$. Then there exists a sequence of dyadic lengths $\{ l_k \}$ and compact sets $\{ Z_k \}$ such that
	%
	\begin{enumerate}
		\item For each index $k \geq 2$, $l_k \leq f_{k-1}(l_{k-1})$.
		\item For each index $k$, $Z_k$ is a union of cubes in $\B^{dn}_{l_k}$.
		\item $Z$ is strongly covered by the sets $\{ Z_k \}$.
		\item For each index $k$, $\# \B^{dn}_{l_k}(Z_k) \leq (1/l_k)^{\alpha + \varepsilon_k}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let $Z$ be the union of sets $\{ Y_k \}$ with $\lowminkdim(Y_k) \leq \alpha$ for any $k$. Let $m_1, m_2, \dots$ be a sequence of integers that repeats each integer infinitely often. For each positive integer $k$, since $\lowminkdim(Y_{m_k}) \leq \alpha$, definition (C) implies that there exists arbitrarily small lengths $l$ which satisfy $\# \B_l^{dn}(Y_{m_k}) \leq 1/l^{\alpha + (\varepsilon_k/2)}$. Replacing $l$ with a dyadic length at most twice the size of $l$, there are infinitely many {\it dyadic} scales $l$ with
	%
	%\begin{equation} \label{minkdimimplication}
	\[	\# \B^{dn}_l(Y_{m_k}) \leq \frac{1}{(l/2)^{\alpha + \varepsilon_k}} \leq \frac{2^{dn}}{l^{\alpha + (\varepsilon_k/2)}} = \frac{\left( 2^{dn} l^{\varepsilon_k/2} \right)}{l^{\alpha + \varepsilon_k}}. \]
	%\end{equation}
	%
	In particular, we may select a dyadic length $l$ such that $2^{dn} l^{\varepsilon_k/2} \leq 1$, and, if $k \geq 2$, also satisfying $l \leq f_{k-1}(l_{k-1})$. The first constraint together with the last calculation implies $\# \B^{dn}_l(Y_{m_k}) \leq 1/l^{\alpha + \varepsilon_k}$. We then set $l_k = l$, and define $Z_k$ to be the union of all cubes in $\B_{l_k}^{dn}(Y_{m_k})$.
\end{proof}

We now construct $X$ by avoiding the various discretizations of $Z$ at each scale. The aim is to find a nested decreasing family of discretized sets $\{ X_k \}$ with $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$ and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $Z_k$ be a union of cubes in $\B^{dn}_{l_k}$, and suppose the sets $\{ Z_k \}$ strongly cover $Z$. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for any $k$, $X_k^n$ avoids strongly non-diagonal cubes in $Z_k$. If $X = \bigcap X_k$, then $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Set
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn}: \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for any index $m$. For suitably large $m$, the sidelength $l_k$ cube $I$ in $Z_{k_m}$ containing $z$ is disjoint from $\Delta$. But this means $I$ is strongly non-diagonal, and so $z \not \in X_{k_m}^n$. In particular, $z$ is not an element of $X^n$.
\end{proof}

We are now ready to construct the set $X$ in Theorem \ref{mainTheorem}. Let $l_0 = 1$ and $X_0 = [0,1)^d$. For each $k \geq 1$, define $\varepsilon_k = c_0/k$, where we view $c_0 = (dn - \alpha)/4$ as a irrelevant constant small enough that $dn - \alpha - 2\varepsilon_k > 0$ for any $k$. We set
%
%\begin{equation}\label{defFK}
\[	f_k(x) = \min \left( x^{k^2}, (x^{dn}/2)^{1/(dn - \alpha - \varepsilon_{k+1})}, (1/2A_x)^{d(n-1)/\varepsilon_{k+1}} \right). \]
%	f_k(x)=\min \left( x^{k^2}, (x^d4^{-k-1})^{\frac{1}{\varepsilon_{k+1}d(n-1)}} \right).
%\end{equation}
%
Apply Lemma \ref{coveringlemma} to $Z$ with this choice of $\{\varepsilon_k\}$ and $\{ f_k \}$; let $\{ l_k \}$ be the resulting sequence of dyadic lengths and let $\{Z_k\}$ be the resulting strong cover of $Z$. Observe that the definition of $f_k$ implies that for any index $k$,
%
\begin{equation} \label{boundOnLk}
	\quad l_{k+1} \leq l_k^{k^2}, \quad l_{k+1}^{dn - \alpha - \varepsilon_{k+1}} \leq l_k^{dn}/2, \quad \text{and} \quad 2A_{l_k} l_{k+1}^{\varepsilon_{k+1}/d(n-1)} \leq 1.
\end{equation}
%
For each index $k \geq 1$, define $l = l_k$ and $s = l_{k+1}$. Observe that $X_k$ is a non-empty union of cubes in $\B^d_l$; that $Z_{k+1}$ is a union of cubes in $\B^{dn}_s$, and that \eqref{boundOnLk} implies
%
\[ |Z_{k+1}| \leq l_{k+1}^{dn - \alpha - \varepsilon_{k+1}} \leq l_k^{dn}/2 = l^{dn}/2. \]
%
Setting $Z_s = Z_{k+1}$, we are therefore justified in applying Lemma \ref{discretelemma}. This produces a dyadic length $r$, which we denote by $r_{k+1}$. Assuming
%\footnote{We remark that this is the only time in our argument where we need to assume $\alpha \geq d$. If $\alpha < d$, then we cannot remove the maxima in the calculation directly following this footnote, which complicates the calculations later on in the argument. It isn't worth it to extend the remainder of the argument to this case since it is trivial to obtain a full dimensional set in this setting, as remarked directly after the statement of Theorem \ref{discretelemma}.}
$\alpha \geq d$, by \eqref{rBound} and \eqref{boundOnLk}, we find
%
\begin{equation} \label{rKBound}
\begin{aligned}
	r_{k+1} &\leq \max \left(l_{k+1}, 2 A_{l_k} |Z_{k+1}|^{1/d(n-1)} \right) \leq \max \left(l_{k+1}, 2 A_{l_k} l_{k+1}^{(dn - \alpha - \varepsilon_{k+1})/d(n-1)} \right)\\
	&\leq \max \left(l_{k+1}, l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)} \right) = l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)}.
\end{aligned}
\end{equation}
%
For this choice of $r$, we obtain a set $F \subset X_k$ which is a union of cubes in $\B^d_s(E)$ satisfying Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the lemma, and we define $X_{k+1} = F$. Property \ref{avoidanceItem} implies $X_{k+1}$ avoids strongly non-diagonal cubes in $Z_{k+1}$, so if we define $X = \bigcap X_k$, then Lemma \ref{stronglydiagonal} implies $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.

\begin{lemma}
	\[ \upminkdim(X) \geq \frac{dn - \alpha}{n - 1} \]
\end{lemma}
\begin{proof}
	Consider $X$ as the limit of the sequence $\{ X_k \}$. Since every cube in $\B^d_{l_{k+1}}(X_{k+1})$ intersects $X$, $\B^d_{l_{k+1}}(X_{k+1}) = \B^d_{l_{k+1}}(X)$. And so by Property \ref{largeSizeItem} of Lemma \ref{discretelemma}, \eqref{boundOnLk}, and \eqref{rKBound}, we conclude
	%
	\begin{align*}
		\frac{\log(\# \B^d_{l_{k+1}}(X))}{\log(1/l_{k+1})} &= \frac{\log(\# \B^d_{l_{k+1}}(X_{k+1}))}{\log(1/l_{k+1})} \geq \frac{\log((l_k/r_{k+1})^d \cdot \# \B^d_{l_k}(X_k))}{\log(1/l_{k+1})}\\
		&= \frac{d \log(1/r_{k+1})}{\log(1/l_{k+1})} - \frac{d \log(1/l_k)}{\log(1/l_{k+1})}\\
		&\geq \frac{d \log \left(1/l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)} \right)}{\log(1/l_{k+1})} - \frac{d \log(1/l_k)}{\log(1/l_k^{k^2})}\\
		&= \frac{dn - \alpha - 2\varepsilon_{k+1}}{n-1} - \frac{d}{k^2}\\
		&= \frac{dn - \alpha}{n-1} - o(1)
	\end{align*}
	%
	Taking $k \to \infty$, we conclude $\upminkdim(X) \geq (dn - \alpha)/(n-1)$.
\end{proof}







\section{Dimension Bounds}\label{dimensionsection}

To complete the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf{H}}(X) \geq \beta$, where
%
\[ \beta = \frac{dn - \alpha}{n - 1}. \]
%
We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma (see Definition \ref{defFrostmanMeasure}). We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all dyadic lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. We begin by proving the bound $\mu(I) \lesssim l_k^{\beta - O(1/k)}$ when $I \in \B^d_{l_k}$, which we view as saying $X$ looks like a set with dimension $\beta - O(1/k)$ at the lengths $\{ l_k \}$. To obtain the complete dimension bound, it then suffices to interpolate to get an acceptable bound at all intermediate scales. In this construction, as in \cite{MalabikaRob}, the rapid decay of the lengths $\{ l_k \}$ forced on us in the construction means interpolation poses a significant difficulty. We avoid this difficulty because of the uniform way that we have selected cubes in consecutive scales. This will imply that between the scales $l_k$ and $r_{k+1}$, the mass of $\mu$ distributes with similar properties to the full dimensional Lebesgue measure, which makes interpolation easy.

We now define the measure $\mu$, by first defining it recursively on cubes $I \in \B_{l_k}^d[0,1)^d$, for each positive integer $k$. Start by setting $\mu([0,1)^d) = 1$. Given $I \in \B^d_{l_k}$, we find the unique `parent cube' $I' \in \B^d_{l_{k-1}}$ with $I \subset I'$. If $I \subset X_k$, then we set
%
\begin{equation} \label{muRecurse} \mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I')}. \end{equation}
%
Otherwise, if $I \not \subset X_k$, we set $\mu(I) = 0$. Notice
%
\[ \mu(I') = \sum_{I \in \B^d_{l_k}(X_k \cap I')} \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I')} = \sum_{I \in \B^d_{l_k}(I')} \mu(I). \]
%
Thus mass is maintained at each stage of the construction. Proposition 1.7 of \cite{Falconer} then implies $\mu$ extends to a measure on the entire Borel sigma algebra. The remainder of this section is devoted to showing that $\mu$ is a Frostman measure of dimension $\beta - \varepsilon$ for any $\varepsilon > 0$.

% General principle:
% Let Q_k be all dyadic cubes of sidelength 1/2^k.
% For each mu, define E_k(mu) = sum_{Q in Q_k} mu(Q)/2^k * (Lebesgue measure restricted to Q).
% Then |E_k(\mu)| <= |mu|, so E_k is a continuous operator on finite Borel measures.
% Given mu_1, mu_2, ... in M[0,1] such that E_i(f_j) = f_i, for i < j,
% let mu be a weak * limit of the mu_i.
% The E_i are continuous on weak *, so E_i(mu) = mu_i for all i.

\begin{lemma} \label{muBoundLemma}
	If $I \in \B^d_{l_k}$, then
	%
	\begin{equation} \label{muBound}
		\mu(I) \leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d.
	\end{equation}
\end{lemma}
\begin{proof}
	We prove the theorem inductively on $k$. For $k = 0$, the theorem is obvious, because $\mu(I) \leq 1$. For the purposes of induction, let $I \in \B^d_{l_k}$, together with a parent cube $I' \in \B^d_{l_{k-1}}$ with $I \subset I'$. If $\mu(I) > 0$, $I \subset X_k$, so $I' \subset X_{k-1}$. Because $X_k$ was obtained from $X_{k-1}$ via an application of Lemma 1, Property \ref{largeSizeItem} of that lemma states that $\# \B^d_{l_k}(X_k \cap I) \geq (l_{k-1}/r_k)^d/2$, so together with the inductive hypothesis and \eqref{muRecurse}, we conclude
	%
	%	\begin{equation} \label{oneStepBound}
	\[ \mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I)} \leq \frac{\mu(I')}{(l_{k-1}/r_k)^d/2} \leq \frac{2^{k-1} \cdot \left[ \frac{r_{k-1} \dots r_1}{l_{k-2} \dots l_1} \right]^d}{(l_{k-1}/r_k)^d/2} = 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d. \qedhere \]
\end{proof}

Treating all parameters in \eqref{muBound} which depend on indices smaller than $k$ as essentially constant, and using \eqref{rKBound}, we `conclude' that
%
\[ \mu(I) \lesssim r_k^d \lesssim l_k^{\beta - 2 \cdot \varepsilon_k / (n-1)} = l_k^{\beta - O(1/k)}. \]
%
The bounds in \eqref{boundOnLk} imply $l_k$ decays very rapidly, which enables us to ignore quantities depending on previous indices, and obtain a true inequality.

\begin{corollary}
	There exists $c > 0$ such that for all $I \in \B^d_{l_k}$, $\mu(I) \lesssim l_k^{\beta - c/k}$.
\end{corollary}
\begin{proof}
	Given $\varepsilon > 0$, Lemma \ref{muBoundLemma}, Equation \eqref{rKBound}, the inequality $l_k \leq l_{k-1}^{(k-1)^2}$ from \eqref{boundOnLk}, and the fact that there exists a constant $c_0$ such that $\varepsilon_{k+1} = c_0/k$, we find
	%
	\begin{align*}
		\mu(I) &\leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d \leq \left( \frac{2^k}{l_{k-1}^d \dots l_1^d} \right) l_k^{\beta - \varepsilon_k / (n-1)} = \left( \frac{2^k l_k^{2d/k}}{l_{k-1}^{d(k-1)}} \right) l_k^{\beta - \varepsilon_k/(n-1) - 2d/k}\\
		&\leq \left( 2^k l_{k-1}^{(2d/k)(k-1)^2 - d(k-1)} \right) l_k^{\beta - (c_0/(n-1) + 2d)/k} = o \left(l_k^{\beta - (c_0/(n-1) + 2d)/k} \right), %\tag*{\qedhere}
	\end{align*}
	%
	so we can then set $c = c_0/(n-1) + 2d$.
\end{proof}

Corollary 3 gives a clean expression of the $\beta$ dimensional behaviour of $\mu$ at discrete scales. To obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for any $m > 0$.

\begin{lemma} \label{frostmanBound}
	If $l$ is dyadic and $I \in \B_l^d$, then $\mu(I) \lesssim_k l^{\beta - c/k}$ for each integer $k$.
\end{lemma}
\begin{proof}
	We begin by assuming $l \leq l_k$. To bound $\mu(I)$, we apply a covering argument, which breaks into cases depending on the size of $l$ in proportion to the scales $l_k$ and $r_k$:
	%
	\begin{itemize}
		\item If $r_{k+1} \leq l \leq l_k$, we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} and \ref{largeSizeItem} of Lemma \ref{discretelemma}, we know that the mass of each cube in $\B^d_{r_{k+1}}$ is bounded by at most $2 (r_{k+1}/l_{k+1})^d$ times the mass of a cube in $\B_{l_k}^d$. Thus
		%
		\[ \mu(I) \lesssim (l/r_{k+1})^d (2(r_{k+1}/l_k)^d) l_k^{\beta - c/k} \leq 2l^d/l_k^{d - \beta + c/k} \leq 2l^{\beta - c/k}, \]
		%
		where we used the fact that $d - \beta + c/k \geq 0$, so $l_k^{d - \beta + c/k} \geq l^{d - \beta + c/k}$.

		\item If $l_{k+1} \leq l \leq r_{k+1}$, we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, each cube in $\B^d_{r_{k+1}}$ contains at most one cube of $\B^d_{l_{k+1}}(X_{k+1})$, so
		%
		\[ \mu(I) \lesssim l_{k+1}^{\beta - c/k} \leq l^{\beta - c/k}. \]

		\item If $l \leq l_{k+1}$, there certainly exists $m$ such that $l_{m+1} \leq l \leq l_m$, and one of the previous cases yields that $\mu(I) \lesssim l^{\beta - c/m} \leq l^{\beta - c/k}$.
	\end{itemize}
	%
	If $l \geq l_k$, then $\mu(I) \leq 1 \lesssim_k l_k^{\beta - c/k} \leq l^{\beta - c/k}$, so $\mu(I) \lesssim_k l^{\beta - c/k}$ for arbitrary dyadic $l$.
\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \beta - c/k$ for each $k > 0$. Taking $k \to \infty$ proves the needed dimension bound. Since we have already shown in Section \ref{discretizationsection} that $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$, this concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem 1 generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods cannot obtain any results.

\begin{theorem}[Sum-sets avoiding specified sets]
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\alpha$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension at least $1 - \alpha$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) : x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y): y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\alpha$, $Z$ is a countable union of sets with lower Minkowski dimension at most $1 + \alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$, $n = 2$, giving a set $X \subset \RR^d$ with Hausdorff dimension $1 - \alpha$ avoiding $Z$. Since $X$ avoids $Z_1$, whenever $x,y \in X$ are distinct, $x + y \not \in Y$. Since $X$ avoids $Z_2$, $X \cap (Y/2) = \emptyset$, and thus for any $x \in X$, $x + x \not \in Y$. Thus $X + X$ is disjoint from $Y$.
\end{proof}

\begin{remark}
	One weakness of our result is that as the number of variables $n$ increases, the dimension of $X$ tends to zero. If we try and make the $n$-fold sum $X + \cdots + X$ disjoint from $Y$, current techniques only yield a set of dimension $(1 - \alpha)/(n-1)$. We have ideas on how to improve our main result when $Z$ is `flat', in addition to being low dimension, which will enable us to remove the dependence of $\hausdim(X)$ on $n$. In particular, we expect to be able to construct a set $X$ of dimension $1 - \alpha$, such that $X$ is disjoint from $Y$, and $X$ is closed under addition, and multiplication by rational numbers. In particular, given a $\QQ$ subspace $V$ of $\RR^d$ with dimension $\alpha$, we can always find a `complementary' $\QQ$ vector space $W$ with complementary fractional dimension $d - \alpha$ such that $V \cap W = (0)$.
\end{remark}

One of the most interesting uses of our method is to construct subsets of fractals avoiding patterns. In \cite{MalabikaRob}, Fraser and the second author show that if $\gamma$ is a $C^2$ curve with non-vanishing curvature, then there exists a set $E \subset \gamma$ of Hausdorff dimension $1/2$ that does not contain isoceles triangles. Our method can extend this result from the case of curves to more general sets, which gives an example of the flexibility of our method. For simplicity, we stick to an analysis of planar sets.

\begin{theorem}[Restricted sets avoiding isoceles triangles]
	Let $Y \subset \RR^2$ and let $\pi: \RR^2 \to \RR$ be an orthogonal projection such that $\pi(Y)$ has non-empty interior. Let $d$ be an arbitrary metric on $\RR^2$. Suppose that
	%
	\[ Z_0 = \{ (y_1, y_2, y_3) \in Y^3: d(y_1,y_2) = d(y_1,y_3) \} \]
	%
	is the countable union of sets with lower Minkowski dimension at most $\alpha$, for $\varepsilon \geq 0$. Then there exists a set $X \subset Y$ with dimension at least $(3 - \alpha)/2$ so that no triple of points $(x_1, x_2, x_3) \in X^3$ form the vertices of an isoceles triangle.
\end{theorem}
\begin{proof}
	Without loss of generality, by translation and rescaling, we may assume $\pi(Y)$ contains $[0,1)$. Form the set
	%
	\[ Z = \pi(Z_0) = \{ (\pi(y_1), \pi(y_2), \pi(y_3)) : y \in Z_0 \} \]
	%
	Then $Z$ is the projection of an $\alpha$ dimensional set, and therefore has dimension at most $\alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$ and $n = 3$, we construct a set $X_0 \subset [0,1)$ with Hausdorff dimension at least $(3 - \alpha)/2$ such that for any distinct $x_1,x_2,x_3 \in X_0$, $(x_1,x_2,x_3) \not \in Z$. Thus if we form a set $X$ by picking, from each $x \in X_0$, a single element of $\pi^{-1}(x)$, then $X$ avoids isoceles triangles, and has Hausdorff dimension at least as large as $X_0$.
\end{proof}

To see that Theorem 3 indeed generalizes the result of Fraser and the second author, observe that if $d$ is the Euclidean metric, then for every pair of points $x,y \in \RR^2$, the set
%
\[ \{ z \in \RR^2: d(x,z) = d(y,z) \} \]
%
is the perpendicular bisector $B_{xy}$ of $x$ and $y$. If $\gamma$ is a compact portion of a smooth curve with non-vanishing curvature, then the number of points in $\gamma \cap B_{xy}$ is bounded independantly of $x$ and $y$. Thus the set $Z_0$ in the statement of Theorem 3 has Minkowski dimension at most 2, and we can find a set with Hausdorff dimension $(3 - 2)/2 = 1/2$ on the curve avoiding isoceles triangles.

Results about slice of measures, such as those detailed in Chapter 6 of \cite{Matilla}, show that for any one dimensional set $Y$, for almost every line $L$, $L \cap Y$ consists of a finite collection of points. This suggests that if $Y$ is any set with fractional dimension one, then $Z_0$ has dimension at most 2. This implies that we can find a subset of $Y$ with dimension $1/2$ avoiding curves. We are unsure if this is true for every set with dimension one, but we provide two examples suggesting this is true for a generic set. The first result shows that for any $\varepsilon > 0$, there is an infinite family of Cantor-type sets with dimension $1 + \varepsilon$ such that $Z_0$ has dimension at most $2 + \varepsilon$. The second shows that for any rectifiable curve, $Z_0$ has dimension at most $2$. Thus Theorem 3 can be applied in settings where $Y$ is incredibly `rough', i.e. totally disconnected.

To study the first example, we consider a probabilistic model for a Cantor-type set which almost surely has the required properties. This model is obtained by considering a nested decreasing family of discretized random sets $\{ C_k \}$, with each $C_k$ a union of sidelength $1/2^k$ squares. First, we fix $p \in [0,1]$. Then we set $C_0 = [0,1]^2$. To construct $C_{k+1}$, we split each sidelength $1/2^k$ cube in $C_k$ into four sidelength $1/2^{k+1}$ squares, and keep each square in $C_{k+1}$ with probability $p$. To study this model, we employ some results about tail bounds and asymptotics for branching processes.

\begin{lemma} \label{randomdimension}
	If $p > 1/4$, then with non-zero probability, $\dim_{\mathbf{M}}(C) = 2 - \log_2(1/p)$.
\end{lemma}
\begin{proof}
	Let $p > 1/4$. For each $k$, let $Z_k$ denote the number of sidelength $1/2^k$ cubes in $[0,1]^2$. Then the sequence $\{ Z_k \}$ is a branching process, where each cube can produce between zero and four subcubes, with each of these four cubes kept with probability $p$. Thus $\Expect[Z_{k+1}|Z_k] = (4p) Z_k$. Since $4p > 1$, A simple calculation, summarized in Theorem 8.1 of \cite{Harris}, shows that the process $W_k = Z_k / (4p)^k$ is an $L^2$ bounded martingale, and so there exists a random variable $W$ such that $W_k \to W$ almost surely, and $\mathbf{E}(W|W_k) = W_k$ for all $k$. Whenever $W$ is non-zero,
	%
	\[ \minkdim(C) = \lim_{k \to \infty} \frac{\log Z_k}{k \log 2} = \lim_{k \to \infty} \frac{\log(W_k/W) + \log(W (4p)^k)}{k \log 2} = 2 - \log_2(1/p). \]
	%
	Since $\mathbf{E}(W) = \mathbf{E}(\mathbf{E}(W|W_0)) = \mathbf{E}(W_0) = 1$, $W$ is non-zero with positive probability.
\end{proof}

Similar asymptotics for branching processes show that the set $Z_0$ associated with $C$ as in Theorem 3 almost surely has Minkowski dimension $3 - \alpha$. We do this first by proving a supplementary result.

%We say a stochastic process $\{ Z_k \}$ is a $(p,M)$ {\it sub-branching process}, for $p \geq 0$ and $M > 0$, if there exists a branching process $\{ \tilde{Z_k} \}$ such that $Z_k \leq \tilde{Z}_k$ and $\mathbf{E}(\tilde{Z}_{k+1}|\tilde{Z}_k) = M \tilde{Z}_k$ holds for all $k$, and the branching process has extinction probability $p$. In the following, we assume that the offspring law of any branching process takes only finitely many values, so we have an upper bound on the maximum number of offspring that can be produced in each iteration.

\begin{lemma}\label{branchingtrick}
	Let $\{ Z_k \}$ be a supercritical branching process with extinction probability $q$. If we set $\tilde{M} = q + M$, then there exists small positive constants $\lambda$ and $\varepsilon$, depending only on the offspring law of $\{ Z_k \}$, such that $\Prob(Z_k \geq k \tilde{M}^k) \lesssim \exp \left(-\lambda k^{1 + \varepsilon} \right)$.
\end{lemma}
\begin{proof}
	Let $q_0, q_1, \dots, q_M$ denote the offspring law for the branching process, so $q = q_0$. Then there exists a grid of i.i.d discrete random variables $X_{ij}$ with $\Prob(X_{ij} = k) = q_k$ such that
	%
	\[ Z_{k+1} = \sum_{j = 1}^{Z_k} X_{ij}. \]
	%
	Now consider the branching process $\{ \tilde{Z}_k \}$ defined by setting $\tilde{Z}_0 = 1$, and
	%
	\[ \tilde{Z}_{k+1} = \sum_{j = 1}^{\tilde{Z}_k} \max(X_{ij}, 1). \]
	%
	We find $Z_k \leq \tilde{Z}_k$, and if $\tilde{M} = q + M$, then
	%
	\[ \Expect(\tilde{Z}_{k+1}|\tilde{Z}_k) = \left( q + \sum_{k = 1}^N k q_k \right) \tilde{Z}_k = (q + M) \tilde{Z}_k = \tilde{M} \tilde{Z}_k. \]
	%
	Most importantly for our purposes, $\{ \tilde{Z}_k \}$ has zero chance of extinction. Theorem 5 of \cite{Athreya} implies that for such a supercritical branching process, there exists $\lambda > 0$ depending only on the offspring distribution of $\tilde{Z}$, such that if $\tilde{W}_k = \tilde{Z}_k / \tilde{M}^k$, and $\tilde{W} = \lim \tilde{W}_k$, then
	% TODO: lambda = \theta_1^{1/3} min(1,\theta_1)^{2/3},
	% where theta_1 = inf \tilde{M}^n log g_{n-1}(e^{theta_0}), where g_{n-1} is the n-1'th iterate of g, where g is the inverse function of the generating function of the branching process.
	%
	\[ \Prob(| \tilde{W} - \tilde{W}_k | \geq t) \lesssim \exp \left( - \lambda t^{2/3} \tilde{M}^{k/3} \right) \]
	%
	In particular, this means
	%
	\begin{align*}
		\Prob \left( Z_k \geq (1 + \tilde{W}) \tilde{M}^k \right) &\leq \Prob( \tilde{Z}_k \geq (1 + \tilde{W}) \tilde{M}^k )\\
		&\leq \Prob \left( | \tilde{W} \tilde{M}^k - \tilde{Z}_k | \geq \tilde{M}^k \right)\\
		&= \Prob \left( | \tilde{W} - \tilde{W}_k| \geq 1 \right) \lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right),
	\end{align*}
	%
	Theorem 2 of \cite{Biggins} implies that as $t \to \infty$, there are constants $C$ and $\varepsilon > 0$ depending only on the offspring distribution of $\tilde{Z}$ such that
	%
	\[ - \log \Prob(\tilde{W} \geq t) \geq (C + o(1)) t^{1 + \varepsilon} \]
	%
	In particular, there exists a small constant $\lambda$ such that
	%
	\[ \Prob(1 + \tilde{W} \geq k) \leq \exp \left( - \lambda k^{1 + \varepsilon} \right) \]
	%
	Applying a union bound gives
	%
	\begin{align*}
		\Prob(Z_k \geq k \tilde{M}^k ) &\leq \Prob( Z_k \geq (1 + \tilde{W}) \tilde{M}^k ) + \Prob(1 + \tilde{W} \geq k)\\
		&\lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right) + \exp \left( - \lambda k^{1 + \varepsilon} \right) \lesssim \exp \left( - \lambda k^{1 + \varepsilon} \right). \qedhere
	\end{align*}
\end{proof}

For a set $E$, let $E_\delta = \{ x: d(x,E) \leq \delta \}$ denote the $\delta$ thickened version of $E$.

\begin{lemma} \label{lineCounting}
	There exists a constant $B$ such that for any $k$, we can find lines $L_{k,1}, \dots, L_{k,M}$ with $M \leq B \cdot 8^{kN}$ such that for any line $L$, there exists $i$ such that $[0,1]^2 \cap L_{1/2^{kN+1}} \subset (L_{k,i})_{2^{-kN}}$.
\end{lemma}
\begin{proof}
	For each $(x,\theta) \in [0,1]^2 \times [0,1]$, let
	%
	\[ L^{\theta,x} = \{ x + t e^{2 \pi i \theta} : t \in \mathbf{R} \} \]
	%
	Note that
	%
	\[ L^{\theta,x} \cap [0,1]^2 \subset \{ x + t e^{2 \pi i \theta} : t \in [-2,2] \} \]
	%
	Any line intersecting $[0,1]^2$ is equal to $L^{\theta,x}$ for some $\theta$ and some $x$. For any $k$, we consider the set of $8^5 \cdot 8^{kN}$ points $E = (\mathbf{Z}/2^{kN+5})^3 \cap [0,1]^3$. For any $(x_1,\theta_1)$ and $(x_2,\theta_2)$, and $t \in [-2,2]$, we calculate that
	%
	\[ |(x_1 + t e^{2 \pi i \theta_1}) - (x_2 + te^{2 \pi i \theta_2})| \leq |x_1 - x_2| + 2 \pi t |\theta_1 - \theta_2| \leq |x_1 - x_2| + 4 \pi |\theta_1 - \theta_2| \]
	%
	Thus $L^{\theta_1,x_1} \cap [0,1]^2$ is contained in the $|x_1 - x_2| + 4 \pi |\theta_1 - \theta_2|$ thickening of $L^{\theta_2,x_2}$. For any line $L^{\theta,x}$, there exists $(\theta_0,x_0) \in E$ such that $|\theta - \theta_0| \leq 1/2^{kN+2}$ and $|x - x_0| \leq \sqrt{2}/2^{kN+5}$, and so $L^{\theta,x} \cap [0,1]^2$ is contained in the $\sqrt{2}/2^{kN+5} + 4\pi/2^{kN+5} \leq 14/2^{kN+5} \leq 1/2^{kN+1}$, and thus $L^{\theta,x}_{1/2^{kN+1}} \cap [0,1]^2 \subset L_{1/2^{kN}}$. Thus we may set $B = 8^5$, completing the proof.
\end{proof}

\begin{lemma} \label{lineBounding}
	Fix $N$. If $p > 1/2$, then almost surely, there exists a value $k_0$ such that if $k \geq k_0$, and $L$ is any line, then
	%
	\[ \# \B^2_{2^{-kN}}(L_{2^{-kN}}) \leq k \cdot 10^k (2p)^{kN} \]
\end{lemma}
\begin{proof}
	Fix $N$, and for any index $k$ let $\delta_k = 1/2^{Nk}$. Given a line $L$, let $I$ be a sidelength $\delta_k$ square intersecting the $\delta_k$ thickened line $L_{\delta_k}$. Then $L$ passes from one edge of $I$ to another edge, and so if we split $I$ into $4^N$ sidelength $\delta_{k+1}$ squares, then $L_{\delta_{k+1}}$ intersects at most $5 \cdot 2^N$ of these boxes. Conditioned on $I$ being contained in $C_{kN}$, each of these subboxes occurs in $C_{(k+1)N}$ with probability $p^N$. We let $Z_k(L)$ denote the number of sidelength $1/2^{Nk}$ boxes in $C_{Nk}$ intersecting $L_{\delta_k}$. We now find $\tilde{Z_k}(L) \geq Z_k(L)$ by adding {\it exactly} $5 \cdot 2^N$ potential subboxes of each box at each subsequent stage, then $\tilde{Z_k}(L)$ is a branching process, whose offspring distribution is independant of $L$. Since each subbox is added with probability $p^N$, the extinction probability of $\tilde{Z_k}$ is $(1 - p^N)^{5 \cdot 2^N}$. Also, $\mathbf{E}(\tilde{Z}_{k+1}(L)|\tilde{Z}_k(L)) = 5 \cdot (2p)^N \tilde{Z}_k$.  Setting $M = 5 (2p)^N$ and $q = (1 - p^N)^{5 \cdot 2^N}$, Lemma \ref{branchingtrick} shows that there exists positive constants $\lambda$ and $\varepsilon$, independant of $L$, such that if $\tilde{M} = M + q$,
	%
	\[ \Prob \left( \tilde{Z}_k(L) \geq k \tilde{M}^k \right) \lesssim \exp(- \lambda k^{1 + \varepsilon}). \]
	%
	Elementary bounds on the logarithm show that
	%
	\[ 5 \cdot 2^N \log(1 - p^N) \leq \frac{-5 (2p)^N}{2 - p^N} \leq -5(2p)^N \]
	%
	so if $p > 1/2$,
	%
	\[ q = (1 - p^N)^{5 \cdot 2^N} \leq e^{-5 (2p)^N} \leq 1 \leq 5(2p)^N \]
	%
	and this implies $\tilde{M} \leq 10 (2p)^N$, so we have shown
	%
	\[ \Prob ( \tilde{Z}_k(L) \geq k \cdot 10^k (2p)^{kN}) \lesssim \exp( - \lambda k^{1 + \varepsilon}). \]
	%
	This gives an upper bound on $\tilde{Z}_k(L)$ up to a superexponentially decaying term in $k$.

	For each $k$, Lemma \ref{lineCounting} shows we can find lines $L_{k,1}, \dots, L_{k,M}$, with $M \leq B \cdot 8^{kN}$ such that for any line $L$, there exists $i$ such that $[0,1]^2 \cap L_{\delta_k/2} \subset (L_{k,i})_{\delta_k}$. Applying a union bound, we find that
	%
	\[ \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k \cdot 10^k (2p)^{kN} \right) \lesssim B \cdot 8^{kN} \exp(-c k^\lambda) \]
	%
	But since $\lambda > 1$, we therefore find
	%
	\[ \sum_{k = 1}^\infty \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k \cdot 10^k (2p)^{kN} \right) < \infty \]
	%
	Applying the Borel-Cantelli lemma, we conclude that almost surely, it is eventually true for sufficiently large $k$ that $Z_k(L_{k,i}) \leq k \cdot 10^k (2p)^{kN}$ for all $i$. In particular, the number of cubes intersecting $L_{\delta_k/2}$ for any line $L$ is upper bounded by $k \cdot 10^k (2p)^{kN}$.
\end{proof}

\begin{lemma}
	There exists a constant $A$ such that if $I, J \in \B^2_{1/2^{kN}}[0,1]^2$, with $d(I,J) \geq A/2^{kN}$, then
	%
	\[ \bigcup \{ L_{xy}: x \in I, y \in J \} \subset L_{1/2^{kN+1}} \]
	%
	where we recall that $L_{xy}$ is the bisector of the points $x$ and $y$.
\end{lemma}
\begin{proof}
	Denote the bottom left vertices of the boxes $I$ and $J$ by $(N_I,M_I) \cdot 1/2^{kN}$ and $(N_J,M_J) \cdot 1/2^{kN}$, with $0 \leq N_I,M_I,N_J,M_J \leq 2^{kN}$. Let $\Delta_N = |N_I - N_J|$ and $\Delta_M = |M_I - M_J|$. We may assume for simplicity that $N_I \leq N_J$ and $M_I \leq M_J$. Since $d(I,J) \geq A/2^{kN}$,
	%
	\[ (\Delta_N^2 + \Delta_M^2)^{1/2} \geq A \]
	%
	If we let $\theta_1$ and $\theta_2$ denote the minimal and maximal angle between the lines connecting pairs of points in $I$ and $J$ and the horizontal line, then
	%
	\begin{align*}
		\sin(\theta_2 - \theta_1) &= \sin(\theta_2) \cos(\theta_1) - \sin(\theta_1) \cos(\theta_2)\\
		&= \frac{(\Delta_M + 1)(\Delta_N + 1)}{\Delta_N^2 + \Delta_M^2} - \frac{\Delta_N \Delta_M}{\Delta_N^2 + \Delta_M^2}\\
		&\leq \frac{\Delta_N + \Delta_M + 1}{\Delta_N^2 + \Delta_M^2} \leq 1/A
	\end{align*}
	%
	Thus $\theta_2 - \theta_1 \leq 2/A$. Thus all the bisectors are contained in a
	%
	\[ \sqrt{2}/2^{kN} + 4\pi(2/A) \leq 1/2^{kN} \]
\end{proof}

\begin{theorem}
	If $p > 1/2$, then almost surely, the set $Z_0$ associated with $C$ has lower Minkowski dimension at most $5 - 3 \log_2(1/p)$.
\end{theorem}
\begin{proof}
	Almost surely, Lemma \ref{randomdimension} shows that for sufficiently large $k$ we can cover $C_{kN}$ by $O(2^{\alpha kN})$ boxes $I_1, \dots, I_M \in \B^2_{2^{-kN}}$, with $\alpha = 2 - \log_2(1/p)$. Lemma \ref{lineBounding} shows that if $k$ is sufficiently large, then the $1/2^{kN+1}$ thickened line $L$ intersects at most $k \cdot 10^k (2p)^{kN}$ squares in $\B^2_{2^{-kN}}$. There exists a constant $A$ such that for any $i$ and $j$, if $d(I_i, I_j) > A 2^{-kN}$, then there exists a line $L_{ij}$ such that as $x$ ranges over all points in $I_i$, and $y$ over all points in $I_j$,
	%
	\[ \bigcup_{x,y} B_{xy} \cap [0,1]^2 \subset (L_{ij})_{\delta_k/2} \]
	%
	This means that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times (L_{ij})_{\delta_k/2}$, and the last paragraph implies that $(L_{ij})_{\delta_k/2}$ is covered by $k \cdot 10^k (2p)^{kN}$ cubes in $\B^2_{l_k}[0,1]^2$. On the other hand, if $d(I_i,I_j) < A \delta_k$, we can apply the obvious bound that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times C_{kN}$, and $C_{kN}$ is coverable by $O(2^{\alpha kN})$ boxes. Thus we conclude that almost surely, for sufficiently large $k$,
	%
	\begin{align*}
		\# \B^6_{\delta_k}(Z_0) &= \sum_{i,j} \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times [0,1]^2)) \\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times (L_{ij})_{\delta_k/2})) \right)\\
		&\quad\quad+ \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times C_{kN})) \right)\\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^2_{\delta_k}((L_{ij})_{\delta_k/2}) \right) + \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^2_{\delta_k}(C_{kN}) \right)\\
		&\lesssim \sum_i 2^{\alpha kN} \cdot k 10^k (2p)^{kN} + 2^{\alpha kN} \lesssim 2^{2\alpha kN} k 10^k (2p)^{kN}
	\end{align*}
	%
	Thus we conclude that almost surely,
	%
	\begin{align*}
		\minkdim(Z_0) &= \lim_{k \to \infty} \frac{\log \left( \# \B^6_{\delta_k}(Z_0) \right)}{\log(1/\delta_k)}\\
		&\leq \lim_{k \to \infty} \frac{\log(2^{2 \alpha kN} k 10^k (2p)^{kN}) + O(1)}{\log(2^{kN})}\\
		&= \lim_{k \to \infty} \frac{2 \alpha k N \log(2) + k \log 10 + kN \log(2p)}{kN \log(2)}\\
		&= 2 \alpha + 3/N + 1 - \log_2(1/p)\\
		&= 5 - 3\log_2(1/p) + 3/N
	\end{align*}
	%
	Taking $N \to \infty$, we obtain the required result.
\end{proof}

TODO: does a projection of $C$ have non-empty interior almost surely?

\begin{corollary}
	If $p = 1/2^{1 - \varepsilon}$, then conditioned on $C$ having Minkowski dimension $1 + \varepsilon$, we can find a subset $X$ of $C$ avoiding isoceles triangles with $\hausdim(X) \geq 1/2 - (3/2) \varepsilon$.
\end{corollary}










\section{Relation to Literature, and Future Work}\label{futureWorkSection}

Our result is part of a growing body of work finding general methods to find sets avoiding patterns. The main focus of this section is comparing our method to the two other major results in the literature. \cite{MalabikaRob} constructs sets with dimension $k/(n-1)$ avoiding the zero sets of rank $k$ $C^1$ functions. In \cite{Mathe}, sets of dimension $d/l$ are constructed avoiding a degree $l$ algebraic hypersurface specified by a polynomial with rational coefficients.

We can view our result as a robust version of Pramanik and Fraser's result. Indeed, if we try and avoid the zero set of a $C^1$ rank $k$ function, then we are really avoiding a dimension $dn - k$ dimensional manifold. Our method gives a dimension
%
\[ \frac{dn - (dn - k)}{n - 1} = \frac{k}{n - 1} \]
%
set, which is exactly the result obtained in \cite{MalabikaRob}.

That our result generalizes \cite{MalabikaRob} should be expected because the technical skeleton of our construction is heavily modeled after their construction technique. Their result also reduces the problem to a discrete avoidance problem. But they {\it deterministically} select a particular side length $S$ cube in every side length $R$ cube. For arbitrary $Z$, this selection procedure can easily be exploited for a particularly nasty $Z$, so their method must rely on smoothness in order to ensure some cubes are selected at each stage. Our discrete avoidance technique was motivated by other combinatorial optimization problems, where adding a random quantity prevents inefficient selections from being made in expectation. This allows us to rely purely on combinatorial calculations, rather than employing smoothness, and greatly increases the applicability of the sets $Z$ we can apply our method to. Furthermore, it shows that the underlying problem is robust to changes in dimension; slightly `thickening' $Z$ only slightly perturbs the dimension of $X$.

One useful technique in \cite{MalabikaRob}, and its predecessor \cite{KeletiDimOneSet}, is the use of a Cantor set construction `with memory'; a queue in the construction algorithm for their sets allows storage of particular discrete versions of the problem to be stored, and then retrieved at a much later stage of the construction process. This enables them to `separate' variables in the discrete version of the problem, i.e. instead of forming a single set $F$ from a set $E$, they from $n$ sets $F_1, \dots, F_n$ from disjoint sets $E_1, \dots, E_n$. The fact that our result is more general, yet does not rely on this technique is an interesting anomaly. An obvious advantage is that the description of the technique is much more simple. But an additional advantage is that we can attack `one scale' of the problem at a time, rather than having to rely on stored memory from a vast number of steps before the current one. We believe that we can exploit the single scale approach to the problem to generalize our theorem to a much wider family of `dimension $\alpha$' sets $Z$, which we plan to discuss in a later paper.

As a generalization of the result in \cite{MalabikaRob}, our result has the same issues when compared to the result of \cite{Mathe}. When the parameter $n$ is large, the dimension of our result suffers greatly, as with the $n$ fold sum application in the last section. Furthermore, our result can't even beat trivial results if $Z$ is almost full dimensional, as the next example shows.

\begin{example}
	Consider an $\alpha$ dimensional set of angles $Y$, and try and find $X \subset \RR^2$ such that the angle formed from any collection of three points in $X$ avoids $Y$. If we form the set
	%
	\[ Z = \left\{ (x,y,z): \text{There is $\theta \in Y$}\ \text{such that}\ \frac{(x - y) \cdot (x - z)}{|x - y||x - z|} = \cos \theta \right\} \]
	%
	Then we can find $X$ avoiding $Z$. But one calculates that $Z$ has dimension $3d + \alpha - 1$, which means $X$ has dimension $(1 - \alpha) / 2$. Provided the set of angles does not contain $\pi$, the trivial example of a straight line beats our result.
\end{example}

Nonetheless, we still believe our method is a useful inspiration for new techniques in the `high dimensional' setting. Most prior literature studies sets $Z$ only implicitly as zero sets of some regular function $f$. The features of the function $f$ imply geometric features of $Z$, which are exploited by these results. But some geometric features are not obvious from the functional perspective; in particular, the fractional dimension of the zero set of $f$ is not an obvious property to study. We believe obtaining methods by looking at the explicit geometric structure of $Z$ should lead to new techniques in the field, and we already have several ideas in mind when $Z$ has geometric structure in addition to a dimension bound, which we plan to publish in a later paper.

We can compare our randomized selection technique to a discrete phenomenon that has been recently noticed, for instance in \cite{BaloghMorrisSamotij}. There, certain combinatorial problems can be rephrased as abstract problems on hypergraphs, and one can then generalize the solutions of these problems using some strategy to improve the result where the hypergraph is sparse. Our result is a continuous analogue of this phenomenon, where sparsity is represented by the dimension of the set $Z$ we are trying to avoid. One can even view Lemma 1 as a solution to a problem about independent sets in hypergraphs. In particular, we can form a hypergraph by taking the cubes $\B^d_s(E)$ as vertices, and adding an edge $(I_1, \dots, I_n)$ between $n$ distinct cubes $I_k \in \B^d_s(E)$ if $I_1 \times \dots \times I_n$ intersects $Z_s$. An independent set of cubes in this hypergraph corresponds precisely to a set $F$ with $F^n$ disjoint except on a discretization of the diagonal. And so Lemma 1 really just finds a `uniformly chosen' independent set in a sparse graph. Thus we really just applied the discrete phenomenon at many scales to obtain a continuous version of the phenomenon.








\bibliographystyle{amsplain}
\bibliography{FractalsAvoidingFractalSetsPaper}

\end{document}