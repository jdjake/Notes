\input{../../style.tex}

\title{Mechanics}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}

\maketitle

%\tableofcontents

\pagenumbering{arabic}

\chapter{Newton's Laws}

Classical mechanics attempts to describe the motion of objects in space, where the relative motions and masses of those objects are neither too small nor too large, so that relativity and quantum effects can be discounted. Starting with the work of physicists like Newton, Galileo, and Keplar, mechanics has evolved into a large field of techniques. In these notes, we cover the classical methods, as well as introducing the more modern \emph{analytical mechanics} of physicists like Lagrange and Hamilton.

The fundamentals of classical mechanics are based on Newton's laws of motion, who in the 1600s attempted to find a system of laws describing the physical phenomena he observed. His sucess is why this first system of classical mechanics is often called \emph{Newtonian mechanics}. These systems of laws behave somewhat similar to axiom systems in mathematics. Nonetheless, they must often be interpreted only as true when applied as \emph{sufficient approximations} to

The goal of systems of laws in physics is often \emph{not}

axiomatize the physical phenomena he observed in the 1600s. His success is why this system of classical mechanics is called Newtonian mechanics. We cannot axiomatize physics true to the mathematical definition -- this would imply we have fundamental knowledge of how the universe works. Nonetheless, axioms of physics are sufficient approximations to that which we can measure through experimentation, and compactly represent the state of our knowledge and philosophical understanding of the physical mechanica of our universe. Unlike mathematicians, who take their fundamental objects as undefined, in physics, fundamental objects must be directly measurable (for how else could the accuracy of a theory be validified?). In fact, an object is only really defined when we give an operational definition -- we explain how to measure it through our senses. Further physical objects are built from numerical calculations constructed from these measurements.

We begin with some observations that should appear mostly obvious, but are incredibly important to further developments. The first axiom tells us how space can be described -- in classical mechanics, we do this in the style of Euclid. $n$-dimensional affine space is a set $\mathbf{E}^n$ together with a faithful, transitive free group action from the additive group $\mathbf{R}^n$, denoted by $+$. From this, it follows that for any two points $a$ and $b$ in $\mathbf{E}^n$, there is a unique vector $v$ in $\mathbf{R}^n$ such that $a + v = b$. We denote $v$ by $b - a$. From this, we may assign a metric structure on $\mathbf{E}^n$, defining $d(a,b) = \| b - a \|$. The standard metric properties on $\mathbf{R}^n$ then follow in $\mathbf{E}^n$.

Now the space used in euclidean geometry is $\mathbf{E}^3$, since there is no notion of time in geometric studies. To enhance this, we add an additional dimension to our space, and use $\mathbf{E}^4$ to describe space, known as Galilean spacetime. In addition to this, we need a linear transformation $t$ from $\mathbf{R}^4$ to $\mathbf{R}$, which describes the `time displacement' in our system. The use of this transformation is to determine the time between two events (an event is just another word for a point in $\mathbf{E}^4$). If $a$ and $b$ are events, then $t(b - a)$ is the time between the two events. If $t(b - a) = 0$, then $a$ and $b$ are called simultaneous events. The set of all such simultaneous events to some point $a$ is called the space of simultaneous events relative to $a$. Euclid's discourse on geometry arises from any specific simultaneous subspace. However, it is then implicitly assumed that the space of points simultaneous to any point $a$ is three-dimensional -- we must therefore assert that the kernel of $t$ is three dimensional. Space has now been described in a rigorous manner.
%
Because $\mathbf{E}^4$ is an affine space, it has no inherent coordinate system to use (unless you ascribe to some geocentric model of the universe). The Galilean group consists of all invertible affine transformations of $\mathbf{E}^4$ which preserve time and space measurements between events. That is, $T$ is an element of the Galilean group if
%
\[ t(y - x) = t(T(y) - T(x))) \]
%
\[ \| y - x \| = \| T(y) - T(x) \| \]
%
We will see that galilean tranformations are those that preserve Newton's laws.

Let us consider some elementary examples of galilean transformations. Let our euclidean space by $\mathbf{R} \times \mathbf{R}^3$. The first galilean transformation is a motion by constant velocity. For any vector $v$, the map
%
\[ f(t,x) = (t,x + vt) \]
%
is Galilean. The second is the change of origin; for any number $s$ and vector $s'$,
%
\[ f(t,x) = (t + s, x + s') \]
%
is also Galilean. Finally, if $G$ is in $O(3)$, then
%
\[ f(t,x) = (t, Gx) \]
%
is Galilean, and is a rotation of the coordinate axis. It can be shown that every galilean transformation arises uniquely as the composition of a translation, rotation and motion of constant velocity, so that the dimension of the Galilean group is $3 + 4 + 3 = 10$.

Every euclidean space $\mathbf{E}^4$ can be put in one-to-one correspondence with $\mathbf{R} \times \mathbf{R}^3$. We call any such one to one correspondence $\varphi$ a galilean coordinate system. If $\varphi$ and $\varphi'$ are coordinate systems, then $\varphi$ is Galilean with respect to $\varphi'$ if $\varphi \circ \varphi^{-1}$ is a Galilean transformation.

Empty space is easy to describe. The problem of physics is to describe space when objects are introduced into it. A motion in $\mathbf{R}^n$ is a differentiable mapping $x$ from some interval $I$ in $\mathbf{R}$ to $\mathbf{R}^n$. The derivative $\dot{x}$ is calOled the velocity, and the second deriviative $\ddot{x}$ is called the acceleration. The image of this mapping is called a trajectory, and the graph of the function is a curve in $\mathbf{R} \times \mathbf{R}^n$. A curve in $\mathbf{E}^4$ is called a world line if it appears in some (and hence every) galilean coordinate system as the graph of a motion. The direct product of $\mathbf{R}^3$ $n$ times is called the configuration space of a system of $n$ points. $n$ motions $x_1, x_2, \dots, x_n$ in $\mathbf{R}^3$ define a single motion $\mathbf{x}:\mathbf{R} \to \mathbf{R}^{3n}$.

If we know $\mathbf{x}(t_0)$ and $\dot{\mathbf{x}}(t_0)$ at a single time $t_0$, Newton's principle of determinancy guarantees that we can determine $\mathbf{x}$ at all times bot before and after $t_0$. In particular, this is actually a notion equivalent to the second law that Newton describes. That is, Newton's second law perscribes exactly that in each galilean reference frame there exists a function $F:\mathbf{R}^N \times \mathbf{R}^N \times \mathbf{R} \to \mathbf{R}^N$ such that
%
\[ \ddot{x}(t) = F(\mathbf{x}(t), \dot{x}(t), t) \]
%
Provided this function $F$ is smooth enough, which is always assumed in physics, then the theorem of uniqueness and existence of solutions to ordinary differential equations states that there is a unique motion $\mathbf{x}$ determined by any initial conditions $\mathbf{x}(t_0)$ and $\dot{\mathbf{x}}(t_0)$. The importance of the second law is thus paramount to the description of motions in space that classical mechanics attempts to describe.

Newton's first law classically states that objects which are at rest remain at rest unless acted upon by some force. Of course, this cannot be completely true regardless of the frame of reference objects are measured in. If I sit on a roundabout, objects that are at rest relative to me begin to move as the roundabout begins to rotate, and they have no force acted on them. Obviously, the first law requires some higher sense of rigour. Nowadays, the only use of the first law should more relevantly be called the Galilean principle of relativity. This principle states that in $\mathbf{E}^4$ there exists a class of galilean coordinate frames called inertial, having the following property. Let $f$ is inertial, and if $\mathbf{x}$ is a motion in $f$ such that $\ddot{\mathbf{x}} = F$ is satisfied. If $f'$ is a reference frame galilean with respect to $f$, then not only should $F'$ be equal to $F$, but also $\mathbf{x}' (f' \circ f^{-1} \circ \mathbf{x})$ should satisfy $\ddot{\mathbf{x}'} = F'$.

We can deduce many interesting facts about inertial reference frames from the first law. Since the map
%
\[ \varphi(t,x) = (t + s,x) \]
%
is a galilean transformation, then if $F$ is the force in an inertial reference frame, then $F(\mathbf{x}(t), \dot{\mathbf{x}}(t), t) = F(\mathbf{x}, \dot{\mathbf{x}}, t + s)$ for any real number $s$. Thus $F$ is really only a function of position and velocity. This expresses the knowledge that the laws of physics are irrelevant with respect to time. Therefore, if we see that a force depends on the time of a system, we know that there we are either missing some forces, or we are not measuring the force with respect to an inertial reference frame.

The second simplification results from the fact that the map
%
\[ \varphi(t,x) = (t,x + r) \]
%
is galilean for any vector $r$, so that $F(\mathbf{x}, \dot{\mathbf{x}}, t) = F(\mathbf{x} + r, \dot{\mathbf{x}}, t)$. We must therefore have the force $F$ be related only to relative positions $x_i - x_j$. Similarily, since a shift by constant velocity is galilean, $F$ can also only be described by relative velocities $\dot{x_i} - \dot{x_j}$. This tells us that space is homogenous -- it has the same properties at all points. Furthermore, it tells us that forces are intrisically linked to the motions of particles themselves, since the forces are related only to a particles position between one another.

Our final notion is that space is isotropic -- it prefers no sense of direction. If $G$ is a rotation, since $G$ is also a galilean transformation, then we must have $F(\dot{x}, \ddot{x}, t) = F(G\dot{x}, G\ddot{x}, t)$.x



\begin{enumerate}
    \item There exists an inertial reference frame in which objects at rest remain at rest unless acted upon by some force.
    \item The net force on an object is equal to the change in its momentum.
\end{enumerate}

Newton's first law is also known as Galileo's law of inertia. Mathematically, the second law states that, if $r(t)$ parameterizes the movement of some body in space in relation to time, and if $F_{net}(t)$ represents the force, then, since
%
\[ p(t) = mr'(t) \]
%
described the momentum of a particle,
%
\[ F_{net}(t) = mr''(t) \]
%
assuming mass remains constant throughout the objects movement.

Separated from Newton's second law, forces are constrained by some other physical law, derived by experimentation, and mainly described by a diffeential equation. The goal of classical mechanics, is, given a set of particles in an initial position, given the physical laws present, determine completely the motion of each particle.

Let us consider an elementary example, the motion of a single particle in one dimension due to the effects of gravity. Suppose $r(0) = h$, and $r'(0) = 0$. A simplification of Newton's laws of gravitation, which are accurate for small distances, tells us that the force due to gravity is described
%
\[ F_G(t) = mg \]
%
where $m$ is the particles mass, and $g$ is the gravitational acceleration. Assuming this is the only force on the particle (so $F_{net} = F_G$), we obtain from Newton's second law that
%
\[ mr''(t) = F_G(t) = mg \]
%
Dividing by $m$ (assuming the particle has some mass),
%
\[ r''(t) = g \]
%
Functions that have the same derivative on an open interval differ by a constant on that interval. Thus, for some constant $c_0$
%
\[ r'(t) = gt + c_0 \]
%
As the initial velocity of $0$, $c_0 = r'(0) = 0$, and $r'(t) = gt$. Performing an antidifferentiation again, for some constant $c_1$,
%
\[ r(t) = \frac{g}{2}t^2 + c_1 \]
%
and $c_1 = r(0) = h$. Hence our motion is completely defined by
%
\[ r(t) = \frac{g}{2}t^2 + h \]
%
In the manner of classical mechanics, this simple problem has been `solved'.

Suppose we add an additional drag force to resist the downward velocity,
%
\[ F_d = -\beta r' \]
%
so that
%
\[ F_{net} = F_d + F_g = -\beta r' + mg \]
%
By Newton's 2nd,
%
\[ m r''(t) = mg - \beta r'(t) \]
%
\[ r''(t) = g - \frac{\beta}{m} r'(t) \]
%
If $g - \frac{\beta}{m} r'(t) \neq 0$ for any $t$ in the interval considered,
%
\[ \frac{r''(t)}{g - \frac{\beta}{m} r'(t)} = 1 \]
%
Hence
%
\[ - \frac{m}{\beta} \log|g - \frac{\beta}{m} r'(t)| = t + c_0 \]
%
\[ \log|g - \frac{\beta}{m} r'(t)| = - \frac{\beta}{m} (t + c_0) \]
%
\[ |g - \frac{\beta}{m} r'(t)| = e^{-\frac{\beta}{m} (t + c_0)} \]
%
When $g - \frac{\beta}{m} r'(t) > 0$ for all $t$,
%
\[ r'(t) = -\frac{m}{\beta} \big( e^{-\frac{\beta}{m} (t + c_0)} - g \big) \]
%
Via some antidifferentiation,
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 e^{-\frac{\beta}{m} (t + c_0)} + c_1 \]
%
Since $0 = r'(0) = - \frac{m}{\beta} (e^{\frac{-c_0 \beta}{m}} - g)$, $e^{\frac{-c_0 \beta}{m}} = g$, hence
%
\[ c_0 = - \frac{m}{\beta} log(g) \]
%
This allows us to simplify the motion above. Since
%
\[ e^{-\frac{\beta}{m}(t - \frac{m}{\beta}log(g))} = e^{-\frac{\beta}{m}t}e^{log(g)} = ge^{-\frac{\beta}{m}t} \]
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} + c_1 \]
%
and then $r(0) = h = c_1 + \big( \frac{m}{\beta} \big)^2 g $, hence $c_1 = h - \big( \frac{m}{\beta} \big)^2 g$, and the motion is completely described by
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} +  h - \big( \frac{m}{\beta} \big)^2 g \]
%
Experimental tests tells us this equation is more accurate than the last. We also gain something more interesting than just the equation.
%
\[ \lim_{t \to \infty} r'(t) = \lim_{t \to \infty} \big( \frac{gm}{\beta} - \frac{mg}{\beta} e^{- \frac{\beta}{m} t} \big) = \frac{gm}{\beta} \]
%
Which we call the terminal velocity of an object. The contant $\beta$ is proportional to the square of the length of a body. In many objects, the mass is proportional to the cube of the length of a body. Hence the terminal velocity is proportional to the length.

We have two equations for motion:
%
\[ r(t) = \frac{gt^2}{2} + h \]
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} +  h - \big( \frac{m}{\beta} \big)^2 g \]
%
The first function somehow represents the second when $\beta = 0$, in some sense. Of course, we cannot simply set $\beta = 0$, since this would mean we would have to divide by zero. We remember that for any complex number $z$,
%
\[ e^z = \sum_{k = 0}^\infty \frac{z^k}{k!} \]
%
Hence
%
\[ e^{-\frac{\beta}{m}t} = \sum_{k = 0}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} \]
%
and
%
\begin{align*}
    r(t) &= \frac{mg}{\beta} t + \big( \frac{m}{\beta} \big)^2 g \sum_{k = 0}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} +  h - \big( \frac{m}{\beta} \big)^2 g\\
    &= \frac{mg}{\beta} t + \big( \frac{m}{\beta} \big)^2 g - \frac{mg}{\beta}t + \frac{gt^2}{2} + \big( \frac{m}{\beta} \big)^2 g \sum_{k = 3}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} +  h - \big( \frac{m}{\beta} \big)^2g\\
    &= h + \frac{gt^2}{2} + g \sum_{k = 3}^\infty \frac{(\frac{\beta}{m})^{k - 2} (-t)^k}{k!}
\end{align*}
%
And now $\beta$ is only in the numerator, hence when $\beta$ is set to zero, we obtain the first formula.

\chapter{Oscillations: Disguised\\Linear Differential Equations}

We now come to a chapter that not only has applications to mechanics, but also to almost all other branches of physics. That is because most physics have motion that is inherently symmetric -- it oscillates back and forth in a smooth motion. Whether this is a pendulum, spring, atomic vibration or planetary orbitation, the oscillations can all be described by the same mathematics: Linear differential equations. The best way to see how these relate is to consider an example.

The Force on a spring is described as proportional to the displacement of a particle from the equilibrium in the direction opposite to the displacement. Placing the equilibrium at the origin, we obtain the equation
%
\[ F = -kx(t) \]
%
This is known as Hooke's law. Of course, any system with a stable equilibrium can be approximated by this equation which results from the Taylor polynomial, so this is an obvious approximation that applies to a wide variety of situations. If we let $\omega$ be a number such that $\omega^2 = k/m$, then we are solving the differential equation
%
\[ x'' + \omega^2 x = 0 \]
%
This is a linear differential equation, and can be solved in terms of exponential functions. That is, we are looking for a constant $\alpha$ such that
%
\[ \alpha^2 e^{\alpha t} + \omega^2 e^{\alpha t} = 0 \]
%
Hence $\alpha^2 = -\omega^2$, and $\alpha = \pm \sqrt{-\omega^2} = \pm i \omega$, and our general solution to the differential equation is
%
\[ x(t) = Ae^{i \omega t} + Be^{-i \omega t} \]
%
for some constants $A$ and $B$. A rule in complex analysis tells us that
%
\[ e^{i \theta} = \cos \theta + i \sin \theta \]
%
Hence we can write our solution as
%
\begin{align*}
    x(t) &= [A \cos (\omega t) + B \cos (- \omega t)] + i [A \sin (\omega t) + B \sin (- \omega t)]\\
         &= (A + B) \cos(\omega t) + i (A - B) \sin(\omega t)
\end{align*}
%
We require that our coefficients are real numbers. That is, both $A + B$ and $i(A - B)$ are real. Hence if
%
\begin{align*} A = m + ni && B = p + qi \end{align*}
%
Then we require that
%
\begin{align*} A + B = (m + p) + (n + q)i && (A - B)i = (m - p)i - (n - q) \end{align*}
%
are real, so that $n = -q$, and $m = p$, so $A + B = 2m$, and $(A - B)i = 2n$, and we obtain the solution (since $m$ and $n$ are arbitrary real numbers),
%
\[ x(t) = A \cos(\omega t) + B \sin(\omega t) \]
%
If the initial velocity is zero,
%
\[ x'(0) = B \cos (0) - A \sin (0) = 0 \]
%
we must have $B = 0$, so that
%
\[ x(t) = A \cos (\omega t) \]




\chapter{Energy}

Suppose that the force on an object moving in a single axis depends only on the position of that object (denoted by $s$). Then, since
%
\[ F \circ s = m \ddot{s} \]
%
we may multiple $\dot{s}$ on both sides to conclude
%
\[ (F \circ s) \dot{s} = m \dot{s} \ddot{s} \]
%
Integrating both sides, for some times $t_0$ (where the object is at position $x_0$) and $t$,
%
\[ \int_{t_0}^{t} (F \circ s) \dot{s} = m \int_{t_0}^{t} \dot{s} \ddot{s} \]
%
By a change of variables,
%
\[ m \int_{t_0}^{t} \dot{s} \ddot{s} = m \int_{\dot{s}(t_0)}^{\dot{s}(t)} \mathbf{1} = m \bigg[ \frac{\dot{s}(t)^2}{2} - \frac{\dot{s}(t_0)^2}{2} \bigg] \]
%
\[ \int_{t_0}^{t} (F \circ s) \dot{s} = \int_{x_0}^{s(t)} F \]
%
Therefore, if we define the potential energy $U$ at a point $x$ to be
%
\[ U(x) = - \int_{x_0}^{s(t)} F = \int_{s(t)}^{x_0} \]
%
And if we define the kinetic energy to be
%
\[ K(t) = \frac{m\dot{s}(t)^2}{2} \]
%
Then our above discussion amounts to the fact that, at any time $t$,
%
\[ (U \circ s)(t) + K(t) = \frac{m\dot{s}(t_0)}{2} = E \]
%
Which states that in this system, the conservation of energy holds.










\chapter{Mechanics in Differential Geometry}

Let us try and consider a coordinate independent, \emph{geometric} approach to mechanics. Thus we fix Euclidean space $\mathbf{E}$, viewed as a differential manifold, and we try and model the laws of mechanics in a coordinate independent way, with the hope that this will bring out the symmetries in the equation. We will find there are two approaches to defining momentum and force in a coordinate invariant way. First, we can consider them as \emph{vectors} on $\mathbf{E}$, i.e. so that a force and momentum is given in terms of a direction and magnitude on the manifold. Alternately, we can view them as \emph{covectors} on $\mathbf{E}$, so that force measures the work required to move in a particular direction on the manifold.

Let us begin by setting us the equations of motion if momentum $p$ is viewed as elements of $T \mathbf{E}$. Newton's law tells us that we should view $F$ as an element of $T(T \mathbf{E})$. Then Newton's law says that
%
\[ F = \frac{dp}{dt} \]
%
makes sense, and $F$ depends solely on the time, and position and velocity of the particle. To expand upon this geometrically, we consider two maps $\pi$ and $\Pi$ from $T(T \mathbf{E})$ to $T \mathbf{E}$, where $\pi$ is just the basepoint map, and $\Pi$ is obtained from differentiating the projection map $T \mathbf{E} \to \mathbf{E}$. We let $A$ be the \emph{equalizer} fiber subbundle of $T(T\mathbf{E})$ consisting of all $\mathbf{v} \in T(T\mathbf{E})$ such that $\pi(\mathbf{v}) = \Pi(\mathbf{v})$ (the \emph{semi spray condition}). Then we can consier $F$ as a kind of time dependent section $F: I \times T \mathbf{E} \to A$. We can model the momentum as $p: I \to T \mathbf{E}$, and then Newton's law becomes
%
\[ F(t,p) = \frac{dp}{dt}. \]
%
Working in coordinates, if $(x,y,z,v_x,v_y,v_z)$ are the coordinates on $T\mathbf{E}$ induced by the coordinates $(x,y,z)$ on $\mathbf{E}$, then, we can write
%
\[ F = v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_x \frac{\partial}{\partial v_x} + F_y \frac{\partial}{\partial v_y} + F_z \frac{\partial}{\partial v_z}, \]
%
for component functions $F_x,F_y,F_z: T \mathbf{E} \to \mathbf{R}$ (in any coordinates, the assumption that $F$ lies in $A$ amounts to the `first order' components of the vector field being determined). Let us also write the momentum in coordinates, i.e. as
%
\[ p = p_x \frac{\partial}{\partial x} + p_y \frac{\partial}{\partial y} + p_z \frac{\partial}{\partial z}, \]
%
where $p_x,p_y,p_z: I \to \mathbf{R}$ are the components of momentum. Then Newton's First Law reads precisely that, in Euclidean coordinates
%
\[ F_x = \frac{d p_x}{dt} \quad\text{and}\quad F_y = \frac{d p_y}{d t} \quad\text{and}\quad F_z = \frac{d p_z}{dt}. \]
%
These equations are elegant, but \emph{do not} remain elegant in more general coordinate systems. Indeed, let us work with cylindrical coordinates $(r,\theta,z)$, where $x = r \cos \theta$ and $y = r \sin \theta$. Then we can write
%
\[ p = p_r \frac{\partial}{\partial r} + p_\theta \frac{\partial}{\partial \theta} + p_z \frac{\partial}{\partial z} \]
%
for some new component functions $p_r,p_\theta: I \to \mathbf{R}$. If we consider the variables $(r,\theta,z,v_r,v_\theta,v_z)$ then we have
%
\[ F = v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_r \frac{\partial}{\partial v_r} + F_\theta \frac{\partial}{\partial v_\theta} + F_z \frac{\partial}{\partial v_z}, \]
%
for new functions $F_r,F_\theta: I \times T \mathbf{E} \to \mathbf{R}$. Then Newton's laws combine with a change of variables, telling us that
%
\begin{align*}
    F_r &= (\cos \theta) F_x + (\sin \theta) F_y\\
    &= (\cos \theta) \frac{d p_x}{dt} + (\sin \theta) \frac{d p_y}{dt}\\
    &= \cos \theta \frac{d}{dt} \left( \cos \theta p_r - r \sin \theta p_\theta \right) + \sin \theta \frac{d}{dt} \left( \sin \theta p_r + r \cos \theta p_\theta \right)\\
    &= \frac{dp_r}{dt} - r p_\theta \frac{d\theta}{dt}\\
    &= \frac{dp_r}{dt} - \frac{rp_\theta^2}{m},
\end{align*}
%
and
%
\begin{align*}
    F_\theta &= - \frac{\sin \theta}{r} F_x + \frac{\cos \theta}{r} F_y\\
    &= - \frac{\sin \theta}{r} \frac{dp_x}{dt} + \frac{\cos \theta}{r} \frac{dp_y}{dt}\\
    &= - \frac{\sin \theta}{r} \frac{d}{dt} \left( \cos \theta p_r - r \sin \theta p_\theta \right) + \frac{\cos \theta}{r} \frac{d}{dt} \left( \sin \theta p_r + r \cos \theta p_\theta \right)\\
    &= \frac{dp_\theta}{dt} + \frac{p_r}{r} \frac{d\theta}{dt} + \frac{dp_\theta}{dt} + \frac{p_\theta}{r} \frac{dr}{dt}\\
    &= \frac{dp_\theta}{dt} + \frac{2p_rp_\theta}{rm}.
\end{align*}
%
We get more elegant equations by switching to \emph{covector fields}.

We can also view $p$ as a \emph{covector}, i.e. as an element of $T^* \mathbf{E}$. Thus we write
%
\[ p = p_x dx + p_y dy + p_z dz, \]
%
where $p_x,p_y$, and $p_z$ are above. This is a coordinate dependent definition, but can be made coordinate independent. Indeed, if we define the metric $g^2 = m dx^2 + m dy^2 + m dz^2$ on $\mathbf{E}$, then we get a map $T\mathbf{E} \to T^*\mathbf{E}$ induced by the musical isomorphism with respect to this metric. A trajectory on $\mathbf{E}$ induces a velocity vector in a coordinate independent way, and thus we get a momentum vector by applying the isomorphism. If we define force $F$ to be a time dependent section $F: I \times T \mathbf{E} \to A$, where $A$ is a fiber subbundle of $T(T^* \mathbf{E})$ defined analogously to the bundle in the last paragraph. The musical isomorphism gives each position trajectory $x: I \to \mathbf{E}$ a momentum trajectory $p: I \to T^* \mathbf{E}$. Then Newton's law now becomes
%
\[ F \left( t, \frac{dx}{dt} \right) = \frac{dp}{dt}. \]
%
This approach tends to be more advantageous when considering energy approaches to Newtonian physics, i.e. Lagrangian and Hamiltonian approaches to the theory. Suppose that $F$ is a conservative force, which in the vector case, means that there exists a function $V: \mathbf{E} \to \mathbf{R}$ such that, in Euclidean coordinates, $(F_x,F_y,F_z) = - \nabla V$. This equation does not transform nicely with respect to general coordinate systems. But our formulation of momentum as a covector allows us to obtain an equivalent form that is coordinate independent. First, we begin by discussing a natural isomorphism
%
\[ j: T(T^* \mathbf{E}) \to T^*(T \mathbf{E}). \]
%
This can be done by analyzing the coordinate systems induced on an appropriate coordinate patch. Given a coordinate system $x$ on $\mathbf{E}$, we obtain a coordinate system $(x,\xi)$ and $(x,v)$ on $T^* \mathbf{E}$ and $T \mathbf{E}$. Then we get coordinate systems $(x,\xi,\alpha,\beta)$ and $(x,v,a,b)$ on $T(T^* \mathbf{E})$ and $T^*(T \mathbf{E})$. As we vary the coordinate system $x$, we note that $\alpha$ and $v$ transform covariantly, $\xi$ and $b$ transform contravariantly, and $\beta$ and $a$ transform `weirdly', but in a way which is compatible with one another. Thus the map given in coordinates by $j(x,\xi,\alpha,\beta) = (x,\alpha,\beta,\xi)$, with inverse $j^{-1}(x,v,a,b) = (x,b,v,a)$, is well defined globally, and gives an isomorphism. Now given a potential $V$ and a kinetic energy, we can define the \emph{Lagrangian} $L: T \mathbf{E} \to \mathbf{R}$ equal to the difference between potential and kinetic energy, i.e. such that for $v \in T_x \mathbf{E}$,
%
\[ L(v) = V(x) - (m/2) \langle v, v \rangle_g. \]
%
Then in Cartesian coordinates the differential map $dL: T \mathbf{E} \to T^*(T \mathbf{E})$ has
%
\[ dL(v) = - \left( F_x dx + F_y dy + F_z dz + p_x dv_x + p_y dv_y + p_z dv_z \right), \]
%
and so it is simple to compute that $(j \circ dL)(v)$ is the tangent vector to the corresponding moment $p \in T^*_x \mathbf{E}$ with coordinates
%
\[ (j \circ dL)(v) = - \left( v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_x \frac{\partial}{\partial \xi} + F_y \frac{\partial}{\partial \eta} + F_z \frac{\partial}{\partial \zeta} \right) = - F( v ). \]
%
The equation $j \circ dL = - F$ is now \emph{coordinate independent}, and can be applied in an arbitrary coordinate system. In practice, we do not need to go through all this formality, since the relevant acceleration vectors are given by the components of $j \circ dL$ corresponding to the tangent vectors pointing in the tangential directions of $T^* \mathbf{E}$.

\begin{comment}
Here's an example of how this approach might work. Consider a double pendulum, i.e. a pendulum with two equal masses, one lying at the end of the pendulum, and one lying in the middle of the pendulum, under the influence of gravity. The connections between the masses and the overhead support are rigid enough that we can assume they cannot bend. It is therefore natural to consider this problem in the coordinate system $(\theta_1,\theta_2)$, where $\theta_1$ gives the angle of the deviation of the vertical line from the support to the middle mass, and $\theta_2$ gives the angle of the deviation of the vertical line from the middle mass to the end mass. If we consider Cartesian coordinates in which the support is centred at the origin, and the two connections have length $L$, then the coordinates of the middle mass is
%
\[ L (\sin \theta_1, - \cos \theta_1) \]
%
and the coordinates of the end mass is
%
\[ L (\sin \theta_1 + \sin \theta_2, - \cos \theta_1 - \cos \theta_2). \]
%
If we consider a constant force pulling down, then the potential energy in the system is therefore
%
\[ V(\theta_1,\theta_2) = - mg L \cos \theta_1 - mg L (\cos \theta_1 + \cos \theta_2) = - mgL \left( 2 \cos \theta_1 + \cos \theta_2 \right). \]
%
The momentum vector of each mass is equal to
%
\[ L m \cos(\theta_1) \dot{\theta_1} dx + Lm \sin(\theta_1) \dot{\theta_1} dy \]
\[ L (\cos \theta_1) \dot{\theta_1}, \sin \theta_1) \dot{\theta_1} \]

We compute that
%
\[ dV = 2mg L \sin \theta_1 \frac{\partial}{\partial \theta_1} + mg L \sin \theta_2 \frac{\partial}{\partial \theta_2}, \]
%


The momentum metric can be computed to be $g^2 = L m d\theta_1^2 + $
 
$g^2 = m $

The metric $g^2 = m dx^2 + m dy^2 + m dz^2$

and plugging these values into the $j$ functions, we find that
%
\[ F = v_\theta \cdot \frac{\partial}{\partial \theta} + v_{\theta_1} \]

Finally, we notice that this approach can be seen to geometrically visualize the correspondence between Newton's Laws, and the Lagrangian approach
\end{comment}














\chapter{Keplar's Laws}

Keplar's Laws, discovered empirically by Keplar in 1609 discuss the motion of planets about the sun, in the reference frame of the sun:
%
\begin{itemize}
    \item \emph{Keplar's First Law} states the planets move in ellipses, with the sun at one focus of the ellipse.

    \item \emph{Keplar's Second Law} states that the area swept out radially by a planet, relative to the sun, is the same at all times.

    \item \emph{Keplar's Third Law} states that if $a$ is the major axis of the ellipse that a planet orbits, and $T$ is the period of orbit of the planet, then $a^3/T^2$ is the same for all planets orbiting the sun.
\end{itemize}
%
One of the major achievements of the invention of the calculus by Newton, and his resulting physical system, was his ability to show that Keplar's laws followed from the assumption that the planets are attracted to the sun by a gravitational force proportional to the mass of the planet, and following an inverse square law. Let us now see the connection.

To analyze the situation, we consider a single point particle with coordinates $x$, representing the planet, travelling with respect to a force field $F$ depending only on the position of the planet. We will see how Keplar's Laws follow from properties of the force field $F$. It will be convenient to work in polar coordinates, so we write the motion of a planet via a parameterization $x = r e^{i \theta}$. Recall that a force on the particle is central if, whenever the particle lies at a point $x$, it always lies on the line passing through $x$ and the origin.

\begin{theorem}
    Keplar's Second Law is true if and only if the force on the particle is central.
\end{theorem}
\begin{proof}
    In a small time interval $[t, t + \delta]$, the particle traces out an area approximated by the triangle with vertices at the origin, at $x(t)$, and at $x(t + \delta)$. The area of this triangle is precisely
    %
    \[ \frac{\det(x(t), x(t + \delta))}{2} = \frac{\det(x(t), \dot{x}(t))}{2} + O(\delta). \]
    %
    Taking Riemann sums, we conclude that the area traced out by the particle over a time interval $[t_0, t_1]$ is precisely
    %
    \[ \int_{t_0}^{t_1} \frac{\det(x(t), \dot{x}(t))}{2}\; dt, \]
    %
    Let
    %
    \[ A(t) = \int_0^t \frac{\det(x(s), \dot{x}(s))}{2}\; ds. \]
    %
    Then our theorem amounts to saying that $A(t_1 + t) - A(t_0 + t)$ is independent of $t$, which is only true if $A'$ is a constant function, i.e. which holds if $A'' = 0$. But
    %
    \[ A' = \frac{\det(x, \dot{x})}{2}, \]
    %
    and thus
    %
    \[ A'' = \frac{\det(x, \ddot{x})}{2}. \]
    %
    Newton's law tells us that $\ddot{x}$ is proportional to the force $F$. But the fact that $F$ is central immediately implies that $\det(x, \ddot{x}) = 0$, and thus $A'' = 0$. Thus Keplar's Second Law holds. Conversely, it could only be the case that $A''$ was equal to zero at a particular time if $\ddot{x}$ was always a scalar multiple of $x$, i.e. if and only if the force is always central on the trajectory of the particle.
\end{proof}

\begin{remark}
    This proof should be compared to Newton's original proof, which purely used geometry, treating motion over two discrete instants, in which all velocities are linear (see Spivak's Calculus, Chapter 17). Newton first proves that, under the influence of no force at all; over three equally spaced instants the particle moves between the three points $\{ x, x + v, x + 2v \}$, where $v$ is a velocity vector, and we see the result holds in these instants, i.e. because
    %
    \[ \det( x + v, x + 2v ) = 2 \det( x, v ) + \det( v, x ) = \det( x, v ). \]
    %
    Next, Newton analyzes what happens if a force is experienced instantaneously when the particle lies at the point $x + v$, shifting the velocity vector $v$ to some other velocity vector $w$; the fact that the force on the object is central then takes the assumption that $w - v$ is a constant multiple of $x + v$. But this means that
    %
    \begin{align*}
        \det(x + v, x + v + w) &= \det( x + v, w )\\
        &= \det( x + v, v) + \det( x + v, w - v )\\
        &= \det( x, v) + \lambda \det( x + v, x + v )\\
        &= \det( x, x + v ).
    \end{align*}
    %
    But this means the areas of the triangles are the same. The result thus holds infinitisimally.
\end{remark}

Next, let us analyze Keplar's First Law.

\begin{theorem}
    If the force on the particle is central, and satisfies an inverse square law, i.e.
    %
    \[ F = - \frac{H}{r^2} e^{i \theta}, \]
    %
    then the path of any body will be a conic section with the origin as one focus.
\end{theorem}
\begin{proof}
    We have seen that the area traced out by the particle is the same at all times, which amounts to saying that there exists some quantity $L$ such that
    %
    \[ \det(x, \dot{x}) = L. \]
    %
    We calculate that
    %
    \[ \dot{x} = \dot{r} e^{i \theta} + i r \dot{\theta} e^{i \theta}. \]
    %
    In particular, we conclude that
    %
    \[ \det(x, \dot{x}) = r^2 \dot{\theta}. \]
    %
    Thus $r^2 \dot{\theta} = L$. Now Newton's Law implies that
    %
    \[ \ddot{x} = - \frac{H}{r^2} e^{i \theta} = - \frac{H}{L} \dot{\theta} e^{i \theta}. \]
    %
    The right hand side has as antiderivative $i (H/L) e^{i \theta}$. Thus we conclude that there exists a velocity vector $v_0$ such that
    %
    \[ \dot{x} = v_0 + i \frac{H}{L} e^{i \theta}. \]
    %
    Recalling that $x = r e^{i \theta}$, we get that
    %
    \begin{align*}
        L &= \det(x, \dot{x})\\
        &= r \det( e^{i \theta}, v_0 + i \frac{H}{L} e^{i \theta} )\\
        &= r \left[ \det( e^{i \theta}, v_0 ) + \frac{H}{L} \right].
    \end{align*}
    %
    If $v_0 = 0$, then the equation above states that $r$ is constant, and then $r^2 \dot{\theta} = L$ gives us that $\theta$ is linear in $t$, and so the particle orbits on a circle about the origin, so the required claim is true. Alternatively, if $v_0 \neq 0$, then by applying a change of coordinate system by rotating and dilating the coordinate axis, we may assume that $v_0$ points in the $y$ axis and has magnitude one, i.e. $v_0 = (0,1)$. Then the equation above becomes that
    %
    \[ L = r \cos \theta + \frac{H}{L}. \]
    %
    Our equation is thus of the form
    %
    \[ \Lambda = r [ \varepsilon \cos \theta + 1 ], \]
    %
    where $\Lambda = L^2 / H$, and $\varepsilon = L / H$. But this is \emph{precisely} the equation describing a conic section in polar coordinates.
\end{proof}

Now let's prove Keplar's Third Law.

\begin{theorem}
    Suppose the force on the particle is central, with a fixed constant $H$ giving the constant in the inverse square law. Then for any ellipse with major axis $a$ the particle can travel on with period $T$, we have
    %
    \[ \frac{a^3}{T^2} = \frac{H}{4 \pi^2}. \]
    %
    Thus we see, for instance, that as $H$ increases, the particle must orbit faster and faster.
\end{theorem}
\begin{proof}
    Let us consider an particle $x$ as in the last proof, travelling subject to an equation of the form
    %
    \[ \Lambda = r [ \varepsilon \cos \theta + 1 ], \]
    %
    where $\Lambda \neq 0$, and $|\varepsilon| < 1$, so the particle travels along an ellipse, with the origin as a focus. In the last proof, we calculated that
    %
    \[ \ddot{x} = - \frac{L^2}{\Lambda} \frac{1}{r^2} e^{i \theta}. \]
    %
    If $a$ is the length of the major axis of the ellipse that the particle travels through, then
    %
    \[ a = \frac{\Lambda}{1 - \varepsilon^2}. \]
    %
    Similar, if $b$ denotes the minor axis, then
    %
    \[ b = \frac{\Lambda}{\sqrt{1 - \varepsilon^2}}. \]
    %
    Thus $b^2 / \Lambda = a$. We can use this fact to calculate the \emph{period} of the orbit of the particle. If $A(t)$ is the area swept out by the particle from time $0$ to time $t$, then we have seen that $A'(t) = L / 2$, and thus $A(t) = Lt/2$. If the particle has period $T$, then $A(T)$ is equal to the area of the entire ellipse of the particle's orbit, and thus is equal to $\pi a b$. But this means we conclude that
    %
    \[ L = \frac{2 \pi a b}{T}, \]
    %
    and so
    %
    \[ \frac{L^2}{\Lambda} = \frac{4 \pi^2 a^2 b^2}{\Lambda T^2} = \frac{4 \pi^2 a^3}{T^2}. \]
    %
    Thus
    %
    \[ - \frac{H}{r^2} e^{i \theta} = - \frac{4 \pi^2 a^3}{T^2} \frac{1}{r^2} e^{i \theta}, \]
    %
    and so we conclude that
    %
    \[ \frac{a^3}{T^2} = \frac{H}{4 \pi^2}, \]
    %
    and so we see that the quantity on the left hand side depends only on $H$.
\end{proof}

Finally, let's show that the consequences of Keplar's First and Third Law can only be true if the force on the particle satisfies an inverse square law.

\begin{theorem}
    If a force is central, then the consequences of Keplar's First and Third Law can only be true if the force satisfies an inverse square law.
\end{theorem}
\begin{proof}
    We first consider one consequence of Keplar's Second Law, which is satisfied by central forces. Then
    %
    \[ \dot{x} = \dot{r} e^{i \theta} + i r \dot{\theta} e^{i \theta} \]
    %
    and
    %
    \[ \ddot{c} = \left[ \ddot{r} - \dot{\theta}^2 r \right] e^{i \theta} + i \left[ 2 \dot{r} \dot{\theta} + r \ddot{\theta} \right] e^{i \theta}. \]
    %
    Since the force is central, this quantity must be a constant multiple of $e^{i\theta(t)}$, which implies that the latter term has to be zero, i.e.
    %
    \[ 2 \dot{r} \dot{\theta} + r \ddot{\theta} = 0, \]
    %
    and thus
    %
    \[ \ddot{x} = \left[ \ddot{r} - \dot{\theta}^2 r \right] e^{i \theta}. \]
    %
    Now suppose an particle travels under the influence of a central force, on an ellipse with the origin as one focus. Then the particle satisfies an equation of the form
    %
    \[ r [1 + \varepsilon \cos \theta] = \Lambda. \]
    % 2 r' theta' + r theta'' = 0
    % 
    We claim this equation is sufficient to conclude that the force on the particle at any time satisfies the inverse square law, i.e. that
    %
    \[ \ddot{r} - \dot{\theta}^2 r = \frac{-H}{r^2}, \]
    %
    for some time independent constant $H$. Implicitly differentiating the equation constraining the motion of the particle to a conic, we have
    %
    \[ \dot{r} [ 1 + \varepsilon \cos \theta ] - \varepsilon r \dot{\theta} \sin \theta = 0, \]
    %
    and so
    %
    \[ r \dot{r} [ 1 + \varepsilon \cos \theta] - \varepsilon r^2 \dot{\theta} \sin \theta = 0. \]
    %
    Now $r^2 \dot{\theta} = L$ for some constant $L$, and thus
    %
    \[ \dot{r} \Lambda - \varepsilon L \sin \theta = 0. \]
    %
    Thus we can write
    %
    \[ \dot{r} = \frac{\varepsilon L}{\Lambda} \sin \theta. \]
    %
    But this means that
    %
    \[ \ddot{r} = \frac{\varepsilon L}{\Lambda} \dot{\theta} \cos \theta = \frac{\varepsilon L^2}{\Lambda} \frac{\cos \theta}{r^2}. \]
    %
    Guessing from our calculations in the last proof that we should set $H = L^2 / \Lambda$, we calculate that
    %
    \begin{align*}
        \ddot{r} - \dot{\theta}^2 r &= \frac{\varepsilon L^2}{\Lambda} \frac{\cos \theta}{r^2} - ( L / r^2 )^2 r\\
        &= - \frac{L^2}{\Lambda} \frac{1}{r^2} \left( \frac{\Lambda}{r} - \varepsilon \cos \theta \right).\\
        &= - \frac{L^2}{\Lambda} \frac{1}{r^2} \Big( (1 + \varepsilon \cos \theta) - \varepsilon \cos \theta \Big)\\
        &= - \frac{L^2}{\Lambda} \frac{1}{r^2}.
    \end{align*}
    %
    Thus we see an inverse square law emerging from our calculations.
\end{proof}














\end{document}