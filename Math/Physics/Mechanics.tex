\documentclass[12pt]{amsbook}

\usepackage{kpfonts}

\usepackage{amsthm}

% To adjust itemize for better margin fitting.
\usepackage{enumitem}
\setlist[enumerate,1]{leftmargin=20pt}
\setlist[itemize,1]{leftmargin=10pt}

\usepackage{verbatim}

\usepackage{thmtools}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=-1mm
  \thm@postskip=0mm % or whatever, if you don't want them to be equal
}
\makeatother
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{exercise}{Exercise}[chapter]
\newtheorem{definition}{Definition}

\makeatletter  
\def\@endtheorem{\qed\endtrivlist\@endpefalse } % insert `\qed` macro
\makeatother
\newtheorem*{prf}{Proof}

\usepackage[a4paper]{geometry}

\usepackage{tikz}
\usepackage{tkz-berge}
\usetikzlibrary{arrows,chains,matrix,positioning,scopes}

\usepackage{hyperref} 
\hypersetup{
    colorlinks = true,
    linkcolor = black,
}

\renewcommand*\contentsname{\hfill Table Of Contents \hfill}

%\usepackage{makeidx} % Not Needed if using AMSBook class
\makeindex

\setlength\parindent{0pt} % sets indent to zero
\setlength{\parskip}{10pt} % changes vertical space between paragraphs

\newcommand{\lcm}{\operatorname{lcm}} % Lowest Common Multiple.
\newcommand{\im}{\operatorname{im}} % Image of a function.
\newcommand{\bint}{\mathbf{Z}} % Bold integer Symbol.
\newcommand{\gen}[1]{\langle #1 \rangle} % Generator of a group.
\newcommand{\End}{\operatorname{End}}
\newcommand{\Mor}{\operatorname{Mor}}

\usepackage[compact]{titlesec}
\titleformat{\chapter}[display]{}
    {\flushright\fontsize{15}{15}\selectfont{\MakeUppercase{\chaptertitlename}\hspace{2ex}}\fontsize{60}{60}\selectfont{\thechapter}}{-20pt}{\huge\bfseries}
\titlespacing*{\chapter}{0pt}{0ex}{4ex}

\newcommand*{\plogo}{\fbox{$\mathcal{JD}$}} % Generic publisher logo

%----------------------------------------------------------------------------------------
%   TITLE PAGE
%----------------------------------------------------------------------------------------

\newcommand*{\titleGP}{\begingroup % Create the command for including the title page in the document
\centering % Center all text
\vspace*{\baselineskip} % White space at the top of the page

\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal line
\rule{\textwidth}{0.4pt}\\[\baselineskip] % Thin horizontal line

{\bf \Huge Classical Mechanics\\[0.3\baselineskip]} % Title

\rule{\textwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal line
\rule{\textwidth}{1.6pt}\\[\baselineskip] % Thick horizontal line

\large Edmonton, Alberta, Canada\par % Location and year

\vspace*{2\baselineskip} % Whitespace between location/year and editors

{\Huge Jacob Denson\par} % Editor list

\vfill % Whitespace between editor names and publisher logo

\plogo \\[0.3\baselineskip] % Publisher logo
{\scshape \the\year} \\[0.3\baselineskip] % Year published
%{\large THE PUBLISHER}\par % Publisher

\endgroup}

\begin{document}

\pagenumbering{gobble}

\titleGP % This command includes the title page

\tableofcontents

\pagenumbering{arabic}

\chapter{Newton's Laws}

Classical mechanics attempts to describe the motion of objects in the classical manner of physicists such as Newton, Galileo, or Keplar, general laws of motion which remain precise whenever relative motions and masses are neither too small nor too large, where relativity and quantum effects become undismissable.

The fundamentals of classical mechanics are based on Newton's laws of motion, who attempted to axiomatize the physical phenomena he observed in the 1600s. His success is why classical mechanics is called Newtonian mechanics. We cannot axiomatize physics true to the mathematical definition -- this would imply we have fundamental knowledge of how the universe works. Nonetheless, axioms of physics are sufficient approximations to that which we can measure through experimentation, and compactly represent the state of our knowledge and philosophical understanding of the physical mechanica of our universe. Unlike mathematicians, who take their fundamental objects as undefined, in physics, fundamental objects must be directly measurable (for how else could the accuracy of a theory be validified?). In fact, an object is only really defined when we give an operational definition -- we explain how to measure it through our senses. Further physical objects are built from numerical calculations constructed from these measurements.

We begin with some observations that should appear mostly obvious, but are incredibly important to further developments. The first axiom tells us how space can be described -- in classical mechanics, we do this in the style of Euclid. $n$-dimensional affine space is a set $\mathbf{E}^n$ together with a faithful, transitive free group action from the additive group $\mathbf{R}^n$, denoted by $+$. From this, it follows that for any two points $a$ and $b$ in $\mathbf{E}^n$, there is a unique vector $v$ in $\mathbf{R}^n$ such that $a + v = b$. We denote $v$ by $b - a$. From this, we may assign a metric structure on $\mathbf{E}^n$, defining $d(a,b) = \| b - a \|$. The standard metric properties on $\mathbf{R}^n$ then follow in $\mathbf{E}^n$.

Now the space used in euclidean geometry is $\mathbf{E}^3$, since there is no notion of time in geometric studies. To enhance this, we add an additional dimension to our space, and use $\mathbf{E}^4$ to describe space, known as Galilean spacetime. In addition to this, we need a linear transformation $t$ from $\mathbf{R}^4$ to $\mathbf{R}$, which describes the `time displacement' in our system. The use of this transformation is to determine the time between two events (an event is just another word for a point in $\mathbf{E}^4$). If $a$ and $b$ are events, then $t(b - a)$ is the time between the two events. If $t(b - a) = 0$, then $a$ and $b$ are called simultaneous events. The set of all such simultaneous events to some point $a$ is called the space of simultaneous events relative to $a$. Euclid's discourse on geometry arises from any specific simultaneous subspace. However, it is then implicitly assumed that the space of points simultaneous to any point $a$ is three-dimensional -- we must therefore assert that the kernel of $t$ is three dimensional. Space has now been described in a rigorous manner.
%
Because $\mathbf{E}^4$ is an affine space, it has no inherent coordinate system to use (unless you ascribe to some geocentric model of the universe). The Galilean group consists of all invertible affine transformations of $\mathbf{E}^4$ which preserve time and space measurements between events. That is, $T$ is an element of the Galilean group if
%
\[ t(y - x) = t(T(y) - T(x))) \]
%
\[ \| y - x \| = \| T(y) - T(x) \| \]
%
We will see that galilean tranformations are those that preserve Newton's laws.

Let us consider some elementary examples of galilean transformations. Let our euclidean space by $\mathbf{R} \times \mathbf{R}^3$. The first galilean transformation is a motion by constant velocity. For any vector $v$, the map
%
\[ f(t,x) = (t,x + vt) \]
%
is Galilean. The second is the change of origin; for any number $s$ and vector $s'$,
%
\[ f(t,x) = (t + s, x + s') \]
%
is also Galilean. Finally, if $G$ is in $O(3)$, then
%
\[ f(t,x) = (t, Gx) \]
%
is Galilean, and is a rotation of the coordinate axis. It can be shown that every galilean transformation arises uniquely as the composition of a translation, rotation and motion of constant velocity, so that the dimension of the Galilean group is $3 + 4 + 3 = 10$.

Every euclidean space $\mathbf{E}^4$ can be put in one-to-one correspondence with $\mathbf{R} \times \mathbf{R}^3$. We call any such one to one correspondence $\varphi$ a galilean coordinate system. If $\varphi$ and $\varphi'$ are coordinate systems, then $\varphi$ is Galilean with respect to $\varphi'$ if $\varphi \circ \varphi^{-1}$ is a Galilean transformation.

Empty space is easy to describe. The problem of physics is to describe space when objects are introduced into it. A motion in $\mathbf{R}^n$ is a differentiable mapping $x$ from some interval $I$ in $\mathbf{R}$ to $\mathbf{R}^n$. The derivative $\dot{x}$ is calOled the velocity, and the second deriviative $\ddot{x}$ is called the acceleration. The image of this mapping is called a trajectory, and the graph of the function is a curve in $\mathbf{R} \times \mathbf{R}^n$. A curve in $\mathbf{E}^4$ is called a world line if it appears in some (and hence every) galilean coordinate system as the graph of a motion. The direct product of $\mathbf{R}^3$ $n$ times is called the configuration space of a system of $n$ points. $n$ motions $x_1, x_2, \dots, x_n$ in $\mathbf{R}^3$ define a single motion $\mathbf{x}:\mathbf{R} \to \mathbf{R}^{3n}$.

If we know $\mathbf{x}(t_0)$ and $\dot{\mathbf{x}}(t_0)$ at a single time $t_0$, Newton's principle of determinancy guarantees that we can determine $\mathbf{x}$ at all times bot before and after $t_0$. In particular, this is actually a notion equivalent to the second law that Newton describes. That is, Newton's second law perscribes exactly that in each galilean reference frame there exists a function $F:\mathbf{R}^N \times \mathbf{R}^N \times \mathbf{R} \to \mathbf{R}^N$ such that
%
\[ \ddot{x}(t) = F(\mathbf{x}(t), \dot{x}(t), t) \]
%
Provided this function $F$ is smooth enough, which is always assumed in physics, then the theorem of uniqueness and existence of solutions to ordinary differential equations states that there is a unique motion $\mathbf{x}$ determined by any initial conditions $\mathbf{x}(t_0)$ and $\dot{\mathbf{x}}(t_0)$. The importance of the second law is thus paramount to the description of motions in space that classical mechanics attempts to describe.

Newton's first law classically states that objects which are at rest remain at rest unless acted upon by some force. Of course, this cannot be completely true regardless of the frame of reference objects are measured in. If I sit on a roundabout, objects that are at rest relative to me begin to move as the roundabout begins to rotate, and they have no force acted on them. Obviously, the first law requires some higher sense of rigour. Nowadays, the only use of the first law should more relevantly be called the Galilean principle of relativity. This principle states that in $\mathbf{E}^4$ there exists a class of galilean coordinate frames called inertial, having the following property. Let $f$ is inertial, and if $\mathbf{x}$ is a motion in $f$ such that $\ddot{\mathbf{x}} = F$ is satisfied. If $f'$ is a reference frame galilean with respect to $f$, then not only should $F'$ be equal to $F$, but also $\mathbf{x}' (f' \circ f^{-1} \circ \mathbf{x})$ should satisfy $\ddot{\mathbf{x}'} = F'$.

We can deduce many interesting facts about inertial reference frames from the first law. Since the map
%
\[ \varphi(t,x) = (t + s,x) \]
%
is a galilean transformation, then if $F$ is the force in an inertial reference frame, then $F(\mathbf{x}(t), \dot{\mathbf{x}}(t), t) = F(\mathbf{x}, \dot{\mathbf{x}}, t + s)$ for any real number $s$. Thus $F$ is really only a function of position and velocity. This expresses the knowledge that the laws of physics are irrelevant with respect to time. Therefore, if we see that a force depends on the time of a system, we know that there we are either missing some forces, or we are not measuring the force with respect to an inertial reference frame.

The second simplification results from the fact that the map
%
\[ \varphi(t,x) = (t,x + r) \]
%
is galilean for any vector $r$, so that $F(\mathbf{x}, \dot{\mathbf{x}}, t) = F(\mathbf{x} + r, \dot{\mathbf{x}}, t)$. We must therefore have the force $F$ be related only to relative positions $x_i - x_j$. Similarily, since a shift by constant velocity is galilean, $F$ can also only be described by relative velocities $\dot{x_i} - \dot{x_j}$. This tells us that space is homogenous -- it has the same properties at all points. Furthermore, it tells us that forces are intrisically linked to the motions of particles themselves, since the forces are related only to a particles position between one another.

Our final notion is that space is isotropic -- it prefers no sense of direction. If $G$ is a rotation, since $G$ is also a galilean transformation, then we must have $F(\dot{x}, \ddot{x}, t) = F(G\dot{x}, G\ddot{x}, t)$.x



\begin{enumerate}
    \item There exists an inertial reference frame in which objects at rest remain at rest unless acted upon by some force.
    \item The net force on an object is equal to the change in its momentum.
\end{enumerate}

Newton's first law is also known as Galileo's law of inertia. Mathematically, the second law states that, if $r(t)$ parameterizes the movement of some body in space in relation to time, and if $F_{net}(t)$ represents the force, then, since
%
\[ p(t) = mr'(t) \]
%
described the momentum of a particle,
%
\[ F_{net}(t) = mr''(t) \]
%
assuming mass remains constant throughout the objects movement.

Separated from Newton's second law, forces are constrained by some other physical law, derived by experimentation, and mainly described by a diffeential equation. The goal of classical mechanics, is, given a set of particles in an initial position, given the physical laws present, determine completely the motion of each particle.

Let us consider an elementary example, the motion of a single particle in one dimension due to the effects of gravity. Suppose $r(0) = h$, and $r'(0) = 0$. A simplification of Newton's laws of gravitation, which are accurate for small distances, tells us that the force due to gravity is described
%
\[ F_G(t) = mg \]
%
where $m$ is the particles mass, and $g$ is the gravitational acceleration. Assuming this is the only force on the particle (so $F_{net} = F_G$), we obtain from Newton's second law that
%
\[ mr''(t) = F_G(t) = mg \]
%
Dividing by $m$ (assuming the particle has some mass),
%
\[ r''(t) = g \]
%
Functions that have the same derivative on an open interval differ by a constant on that interval. Thus, for some constant $c_0$
%
\[ r'(t) = gt + c_0 \]
%
As the initial velocity of $0$, $c_0 = r'(0) = 0$, and $r'(t) = gt$. Performing an antidifferentiation again, for some constant $c_1$,
%
\[ r(t) = \frac{g}{2}t^2 + c_1 \]
%
and $c_1 = r(0) = h$. Hence our motion is completely defined by
%
\[ r(t) = \frac{g}{2}t^2 + h \]
%
In the manner of classical mechanics, this simple problem has been `solved'.

Suppose we add an additional drag force to resist the downward velocity,
%
\[ F_d = -\beta r' \]
%
so that
%
\[ F_{net} = F_d + F_g = -\beta r' + mg \]
%
By Newton's 2nd,
%
\[ m r''(t) = mg - \beta r'(t) \]
%
\[ r''(t) = g - \frac{\beta}{m} r'(t) \]
%
If $g - \frac{\beta}{m} r'(t) \neq 0$ for any $t$ in the interval considered,
%
\[ \frac{r''(t)}{g - \frac{\beta}{m} r'(t)} = 1 \]
%
Hence
%
\[ - \frac{m}{\beta} \log|g - \frac{\beta}{m} r'(t)| = t + c_0 \]
%
\[ \log|g - \frac{\beta}{m} r'(t)| = - \frac{\beta}{m} (t + c_0) \]
%
\[ |g - \frac{\beta}{m} r'(t)| = e^{-\frac{\beta}{m} (t + c_0)} \]
%
When $g - \frac{\beta}{m} r'(t) > 0$ for all $t$,
%
\[ r'(t) = -\frac{m}{\beta} \big( e^{-\frac{\beta}{m} (t + c_0)} - g \big) \]
%
Via some antidifferentiation,
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 e^{-\frac{\beta}{m} (t + c_0)} + c_1 \]
%
Since $0 = r'(0) = - \frac{m}{\beta} (e^{\frac{-c_0 \beta}{m}} - g)$, $e^{\frac{-c_0 \beta}{m}} = g$, hence
%
\[ c_0 = - \frac{m}{\beta} log(g) \]
%
This allows us to simplify the motion above. Since
%
\[ e^{-\frac{\beta}{m}(t - \frac{m}{\beta}log(g))} = e^{-\frac{\beta}{m}t}e^{log(g)} = ge^{-\frac{\beta}{m}t} \]
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} + c_1 \]
%
and then $r(0) = h = c_1 + \big( \frac{m}{\beta} \big)^2 g $, hence $c_1 = h - \big( \frac{m}{\beta} \big)^2 g$, and the motion is completely described by
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} +  h - \big( \frac{m}{\beta} \big)^2 g \]
%
Experimental tests tells us this equation is more accurate than the last. We also gain something more interesting than just the equation.
%
\[ \lim_{t \to \infty} r'(t) = \lim_{t \to \infty} \big( \frac{gm}{\beta} - \frac{mg}{\beta} e^{- \frac{\beta}{m} t} \big) = \frac{gm}{\beta} \]
%
Which we call the terminal velocity of an object. The contant $\beta$ is proportional to the square of the length of a body. In many objects, the mass is proportional to the cube of the length of a body. Hence the terminal velocity is proportional to the length.

We have two equations for motion:
%
\[ r(t) = \frac{gt^2}{2} + h \]
%
\[ r(t) = \frac{gm}{\beta} t + \big( \frac{m}{\beta} \big)^2 g e^{-\frac{\beta}{m}t} +  h - \big( \frac{m}{\beta} \big)^2 g \]
%
The first function somehow represents the second when $\beta = 0$, in some sense. Of course, we cannot simply set $\beta = 0$, since this would mean we would have to divide by zero. We remember that for any complex number $z$,
%
\[ e^z = \sum_{k = 0}^\infty \frac{z^k}{k!} \]
%
Hence
%
\[ e^{-\frac{\beta}{m}t} = \sum_{k = 0}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} \]
%
and
%
\begin{align*}
    r(t) &= \frac{mg}{\beta} t + \big( \frac{m}{\beta} \big)^2 g \sum_{k = 0}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} +  h - \big( \frac{m}{\beta} \big)^2 g\\
    &= \frac{mg}{\beta} t + \big( \frac{m}{\beta} \big)^2 g - \frac{mg}{\beta}t + \frac{gt^2}{2} + \big( \frac{m}{\beta} \big)^2 g \sum_{k = 3}^\infty \frac{(-\frac{\beta}{m}t)^k}{k!} +  h - \big( \frac{m}{\beta} \big)^2g\\
    &= h + \frac{gt^2}{2} + g \sum_{k = 3}^\infty \frac{(\frac{\beta}{m})^{k - 2} (-t)^k}{k!}
\end{align*}
%
And now $\beta$ is only in the numerator, hence when $\beta$ is set to zero, we obtain the first formula.

\chapter{Oscillations: Disguised\\Linear Differential Equations}

We now come to a chapter that not only has applications to mechanics, but also to almost all other branches of physics. That is because most physics have motion that is inherently symmetric -- it oscillates back and forth in a smooth motion. Whether this is a pendulum, spring, atomic vibration or planetary orbitation, the oscillations can all be described by the same mathematics: Linear differential equations. The best way to see how these relate is to consider an example.

The Force on a spring is described as proportional to the displacement of a particle from the equilibrium in the direction opposite to the displacement. Placing the equilibrium at the origin, we obtain the equation
%
\[ F = -kx(t) \]
%
This is known as Hooke's law. Of course, any system with a stable equilibrium can be approximated by this equation which results from the Taylor polynomial, so this is an obvious approximation that applies to a wide variety of situations. If we let $\omega$ be a number such that $\omega^2 = k/m$, then we are solving the differential equation
%
\[ x'' + \omega^2 x = 0 \]
%
This is a linear differential equation, and can be solved in terms of exponential functions. That is, we are looking for a constant $\alpha$ such that
%
\[ \alpha^2 e^{\alpha t} + \omega^2 e^{\alpha t} = 0 \]
%
Hence $\alpha^2 = -\omega^2$, and $\alpha = \pm \sqrt{-\omega^2} = \pm i \omega$, and our general solution to the differential equation is
%
\[ x(t) = Ae^{i \omega t} + Be^{-i \omega t} \]
%
for some constants $A$ and $B$. A rule in complex analysis tells us that
%
\[ e^{i \theta} = \cos \theta + i \sin \theta \]
%
Hence we can write our solution as
%
\begin{align*}
    x(t) &= [A \cos (\omega t) + B \cos (- \omega t)] + i [A \sin (\omega t) + B \sin (- \omega t)]\\
         &= (A + B) \cos(\omega t) + i (A - B) \sin(\omega t)
\end{align*}
%
We require that our coefficients are real numbers. That is, both $A + B$ and $i(A - B)$ are real. Hence if
%
\begin{align*} A = m + ni && B = p + qi \end{align*}
%
Then we require that
%
\begin{align*} A + B = (m + p) + (n + q)i && (A - B)i = (m - p)i - (n - q) \end{align*}
%
are real, so that $n = -q$, and $m = p$, so $A + B = 2m$, and $(A - B)i = 2n$, and we obtain the solution (since $m$ and $n$ are arbitrary real numbers),
%
\[ x(t) = A \cos(\omega t) + B \sin(\omega t) \]
%
If the initial velocity is zero,
%
\[ x'(0) = B \cos (0) - A \sin (0) = 0 \]
%
we must have $B = 0$, so that
%
\[ x(t) = A \cos (\omega t) \]




\chapter{Energy}

Suppose that the force on an object moving in a single axis depends only on the position of that object (denoted by $s$). Then, since
%
\[ F \circ s = m \ddot{s} \]
%
we may multiple $\dot{s}$ on both sides to conclude
%
\[ (F \circ s) \dot{s} = m \dot{s} \ddot{s} \]
%
Integrating both sides, for some times $t_0$ (where the object is at position $x_0$) and $t$,
%
\[ \int_{t_0}^{t} (F \circ s) \dot{s} = m \int_{t_0}^{t} \dot{s} \ddot{s} \]
%
By a change of variables,
%
\[ m \int_{t_0}^{t} \dot{s} \ddot{s} = m \int_{\dot{s}(t_0)}^{\dot{s}(t)} \mathbf{1} = m \bigg[ \frac{\dot{s}(t)^2}{2} - \frac{\dot{s}(t_0)^2}{2} \bigg] \]
%
\[ \int_{t_0}^{t} (F \circ s) \dot{s} = \int_{x_0}^{s(t)} F \]
%
Therefore, if we define the potential energy $U$ at a point $x$ to be
%
\[ U(x) = - \int_{x_0}^{s(t)} F = \int_{s(t)}^{x_0} \]
%
And if we define the kinetic energy to be
%
\[ K(t) = \frac{m\dot{s}(t)^2}{2} \]
%
Then our above discussion amounts to the fact that, at any time $t$,
%
\[ (U \circ s)(t) + K(t) = \frac{m\dot{s}(t_0)}{2} = E \]
%
Which states that in this system, the conservation of energy holds.










\chapter{Mechanics in Differential Geometry}

Let us try and consider a coordinate independent, \emph{geometric} approach to mechanics. Thus we fix Euclidean space $\mathbf{E}$, viewed as a differential manifold, and we try and model the laws of mechanics in a coordinate independent way, with the hope that this will bring out the symmetries in the equation. We will find there are two approaches to defining momentum and force in a coordinate invariant way. First, we can consider them as \emph{vectors} on $\mathbf{E}$, i.e. so that a force and momentum is given in terms of a direction and magnitude on the manifold. Alternately, we can view them as \emph{covectors} on $\mathbf{E}$, so that force measures the work required to move in a particular direction on the manifold.

Let us begin by setting us the equations of motion if momentum $p$ is viewed as elements of $T \mathbf{E}$. Newton's law tells us that we should view $F$ as an element of $T(T \mathbf{E})$. Then Newton's law says that
%
\[ F = \frac{dp}{dt} \]
%
makes sense, and $F$ depends solely on the time, and position and velocity of the particle. To expand upon this geometrically, we consider two maps $\pi$ and $\Pi$ from $T(T \mathbf{E})$ to $T \mathbf{E}$, where $\pi$ is just the basepoint map, and $\Pi$ is obtained from differentiating the projection map $T \mathbf{E} \to \mathbf{E}$. We let $A$ be the \emph{equalizer} fiber subbundle of $T(T\mathbf{E})$ consisting of all $\mathbf{v} \in T(T\mathbf{E})$ such that $\pi(\mathbf{v}) = \Pi(\mathbf{v})$ (the \emph{semi spray condition}). Then we can consier $F$ as a kind of time dependent section $F: I \times T \mathbf{E} \to A$. We can model the momentum as $p: I \to T \mathbf{E}$, and then Newton's law becomes
%
\[ F(t,p) = \frac{dp}{dt}. \]
%
Working in coordinates, if $(x,y,z,v_x,v_y,v_z)$ are the coordinates on $T\mathbf{E}$ induced by the coordinates $(x,y,z)$ on $\mathbf{E}$, then, we can write
%
\[ F = v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_x \frac{\partial}{\partial v_x} + F_y \frac{\partial}{\partial v_y} + F_z \frac{\partial}{\partial v_z}, \]
%
for component functions $F_x,F_y,F_z: T \mathbf{E} \to \mathbf{R}$ (in any coordinates, the assumption that $F$ lies in $A$ amounts to the `first order' components of the vector field being determined). Let us also write the momentum in coordinates, i.e. as
%
\[ p = p_x \frac{\partial}{\partial x} + p_y \frac{\partial}{\partial y} + p_z \frac{\partial}{\partial z}, \]
%
where $p_x,p_y,p_z: I \to \mathbf{R}$ are the components of momentum. Then Newton's First Law reads precisely that, in Euclidean coordinates
%
\[ F_x = \frac{d p_x}{dt} \quad\text{and}\quad F_y = \frac{d p_y}{d t} \quad\text{and}\quad F_z = \frac{d p_z}{dt}. \]
%
These equations are elegant, but \emph{do not} remain elegant in more general coordinate systems. Indeed, let us work with cylindrical coordinates $(r,\theta,z)$, where $x = r \cos \theta$ and $y = r \sin \theta$. Then we can write
%
\[ p = p_r \frac{\partial}{\partial r} + p_\theta \frac{\partial}{\partial \theta} + p_z \frac{\partial}{\partial z} \]
%
for some new component functions $p_r,p_\theta: I \to \mathbf{R}$. If we consider the variables $(r,\theta,z,v_r,v_\theta,v_z)$ then we have
%
\[ F = v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_r \frac{\partial}{\partial v_r} + F_\theta \frac{\partial}{\partial v_\theta} + F_z \frac{\partial}{\partial v_z}, \]
%
for new functions $F_r,F_\theta: I \times T \mathbf{E} \to \mathbf{R}$. Then Newton's laws combine with a change of variables, telling us that
%
\begin{align*}
    F_r &= (\cos \theta) F_x + (\sin \theta) F_y\\
    &= (\cos \theta) \frac{d p_x}{dt} + (\sin \theta) \frac{d p_y}{dt}\\
    &= \cos \theta \frac{d}{dt} \left( \cos \theta p_r - r \sin \theta p_\theta \right) + \sin \theta \frac{d}{dt} \left( \sin \theta p_r + r \cos \theta p_\theta \right)\\
    &= \frac{dp_r}{dt} - r p_\theta \frac{d\theta}{dt}\\
    &= \frac{dp_r}{dt} - \frac{rp_\theta^2}{m},
\end{align*}
%
and
%
\begin{align*}
    F_\theta &= - \frac{\sin \theta}{r} F_x + \frac{\cos \theta}{r} F_y\\
    &= - \frac{\sin \theta}{r} \frac{dp_x}{dt} + \frac{\cos \theta}{r} \frac{dp_y}{dt}\\
    &= - \frac{\sin \theta}{r} \frac{d}{dt} \left( \cos \theta p_r - r \sin \theta p_\theta \right) + \frac{\cos \theta}{r} \frac{d}{dt} \left( \sin \theta p_r + r \cos \theta p_\theta \right)\\
    &= \frac{dp_\theta}{dt} + \frac{p_r}{r} \frac{d\theta}{dt} + \frac{dp_\theta}{dt} + \frac{p_\theta}{r} \frac{dr}{dt}\\
    &= \frac{dp_\theta}{dt} + \frac{2p_rp_\theta}{rm}.
\end{align*}
%
We get more elegant equations by switching to \emph{covector fields}.

We can also view $p$ as a \emph{covector}, i.e. as an element of $T^* \mathbf{E}$. Thus we write
%
\[ p = p_x dx + p_y dy + p_z dz, \]
%
where $p_x,p_y$, and $p_z$ are above. This is a coordinate dependent definition, but can be made coordinate independent. Indeed, if we define the metric $g^2 = m dx^2 + m dy^2 + m dz^2$ on $\mathbf{E}$, then we get a map $T\mathbf{E} \to T^*\mathbf{E}$ induced by the musical isomorphism with respect to this metric. A trajectory on $\mathbf{E}$ induces a velocity vector in a coordinate independent way, and thus we get a momentum vector by applying the isomorphism. If we define force $F$ to be a time dependent section $F: I \times T \mathbf{E} \to A$, where $A$ is a fiber subbundle of $T(T^* \mathbf{E})$ defined analogously to the bundle in the last paragraph. The musical isomorphism gives each position trajectory $x: I \to \mathbf{E}$ a momentum trajectory $p: I \to T^* \mathbf{E}$. Then Newton's law now becomes
%
\[ F \left( t, \frac{dx}{dt} \right) = \frac{dp}{dt}. \]
%
This approach tends to be more advantageous when considering energy approaches to Newtonian physics, i.e. Lagrangian and Hamiltonian approaches to the theory. Suppose that $F$ is a conservative force, which in the vector case, means that there exists a function $V: \mathbf{E} \to \mathbf{R}$ such that, in Euclidean coordinates, $(F_x,F_y,F_z) = - \nabla V$. This equation does not transform nicely with respect to general coordinate systems. But our formulation of momentum as a covector allows us to obtain an equivalent form that is coordinate independent. First, we begin by discussing a natural isomorphism
%
\[ j: T(T^* \mathbf{E}) \to T^*(T \mathbf{E}). \]
%
This can be done by analyzing the coordinate systems induced on an appropriate coordinate patch. Given a coordinate system $x$ on $\mathbf{E}$, we obtain a coordinate system $(x,\xi)$ and $(x,v)$ on $T^* \mathbf{E}$ and $T \mathbf{E}$. Then we get coordinate systems $(x,\xi,\alpha,\beta)$ and $(x,v,a,b)$ on $T(T^* \mathbf{E})$ and $T^*(T \mathbf{E})$. As we vary the coordinate system $x$, we note that $\alpha$ and $v$ transform covariantly, $\xi$ and $b$ transform contravariantly, and $\beta$ and $a$ transform `weirdly', but in a way which is compatible with one another. Thus the map given in coordinates by $j(x,\xi,\alpha,\beta) = (x,\alpha,\beta,\xi)$, with inverse $j^{-1}(x,v,a,b) = (x,b,v,a)$, is well defined globally, and gives an isomorphism. Now given a potential $V$ and a kinetic energy, we can define the \emph{Lagrangian} $L: T \mathbf{E} \to \mathbf{R}$ equal to the difference between potential and kinetic energy, i.e. such that for $v \in T_x \mathbf{E}$,
%
\[ L(v) = V(x) - (m/2) \langle v, v \rangle_g. \]
%
Then in Cartesian coordinates the differential map $dL: T \mathbf{E} \to T^*(T \mathbf{E})$ has
%
\[ dL(v) = - \left( F_x dx + F_y dy + F_z dz + p_x dv_x + p_y dv_y + p_z dv_z \right), \]
%
and so it is simple to compute that $(j \circ dL)(v)$ is the tangent vector to the corresponding moment $p \in T^*_x \mathbf{E}$ with coordinates
%
\[ (j \circ dL)(v) = - \left( v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} + F_x \frac{\partial}{\partial \xi} + F_y \frac{\partial}{\partial \eta} + F_z \frac{\partial}{\partial \zeta} \right) = - F( v ). \]
%
The equation $j \circ dL = - F$ is now \emph{coordinate independent}, and can be applied in an arbitrary coordinate system. In practice, we do not need to go through all this formality, since the relevant acceleration vectors are given by the components of $j \circ dL$ corresponding to the tangent vectors pointing in the tangential directions of $T^* \mathbf{E}$.

\begin{comment}
Here's an example of how this approach might work. Consider a double pendulum, i.e. a pendulum with two equal masses, one lying at the end of the pendulum, and one lying in the middle of the pendulum, under the influence of gravity. The connections between the masses and the overhead support are rigid enough that we can assume they cannot bend. It is therefore natural to consider this problem in the coordinate system $(\theta_1,\theta_2)$, where $\theta_1$ gives the angle of the deviation of the vertical line from the support to the middle mass, and $\theta_2$ gives the angle of the deviation of the vertical line from the middle mass to the end mass. If we consider Cartesian coordinates in which the support is centred at the origin, and the two connections have length $L$, then the coordinates of the middle mass is
%
\[ L (\sin \theta_1, - \cos \theta_1) \]
%
and the coordinates of the end mass is
%
\[ L (\sin \theta_1 + \sin \theta_2, - \cos \theta_1 - \cos \theta_2). \]
%
If we consider a constant force pulling down, then the potential energy in the system is therefore
%
\[ V(\theta_1,\theta_2) = - mg L \cos \theta_1 - mg L (\cos \theta_1 + \cos \theta_2) = - mgL \left( 2 \cos \theta_1 + \cos \theta_2 \right). \]
%
The momentum vector of each mass is equal to
%
\[ L m \cos(\theta_1) \dot{\theta_1} dx + Lm \sin(\theta_1) \dot{\theta_1} dy \]
\[ L (\cos \theta_1) \dot{\theta_1}, \sin \theta_1) \dot{\theta_1} \]

We compute that
%
\[ dV = 2mg L \sin \theta_1 \frac{\partial}{\partial \theta_1} + mg L \sin \theta_2 \frac{\partial}{\partial \theta_2}, \]
%


The momentum metric can be computed to be $g^2 = L m d\theta_1^2 + $
 
$g^2 = m $

The metric $g^2 = m dx^2 + m dy^2 + m dz^2$

and plugging these values into the $j$ functions, we find that
%
\[ F = v_\theta \cdot \frac{\partial}{\partial \theta} + v_{\theta_1} \]

Finally, we notice that this approach can be seen to geometrically visualize the correspondence between Newton's Laws, and the Lagrangian approach
\end{comment}










\end{document}