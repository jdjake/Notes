%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Classical Fourier Analysis}

Deep mathematical knowledge often arises hand in hand with the characterization of symmetry. Nowhere is this more clear than in the foundations of harmonic analysis, where we attempt to understand mathematical `signals' by the `frequencies' from which they are composed. In the mid 18th century, problems in mathematical physics led D. Bernoulli, D'Alembert, Lagrange, and Euler to consider periodic functions representable as a trigonometric series
%
\[ f(t) = A + \sum_{m = 1}^\infty B_n \cos(2 \pi mt) + C_n \sin(2 \pi mt). \]
%
In his book, Th\'{e}orie Analytique de la Chaleur, published in 1811, Joseph Fourier had the audacity to announce that {\it all} functions were representable in this form, and used it to sove linear partial differential equations in physics. His conviction is the reason the classical theory of harmonic analysis is often named Fourier analysis, where we analyze the degree to which Fourier's proclamation holds, as well as it's paired statement on the real line, that a function $f$ on the real line can be written as
%
\[ f(t) = \int_{-\infty}^\infty A(\xi) \cos(2 \pi \xi t) + B(\xi) \sin(2 \pi\xi t)\; d\xi. \]
%
for some functions $A$ and $B$ on the line.

In the 1820s, Poisson, Cauchy, and Dirichlet all attempted to form rigorous proofs that `Fourier summation' holds for all functions. Their work is responsible for most of the modern subject of analysis we know today. In particular, it is essential to utilize all the convergence techniques developed through the rigorous study of analysis. Under pointwise convergence, the representation of a function by Fourier series need not be unique. Uniform convergence is more useful, and uniform convergence holds for all smooth functions, but does not hold if we only assume a function is continuous. Thus we must introduce more subtle methods.

\chapter{Introduction}

One fundamental family of oscillatory functions in mathematics are the trigonometric functions
%
\[ f(t) = A \cos(st) + B \sin(st) = C \cos(st + \phi). \]
%
The value $\phi$ is the \emph{phase} of the oscillation, $C$ is the \emph{amplitude}, and $s/2\pi$ is the \emph{frequency} of the oscillation. These oscillatory functions occur in many situations; for instance, in the study of the solution of the harmonic oscillator. The main topic of Fourier analysis is to study how well one may represent a general function as an analytical combination of these trigonometric functions. In the periodic setting, we fix a function $f: \RR \to \CC$ such that $f(x + 1) = f(x)$ for all $x \in \RR$, and try and find coefficients $\{ A_m \}$, $\{ B_m \}$, and $C$ such that
%
\[ f(t) \sim C + \sum_{m = 1}^\infty A_m \cos(2 \pi mt) + B_m \sin(2 \pi mt). \]
%
In the continuous setting, we fix a function $f: \RR \to \CC$, trying to find values $A(s)$, $B(s)$, and $C$ such that
%
\[ f(t) \sim C + \int_0^\infty A(s) \cos(2 \pi st) + B(s) \sin(2 \pi st)\; ds. \]
%
The main contribution of Fourier was a method to formally find a reliable choice of coefficients which represents $f$. This choice is given by the \emph{Fourier transform} of $f$ in the continuous case, and the \emph{Fourier series} in the discrete case.

\section{Obtaining the Fourier Coefficients}

A \emph{formal trigonometric series} is a formal sum of the form
%
\[ C + \sum_{m = 1}^\infty A_m \cos(2\pi mt) + B_m \sin(2\pi mt). \]
%
Our goal, given a function $f$, is to find a family $\{ A_m \}$, $\{ B_m \}$, and $C$ which `represents' the function $f$. In particular, we say a periodic function $f$ \emph{admits a trigonometric expansion} if there is a series such that for each $t \in \RR$,
%
\[ f(t) = C + \sum_{m = 1}^\infty A_m \cos(2 \pi mt) + B_m \sin(2 \pi mt). \]
%
It is a \emph{very difficult question} to characterize which functions $f$ admit a trigonometric expansion. Nonetheless, Fourier found a way to formally associate a formal trigonometric series with any integrable periodic function. If the function is differentiable, then the trigonometric series gives a trigonometric expansion for the function. But even if this series does not give a trigonometric expansion for this function, the series itself still reflects many important properties of the function, which are of interest independant of their convergence to the function $f$.

\section{Orthogonality}

The key technique Fourier realized could be used to come up with a canonical trigonometric series for a function is \emph{orthogonality}. Note that the various frequencies of sine functions are orthogonal to one another, in the sense that
%
\[ \int_0^1 \sin(2 \pi mt) \sin(2\pi nt) = \int_0^1 \cos(2 \pi mt) \cos(2 \pi nt) = \begin{cases} 0 & : m \neq n, \\ 1/2 & : m = n, \end{cases} \]
%
and for any $m,n \in \ZZ$,
%
\[ \int_0^1 \sin(2 \pi mt) \cos(2 \pi nt) = 0. \]
%
This means that for a finite trigonometric sum
%
\[ f(t) = C + \sum_{m = 1}^N A_m \cos(2 \pi mt) + B_m \sin(2 \pi mt), \]
%
we have
%
\[ C = \int_0^1 f(t)\; dt, \]
\[ A_m = 2 \int_0^1 f(t) \cos(2 \pi mt)\; dt, \quad\text{and}\quad B_m = 2 \int_{-\pi}^\pi f(t) \sin(2 \pi mt)\; dt. \]
%
We note that these values may still be defined even if $f$ is not a trigonometric polynomial. Thus given \emph{any} periodic integrable function $f$, a reasonable candidate for the coefficients is given by the values $A_m$, $B_m$, and $C$ above. Unlike when $f$ is a trigonometric polynomial, we can have infinitely many non-zero coefficients.

There is an additional choice of oscillatory functions, which replaces the sine and cosine with a single family of trigonometric functions, and thus gives a more notationally convenient analysis. For $\xi, t \in \RR$, we let $e_\xi(t) = e^{2 \pi \xi i t}$. For each integer $n \in \ZZ$, $e_n$ is periodic with period 1. Applying orthogonality again, we find
%
\[ \int_0^1 e_n(t) \overline{e_m(t)}\; dt = \int_0^1 e_{n-m}(t) = \begin{cases} 0 & : m \neq n, \\ 1 & : m = n. \end{cases}  \]
%
Thus we can use orthogonality to find a natural choice of an expansion
%
\[ f(t) \sim \sum_{n \in \ZZ} C_n e^{2 \pi nit}, \]
%
given by setting
%
\[ C_n = \int_0^1 f(t) \overline{e_n(t)}\; dt = \int_0^1 f(t) e^{- 2 \pi i n t}\; dt. \]
%
Euler's formula $e^{nit} = \cos(nt) + i \sin(nt)$ shows this is the same as the Fourier expansion in sines and cosines. Thus the values $\{ A_m, B_m, C : m \geq 0 \}$ can be recovered from the values of $\{ C_m : m \in \ZZ \}$. Because of it's elegance, unifying the three families of coefficients, the expansion by complex exponentials is the most standard used in Fourier analysis today.

To summarize, we have shown a periodic integrable function $f: \RR \to \CC$ gives rise to a formal trigonometric series
%
\[ \sum_{m \in \ZZ} C_m e_m(t). \]
%
This is the \emph{Fourier series} of $f$. Because we will be concentrating on the Fourier series of a function, it is worth reserving a particular notation. Given a periodic, integrable function $f$, and an integer $m \in \ZZ$, we set
%
\[ \widehat{f}(m) = \int_0^1 f(t) \overline{e_m(t)}\; dt. \]
%
The Fourier series representation in terms of complex exponentials will be our choice throughout the rest of these notes. No deep knowledge of the complex numbers is used here. For most basic purposes, the exponential notation is just a simple way to represent the oscillations of sines and cosines in a unified manner.

\section{The Fourier Transform}

For a general function $f: \RR \to \CC$, we cannot rely \emph{just} on orthogonality, because the functions $\sin(2 \pi mx)$ are not integrable on the entirety of $\RR$, and therefore cannot be integrated against one another. Nonetheless, we can consider the functions $g_N: [0,1] \to \CC$ by setting $g_N(s) = f(N(s-1/2))$. Then for $|t| \leq N/2$, we can apply the usual Fourier series to conclude
%
\begin{align*}
    f(t) &= g_N(t/N+1/2)\\
    &\sim \sum_{m \in \ZZ} \widehat{g_N}(m) e^{2 \pi m i (t/N + 1/2)}\\
    &=  \sum_{m \in \ZZ} (-1)^m \left( \int_0^1 f(N(s-1/2)) e^{-2 \pi mis}\; ds \right) e^{2 \pi (m/N) it}\\
    &= \sum_{m \in \ZZ} \frac{1}{N} \left( \int_{-N/2}^{N/2} f(s) e^{-2\pi (m/N) i s}\; ds \right) e^{(m/N)it}.
\end{align*}
% u = N(s - 1/2)
% du = Nds
%
If we take $N \to \infty$, the exterior sum operates like a Riemann sum, so we might expect
%
\[ f(t) \sim \int_{-\infty}^\infty \left( \int_{-\infty}^\infty f(s) e^{-2 \pi \xi is}\; ds \right) e^{2 \pi \xi i t}\; d\xi. \]
%
The interior integral defines the \emph{Fourier transform} of the function $f$, given for each $\xi \in \RR$ as
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(s) e^{- 2 \pi \xi is}\; ds. \]
%
Thus the resultant \emph{Fourier inversion formula} takes the form
%
\[ f(t) \sim \int_{-\infty}^\infty \widehat{f}(\xi) e_\xi(t)\; d\xi. \]
%
As the \emph{limit} of a discrete series defined in terms of orthogonality, the Fourier transform possesses many of the same properties at the Fourier series. But the non-compactness causes issues which are not present in the case of Fourier series, and so the Fourier series theory is often a simpler theory to begin with.

\section{Multidimensional Theory}

Finally, we note that the Fourier series and Fourier transform are not relegated to a one dimensional theory. If $f: \RR^d \to \CC$ is periodic, in the sense that $f(x + n) = f(x)$ for each $x \in \RR^d$ and $n \in \ZZ^d$, then we can consider the natural higher dimensional Fourier series
%
\[ f(t) \sim \sum_{n \in \ZZ^d} \widehat{f}(n) e_n(t) \] 
%
where for each $\xi \in \RR^d$, $e_\xi: \RR^d \to \CC$ is the function given for each $t \in \RR^d$ by setting $e_\xi(t) = e^{2 \pi i \xi \cdot t}$, and
%
\[ \widehat{f}(n) = \int_{[0,1]^d} f(t) \overline{e_n(t)}\; dt \]
%
Similarily, for $f: \RR^d \to \CC$, we can consider the Fourier inversion formula
%
\[ f(t) \sim \int_{\RR^d} \widehat{f}(\xi) e_\xi(x)\; d\xi \]
%
where for each $\xi \in \RR^d$,
%
\[ \widehat{f}(\xi) = \int_{\RR^d} f(t) \overline{e_\xi(t)} \]
%
The basic theory of Fourier series and the Fourier transform in one dimension extends naturally to higher dimensions, as do the basic theories of orthogonality. On the other hand, the theory of convergence in higher dimensions requires much greater regularity in higher dimensions and many fundamental questions about the convergence of Fourier series here more nuance than in the lower dimensional theory.

%
%\begin{example}
%    This method can be used to find all harmonic functions $f$ on a rectangle $[0,\pi] \times [0,1]$, such that $f(0,y) = f(\pi,y) = 0$. Let us first attempt to find all separable solutions $f(x,y) = u(x) v(y)$. Then the equations defining harmonic functions tell us that
%    %
%    \[ u''v + v''u = 0 \]
%    %
%    or
%    %
%    \[ \frac{u''}{u} = - \frac{v''}{v} = - \lambda^2 \]
%    %
%    (we assume the constant factor is negative, since the constraints on $u$ would force $f$ to be trivial otherwise). Then we have
%    %
%    \[ u'' = - \lambda^2 u \]
%    %
%    so $u(x) = A \cos(\lambda x) + B \sin(\lambda x)$. The constraints that $u(0) = u(\pi) = 0$ force $A = 0$, and $\lambda \in \ZZ$. We may similarily solve the equation
%    %
%    \[ v'' = \lambda^2 v \]
%    %
%    to conclude $v(y) = M e^{\lambda y} + N e^{- \lambda y}$, so we obtain the solution set
%    %
%    \[ f(x,y) = \sin(n x) (Ae^{n y} + Be^{-ny}) \]
%    %
%    where $n \in \ZZ$, $A,B \in \RR$.

%    Now suppose we can write
%    %
%    \[ f(x,y) = \sum_{n = -\infty}^\infty \sin(nx) (A_n e^{ny} + B_n e^{-ny}) \]
%    %
%    Then
%    %
%    \[ f_0(x) = \sum_{n = -\infty}^\infty (A_n + B_n) \sin(nx) \]
%    \[ f_1(x) = \sum_{n = -\infty}^\infty (A_n e^n + B_n e^{-n}) \sin(nx) \]
%    %
%    So if $\widehat{f_0}$ and $\widehat{f_1}$ denote the sine coefficients of $f_0$ and $f_1$, then
%    %
%    \[ A_n + B_n = \widehat{f_0}(n)\ \ \ \ \ A_n e^n + B_n e^{-n} = \widehat{f_1}(n) \]
%    %
%    \[ A_n = \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} \]
%    %
%    \[ B_n = \widehat{f_0}(n) - \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} = \frac{e^n \widehat{f_0}(n) - \widehat{f_1}(n)}{e^n - e^{-n}} \]
%    %
%    Thus
%    %
%    \begin{align*}
%        f(x,y) &= \sum_{n = -\infty}^\infty \sin(nx) \left( \frac{(\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}) e^{ny} + (e^n \widehat{f_0}(n) - \widehat{f_1}(n)) e^{-ny}}{e^n - e^{-n}} \right)\\
%        &= \sum_{n = -\infty}^\infty \frac{\sin(nx)}{e^n - e^{-n}} [(e^{n(1-y)} - e^{n(y-1)}) \widehat{f_0}(n) + (e^{ny} - e^{-ny}) \widehat{f_1}(n)]\\
%        &= \sum_{n = -\infty}^\infty \left( \frac{\sinh n(1-y)}{\sinh n} \widehat{f_0}(n) + \frac{\sinh ny}{\sinh n} \widehat{f_1}(n) \right) \sin(nx)
%    \end{align*}
%\end{example}

%
%First, define the circle group $\TT$ to be the set of complex numbers $z$ with $|z| = 1$. Functions from $\TT$ to $\RR$ naturally correspond to $2 \pi$-periodic functions; given $g: \TT \to \RR$, the correspondence is given by the equation $f(t) = g(e^{it})$. Thus, when defining $2\pi$ periodic functions, we shall make no distinction between a function `defined in terms of $t$' and a function `defined in terms of $z$', after making the explicit identification $z = e^{it}$. Then an expansion of the form
%
%\[ f(t) = \sum_{k = 0}^\infty A_k \cos(kt) + \sum B_k \sin(kt) \]
%
%leads to an expansion
%
%\begin{align*}
%    f(z) &= \sum_{k = 0}^\infty A_k \Re[z^k] + B_k \Im[z^k]\\
%    &= \sum_{k = 0}^\infty A_k \left( \frac{z^k + z^{-k}}{2} \right) - i B_k \left( \frac{z^k - z^{-k}}{2} \right) = \sum_{k = -\infty}^\infty C_k z^k
%\end{align*}
%
%so a Fourier expansion on $[0,2\pi]$ is really just a power series expansion on the circle in disguise.
%
%Thus expanding a real-valued function in the exponentials $e_n(t) = e^{nit}$ is the same as expanding the function in terms of sines and cosines. The complex exponentials $e_n$ have the same orthogonality properties as $\sin$ and $\cos$, so given a function $f$, the coefficients $C_n$ can be found by the expansion
%
%\[ C_n = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_n(-t) dt \]

\section{Examples of Expansions}

Before we get to the real work, let's start by computing some examples of Fourier series and examples of the Fourier transform. We also illustrate the convergence properties of these series, which we shall look at in more detail later.

\begin{example}
    Consider the function $f: [0,\pi] \to \RR$ defined by $f(x) = x(\pi - x)$. Then a series of integration by parts gives that
    %
    \[ \int x(\pi - x) \sin(nx) = \frac{x(\pi - x) \cos(nx)}{n} + \frac{(\pi - 2x) \sin(nx)}{n^2} - \frac{2\cos(nx)}{n^3}. \]
    %
    Thus
    %
    \[ \frac{2}{\pi} \int_0^\pi x(\pi - x) \sin(nx) = \frac{4(1 - \cos(n\pi))}{n^3} = \begin{cases} \frac{8}{\pi n^3} & n\ \text{odd}, \\ 0 & n\ \text{even}. \end{cases}  \]
    %
    Thus we have a formal representation
    %
    \[ f(x) \sim \sum_{n\ \text{odd}} \frac{8 \sin(nx)}{\pi n^3}. \]
    %
    This sum converges absolutely and uniformly for $x \in [0,\pi]$. If we extend the domain of $f$ to $[-\pi,\pi]$ by making $f$ odd, then
    %
    \[ \widehat{f}(n) = \begin{cases} \frac{4}{\pi i n^3} & : n\ \text{odd}, \\ 0 & : n\ \text{even}. \end{cases} \]
    %
    In this case, we still have
    %
    \[ f(x) \sim \sum_{\substack{n\ \text{odd}\\ n > 0}} \frac{4}{\pi i n^3} [e_n(x) - e_n(-x)] = \sum_{n\ \text{odd}} \frac{8 \sin(nx)}{\pi n^3}. \]
    %
    This sum converges absolutely and uniformly on the entire real line.
\end{example}

\begin{example}
    The tent function
    %
    \[ f(x) = \begin{cases} 1 - \frac{|x|}{\delta} & : |x| < \delta, \\ 0 & : |x| \geq \delta. \end{cases} \]
    %
    is even, and therefore has a purely real Fourier expansion
    %
    \[ \widehat{f}(0) = \frac{\delta}{2\pi},\quad\widehat{f}(n) = \frac{1 - \cos(n\delta)}{\delta \pi n^2}. \]
    %
    Thus we obtain an expansion
    %
    \[ f(x) = \frac{\delta}{2\pi} + \sum_{n \neq 0} \frac{1 - \cos(n\delta)}{\delta \pi n^2} e_n(x) = \frac{\delta}{2 \pi} + 2 \sum_{n = 1}^\infty \frac{1 - \cos(n\delta)}{\delta \pi n^2} \cos(nx). \]
    %
    This sum also converges absolutely and uniformly on the entire real line.
\end{example}

\begin{example}
    Consider the characteristic function
    %
    \[ \chi_{(a,b)}(x) = \begin{cases} 1 & : x \in (a,b), \\ 0 & : x \not \in (a,b). \end{cases} \]
    %
    Then
    %
    \[ \widehat{\chi}_{(a,b)}(n) = \frac{1}{2\pi} \int_a^b e_n(-x) = \frac{e_n(-a) - e_n(-b)}{2\pi i n}. \]
    %
    Hence we may write
    %
    \begin{align*}
        \chi_{(a,b)}(x) &= \frac{b-a}{2\pi} + \sum_{n \neq 0} \frac{e_n(-a) - e_n(-b)}{2 \pi i n} e_n(x)\\
        &= \frac{b-a}{2\pi} + \sum_{n = 1}^\infty \frac{\sin(nb) - \sin(na)}{\pi n} \cos(nx) + \frac{\cos(na) - \cos(nb)}{\pi n} \sin(nx).
    \end{align*}
    %
    This sum does not converge absolutely for any value of $x$ (except when $a$ and $b$ are chosen trivially). To see this, note that
    %
    \[ \left|\frac{e_n(-b) - e_n(-a)}{2 \pi n}\right| = \left| \frac{1 - e_n(b-a)}{2 \pi n} \right| \geq \left| \frac{\sin(n(b-a))}{2 \pi n} \right|, \]
    %
    so that it suffices to show $\sum |\sin(nx)| n^{-1} = \infty$ for every $x \not \in \pi \ZZ$. This follows because the values of $|\sin(nx)|$ are often large, so that we may apply the divergence of $\sum n^{-1}$. First, assume $x \in (0,\pi/2)$. If
    %
    \[ m \pi - x/2 < nx < m \pi + x/2 \]
    %
    for some $m \in \ZZ$, then
    %
    \[ m \pi + x/2 < (n+1)x < m \pi + 3x/2 < (m+1) \pi - x/2. \]
    %
    Thus if $nx \in (-x/2,x/2) + \pi \ZZ$, $(n+1)x \not \in (-x/2,x/2) + \pi \ZZ$. For $y$ outside of $(-x/2,x/2) + \pi \ZZ$, we have $|\sin(y)| > |\sin(x/2)|$, and therefore for any $n$,
    %
    \[ \frac{|sin(nx)|}{n} + \frac{|\sin((n+1)x)|}{n+1} > \frac{|\sin(x/2)|}{n+1}. \]
    %
    This means
    %
    \begin{align*}
        \sum_{n = 1}^\infty \frac{|\sin(nx)|}{n} &= \sum_{n = 1}^\infty \frac{|\sin(2nx)|}{2n} + \frac{|\sin((2n+1)x)|}{2n+1}\\
        &> |\sin(x/2)| \sum_{n = 1}^\infty \frac{1}{2n+1} = \infty
    \end{align*}
    %
    In general, we may replace $x$ with $x - k \pi$, with no effect to the values of the sum, so we may assume $0 < x < \pi$. If $\pi/2 < x < \pi$, then
    %
    \[ \sin(nx) = \sin(n(\pi - x)), \]
    %
    and $0 < \pi - x < \pi/2$, completing the proof, except when $x = \pi$, in which case
    %
    \[ \sum_{n = 1}^\infty \left| \frac{1 - e_n(\pi)}{2 \pi n} \right| = \sum_{n\ \text{even}} \left| \frac{1}{\pi n} \right| = \infty. \]
    %
    Thus the convergence of a Fourier series need not be absolute.
\end{example}

\begin{comment}
\begin{example}
    We can often find formulas for certain Fourier summations from taking the corresponding power series. This is because if we set $z = e^{it}$, then
    %
    \[ \sum_{n = -\infty}^\infty a_n e^{nit} = \sum_{n = -\infty}^\infty a_n z^n \]
    %
    becomes a Laurent series in $z$. For instance, we have a power series expansion
    %
    \[ \log \left( \frac{1}{1-x} \right) = \sum_{k = 1}^\infty \frac{z^k}{k}. \]
    %
    This converges pointwise for every $z \in \mathbf{D}$ but $z = 1$. Thus for $x \not \in 2 \pi \ZZ$,
    %
    \begin{align*}
        \sum_{k = 1}^\infty \frac{\cos(kx)}{k} &= \Re \left( \log \left( \frac{1}{1 - e^{ix}} \right) \right) = -\frac{1}{2} \log(2 - 2\cos(x)),\\
        \sum_{k = 1}^\infty \frac{\sin(kx)}{k} &= \Im \left( \log \left( \frac{1}{1 - e^{ix}} \right) \right) = \arctan \left( \frac{\sin(x)}{1 - \cos(x)} \right).
    \end{align*}
    %
    Here we agree that $\arctan(\pm \infty) = \pm \pi/2$. One can check that, indeed, the Fourier series of these two functions corresponds precisely to these summations. If a power series' radius of convergence exceeds $1$, then it is likely that the corresponding Fourier series taken on the circle will be pleasant, whereas if the power series' radius is equal to $1$, we can expect nasty behaviour on the boundary, which actually works in our benefit because it enables us to represent more pathological functions by means of a Fourier series.
\end{example}
\end{comment}



\chapter{Fourier Series}

Let us now focus on the theory of \emph{Fourier series} we introduced in the last chapter. We write $\TT = \RR / \ZZ$, so that a function $f: \TT \to \CC$ is a complex-valued periodic function on the real line. We then have a metric on $\TT$ given by setting $d(t,s) = |t - s|$, where $|t| = \min_{n \in \ZZ} |t + n|$ for $t \in \TT$. The Lebesgue measure on $\RR$ induces a natural Borel measure on $\TT$, such that for any periodic function $f: \TT \to \CC$,
%
\[ \int_{\TT} f(t)\; dt = \int_0^1 f(t)\; dt. \]
%
It will also be of interest to consider the higher dimensional torii $\TT^d = \RR^d / \ZZ^d$, which naturally has the induced product metric and measure from $\TT$. For each $f \in L^1(\TT^d)$, we associate the \emph{formal trigonometric series}
%
\[ \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot t} \]
%
where for each $n \in \ZZ^d$,
%
\[ \widehat{f}(n) = \int_{\TT^d} f(t) e^{-2\pi i n \cdot t}\; dt. \]
%
In some sense, $f$ should be able to be approximated by the trigonometric polynomials obtained by truncating this series, and the study of the extent to which this is true is the primary goal of this chapter.

In one dimension, it is most natural to consider the partial sums
%
\[ \sum_{n = -N}^N \widehat{f}(n) e_n. \]
%
Notice that if $f$ is real-valued, then the complex parts of $\widehat{f}(n)$ and $\widehat{f}(-n)$ cancel out, so that $S_N f$ is a real-valued sum of cosines and sines. For each positive integer $N$, we set $S_N$ to be the operator such that for each $f \in L^1(\TT)$,
%
\[ S_N f = \sum_{n = -N}^N \widehat{f}(n) e_n. \]
%
In higher dimensions, no canonical `cutoff' is chosen. Two possible options are \emph{spherical summation}
%
\[ \sum_{|n| \leq N} \widehat{f}(n) e_n \]
%
and \emph{square summation}
%
\[ \sum_{n_1, \dots, n_d = -N}^N \widehat{f}(n) e_n. \]
%
There are subtle differences in these operators which cause problems in the higher dimensional theory. Nonetheless, most basic results do not really care about the domain we look at. Thus right now, all we assume in the higher dimensional case is that we are consider an increasing family of sets $\{ E_N \}$ in $\ZZ^d$ with $\lim_{N \to \infty} E_N = \ZZ^d$, and we then define
%
\[ S_N f = \sum_{n \in E_N} \widehat{f}(n) e_n \]
%
for $f \in L^1(\TT^d)$. If $E_N$ is a symmetric set for each $N$, then $S_N f$ will be real-valued if $f$ is real-valued, but this isn't of particular importance to us in the sequel.

An initial problem to study is what conditions on $f$ we must assume in order to conclude that $S_N f$ converges \emph{pointwise} to $f$, i.e. for each $t \in \TT^d$, $\lim_{N \to \infty} (S_N f)(t) = f(t)$. We will soon see that if $f \in C^\infty(\TT^d)$ then this statement will be true. But there are continuous periodic functions such that $S_N f$ does not converge pointwise everwhere to $f$. Thus we look at more exotic forms of convergence. Later on, we also look at other quantitative descriptions of convergence which provides an alternate, but closely related theory to study than the theory of pointwise convergence.

\section{Basic Properties of Fourier Series}

One of the most important properties of the Fourier series is that the coefficients are controlled by reasonable transformations. A basic, but unappreciated property of the Fourier transform is \emph{linearity}: For any two functions $f$ and $g$, if $h = f + g$, then $\widehat{h} = \widehat{f} + \widehat{g}$. Linearity is \emph{essential} to most methods in this book, and much remains unknown about nonlinear transforms. The Fourier series is also stable under various transformations which occur in analysis, which makes the Fourier series tractable to analyze, and therefore useful. We summarize these properties here:
%
\begin{itemize}
    \item For each $f \in L^1(\TT^d)$, define $f^* \in L^1(\TT^d)$ by setting $f^*(x) = \overline{f(x)}$. Then for each $n \in \ZZ^d$,
    %
    \[ \widehat{f^*}(n) = \overline{\widehat{f}(-n)}. \]
    %
    As a corollary, if $f$ is real-valued, then $\widehat{f}(-n) = \overline{\widehat{f}(n)}$ for each $n \in \ZZ^d$.

    \item For each $s \in \RR^d$, $m \in \ZZ^d$, and any $f \in L^1(\TT^d)$, define the translation and frequency modulation operators $T_s$ and $M_m$ by setting
    %
    \[ (T_s f)(t) = f(t + s) \quad\text{and}\quad (M_m f)(t) = e_m(t) f(t). \]

    %
    Similarily, for each function $C: \ZZ^d \to \CC$, for each $m \in \ZZ^d$ and $\xi \in \RR$, define
    %
    \[ (T_m C)(n) = C(n + m) \quad\text{and}\quad (M_\xi C)(n) = e_\xi(n) C(n). \]
    %
    Then for any $f \in L^1(\TT^d)$, $\widehat{T_s f} = M_s \widehat{f}$, and $\widehat{M_m f} = T_m \widehat{f}$.

    \item If $f \in L^1(\TT^d)$ is odd, then $\widehat{f}$ is odd, and if $f \in L^1(\TT^d)$ is even, $\widehat{f}$ is even.

    \item An easy integration by parts shows that if $f \in C^\infty(\TT^d)$, then for any $k \in \{ 1, \dots, d \}$, $\widehat{D^k f}(n) = 2 \pi i n_k \widehat{f}(n)$ for each $n \in \ZZ^d$. The proof follows from an easy integration by parts, so the claim is actually true for any $f$ with a weak derivative $D^k f$ in $L^1(\TT^d)$.
\end{itemize}

\begin{remark}
    We note that if $f \in L^1(\TT)$ is even, then $\widehat{f}$ is even, so formally
    %
    \[ f(t) \sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) + e_{-m}(t)] \sim \widehat{f}(0) + 2 \sum_{m = 1}^\infty \widehat{f}(m) \cos(mt). \]
    %
    Moreover,
    %
    \[ \widehat{f}(m) = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) \cos(mt)\; dt \]
    %
    If $f$ is an odd function, then the fact that $\widehat{f}$ is odd implies formally that
    %
    \[ f(t) \sim \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) - e_{-m}(t)] = 2i \sum_{m = 1}^\infty \widehat{f}(m) \sin(mt). \]
    %
    Thus we get a sine expansion, and moreover,
    %
    \[ \widehat{f}(m) = \frac{1}{2\pi i} \int_{-\pi}^\pi f(t) \sin(mt)\; dt. \]
    %
    This is one way to reduce the study of complex exponentials back to the study of sines and cosines, since every function can be written as a sum of an even and an odd function.
\end{remark}

\section{Unique Representation of a Function?}

If $S_N f$ converged pointwise to $f$ for each $f \in L^1(\TT^d)$, we could conclude that if $f$ and $g$ had the same Fourier coefficients, they must necessarily be equal. This is clearly not true, for $S_N f$ depends only on the equivalence class of $f$ in $L^1(\TT^d)$, with functions identified if they are equal almost everywhere. Nonetheless, if $f \in C(\TT^d)$ then there is no way to edit $f$ on a set of measure zero while preserving continuity. Thus we can hope for unique Fourier coefficients in this setting.

\begin{theorem}
    Suppose $f \in L^1(\TT^d)$. If $\widehat{f}(n) = 0$ for all $n \in \ZZ^d$, then $f$ vanishes at all it's continuity points.
\end{theorem}
\begin{proof}
    It suffices to prove that if $f \in L^1(\TT^d)$ is continuous at the origin, then $f(0) = 0$. We treat the real-valued case first. For every trigonometric polynomial $g(x) = \sum a_n e_n(-x)$, we have
    %
    \[ \int_{\TT} f(x) g(x) dx = \sum a_n \widehat{f}(n) = 0. \]
    %
    Suppose that $f$ is continuous at zero, and assume without loss of generality that $f(0) > 0$. Pick $\delta > 0$ such that if $|x| \leq \delta$, $f(x) > f(0)/2$. Consider the trigonometric polynomial
    %
    \[ g(x) = \prod_{k = 1}^d [\varepsilon + \cos(2 \pi x_k)] = \prod_{k = 1}^d \left[ \varepsilon + \frac{e^{2 \pi i x_k} + e^{- 2 \pi i x_k}}{2} \right], \]
    % (1 + e)^{d-1}(e + cos(2 pi delta))
    and where $\varepsilon > 0$ is small enough that if $|x| \geq \delta$, then $g(x) \leq B < 1$. We can then choose $0 < \eta < \delta$ such that if $|x| < \eta$, $g(x) \geq A > 1$. Finally, if $\delta$ is sufficiently small, we also have $g(x) > 0$ if $0 \leq |x| \leq \delta$. The series of trigonometric polynomials $g_n(x) = g(x)^n$ satisfy
    %
    \begin{align*}
        \left| \int_{\TT^d} g_n(x) f(x) dx \right| &\geq \int_{|x| \leq \delta} g_n(x) f(x) dx - \left| \int_{|x| \geq \delta} g_n(x) f(x) dx \right|.
    \end{align*}
    %
    H\"{o}lder's inequality guarantees that as $n \to \infty$,
    %
    \[ \left| \int_{|x| \geq \delta} g_n(x) f(x) dx \right| \lesssim B^n. \]
    %
    On the other hand,
    %
    \[ \left| \int_{|x| \leq \delta} g_n(x) f(x) dx \right| \geq \int_{|x| < \delta/2} g_n(x) f(x) \gtrsim A^n. \]
    %
    Thus we conclude
    %
    \[ 0 = \left| \int_0^1 g_n(x) f(x) dx \right| \gtrsim A^n - B^n. \]
    %
    For suitably large values of $n$, the right hand side is positive, whereas the left hand side is zero, which is impossible. By contradiction, we conclude $f(0) = 0$. In general, if $f$ is complex valued, then we may write $f = u + iv$, where
    %
    \[ u(x) = \frac{f(x) + \overline{f(x)}}{2}\ \ \ \ v(x) = \frac{f(x) - \overline{f(x)}}{2i}. \]
    %
    The Fourier coefficients of $\overline{f}$ all vanish, because the coefficients of $f$ vanish, and so we conclude the coefficients of $u$ and $v$ vanish. $f$ is continuous at $x$ if and only if $u$ and $v$ are continuous at $x$, so we can apply the real-valued case to complete the proof in the case of complex values.
\end{proof}

\begin{corollary}
    If $f,g \in C(\TT^d)$ and $\widehat{f} = \widehat{g}$, then $f = g$.
\end{corollary}
\begin{proof}
    Then $f - g$ is continuous with vanishing Fourier coefficients.
\end{proof}

\begin{corollary}
    If $f \in C(\TT^d)$ and $\widehat{f} \in L^1(\ZZ^d)$, $S_N f \to f$ uniformly as $N \to \infty$.
\end{corollary}
\begin{proof}
    If
    %
    \[ \sum_{n \in \ZZ^d} |\widehat{f}(n)| < \infty, \]
    %
    It is easy to see from this that the sequence $\{ S_N f \}$ is Cauchy in the $L^\infty(\TT^d)$ norm. Because $L^\infty(\TT^d)$ is complete, $S_N f$ converges uniformly to some function $Sf \in C(\TT^d)$. Uniform convergence also implies we can interchange integrals to conclude
    %
    \[ \widehat{Sf}(n) = \lim_{N \to \infty} \int_{\TT^d} S_N(f) \cdot \overline{e_n} = \widehat{f}(n). \]
    %
    Thus $\widehat{Sf} = \widehat{f}$. But since $f$ and $Sf$ are continuous, this implies $f = Sf$.
\end{proof}

\begin{remark}
    Conversely, if $f \in L^1(\TT^d)$ and $\widehat{f} \in L^1(\ZZ^d)$, then $S_N f$ converges uniformly to a function $Sf \in C(\TT^d)$ with $\widehat{Sf} = \widehat{f}$. We will soon see this implies $f = Sf$ almost everywhere. Thus the Fourier series formula can only be interpret literally for continuous functions with integrable Fourier coefficients.
\end{remark}

Later we show that if $f \in C^m(\TT^d)$, then $\widehat{f}(n) = O(1/|n|^m)$. In particular, if $m \geq d + 1$, then $S_N f \to f$ uniformly. Moreover, if $f \in C^\infty(\TT)$, then this shows the $k$'th derivatives $(S_N f)^{(k)}$ converge uniformly to $f^{(k)}$ for each $k$, and $\widehat{f}(m) = O_m(|n|^{-m})$ for each $m \geq 1$. Conversely, if $\{ a_m : m \in \ZZ^d \}$ is a sequence with $|a_m| = O_m(|n|^{-m})$ for each $m \geq 1$, then the infinite sum $\sum a_m e^{mix}$ and all it's derivatives converge uniformly to an infinitely differentiable function $f \in C^\infty(\TT)$, and $\widehat{f}(n) = a_n$ for each $n \in \ZZ^d$. Thus there is a perfect duality between infinitely differentiable functions and arbitrarily fast decaying sequences of integers. In more advanced contexts, like distribution theory, this duality is very useful for studying the Fourier transform.

\section{Quantitative Bounds on Fourier Coefficients}

In practical contexts, most functions we deal with are arbitrarily smooth, so the picture established in the last section seems rather complete. However, a deeper understanding of the Fourier series involves studying more quantitative questions. For instance, does the Fourier series of a function which is uniformly small converge faster than a function which is only small on average. In modern terms, do we get faster convergence rates if $\| f \|_{L^\infty(\TT^d)}$ is small rather than just if $\| f \|_{L^1(\TT^d)}$ is small. Thus we want to understand the behaviour of the Fourier series with respect to a family of \emph{norm spaces}. Similarily, how does the Fourier series of a function $f$ change under a small pertubation in a particular norm space. Of course, these norms are defined in a more general space of measurable functions, and to apply functional analysis arguments it is essential to `complete' the picture of these norms, so we will find that many of our arguments, initially invented to study smooth functions, also work naturally with arbitrarily integrable functions. On the other hand, the density of regular functions in these norm spaces indicates that the behaviour of Fourier summation on an infinitely differentiable space with respect to a norm is at least as bad as the behaviour of Fourier summation on an integrable function.

We note these quantitative problems are still interesting even if we knew everything there was to know about the pointwise convergence of Fourier series, because a series of functions may converge pointwise, whereas none of the individual functions may `look' like the function they converge to. So we may want to look at quantitative measures of how globally similar two functions are, and this leads to norm space estimates.

\begin{example}
    If we consider a square wave $\chi_I$ for some interval $I$, then the techniques of the following section allow us to prove that
    %
    \[ \| \chi_I - S_N \chi_I \|_{L^2(\TT)} \sim 1/\sqrt{N}, \]
    %
    independently of $I$. This means that if we want to simulate square waves with a musical instrument up to some square mean error $\varepsilon$, then we will need about $1/\varepsilon^2$ different notes to represent the sound accurately. Thus a piano with 88 keys can only approximate square waves slightly better than a keyboard with 20 keys. If $f \in C^{m+1}(\TT^d)$, then we will see
    %
    \[ \| f - S_N f \|_{L^2(\TT)} \lesssim 1/N^{m/2}, \]
    %
    so we require significantly less notes to simulate this sound, i.e. $\varepsilon^{-2/m}$. In this case a piano can simulate these sounds much more accurately.
\end{example}

One initial equation which might summarize how well behaved the Fourier series is with respect to suitable norms would be to obtain an estimate of the form $\smash{\| \widehat{f} \|_{L^q(\ZZ^d)} \lesssim \| f \|_{L^p(\TT^d)}}$ for particular values of $p$ and $q$. This does not explicitly answer a question about convergence, but still shows that the Fourier series is stable under small pertubations in the norm on $L^p(\TT^d)$. The first inequality we give is trivial, but is certainly tight, e.g. for $f(t) = e_n(t)$.

\begin{theorem}
    For any $f \in L^1(\TT^d)$, $\| \widehat{f} \|_{L^\infty(\TT^d)} \leq \| f \|_{L^1(\TT^d)}$.
\end{theorem}
\begin{proof}
    We just take absolute values into the oscillatory integral defining the Fourier coefficients, calculating that for any $n \in \ZZ^d$,
    %
    \[ |\widehat{f}(n)| = \left| \int_{\TT^d} f(t) \overline{e_n(t)} \right| \leq \int_{\TT^d} |f(t)| = \| f \|_{L^1(\TT^d)}, \]
    %
    which was the required bound.
\end{proof}

This proof doesn't really take any deep features of the Fourier coefficients. The same bound holds for any integral
%
\[ \int_{\TT} f(t) K(t)\; dt, \]
%
where $|K(t)| \leq 1$ for all $t$. But the bound is still tight, which might be explained by the fact that the Fourier series gives oscillatory information which is not immediately present in the $L^1$ norms of the phase spaces, other than by taking a naive absolute bound into the $L^1$ norm. The only $L^p$ norm where we can get a completely satisfactory bound is for $p = 2$. Here we can use Hilbert space technique; this should be expected since orthogonality was implicitly used to define the Fourier series.

\begin{theorem}
    For any function $f \in L^2(\TT^d)$, $\| \widehat{f} \|_{L^2(\ZZ^d)} = \| f \|_{L^2(\TT^d)}$.
\end{theorem}
\begin{proof}
    With respect to the normalized inner product on the space $L^2(\TT^d)$,the calculations of the last chapter tell us that the exponentials $\{ e_n : n \in \ZZ^d \}$ are an orthonormal family of functions, in the sense that for distinct pair $n,m \in \ZZ^d$, $(e_n,e_m) = 0$ and $(e_n,e_n) = 1$. Since $\smash{\widehat{f}(n) = (f,e_n)}$, we apply Bessel's inequality to conclude
    %
    \[ \| \widehat{f} \|_{L^2(\ZZ^d)} \leq \| f \|_{L^2(\TT^d)}. \]
    %
    The exponentials $\{ e_n \}$ are actually an orthonormal basis for $L^2(\TT^d)$; This can be seen from the Stone Weirstrass theorem, since trigonometric polynomials separate points, or by results we prove independently, later on in these notes. Thus Parsevel's equality tells us $\| \widehat{f} \|_{L^2(\ZZ^d)} = \| f \|_{L^2(\TT^d)}$.
\end{proof}

This equality makes the Hilbert space $L^2(\TT^d)$ often the best place to understand Fourier expansion techniques, and general results are often achieved by reduction to this well understood case. For instance, the inequality above, combined with the trivial inequality, is easily interpolated using the Riesz-Thorin technique to give the Hausdorff Young inequality.

\begin{theorem}
    If $1 \leq p \leq 2$, and $f \in L^p(\TT^d)$, then $\| \widehat{f} \|_{L^{p^*}(\ZZ^d)} \leq \| f \|_{L^p(\TT^d)}$.
\end{theorem}

It might be surprising to note that the Hausdorff Young inequality essentially completes the bounds on the Fourier series with respect to the $L^p$ norms. There is no interesting result one can obtain for $p > 2$ other than the obvious inequality
%
\[ \| \widehat{f} \|_{L^2(\ZZ^d)} \leq \| f \|_{L^2(\TT^d)} \leq \| f \|_{L^p(\TT^d)}. \]
%
Thus we can control the magnitude of the Fourier coefficients in terms of the width of the original function, but we are limited in our ability to control the width of the Fourier coefficients in terms of the magnitudes of the original function. This makes sense, because the $L^p$ norm of $f$ measures fairly different aspects of the function than the $L^q$ norm of the Fourier transform of $f$. It is only in the case of the $L^2$ norm where results are precise, and where $p$ is small that we can take a trivial bound, that we get an inequality like the Hausdorff Young result.

\section{Asymptotic Decay of Fourier Series}

The next result, known as Riemann-Lebesgue lemma, shows that the Fourier series of any integrable function decays, albeit arbitrarily slowly. The proof we give is an instance of an important principle in Functional analysis that we will use over and over again. Suppose for each $n$, we have a bounded operator $T_n: X \to Y$ between norm spaces, and we want to show that for each $x \in X$, $\lim_{n \to \infty} T_n(x) = T(x)$, where $T$ is another bounded operator. Suppose there is a dense set $X_0 \subset X$ such that for each $x_0 \in X_0$, $\lim_{n \to \infty} T_n(x_0) = T(x_0)$, and the family of operators $\{ T_n \}$ are {\it uniformly} bounded in operator norm. Then for any $x \in X$,
%
\begin{align*}
    \| T_n(x) - T(x) \| &\leq \| T_n(x) - T_n(x_0) \| + \| T_n(x_0) - T(x_0) \| + \| T(x_0) - T(x) \|.
\end{align*}
%
If we choose $x_0$ such that $\| x - x_0 \| \leq \varepsilon$, then for $n$ large enough we find that $\| T_n(x) - T(x) \| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, this means that $T_n(x) \to T(x)$ as $n \to \infty$. If we are working in a Banach space, the uniform boundedness says obtaining a uniform operator norm bound on $\{ T_n \}$ is the \emph{only} way to obtain this convergence.

The advantage of the principle is that it is suitably abstract, and can thus be used very flexibly. But the disadvantage is that it is a very soft analytical argument, and cannot be used to obtain results on the rate of convergence of $T_n(x)$ to $T(x)$. Here is a simple application.

\begin{lemma}[Riemann-Lebesgue]
    If $f \in L^1(\TT^d)$, then $\widehat{f}(n) \to 0$ as $|n| \to \infty$.
\end{lemma}
\begin{proof}
    We claim the lemma is true for the characteristic function $\chi_I$ of a cube $I$. If $I = [a_1,b_1] \times \dots \times [a_d,b_d]$, then it is simple to calculate that
    %
    \[ \widehat{\chi_I}(n) = \prod_{k = 1}^d \frac{e_n(-b_k) - e_n(-a_k)}{-in} = O(1/n) \]
    %
    By linearity of the integral, the Fourier transform of any step function vanishes at $\infty$. But if
    %
    \[ \Lambda_n(f) = \widehat{f}(n), \]
    %
    then
    %
    \[ |\Lambda_n f| \leq \| \widehat{f} \|_{L^\infty(\TT)} \leq \| f \|_{L^1(\TT)}, \]
    %
    which shows that the sequence of functionals $\{ \Lambda_n \}$ are uniformly bounded as linear functions on $L^1(\TT^d)$. Since $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for any step function $f$, and the step functions are dense in $L^1(\TT^d)$, we conclude that
    %
    \[ \lim_{|n| \to \infty} \Lambda_n(f) = 0 \]
    %
    for all $f \in L^1(\TT^d)$.
\end{proof}

Even though the Fourier series of any step function decays at a rate $O(1/n)$, it is {\it not} true that a general Fourier series decays at a rate of $O(1/n)$. And in fact, for any sequence of non-negative numbers $\{ \varepsilon_m \}$ with $\varepsilon_m \to 0$ as $|m| \to \infty$, there exists a continuous function $f$ such that $|\widehat{f}(n)| \geq \varepsilon_n$ for infinitely many values $n$. One simply chooses a subsequence $\varepsilon_{m_k}$ with $\sum \varepsilon_{m_k} < \infty$ and considers the resulting trigonometric series
%
\[ \sum_{k = 1}^\infty \varepsilon_{m_k} e_{m_k} \]
%
which converges absolutely to the continuous function. This is precisely the penalty for using a soft type analytical argument. Nonetheless, for smooth functions, we can obtain a uniform decay rate. This is an instance of a general result relating the duality because decay and smoothness in phase and frequency space.

\begin{theorem}
    If $f \in C^m(\TT^d)$, then for each $n \in \ZZ^d$,
    %
    \[ |\widehat{f}(n)| \lesssim_{d,m} |n|^{-m} \max_{1 \leq i \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}. \]
\end{theorem}
\begin{proof}
    We have
    %
    \[ \widehat{\partial_i^m f}(\xi) = (2 \pi i \xi_i)^m \widehat{f}(\xi). \]
    %
    Thus
    %
    \[ |\widehat{f}(\xi)| \leq \frac{|\partial_i^m f|(\xi)|}{(2\pi |\xi_i|)^m} \leq \frac{\| \partial_i^m f \|_{L^1(\TT^d)}}{(2 \pi |\xi_i|)^m}. \]
    %
    But taking infima over all $1 \leq i \leq d$, we find
    %
    \[ |\widehat{f}(\xi)| \leq \frac{\max_{1 \leq k \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}}{[2 \pi \max |\xi_i| |]^m} \leq \frac{d^{1/2}}{(2\pi)^m} \frac{\max_{1 \leq i \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}}{|\xi|^m}. \qedhere \]
\end{proof}

If $0 < \alpha < 1$, we say a function $f$ is \emph{H\"{o}lder continuous} of order $\alpha$ if there exists a constant $A$ such that $|f(x + h) - f(x)| \leq A |h|^\alpha$ for all $x, h \in \TT^d$. We define
%
\[ \| f \|_{C^{0,\alpha}(\TT^d)} = \sup_{x,h \in \TT^d} \frac{|f(x + h) - f(x)}{|h|^\alpha}. \]
%
Then the space $C^{0,\alpha}(\TT^d)$ of all functions satisfying a H\"{o}lder condition of order $\alpha$ forms a Banach space.

\begin{theorem}
    If $f \in C^{0,\alpha}(\TT^d)$, then $|\widehat{f}(n)| \lesssim_d \| f \|_{C^{0,\alpha}(\TT^d)} |n|^{-\alpha}$ for all $n \in \ZZ^d$.
\end{theorem}
\begin{proof}
    Fix $n \in \ZZ^d$. Then there is some $k \in \{ 1, \dots, d \}$ such that $|n_k| \gtrsim_d |n|$.  We calculate that by periodicity,
    %
    \[ \widehat{f}(n) = - \int_{\TT^d} f(x + e_k/n_k) \overline{e_n(x)}\; dx, \]
    %
    so
    %
    \[ \widehat{f}(n) = \frac{1}{2} \int_{\TT^d} [f(x) - f(x + e_k/n_k)] \overline{e_n(x)}\; dx. \]
    %
    Thus taking in absolute values and applying H\"{o}lder continuity gives
    %
    \[ |\widehat{f}(n)| \leq \frac{\| f \|_{C^{0,\alpha}(\TT^d)}}{2 |n_k|^\alpha} \lesssim_d \frac{\| f \|_{C^{0,\alpha}(\TT^d)}}{|n|^\alpha}. \qedhere \]
\end{proof}

\begin{remark}
    Suppose that $\mu$ is a measure on $\TT^d$ with finite variation, for which we write $\mu \in M(\TT^d)$. Then one can define the Fourier series of $\mu$ by setting
    %
    \[ \widehat{\mu}(n) = \int_{\TT^d} \overline{e_n(t)} d\mu(t). \]
    %
    If $\mu$ is absolutely continuous with respect to the normalized Lebesgue measure on $\TT$, and $d\mu = f dx$, then $\widehat{\mu} = \widehat{f}$, so this is an extension of the Fourier series from integrable functions to measures with finite variation. One can verify that
    %
    \[ \| \widehat{\mu} \|_{L^\infty(\ZZ^d)} \leq \| \mu \|_{M(\TT^d)}. \]
    %
    If $\delta$ is the Dirac delta measure at the origin, i.e. $\mu(E) = 1$ if $0 \in E$, and $\mu(E) = 0$ otherwise, then for all $n$,
    %
    \[ \widehat{\delta}(n) = 1. \]
    %
    Thus the Fourier series of $\delta$ has no decay at all. Once can view this as saying functions are `smoother' than measures, and therefore have a Fourier decay. Indeed, a measure $\mu$ on $\RR^d$ is absolutely continuous with respect to the Lebesgue measure if and only if
    %
    \[ \int_{\RR^d} |\mu(x + y) - \mu(x)|\; dx \to 0 \]
    %
    as $y \to 0$ (see Bochner, Lectures on Fourier Integrals).
\end{remark}

\section{Convolution and Kernel Methods}

The notion of the convolution of two functions $f$ and $g$ is a key tool in Fourier analysis, both as a way to regularize functions, and as an operator that transforms nicely when we take Fourier series. Given two integrable functions $f$ and $g$, we define
%
\[ (f * g)(t) = \int_{\TT} f(s) g(t-s)\; ds. \]
%
Thus we smear the values of $g$ with respect to a density function $f$.

\begin{lemma}
    For any $1 \leq p < \infty$, and $f \in L^p(\TT^d)$, $\lim_{h \to 0} T_h f = f$ in $L^p(\TT^d)$.
\end{lemma}
\begin{proof}
    If $f$ is $C^1(\TT^d)$, then $|f(x + h) - f(x)| \lesssim_f h$ uniformly in $x$, implying that $\| T_h f - f \|_{L^p(\TT^d)} \leq \| T_hf - f \|_{L^\infty(\TT^d)} \lesssim_f h$, and so $T_h f \to f$ in all the spaces $L^p(\TT^d)$. We have $\| T_h f \|_{L^p(\TT^d)} = \| f \|_{L^p(\TT^d)}$, so the operators $\{ T_h \}$ are uniformly bounded. Since $C^1(\TT^d)$ is dense in $L^p(\TT^d)$ for $1 \leq p < \infty$, we conclude that $\lim_{h \to 0} T_h f = f$ for all $f \in L^p(\TT^d)$.
\end{proof}

\begin{theorem}
    Convolution has the following properties:
    %
    \begin{itemize}
        \item If $f \in L^p(\TT^d)$ and $g \in L^q(\TT^d)$, for $1/p + 1/q = 1$, then $f * g$ is uniformly continuous.

        \item If $f \in L^p(\TT^d)$ and $g \in L^q(\TT^d)$, and if we define $r$ so that $1/r = 1/p + 1/q - 1$, with $1 \leq r \leq \infty$, then $f * g$ is well-defined by the convolution integral formula almost everywhere, and
        %
        \[ \| f * g \|_{L^r(\TT^d)} \leq \| f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}. \]
        %
        This is known as {\it Young's inequality} for convolutions.

        \item Convolution is a commutative, associative, bilinear operation.

        \item If $f,g \in L^1(\TT)$, then $\widehat{f * g} = \widehat{f} \widehat{g}$.

        \item If $f$ has a weak derivative $D^kf$ in $L^1(\TT^d)$, then $f * g$ has a weak derivative in $L^1(\TT^d)$, and $D^k(f * g) = D^k f * g$. Thus convolution is `additively smoothing'. In particular, if $f \in C^k(\TT^d)$ and $g \in C^l(\TT^d)$, then $f * g \in C^{k+l}(\TT^d)$.

        \item If $f$ is supported on $E \subset \TT^d$, and $g$ on $F \subset \TT^d$, then $f * g$ is supported on $E + F$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Suppose $f \in L^p(\TT^d)$, and $g \in L^q(\TT^d)$, then
    %
    \begin{align*}
        |(f * g)(t - h) - (f * g)(t)| &\leq \int_{\TT^d} |f(t-h-s) - f(t-s)| |g(s)|\; ds\\
        &\leq \| f_h - f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}.
    \end{align*}
    %
    The right hand side is a bound independant of $t$ and converges to zero as $h \to 0$, so $f * g$ is uniformly continuous. Applying H\"{o}lder's inequality again gives that $\| f * g \|_{L^\infty(\TT^d)} \leq \| f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}$. If $f \in L^p(\TT^d)$, and $g \in L^1(\TT^d)$, we use Minkowski's inequality to conclude that
    %
    \begin{align*}
        \| f * g \|_{L^p(\TT^d)} &= \left( \int_{\TT^d} \left| \int_{\TT^d} f(t-s)g(s)\; ds \right|^p\; dt \right)^{1/p}\\
        &\leq \int_{\TT^d} \left( \int_{\TT^d} |f(t-s)g(s)|^p\; dt \right)^{1/p}\; ds\\
        &= \int_{\TT^d} g(s) \| f \|_{L^p(\TT^d)}\; ds = \| f \|_{L^p(\TT^d)} \| g \|_{L^1(\TT^d)}.
    \end{align*}
    %
    Thus $f * g$ is finite almost everywhere. The inequality also implies that
    %
    \[ \| f * g \|_{L^p(\TT^d)} \leq \| f \|_{L^1(\TT^d)} \| g \|_{L^p(\TT^d)} \]
    %
    if $f \in L^1(\TT^d)$, and $g \in L^p(\TT^d)$. But now implying Riesz-Thorin interpolation gives the general Young's inequality. Elementary applications of change of coordinates and Fubini's theorem establish the commutativity and associativity of convolution for functions $f, g \in L^1(\TT^d)$.
    %
    %But $L^1(\TT) \cap L^p(\TT)$ is dense in $L^p(\TT)$. Since $f * g = g * f$ for a dense family of functions, and convolution is continuous from $L^p(\TT) \times L^q(\TT) \to L^r(\TT)$, we obtain the identity for the more general families of functions.
    Similarily, one can apply Fubini's theorem to obtain associativity for $f,g,h \in L^1(\TT^d)$. To obtain the product identity for the Fourier series, we can apply Fubini's theorem to write
    %
    \begin{align*}
        \widehat{f * g}(n) &= \int_{\TT^d} (f * g)(t) e_n(-t)\ dt\\
        &= \int_{\TT^d} \int_{\TT^d} f(s)g(t-s) e_n(-t)\ ds\ dt\\
        &= \int_{\TT^d} f(s) \int_{\TT^d} (L_{-s}g)(t) e_n(-t)\ dt\ ds\\
        &= \int_{\TT^d} f(s) e_n(-s) \widehat{g}(n)\ ds\\
        &= \widehat{f}(n) \widehat{g}(n),
    \end{align*}
    %
    and this is exactly the identity required. To calculate the weak derivative of $f * g$, we fix $\phi \in C^\infty(\TT^d)$, and calculate using two applications of Fubini's theorem that
    %
    \begin{align*}
        \int_{\TT^d} (f' * g)(t) \phi(t)\; dt &= \int_{\TT^d} \int_{\TT^d} f'(t-s) g(s) \phi(t)\; ds\; dt\\
        &= \int_{\TT^d} g(s) \int_{\TT^d} f'(t-s) \phi(t)\; dt\; ds\\
        &= - \int_{\TT^d} g(s) \int_{\TT^d} f(t-s) \phi'(t)\; dt\; ds\\
        &= - \int_{\TT^d} \left( \int_{\TT^d} g(s) f(t-s)\; ds \right) \phi'(t)\; dt\\
        &= - \int_{\TT^d} (f * g)(t) \phi'(t)\; dt.
    \end{align*}
    %
    If $f = 0$ a.e outside $E$, and $g = 0$ a.e. outside $F$, then $(f * g)(t)$ can be nonzero only when there is a set $G$ of positive measure such that for any $s \in G$, $f(s) \neq 0$ and $g(t-s) \neq 0$. But this means that $E \cap G \cap (t-F)$ has positive measure, so that there is $s \in E$ such that $t-s \in F$, meaning that $t \in E + F$.
\end{proof}

We know that suitably smooth functions have convergent Fourier series. The advantage of convolution is if we want to study the properties of a function $f$, convolution with a smooth function $g$ gives a smooth function, and provided $\smash{\widehat{g}}$ is close to 1, $\smash{\widehat{f*g}}$ will be close to $\widehat{f}$. If we can establish the convergence properties on the convolution $f * g$, then we can probably obtain results about $f$. From the frequency side, $\sum \widehat{f}(n) e_n$ might not converge, but $\sum a_n \widehat{f}(n) e_n$ might converge for a suitably fast decaying sequence $a_n$. But if $a_n$ is close to one, this sequence might still reflect properties of the original sequence.

\begin{example}
    Given a function $f \in L^1(\TT^d)$ we define the \emph{autocorrelation function}
    %
    \[ R(\tau) = \int_{\TT^d} f(t + \tau) \overline{f(t)}\; dt. \]
    %
    Then $R$ is the convolution of $f(t)$ with $g(t) = \overline{f(-t)}$. Thus for $f \in L^1(\TT^d)$, $R \in L^1(\TT^d)$, and
    %
    \[ \widehat{R}(n) = \widehat{f}(n) \overline{\widehat{f}(n)} = |\widehat{f}(n)|^2. \]
    %
    The function $\widehat{R}$ is known as the \emph{power spectrum} of $f$.
\end{example}

To make rigorous the idea of approximating the Fourier series of a function, we introduce families of \emph{good kernels}. A good kernel is a sequence of integrable functions $\{ K_n \}$ on $\TT$ bounded in $L^1$ norm, for which
%
\[ \int_{\TT} K_n(t) = 1. \]
%
so that integration against $K_n$ operates essentially like an average, and for any $\delta > 0$,
%
\begin{equation} \label{goodkerneldecaycondition}
    \lim_{n \to \infty} \int_{|t| > \delta} |K_n(t)| \to 0.
\end{equation}
%
Thus the functions $\{ K_n \}$ become concentrated at the origin as $n \to \infty$.If in addition, we have an estimate $\| K_n \|_{L^\infty(\TT^d)} \lesssim n^d$, we say it is an \emph{approximation to the identity}.

\begin{example}
    The simplest way to obtain a good kernel is to fix $K \in L^1(\TT^d)$ with
    %
    \[ \int_{\TT^d} K(x)\; dx = 1, \]
    %
    and to define
    %
    \[ K_n(x) = \begin{cases} n^d \cdot K(nx) &: |x_1|, \dots, |x_d| \leq 1/n, \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Then $\| K_n \|_{L^1(\TT)} = 1$ for all $n > 0$, and $K_n$ is eventually supported on every small ball around the origin, which implies \eqref{goodkerneldecaycondition}. If $K \in L^\infty(\TT^d)$, then the resulting sequence $\{ K_n \}$ is also an approximation to the identity.
\end{example}

\begin{theorem}
    Let $\{ K_n \}$ be a good kernel. Then
    %
    \begin{itemize}
        \item $(K_n * f)(t) \to f(t)$ for any continuity point $t$ of $f$.
        \item $(K_n * f) \to f$ uniformly if $f \in C(\TT^d)$, and $K_n * f$ converges to $f$ in $L^p(\TT^d)$ if $f \in L^p(\TT^d)$, for $1 \leq p < \infty$.
        \item If $K_n$ is an approximation to the identity, $(K_n * f)(t) \to f(t)$ for all $t$ in the Lebesgue set of $f$.
    \end{itemize}
\end{theorem}
\begin{proof}
    The operators $T_nf = K_n * f$ are uniformly bounded as operators on $L^p(\TT)$. Basic analysis shows that $(K_n * f)(t) \to f(t)$ at each point $t$ where $f$ is continuous, and converges uniformly to $f$ if $f$ is in $C(\TT^d)$. But a density argument allows us to conclude that $K_n * f \to f$ in $L^p(\TT)$ for each $f \in L^p(\TT^d)$, for $1 \leq p < \infty$. To obtain pointwise convergence for $t$ in the Lebesgue set of $f$, we calculate
    %
    \[ |(K_n * f)(t) - f(t)| \leq \int_{\TT^d} |f(t - s) - f(t)| |K_n(s)|\; ds. \]
    %
    Let $A(\delta) = \delta^{-d} \int_{|s| < \delta} |f(t-s) - f(t)|$. Then as $\delta \to 0$, $A(\delta) \to 0$ because $t$ is in the Lebesgue set of $f$. And we find that for each $k$, since $|K_n(s)| \lesssim n^d$,
    %
    \[ \int_{2^k/n < |t| < 2^{k+1}/n} |f(t-s) - f(t)| |K_n(s)| \lesssim \frac{A(2^{k+1}/n)}{2^{d(k+1)}}. \]
    %
    Thus we have a bound
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim_d \sum_{k = 0}^\infty \frac{A(2^k/n)}{2^{dk}}. \]
    %
    Because $f$ is integrable, $A$ is continuous, and hence bounded. This means that for each $m$,
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim_d \sum_{k = 0}^m \frac{A(2^k/n)}{2^{dk}} + \| A \|_\infty \sum_{k = m}^\infty \frac{1}{2^{dk}} = \sum_{k = 0}^m \frac{A(2^k/n)}{2^{dk}} + O_d\left( 1/2^{dm} \right). \]
    %
    For any fixed $m$, the finite sum tends to zero as $n \to \infty$, so we obtain that $|(K_n * f)(t) - f(t)| = o(1) + O_d(1/2^m)$. Taking $m \to \infty$ proves the result.
\end{proof}

\section{The Dirichlet Kernel}

For simplicity, let us now focus exclusively on the case $d = 1$ with the canonical summation operators $S_N$. For $f \in L^1(\TT)$, we calculate that
%
\[ (S_Nf)(t) = \sum_{n = -N}^N \widehat{f}(n) e_n(t) = \int_{\TT^d} f(x) \left( \sum_{n = -N}^N e_n(t - x) \right)\; dx.  \]
%
The bracketed part of the final term in the equation is independant of the function $f$, and is therefore key to understanding the behaviour of the sums $S_N$. We call it the \emph{Dirichlet kernel}, denoted $D_N$. Thus
%
\[ D_N(t) = \sum_{n = -N}^N e_n(t) \]
%
and so $S_N f = f * D_N$. Analyzing convolution with this kernel gives results about the sums of Fourier series.

\begin{remark}
    In the higher dimensional case, we can consider the operators
    %
    \[ K_N(t) = \sum_{n \in E_N} e_n(t). \]
    %
    The behaviour of these functions is highly dependant on the choice of the sets $E_N$, and we thus leave the higher dimensional analysis to a different time.
\end{remark}

\begin{theorem}
    For any integer $N$ and $t \in \TT$,
    %
    \[ D_N(t) = \frac{\sin(2\pi(N+1/2)t)}{\sin(\pi t)}. \]
\end{theorem}
\begin{proof}
    By the geometric series summation formula, we may write
    %
    \begin{align*}
        D_N(t) &= 1 + \sum_{n = 1}^N e_n(t) + e_n(-t) = 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + e(-t) \frac{e_N(-t) - 1}{e(-t) - 1}\\
        &= 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + \frac{e_N(-t) - 1}{1 - e(t)} = \frac{e_{N+1}(t) - e_N(-t)}{e(t) - 1}\\
        &= \frac{e_{N+1/2}(t) - e_{N+1/2}(-t)}{e_{1/2}(t) - e_{1/2}(-t)} = \frac{\sin(2 \pi (N + 1/2)t)}{\sin(\pi t)}. \qedhere
    \end{align*}
\end{proof}

If $D_N$ was a good kernel, then we would obtain that the partial sums of $S_N$ converge uniformly. This initially seems a good strategy, because $\int D_N(t) = 1$. However, we find
%
\begin{align*}
    \int_{\TT^d} |D_N(t)| &= \int_0^1 \left| \frac{\sin(2 \pi (N + 1/2)t)}{\sin(\pi t)}\; dt \right|\\
    &\gtrsim \int_0^1 \frac{|\sin(2 \pi (N+1/2) t)|}{\sin(\pi t)}\; dt\\
    &\gtrsim \int_0^1 \frac{|\sin(2 \pi (N+1/2) t)|}{t}\; dt\\
    &= \int_0^{2 \pi N + \pi} \frac{|\sin(t)|}{t}\; dt\\
    &\gtrsim \sum_{n = 0}^N \frac{1}{t}\; dt \gtrsim \log(N).
\end{align*}
%
Thus the $L^1$ norm of $D_N$ grows, albeit slowly, to $\infty$. This reflects the fact that $D_N$ oscillates very frequently, and also that the pointwise convergence of the Fourier series is much more subtle than that provided by good kernels. In fact, a simple functional analysis argument shows that pointwise convergence of Fourier series fails for continuous functions.

\begin{theorem}
    There exists $f \in C(\TT)$ such that $(S_N f)(0)$ diverges as $N \to \infty$.
\end{theorem}
\begin{proof}
    If we consider the linear functionals $\Lambda_N f = (S_N f)(0) = (f * D_N)(0)$ on $C(\TT)$. If we let $f_N$ be a continuous function approximating $\text{sgn}(D_N)$ for each $N$, then $|\Lambda_N f_N| \gtrsim \log N \cdot \| f_N \|_{L^\infty(\TT)}$. This implies that $\| \Lambda_N \| \to \infty$ as $N \to \infty$. The uniform boundedness principle thus implies that there exists a {\it single} function $f \in C(\TT)$ such that $\sup |\Lambda_N f| = \infty$, so $(S_N f)(0)$ diverges as $N \to \infty$.
\end{proof}

The situation is even worse than this for general integrable functions. In 1927, Andrey Kolmogorov constructed an integrable function whose Fourier series diverges everywhere. But there is some hope. In 1928, Marcel Riesz showed, using methods we will develop in these notes, that if $1 < p < \infty$, and $f \in L^p(\TT)$, that $S_N f$ converges in the $L^p$ norm to $f$, by showing the Hilbert transform was bounded from $L^p(\TT)$ to $L^p(\TT)$. And after a half century of the development of techniques in harmonic analysis, in 1966, Carleson proved that for each $f \in L^p(\TT)$, for $1 < p \leq \infty$, the Fourier series of $f$ converges almost everywhere to $f$. The multivariate picture is more complicated and many questions remain open today; tensoring shows that $S_N f$ converges to $f$ in $L^p(\TT^d)$ if $f \in L^p(\TT^d)$, \emph{provided that we interpret $S_N f$ as a square summation}, and in 1970 Charles Fefferman showed that for square summation $S_N f$ converges to $f$ almost everywhere. On the other hand, in 1971 Charles Fefferman showed that for spherical summation the \emph{only} place we have norm convergence is in $L^2(\TT^d)$, and it remains an open question whether $S_N f$ converges to $f$ almost everywhere for spherical summation.

\section{Countercultural Methods of Summation}

We now interpret our convergence of series according to a different kernel, so we do get a family of good kernels, and therefore we obtain pointwise convergence for suitable reinterpretations of partial sums. One reason why the Dirichlet kernel fails to be a good kernel is that the Fourier coefficients of the kernel have a sharp drop -- the coefficients are either equal to one or to zero. If we mollify, then we will obtain a family of good kernels. And the best way to do this is to alter our summation methods slightly.

The standard method of summation suffices for much of analysis. Given a sequence $a_0, a_1, \dots$, we define the infinite sum as the limit of partial sums. Some sums, like $\sum_{k = 1}^\infty k$, obviously diverge, whereas other sums, like $\sum 1/n$, `just' fail to converge because they grow suitably slowly towards infinity over time. Since the time of Euler, a new method of summation developed by Cesaro was introduced which `regularized' certain terms by considering averaging the sums over time. Rather than considering limits of partial sums, we consider limits of averages of sums, known as Cesaro means. Letting $s_n = \sum_{k = 0}^n a_k$, we define the Cesaro means
%
\[ \frac{s_0 + \dots + s_n}{n+1}, \]
%
A sequence is Cesaro summable to some value if these averages converge. If the normal summation exists, then the Cesaro limit exists, and is equal to the original sum. However, the Cesaro summation is stronger than normal convergence.

\begin{example}
In the sense of Cesaro, we have $1 - 1 + 1 - 1 + \dots = 1/2$, which reflects the fact that the partials sums do `converge', but to two different numbers $0$ and $1$, which the series oscillates between, and the Cesaro means average these two points of convergence out to give a single method of convergence.
\end{example}

Another notion of regularization sums emerged from Complex analysis, called Abel summation. Given a sequence $\{ a_i \}$, we can consider the power series $\sum a_k r^k$. If this is well defined for $|r| < 1$, we can consider the Abel means $A_r = \sum a_k r^k$, and ask if $\lim_{r \to 1} A_r$ exists, which should be `almost like' $\sum a_k$. If this limit exists, we call it the Abel sum of the sequence.

\begin{example}
    In the Abel sense, we have $1 - 2 + 3 - 4 + 5 - \dots = 1/4$, because
    %
    \[ \sum_{k = 0}^\infty (-1)^k (k + 1) z^k = \frac{1}{(1 + z)^2}. \]
    %
    The coefficients here are $\Omega(N)$, so they can't be Cesaro summable.
\end{example}

Abel summation is even more general than Cesaro summation, as the following theorem shows.

\begin{theorem}
    A Cesaro summable sequence is Abel summable.
\end{theorem}
\begin{proof}
    Let $\{ a_i \}$ be a Cesaro summable sequence, which we may without loss of generality assume converges to $0$. Now $(n + 1)\sigma_n - n \sigma_{n-1} = s_n$, so
    %
    \[ (1 - r)^2 \sum_{k = 0}^n (k + 1) \sigma_k r^k = (1 - r) \sum_{k = 0}^n s_k r^k = \sum_{k = 0}^n a_k r^k \]
    %
    As $n \to \infty$, the left side tends to a well defined value for $r < 1$, hence the same is true for $\sum_{k = 0}^n a_k r^k$. Given $\varepsilon > 0$, let $N$ be large enough that $|\sigma_n| < \varepsilon$ for $n > N$, and let $M$ be a bound for all $|\sigma_n|$. Then
    %
    \begin{align*}
        \left| (1 - r)^2 \sum_{k = 0}^\infty (k + 1) \sigma_k r^k \right| &\leq (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) |\sigma_k| r^k + \varepsilon \sum_{k = N+1}^\infty (k + 1) r^k \right)\\
        &= (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) (|\sigma_k| - \varepsilon) r^k + \varepsilon \left[ \frac{r^{n+1}}{1-r} + \frac{1}{(1 - r)^2} \right] \right)\\
        &\leq (1 - r)^2 M \sum_{k = 0}^N (k + 1) r^k + \varepsilon r^{n+1} (1 - r) + \varepsilon\\
        &\leq (1 - r)^2 M \frac{(N+1)(N+2)}{2} + \varepsilon r^{n+1} (1 - r) + \varepsilon
    \end{align*}
    %
    Fixing $N$, and letting $r \to 1$, we may make the complicated sum on the end as small as possible, so the absolute value of the infinite sum is less than $\varepsilon$. Thus the Abel limit converges to zero.
\end{proof}

\section{Fejer Summation}

Note that the Cesaro means of the Fourier series of $f$ are given by
%
\[ \sigma_N(f) = \frac{S_0(f) + \dots + S_{N-1}(f)}{N} = f * \left( \frac{D_0 + \dots + D_{N-1}}{N} \right) = f * F_N, \]
%
where we have introduced a new kernel $F_N$, called the \emph{Fejer kernel}. Here, we have a simple formula for the Cesaro means, i.e.
%
\[ F_N(x) = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) e_n(t) = \frac{1}{N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)}. \]
%
Thus the oscillations of the Dirichlet kernel are slightly dampened, and as a result, we can easily see that $F_N$ is an approximation to the identity.

\begin{theorem}[Fej\'{e}r's Theorem] For any $f \in L^1(\TT)$,
    \begin{itemize}
        \item $(\sigma_N f)(x) \to f(x)$ for all $x$ in the Lebesgue set of $f$.
        \item $\sigma_N f \to f$ uniformly if $f \in C(\TT)$.
        \item $\sigma_N f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\TT)$.
    \end{itemize}

\end{theorem}

If we look at the Fourier expansion of the trigonometric polynomial $\sigma_N(f)$, viewing $\sigma_N$ as a \emph{Fourier multiplier operator}, we see that
%
\[ \sigma_N f = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) \widehat{f}(n) e_n. \]
%
Thus the Fourier coefficients are slowly added to the expansion, rather than a sharp cutoff as with ordinary Dirichlet summation. This is one reason for the nice convergence properties the kernel has as compared to the Dirichlet kernel.

\begin{corollary}
    If $f \in L^1(\TT)$ and $\widehat{f} = 0$, then $f = 0$ almost everywhere.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\sigma_N f = 0$ for all $N$. But $\sigma_N f \to f$ in $L^1(\TT)$, which means that $f = 0$ in $L^1(\TT)$, so $f = 0$ almost everywhere.
\end{proof}

This corollary is often more useful than the more technical convergence statements due to it's relative simplicity. We will later see this result is also true for $d > 1$, via use of the Poisson summation formula for the Fourier transform.

\begin{example}
    We say $f \in L^1(\TT^d)$ is \emph{band limited} if it's Fourier series is supported on finitely many points. If $\{ S_N \}$ is defined as before, and $N$ is suitably large that $E_N$ contains the support of $\widehat{f}$, then
    %
    \[ \widehat{f} = \widehat{f} \cdot \mathbf{I}_{E_N} = \widehat{f} \widehat{K_N} = \widehat{f * K_N}. \]
    %
    It thus follows from the previous result that $f = f * K_N$ almost everywhere. But this means we can adjust $f$ on a set of measure zero such that $f \in C^\infty(\TT^d)$.
\end{example}

\section{Abel Summation and Harmonics on the Disk}

Let us now consider the Abel sum of the Fourier integrals. We begin by focusing on the one-dimensional case, as in the last section. Thus for $f \in L^1(\TT)$ we have
%
\[ A_r(f) = \sum_{n = -\infty}^\infty \widehat{f}(n) r^n e_n(t). \]
%
Thus, if we define the {\it Poisson kernel}
%
\[ P_r(t) = \sum_{n = -\infty}^\infty r^{|n|} e_n(t) \]
%
For each $r < 1$, this series converges uniformly for $t \in \TT$, so $P_r$ is a well-defined continuous function, and the uniform convergence shows that $A_r(f) = P_r * f$. As with the Fejer kernel, the family $\{ P_r \}$ is \emph{also} a good kernel as $r \to 1$. To see this, we can apply an infinite geometric series summation to obtain that
%
\begin{align*}
    \sum r^{|n|} e_n(t) &= 1 + \frac{re(t)}{1 - re(t)} + \frac{re(-t)}{1 - re(-t)} = 1 + \frac{2r \cos 2 \pi t - 2r^2}{(1 - re(t))(1 - re(-t))}\\
    &= 1 + \frac{2r \cos 2\pi t - 2r^2}{1 - 2r \cos 2\pi t + r^2} = \frac{1 - r^2}{1 - 2r \cos 2 \pi t + r^2}.
\end{align*}
%
As $r \to 1$, the function concentrates at the origin, because as $r \to 1$, if $\delta \leq |t| \leq \pi$, then $1 - \cos 2\pi t$ is bounded away from the origin, so
%
\begin{align*}
    \left| \frac{1 - r^2}{1 - 2r \cos 2\pi t + r^2} \right| &= \left| \frac{1 + r}{(1+(1-2\cos 2\pi t)r) + 2(1 - \cos 2\pi t) r^2/(1-r)} \right|\\
    &= O \left( \frac{1 - r}{1 - \cos 2\pi t} \right) = O_\delta(1 - r).
\end{align*}
%
Moreover,
%
\[ \| P_r \|_{L^\infty(\TT)} \leq \frac{1 - r^2}{1 - 2r + r^2} \leq \frac{2}{1 - r}. \]
%
Thus the Poisson kernel is an approximation to the identity; the oscillation in the kernel cancels out as $r \to 1$.

\begin{theorem}
    For any $f \in L^1(\TT)$,
    %
    \begin{itemize}
        \item $(A_r f)(t) \to f(t)$ for all $x$ in the Lebesgue set of $f$.
        \item $A_r f \to f$ uniformly if $f \in C(\TT)$.
        \item $A_r f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\TT)$.
    \end{itemize}
\end{theorem}

The Poisson kernel is not a trigonometric polynomial, and therefore not quite as easy to work with as the F\'{e}jer kernel. However, it is the real part of the Cauchy kernel
%
\[ \frac{1 + re^{2 \pi it}}{1 - re^{2 \pi it}}, \]
%
and therefore links the study of trigonometric series and the theory of analytic functions.

\section{The De la Valle\'{e} Poisson Kernel}

By taking a kernel halfway between the Dirichlet kernel and the Fejer kernel, we can actually obtain important results about ordinary summation. For two integers $M > N$, we define
%
\[ \sigma_{N,M}(f) = \frac{M\sigma_M(f) - N\sigma_N(f)}{M-N}. \]
%
If we take a look at the Fourier expansion of $\sigma_{n,m} f$, we find
%
\[ \sigma_{N,M} f = \sum_{n = -M}^M \frac{M - |n|}{M-N} e_n - \sum_{n = -N}^N \frac{N - |n|}{M-N} e_n = S_N f + \sum_{|n| = N+1}^M \frac{M - |n|}{M - N} e_n. \]
%
So we still have a slow decay in the Fourier coefficients. And as a result, if we look at the associated De la Velle\'{e} Poisson kernel, we find that a suitable subsequence is an approximation to the identity. In particular, for any fixed integer $k$, the sequence $\sigma_{kN,(k+1)N}$ leads to a good kernel. More interestingly, if the Fourier coefficients of $f$ have some decay, then the De la Vall\'{e}e does not differ that much from the ordinary sum, which gives useful results.

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, then for any integers $N$ and $k$, if
    %
    \[ kN \leq M < (k+1)N, \]
    %
    then
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \lesssim 1/k. \]
    %
    Where the implicit constant is independant of $N$ and $k$.
\end{theorem}
\begin{proof}
    We just calculate that, since the Poisson sum has essentially the same weight for low term coefficients as the sum $S_M f$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \lesssim \sum_{kN \leq |n| < (k+1)N} |\widehat{f}(n)| \lesssim \sum_{n = kN}^{(k+1)N} \frac{1}{n} \leq \frac{N}{kN} = \frac{1}{k}. \qedhere \]
\end{proof}

\begin{corollary}
    If $f \in L^1(\TT)$ with $\widehat{f}(n) = O(|n|^{-1})$,
    %
    \begin{itemize}
        \item $S_Nf$ converges to $f$ in the $L^p$ norm for $1 \leq p < \infty$.
        \item $S_Nf$ converges uniformly to $f$ if $f \in C(\TT)$.
        \item $(S_N f)(x) \to f(x)$ for each Lebesgue point $x$ of $f$.
    \end{itemize}
\end{corollary}
\begin{proof}
    The idea is quite simple. Fix $N$. Given any $\varepsilon$, we can use the last theorem to find $k$ large enough such that if $kN \leq M < k(N+1)$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \leq \varepsilon. \]
    %
    But this gives the first and second result, up to perhaps a $\varepsilon$ of error. The latter result is given by similar techniques.
\end{proof}

\section{Pointwise Convergence}

One way around around the blowup in the $L^1$ norm of $D_N$ is to consider only functions $f$ which provide a suitable dampening condition on the oscillation of $D_N$ near the origin. This is provided by smoothness of $f$, manifested in various ways. The first thing we note is that the convergence of $(S_N f)(t)$ for a \emph{fixed} $x_0$ depends only \emph{locally} on the function $f$.

\begin{lemma}[Riemann Localization Principle]
    If $f_0$ and $f_1$ agree in an interval around $t_0$, then
    %
    \[ (S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1). \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ X = \{ f \in L^1(\TT) : f(x) = 0\ \text{for almost every $x \in (t_0 - \varepsilon, t_0 + \varepsilon$)} \}. \]
    %
    Then $X$ is a closed subset of $L^1(\TT)$. Note that for all $x \in [-\pi,\pi]$,
    %
    \[ \sin(t/2) \gtrsim t \quad\text{and}\quad \sin((N+1/2)t) \leq 1. \]
    %
    Thus if $|t| \geq \varepsilon$,
    %
    \[ |D_N(t)| = \frac{|\sin(2 \pi (N+1/2)t)|}{|\sin(\pi t)|} \lesssim 1/\varepsilon. \]
    %
    In particular, by H\"{o}lder's inequality, the functionals $T_Nf = (S_N f)(t_0)$ are uniformly bounded on $X$, i.e. $\| T_N \| \lesssim 1/\varepsilon$. If $f$ is smooth, and vanishes on $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $T_N f \to 0$ as $N \to \infty$. But the space of such functions is dense in $X$, which implies that $T_N f \to 0$ for \emph{any} $f \in X$. Thus if $f_0, f_1$ are two functions that agree in $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $f_0 - f_1 \in X$, so $(S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1)$. In particular, the pointwise convergence properties of $f_0$ and $f_1$ are equivalent at $t_0$.
\end{proof}

Thus any result about the pointwise convergence of Fourier series must depend on the local properties of a function $f$. Here, we give two of the main criteria, which corresponds to the smoothness of a function about a point $x$: either $f$ is in a sense, `locally Lipschitz', or `locally of bounded variation'.

\begin{theorem}[Dini's Criterion]
    If there exists $\delta$ such that
    %
    \[ \int_{|t| < \delta} \left| \frac{f(x+t) - f(x)}{t} \right|\; dt < \infty, \]
    %
    then $(S_N f)(x) \to f(x)$.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $x = 0$ and $f(x) = 0$. Fix $\varepsilon > 0$, and pick $\delta_0$ such that
    %
    \[ \int_{|t| < \delta_0} \left| \frac{f(t)}{t} \right|\; dt < \varepsilon. \]
    %
    We have
    %
    \begin{align*}
        |(S_N f)(0)| &= \left| \left( \int_{|t| < \delta_0} + \int_{|t| \geq \delta_0} \right) f(t) D_N(t)\; dt \right|.
    \end{align*}
    %
    Now
    %
    \[ \int_{|t| \geq \delta_0} f(t) D_N(t)\; dt = (D_N * \left( \mathbf{I}_{|t| \geq \delta_0} f \right))(0) = S_N( \mathbf{I}_{|t| \geq \delta_0} f )(0) = o(1) \]
    %
    since $f \mathbf{I}_{|t| \geq \delta_0}$ vanishes in a neighbourhood of the origin. On the other hand, we note that $t/\sin(\pi t)$ is a bounded function on $\TT$, so
    %
    \begin{align*}
        \int_{|t| < \delta_0} f(t) D_N(t)\; dt &= \int_{|t| < \delta_0} \left( \sin(2 \pi (N + 1/2)t) \frac{f(t)}{t} \right) \left( \frac{t}{\sin(\pi t)} \right)\; dt\\
        &\lesssim \| f(t)/t \|_{L^1[-\delta_0,\delta_0]} \leq \varepsilon.
    \end{align*}
    %
    Thus, for suitably large $N$, $|(S_N f)(0)| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, the proof is complete.
\end{proof}

This proof applies, in particular, if $f$ is locally Lipschitz at $x$. Note the application of the Riemann Lebesgue lemma to show that to analyze the pointwise convergence of $(S_N f)(x)$, it suffices to analyze
%
\[ \lim_{N \to \infty} \int_{|t| < \delta} f(x+t) D_N(t)\; dt \]
%
for any fixed $\delta > 0$.

\begin{lemma}[Jordan's Criterion]
    If $f \in L^1(\TT)$ locally has bounded variation about $x$, then
    %
    \[ (S_N f)(x) \to \frac{f(x^+) + f(x^-)}{2}. \]
\end{lemma}
\begin{proof}
    By Riemann's localization principle, we may assume $f$ has bounded variation everywhere. Then without loss of generality, we may assume $f$ is an increasing function, since a bounded variation function is the difference of two monotonic functions. Since
    %
    \[ \int_{-1/2}^{1/2} D_N(t)\; dt = \int_0^{1/2} [f(x + t) + f(x - t)] D_N(t), \]
    %
    it suffices without loss of generality to show that
    %
    \[ \lim_{N \to \infty} \int_0^{1/2} f(x+t) D_N(t)\; dt = \frac{f(x+)}{2}. \]
    %
    Since $\int_0^{1/2} D_N(t) = 1/2$, this is equivalent to showing
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi [f(x + t) - f(x+)] D_N(t)\; dt = 0. \]
    %
    Because of this, we may assume without loss of generality that $x = 0$ and $f(x+) = 0$. Then by the mean value theorem for integrals (which only applies for monotonic functions), for each $N$, there exists $0 \leq \nu_N \leq 1/2$ such that
    %
    \begin{align*}
        \int_0^{1/2} f(t) D_N(t)\; dt &= \| f \|_\infty \int_{\nu_N}^{1/2} D_N(t)\; dt.
    \end{align*}
    %
    Now an integration by parts gives
    %
    \begin{align*}
        \int_{\nu_N}^{1/2} D_N(t) &\lesssim \int_{\nu_N}^{1/2} \frac{\sin((N + 1/2) t)}{t}\; dt = \int_{\nu_N/(N + 1/2)}^{1/2(N + 1/2)} \frac{\sin(t)}{t}\; dt \lesssim \frac{1}{N+1/2}.
    \end{align*}
    %
    Thus
    %
    \[ \int_0^{1/2} f(t) D_N(t) \lesssim \frac{1}{N + 1/2} \to 0. \qedhere \]
\end{proof}

\begin{remark}
    The calculations in this proof also show that if $f \in L^1(\TT)$ has bounded variation, then
    %
    \[ \widehat{f}(n) = O(1/|n|). \]
    %
    We have seen that this implies $S_N f$ converges to $f$ at every point on the Lebesgue set of $f$, $S_N f$ converges uniformly to $f$ if $f \in C(\TT)$, and for any $1 \leq p < \infty$, if $f \in L^p(\TT)$, $S_N f$ converges to $f$ in $L^p(\TT)$. Dirichlet's theorem says that the Fourier series of a continuous function $f$ with only finitely many maxima and minima converges uniformly to $f$ everywhere. Such a function has bounded variation, and so Dirichlet's theorem is an easy consequence of our discussion.
\end{remark}

Of course, applying various better decay rates leads to a more uniform version of this theorem. The decay of the Fourier series depends on the decay of the Fourier coefficients of $yg(y)$ and $g(y) \cos(y/2)(y/\sin(y/2))$. In particular, if these coefficients is $O(|n|^{-m})$, then the convergence rate is also $O(|n|^{-m})$. If this decay rate is independent of $x$ for suitable values of $x$, the convergence will be uniform over these values of $x$.

\begin{example}
    Consider the sawtooth function defined on $[-1/2,1/2)$ by $s(t) = t$, and then made periodic on the entire real line. We can easily calculate the Fourier series here, obtaining that
    %
    \[ s(t) = i \sum_{n \neq 0} \frac{(-1)^n e_n(t)}{2 \pi n} = -2 \sum_{n = 1}^\infty \frac{(-1)^n \sin(2 \pi nt)}{n}. \]
    %
    Thus for any $t \in (-1/2,1/2)$,
    %
    \[ \sum_{n = 1}^\infty \frac{(-1)^n \sin(2 \pi nt)}{n} = -t/2. \]
\end{example}

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, and $f(t_0-)$ and $f(t_0+)$ exist, then
    %
    \[ (S_N f)(t_0) \to \frac{f(t_0-) + f(t_0+)}{2}. \]
\end{theorem}
\begin{proof}
    The idea of our proof is to break $f$ into a nice continuous function, and the sawtooth function, where we already understand the convergence of Fourier series. Without loss of generality, let $t_0 = 1/2$. Define $g(t) = f(t) + (f(1+) - f(1-)) s(t) / 2$ on $(-1/2,1/2)$, where $s$ is the sawtooth function. Then
    %
    \[ \lim_{t \uparrow 1/2} g(t) = \lim_{t \downarrow -1/2} g(t) = \frac{f(1/2+) + f(1/2-)}{2}. \]
    %
    Thus $g$ can be defined on $\TT$ so it is continuous at $t_0$. Now we find $|\widehat{g}| \lesssim |\widehat{f}| + |\widehat{s}| = O(|n|^{-1})$, and so
    %
    \[ (S_N g)(1/2) \to \frac{f(1/2+) + f(1/2-)}{2}. \]
    %
    We also have $(S_N s)(1/2) \to 0$. Thus
    %
    \[ (S_N f)(1/2) = (S_N g)(1/2) - (S_N s)(1/2) \to \frac{f(1/2+) + f(1/2-)}{2}. \qedhere \]
\end{proof}

% Another way to fix the convergence is to use a more quantitative argument in terms of $L^p$ spaces. It is obvious that $S_N f \to f$ in any feasible norm if $f$ is a trigonometric polynomial, because if $f$ has degree $M$, then $S_N f = f$ for $N \geq M$. The Stone-Weirstrass theorem says that we can uniformly approximate any continuous function on $\TT$ by a trigonometric polynomial, so provided we can show that the operators $S_N$ are uniformly bounded in the $L^p$ norm for $1 \leq p < \infty$, we obtain convergence for all $f \in L^p(\TT)$. The fact that the $S_N$ are not bounded in the $L^\infty$ norm is why the Fourier series can diverge pointwise for continuous functions. In fact, the $S_N$ are not bounded as operators on $L^1(\TT)$, and as such, Fourier series do not converge in the $L^1$ norm. The reason for this is that if $\{ K_M \}$ is a good kernel, then $S_N(K_M) = D_N * K_M \to D_N$ as $M \to \infty$, and so as $M \to \infty$, we find $\| S_N(K_M) \|_{L^1(\TT)} = \Omega(\log N)$, hence $\| S_N \|_{L^1(\TT)}$ is unbounded. Later on, using the theory of conjugate functions, we will show that the operators $S_N$ are uniformly bounded in all $L^p(\TT)$ for $1 < p < \infty$, and so the Fourier series of any function $f \in L^p(\TT)$ converges to $f$ in the $L^p$ norm.

\section{Pointwise Behaviour at Discontinuity Points}

This isn't the end of our discussion about points of discontinuity. There is an interesting phenomenon which occurs locally around the point of discontinuity. If $f$ is continuous locally around a discontinuity point $t_0$, $S_N f \to f$ pointwise locally around $t_0$. Thus, being continuous, $S_N f$ must `jump' from $(S_N f)(t_0-)$ to $(S_N f)(t_0+)$ locally around $t_0$. Interestingly enough, we find that the jump is not precise, the jump is overshot and then must be corrected to the left and right of $t_0$. This is known as the {\it Gibb's phenomenon}, after the man who clarified the reason for why this phenomenon occured in physical measurements where first thought to be a defect in the equipment used to take the measurements. Gibb's phenomenon is one instance where a series of functions $\{ f_k \}$ converges pointwise to some function $f$, whereas qualitatively with respect to the $L^\infty$ norm, $\{ f_k \}$ does not converge to $f$.

\begin{theorem}
    Given $f$ with finitely many discontinuity points and with $\widehat{f}(n) = O(|n|^{-1})$, in particular one at $t_0$, we find
    %
    \[ \lim_{N \to \infty} (S_N f)(t_0 \pm 1/N) = f(t_0 \pm ) \pm C \cdot \frac{f(t_0+) - f(t_0-)}{2}, \]
    %
    where
    %
    \[ C = 2 \pi \int_0^\pi \frac{\sin x}{x} \approx 16.610. \]
\end{theorem}
\begin{proof}
    First consider the jump function $s$, with $t_0 = 1/2$. Then
    %
    \begin{align*}
        (S_N s)(1/2 + 1/N) &= -2 \sum_{n = 1}^N \frac{\sin(2 \pi n/N)}{n} = -2  \sum_{n = 1}^N \frac{2 \pi }{N} \left( \frac{\sin(2 \pi n/N)}{2 \pi n / N} \right).
    \end{align*}
    %
    Here we're just taking averages of values of $\sin(x)/x$ at $x = 2\pi/N$, $x = 4\pi/N$, and so on and so forth up to $x = 2 \pi$. Thus is a Riemann sum, so as $N \to \infty$, we get that
    %
    \[ (S_N s)(\pi + 1/N) \to - 2 \int_0^{2\pi} \frac{\sin x}{x}. \]
    %
    The same calculations give
    %
    \[ (S_N s)(\pi - \pi/N) \to 2 \pi \int_0^\pi \frac{\sin x}{x}. \]
    %
    In general, given $f$, we can write $f = g + \sum \lambda_j h_j$, where $g$ is continuous, and $h_j$ is a translate of the sawtooth function. Then $S_N g$ converges to $g$ uniformly, and $S_N h_j \to 0$ for all $h_j$ uniformly in an interval outside of their discontinuity point. To see this, we note that an integration by parts gives
    %
    \[ \left| \int_{-\pi}^\pi D_N(y)[s(x-y) - s(x)]\; dy \right| \leq |G_N(x - \pi)|, \]
    %
    where $G_N(y) = -i \sum_{|n| \leq N} e_n(t)/n$, so $G_N' = D_N$. It now suffices to show $G_N(x - \pi) \to 0$ outside a neighbourhood of $\pi$. But if $A(u,t) = \sum_{|n| \leq u} e_n(t)$, summation by parts gives
    %
    \[ \sum_{|n| \leq N} \frac{e_n(t)}{n} = \frac{A(N,t)}{N} + \int_1^N \frac{A(u,t)}{u^2}. \]
    %
    Now a simple geometric sum shows $A(u,t) \lesssim 1/|e(t) - 1|$, so provided $d(t, 2 \pi \ZZ)$ is bounded below, the quantity above tends to zero uniformly. This gives the required result.
\end{proof}

\chapter{Applications of Fourier Series}

\section{Tchebychev Polynomials}

If $f$ is everywhere continuous, then for every $\varepsilon$, Fej\'{e}r's theorem says that we can find $N$ such that $\| \sigma_N(f) - f \| \leq \varepsilon$. But $\sigma_N f$ is just a trigonometric polynomial, and so we have shown that with respect to the $L^\infty$ norm, the space of trigonometric polynomials is dense in the space of all continuous functions.  Now if $f$ is a continuous function on $[0,\pi]$, then we can extend it to be even and $2\pi$ periodic, and then the trigonometric series $S_N(f)$ of $f$ will be a cosine series, hence $\sigma_N(f)$ will also be a cosine series, and so for each $\varepsilon$, we can find $N$ and coefficients $a_1, \dots, a_N$ such that
%
\[ \left| f(x) - \sum_{n = 1}^N a_n \cos(nx) \right| < \varepsilon. \]
%
Now we use a surprising fact. For each $n$, there exists a degree $n$ polynomial $T_n$ such that $\cos(nx) = T_n(\cos x)$. This is clear for $n = 0$ and $n = 1$. More generally, we can write
%
\begin{align*}
    \cos((m+1)x) &= \cos((m+1)x) + \cos((m-1)x) - \cos((m-1)x)\\
    &= \cos(mx + x) + \cos(mx - x) - \cos((m-1)x)\\
    &= 2 \cos x \cos(mx) - \cos((m-1)x).
\end{align*}
%
Thus we have the relation  $T_{m+1}(x) = 2xT_m(x) - T_{m-1}(x)$. These polynomials are known as {\emph Tchebyshev polynomials}, enabling us to move between `periodic coordinates' and standard Euclidean coordinates.

\begin{corollary}[Weirstrass]
    The polynomials are uniformly dense in $C[0,1]$.
\end{corollary}
\begin{proof}
    If $f$ is a continuous function on $[0,1]$, we can define $g(t) = f(|\cos(t)|)$. Then $g$ is even, and so for every $\varepsilon > 0$, we can find $a_1, \dots, a_N$ such that
    %
    \[ \left|g(t) - \sum_{n = 1}^N a_n \cos(nt) \right| = \left| g(t) - \sum_{n = 1}^N a_n T_n(\cos t) \right| < \varepsilon. \]
    %
    But if $x = \cos t$, for $\cos t \geq 0$, this equation says
    %
    \[ \left| f(x) - \sum_{n = 1}^N a_n T_n(x) \right| < \varepsilon, \]
    %
    and so we have uniformly approximated $f$ by a polynomial.
\end{proof}

\section{Exponential Sums and Equidistribution}

The next result uses Fourier analysis to characterize the asymptotic distribution of a certain sequence $a_1, a_2, \dots$. In particular, it is most useful in determining when this distribution is distributed when we consider $2 \pi a_1, 2 \pi a_2, \dots$ as elements of $\TT$, i.e. so we only care about the fractional part of the numbers, or in other terms their behaviour modulo one. We say the sequence is {\it uniformly distributed} if for any interval $I \subset \TT$, $\# \{ 2 \pi a_n \in I : n \leq N \} \sim N |I|$ as $N \to \infty$. By approximating continuous functions by step functions, this implies that if $f: \TT \to \CC$ is continuous, then
%
\[ \frac{f(2 \pi a_1) + \dots + f(2 \pi a_N)}{N} \to \int_{\TT} f(t)\; dt. \]
%
It is the right hand side to which we can apply Fourier summation to obtain a very useful condition. We let $S_Nf$ denote the left hand side of the equation, and $Tf$ the right hand side.

\begin{theorem}[Weyl Condition]
    A sequence $a_1, a_2, \dots \in \TT$ is uniformly distributed if and only if for every $n$, as $N \to \infty$, $e_n(2 \pi a_1) + \dots + e_n(2 \pi a_N) = o(N)$.
\end{theorem}
\begin{proof}
    The condition in the theorem implies that for any trigonometric polynomial $f$, $S_Nf \to Tf$. The $S_N$ are uniformly bounded as functions on $L^\infty(\TT)$, and $T$ is a bounded functional on this space as well. But this means that $\lim S_N f = T f$ for all $f$ in $C(\TT)$, since this equation holds on the dense subset of trigonometric polynomials.
\end{proof}

This technique enables us to completely characterize the equidistribution behaviour of arithmetic sequences. Given a particular $\gamma$, we consider the equidistribution of the sequence $\gamma, 2 \gamma, \dots$, which depends on the irrationality of $\gamma$.

\begin{example}
    Let $\gamma$ be an arbitrary real number. Then for any $n$, if $e_n(2 \pi \gamma) \neq 1$,
    %
    \[ \sum_{m = 1}^N e_n(2 \pi m \gamma) = \frac{e_n(2 \pi (N + 1) \gamma) - 1}{e_n(2 \pi \gamma) - 1} \lesssim 1 = o(N). \]
    %
    If $\gamma$ is an irrational number, then $e_n(2 \pi \gamma) \neq 1$ for all $n$, which implies that $\gamma, 2\gamma, \dots$ is equidistributed. Conversely, if $e_n(2 \pi \gamma) = 1$ for some $n$, we have
    %
    \[ \sum_{m = 1}^N e_n(a_m) = N. \]
    %
    which is not $o(N)$, so the sequence $\gamma, 2\gamma, \dots$ is {\it not} equidistributed. If $\gamma$ is rational, there certainly is $n$ such that $n \gamma \in \ZZ$, and so $e_n(2 \pi \gamma) = 1$.
\end{example}

On the other hand, it is still an open research to characterize, for which $\gamma$ the sequence $\gamma, \gamma^2, \gamma^3, \dots$ is equidistributed. Here is an example showing that there are $\gamma$ for which the sequence is not equidistributed.

\begin{example}
    Let $\gamma$ be the golden ratio $(1 + \sqrt{5})/2$. Consider the sequence
    %
    \[ a_n = \left( \frac{1 + \sqrt{5}}{2} \right)^n + \left( \frac{1 - \sqrt{5}}{2} \right)^n = b_n + c_n. \]
    %
    Then one checks that $a_n$ is a kind of Fibonacci sequence, with $a_{n+1} = a_n + a_{n-1}$, and initial conditions $a_0 = 2$, $a_1 = 1$. One checks that $c_n$ is always negative for odd $n$, and positive for even $n$, and tends to zero as $n \to \infty$. Since $a_n$ is an integer, this means that $d(b_n, \ZZ) = d(\gamma^n, \ZZ) \to 0$. But this means that the average distribution of the $\gamma^n$ modulo one is concentrated at the origin.
\end{example}

\section{The Isoperimetric Inequality}

TODO

\section{The Poisson Equation}

Consider Poisson's equation
%
\[ \Delta u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial u^2}{\partial y^2} = 0 \]
%
on the unit disk. Solutions are called \emph{harmonic}. We can reduce this equation to a problem about Fourier series by writing
%
\[ u(re^{2 \pi it}) = \sum_{n = 0}^\infty a_n(r) e^{2 \pi n i t}. \]
%
We consider a boundary condition, that $u(e^{2 \pi i t}) = f(t)$ for some function $f(t)$ on $\TT$. Working formally, noting that in radial coordinates,
%
\[ \Delta u = \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} + \frac{1}{r^2} \frac{u}{t^2} \]
%
and then taking Fourier series on each side, we find that for each $n \in \ZZ$,
%
\[ a_n''(r) + a_n'(r)/r - 4\pi^2 n^2 a_n(t)/r^2 = 0. \]
%
The only \emph{bounded} solution to this differential equation subject to the initial condition $a_n(1) = \widehat{f}(n)$ is $a_n(t) = \widehat{f}(n) r^{|n|}$. Thus we might guess that
%
\[ u(re^{2 \pi i t}) = \sum_{n \in \ZZ} \widehat{f}(n) r^{|n|} e^{2 \pi n i t} = (P_r * f)(x), \]
%
where $P_r$ is the Poisson kernel. Working backwards through this calculation shows that if $f \in L^1(\TT)$, then the function $u(re^{2 \pi it}) = (P_r * f)(t)$ lies in $C^\infty(\mathbf{D})$ and
%
\[ \lim_{r \to 1} \int_{\TT} |u(re^{2 \pi i t}) - f(t)|\; dt = 0. \]
%
The next theorem shows this is the \emph{only} harmonic function with this propety.

\begin{theorem}
    Suppose $f \in L^1(\TT)$. Then the function $u: \mathbf{D}^\circ \to \CC$ defined for $r > 0$ and $t \in \TT$ by setting
    %
    \[ u(r e^{2 \pi i t}) = (A_r f)(t) \]
    %
    is the \emph{unique} harmonic function in $C^2(\mathbf{D}^\circ)$ such that
    %
    \[ \lim_{r \to 1} \int \left| u(re^{2 \pi i t}) - f(t) \right|\; dt = 0. \]
\end{theorem}
\begin{proof}
    Suppose $u \in C^2(\mathbf{D})$ is harmonic. Then we can find functions $a_n(r)$ for each $n \in \ZZ$ such that
    %
    \[ u(re^{it}) = \sum_{n = -\infty}^\infty a_n(r) e_n(t), \]
    %
    where
    %
    \[ a_n(r) = \int_{\TT} u(re^{it}) \overline{e_n(t)}\; dt. \]
    %
    Because $u \in C^2(\mathbf{D})$, we see that $a_n \in C^2((0,1))$ and $a_n(r)$ is bounded as $r \to 0$. Interchanging integrals shows that
    %
    \[ a_n''(r) + (1/r) a_n'(r) - (n^2/r^2) a_n(r) = 0. \]
    %
    This is an ordinary differential equation, whose only bounded solutions are given by $a_n(r) = A_n r^{|n|}$. If $u(re^{it}) \to f$ in the $L^1$ norm as $r \to 1$, then we conclude
    %
    \[ A_n = \lim_{r \to 1} \int_{\TT} u(re^{it}) \overline{e_n(t)}\; dt = \int_{\TT} f(t) \overline{e_n(t)} = \widehat{f}(n), \]
    %
    so
    %
    \[ u(re^{it}) = \sum \widehat{f}(n) r^{|n|} e_n(t). \qedhere \]
\end{proof}

In particular, the theorem above gives us a map from $L^1(\TT)$ to the space of harmonic functions on the interior of the unit disk. This is a very handy idea in classical harmonic analysis, and is exploited to it's fullest extent in the theory of Hardy spaces.

%If $u$ is only required to converge to $f$ {\it pointwise} on the boundary, then the function we found is no longer required to be unique. Below is an example of a function $u$ which tends to zero pointwise on the boundary, yet does not vanish on the interior of the unit disk.

%\begin{example}
%    If $P_r$ is the Poisson kernel, define $u(r,\theta) = P_r(\theta)$. Then $u$ is harmonic in the unit disk, because $\Delta u = (\Delta P_r)'' = 0$. We calculate
    %
%    \begin{align*}
%        u(r,t) &= \sum_{n = 1}^\infty in r^n [e_n(t) - e_n(-t)]\\
%        &= i \left[ \frac{r e(t)}{(re(t) - 1)^2} - \frac{r e(-t)}{(re(-t) - 1)^2} \right]\\
%        &= i \left[ \frac{re(-t) + r^{-1}e(t) - re(t) - r^{-1}e(-t)}{(re(t) - 1)^2(re(-t) - 1)^2} \right]\\
%        &= \frac{(r - r^{-1}) \sin(t)}{(re(t) - 1)^2(re(-t) - 1)^2}\\
%        &= \frac{(r^2 - 1) \sin(t)}{r (re(t) - 1)^2(re(-t) - 1)^2}
%    \end{align*}
    %
%    In this form, it is easy to see that for a fixed $t$, as $r \to 1$, $u(r,t) \to 0$. However, the denominator tells us this convergence isn't uniform.
%\end{example}

\section{The Heat Equation on a Torus}

Recall the heat equation. We are given an initial temperature distribution on $\TT^d$. We wish to study the propogation of this temperature over time. If we let $u(x,t)$ denote the temperature density at $x \in \TT^d$ and at time $t$, then this temperature evolves under the heat equation
%
\[ \frac{\partial u}{\partial t} = \Delta u. \]
%
We let $f(x) = u(x,0)$ denote the initial heat distribution. To solve this heat equation, we expand $u$ in a Fourier series, i.e. writing
%
\[ u(x,t) = \sum_{n \in \ZZ^d} a_n(t) e^{2 \pi i n \cdot x}. \]
%
We then formally find that for each $n \in \ZZ^d$,
%
\[ a_n'(t) = - 4 \pi^2 |n|^2 a_n(t), \]
%
which we can solve to give
%
\[ a_n(t) = \widehat{f}(n) e^{- 4 \pi^2 |n|^2 t}. \]
%
In particular, we would expect the solution to the heat equation would be given by letting
%
\[ u(x,t) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{-4 \pi^2 |n|^2 t} e^{2 \pi n i t}. \]
%
As with Poisson's equation on the disk, we can write this as
%
\[ u(x,t) = (H_t * f)(x) \]
%
where $H_t$ is the \emph{heat kernel}
%
\[ H_t(x) = \sum_{n \in \ZZ^d} e^{- 4 \pi^2 |n|^2 t} e^{2 \pi n i t}. \]
%
The rapid convergence of this sum implies that $H_t \in C^\infty(\TT^d)$ and that $\widehat{H_t}(n) = e^{-4\pi^2 |n|^2}$ for each $n \in \ZZ^d$. To study this partial differential equation, it suffices to study the heat kernel $H_t$. Unlike in the case of the Poisson kernel however, we have no explicit formula for the heat kernel, which makes the kernel a little harder to work with.

\begin{lemma}
    The family $\{ H_t : t > 0 \}$ is an approximation to the identity.
\end{lemma}
\begin{proof}
    The Poisson summation formula implies that
    %
    \[ H_t(x) = \frac{1}{(4 \pi t)^{d/2}} \sum_{n \in \ZZ^d} e^{- |x + n|^2 / 4 t}. \]
    %
    This shows that $H_t(x) \geq 0$, and that
    %
    \[ \int_{\TT^d} H_t(x) = \frac{1}{(4 \pi t)^{d/2}} \int_{\RR^d} e^{-|x|^2/4 t}\; dx = \int_{\RR^d} e^{-\pi |x|^2}\; dx = 1. \]
    %
    We claim that for $|x| \leq 1/2$,
    %
    \[ \left| H_t(x) - \frac{e^{- x^2/4t}}{(4 \pi t)^{d/2}} \right| \lesssim_d e^{-c/t}, \]
    %
    where $c > 0$ is a universal constant. To prove this, we note this difference is equal to
    %
    \begin{align*}
        (4 \pi t)^{-d/2} \left| \sum_{n \neq 0} e^{- |x + n|^2 / 4t} \right| &\lesssim t^{-d/2} \sum_{n \neq 0} e^{-c' |n|^2 / 4t}\\
        &\lesssim t^{-d/2} e^{-c'/2t} \sum_{n \neq 0} e^{-c'|n|^2/2}\\
        &\lesssim_d t^{-d/2} e^{-c'/2t} \lesssim_d e^{-c/t}.
    \end{align*}
    %
    This implies that for any fixed $\delta > 0$,
    %
    \begin{align*}
        \int_{|x| > \delta} H_t(x) &\lesssim t^{-d/2} \int_{|x| > \delta} e^{-|x|^2/4t}\; dx + e^{-c/t}\\
        &\lesssim_d t^{-d/2} e^{-\delta^2/4t} + e^{-c/t}
    \end{align*}
    %
    which tends to zero as $t \to \infty$. Thus we have proved that $H_t$ is an approximation to the identity.
\end{proof}

\begin{theorem}
    For any $f \in L^1(\TT^d)$, for $1 \leq p < \infty$. Then the function
    %
    \[ u(x,t) = (H_t * f)(x) \]
    %
    lies in $C^\infty(\TT^d \times (0,\infty))$, and for $t > 0$ solves the heat equation. Moreover, $u$ is the unique solution to the heat equation in $C^2(\TT^d \times (0,\infty))$ such that
    %
    \[ \lim_{t \to 0^+} \int_{\TT^d} \left| u(t,x) - f(x) \right|\; dx = 0. \]
\end{theorem}
\begin{proof}
    We have already shown the former statement by the fact that $\{ H_t : t > 0 \}$ is an approximation to the identity. To prove the latter statement, given $u \in C^2(\TT^d \times (0,\infty))$, we can take a Fourier series, letting
    %
    \[ a_n(t) = \int_{\TT^d} u(x,t) e^{-2 \pi i n \cdot x}\; dx. \]
    %
    Then $a_n \in C^2((0,\infty))$ and differentiation under the integral sign shows that $a_n'(t) = -4\pi^2 a_n(t)$, so that $a_n(t) = c_n e^{- 4 \pi^2 t}$ for some $c_n$. But $a_n(t) \to \widehat{f}(n)$ as $t \to 0$ uniformly in $n$ by the convergence assumption, so $c_n = \widehat{f}(n)$. But this implies that $u(x,t) = (H_t * f)(x)$ for each $x \in \TT^d$, since both sides have the same Fourier series for all $t > 0$.
\end{proof}

%Let us consider an example taken from Fourier's original work. Consider heat moving from above ground to below ground, and vice versa. If we let $H(t,y)$ denote the temperature at a depth $y$ into the ground at time $t$, for $y > 0$. Assuming that the material of the ground is homogenous, by choosing appropriate units, the differential equation becomes $H_t = H_{yy}$, a variant of the heat equation. We assume that the heat at the surface changes periodically over the days and seasons, so
%
%\[ H(t,0) = A \cos(2\pi t / D) + B \cos(2 \pi t/Y) + C, \]
%
%where $A,B,C$ are arbitrary constants, $D$ is the length of a day, and $Y$ is the length of a year, so $Y = 365 D$. In our calculation, we assume the regularity condition that $H \in L^\infty [0,\infty)^2$, so the temperature does not magnify infinitely at large depths or large times.

%To solve this equation, we use two tricks: linearity, and Fourier series. We can solve the heat equation by solving the three heat equations with initial conditions $H_D(t,0) = \cos(2\pi t/D)$, $H_Y(t,0) = \cos(2 \pi t/Y)$, and $H_C(t,0) = 1$, and then obtain a general solution by letting $H = A H_D + B H_Y + C H_C$. The third equation is easiest: we let $H_C(t,y) = 1$ for all $t$ and $y$. To solve the other equations, we can use variable separation. Assuming $H_D$ and $H_Y$ are bounded, this means we have
%
%\[ H_D(t,y) = \cos((2 \pi /D) t - (\pi / D)^{1/2} y) e^{- (\pi / D)^{1/2} y}, \]
%\[ H_Y(t,y) = \cos((2\pi/Y)t - (\pi/Y)^{1/2} y) e^{- (\pi/Y)^{1/2} y}. \]
%
%Thus the temperature in the ground splits into a daily heating effect $H_D$, a seasonal heating effect $H_Y$, and a constant temperature $H_C$. From these equations we get several interesting qualitative properties. As we go deeper into the ground, the temperature decays at a rate inversely dependant on the length of time, so even at small depths, the daily temperature becomes neglible, and only the seasonal temperature is important. Experimently, determining the constants in our equation, we determine this happens about half a foot into the ground. Next, the deeper we go in the ground, the more a `time lag' exists, where the seasonal temperature back in time has now travelled to the temperature at the current point in the ground. Experimentally, we determine that about 2-3 metres below ground, the temperature lags by six months. Fourier mentions this is a good depth to build a wine cellar which is cool during the summer months.

\begin{comment}
\section{Seafaring with Fourier}

Here we discuss two problems in seafaring that can be solved quite accurately with Fourier analysis, first done by Kelvin in the late 1800s. Consider first the problem in determining the error of compass measurement on a ship when taking an initial bearing at harbor travelling. Thus for each angle $\theta$, we consider an error $g(\theta)$ such that if, at an angle $\theta$, we take a measurement $f(\theta)$, then $f(\theta) = \theta + g(\theta)$. Often $g$ is up to 20 degrees, but it will suffice to know $g$ up to an angle of two or three degrees, since other systematic errors in travel disturb the angle the ship actually travels by this amount anyway. And thus experimentally we find it suffices to approximate $g$ by a degree four trigonometric polynomial, i.e. we subtitute $g$ for an approximate value
%
\[ g_1(\theta) = A_0 + A_1 \cos \theta + B_1 \sin \theta + A_2 \cos(2\theta) + B_2 \sin(2\theta). \]
%
We can obtain measurements $g(\theta)$ for certain values of $\theta$ by locating landmarks, and 6 measurements suffice to uniquely identify $g_1$ from all other degree five trigonometric polynomials.

Another seafaring problem is to determine the future height of the tide. We expect the height of the tides to be due to periodic forces in nature. If $h(t)$ is the height of the tide, we might expect by linearity of the wave equation that $h(t) = h_1(t) + h_2(t) + \dots$, where $h_1(t)$ is the height with relation to the rotation of the earth and the moon, $h_2(t)$ the height with respect to the rotation of the earth and the sun, and so on and so forth to more neglible values. Each $h_k$ is periodic with some period $\omega_k$. If we assume that each $h_k$ is a trigonometric polynomial, then there is a way to reduce the calculation of the coefficients to a certain integral formula which one can approximate by taking samples of the height of the tides over time. Unfortunately, one must take a large number of samples to obtain this integral formula, but Kelvin designed one of the first automated calculators to approximate this without hard work on the part of the navigator.

\begin{theorem}
    If $h(t) = \sum_{n = 1}^N A_n \cos(\omega_n t)$, where $\omega_1, \dots, \omega_n$ are distinct, then for any $S$,
    %
    \[ A_n = \lim_{T \to \infty} \frac{2}{T} \int_S^{S + T} h(t) \cos(\omega_n t)\; dt. \]
\end{theorem}
\begin{proof}
    We just change variables. If $2 \pi N / \omega_n < T \leq 2 \pi (N + 1)/\omega_n$,
    %
    \begin{align*}
        \int_S^{S+T} h(t) \cos(\omega_n t)\; dt &= N \int_0^{2 \pi/ \omega_n} h(t) \cos(\omega_n t)\; dt + O(1)\\
        &= \frac{N}{\omega_n} \int_0^{2 \pi} \left( \frac{1}{N} \sum_{n = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) \right) \cos(t)\; dt + O(1).
    \end{align*}
    %
    We calculate that
    %
    \[ \frac{1}{N} \sum_{n = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) = A_n \cos(t) + O(1), \]
    %
    and so
    %
    \[ \frac{2}{T} \int_S^{S+T} h(t) \cos(\omega_n t)\; dt = A_n + O(1/T). \]
    %
    and we then take $T \to \infty$.
\end{proof}

\end{comment}








\chapter{The Fourier Transform}

In the last few chapters, we discussed the role of analyzing the frequency decomposition of a periodic function on the real line. In this chapter, we explore the ways in which we may extend this construction to perform frequency analysis for not necessarily periodic functions on the real line, and more generally, in higher dimensional Euclidean space. The only periodic trigonometric functions on $[0,1]$ on the real line had integer frequencies of the form $2\pi n$, whereas on the real line periodic functions can have frequencies corresponding to any real number. The analogue of the discrete Fourier series formula
%
\[ f(x) = \sum_{k = -\infty}^\infty \widehat{f}(k) e^{2 \pi i k x} \]
%
is the Fourier inversion formula
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi, \]
%
where for each real number $\xi$, we define
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(x) e^{- 2 \pi i \xi x}\; dx. \]
%
The function $\widehat{f}$ is known as the {\emph Fourier transform} of the function $f$. It is also denoted by $\mathcal{F}(f)$. The role to which we can justify this formula is the main focus of this chapter. The fact that $\RR$ is non-compact and has infinite measure adds some difficulty to the study of the Fourier transform over the Fourier series, but many of the same properties continue to hold in this setting. We add an additional difficulty by also analyzing the Fourier transform on $\RR^d$, which, given $f: \RR^d \to \CC$, considers the quantities
%
\[ f(x) \sim \int_{\RR^d} \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\ d\xi,\quad\text{where}\quad \widehat{f}(\xi) = \int_{\RR^d} f(x) e^{- 2 \pi i \xi \cdot x}\; dx \]
%
for $\xi \in \RR^d$. The basic theory of the Fourier transform in one dimension is essentially the same as the theory of the Fourier transform in $d$ dimensions, though as $d$ increases certain more technical considerations such as pointwise convergence become more difficult to understand.

\section{Basic Calculations}

Later, we will interpret the Fourier transform in a very general manner for a very arbitrary class of functions. But first we must interpret the Fourier transform as a Lebesgue integral, and the weakest assumptions we can make in order to do this are that $f$ is an integrable function, i.e. that $f \in L^1(\RR^d)$. During arguments, we can often assume additional regularity properties of $f$, and then apply density arguments to get the result in general. Most of the properties of the Fourier transform are exactly the same as for Fourier series. The only generally novel phenomenon in the basic theory is that the Fourier transform of an integrable function is continuous.

\begin{theorem}
    For any $f \in L^1(\RR^d)$, $\smash{\| \widehat{f} \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}}$, and $\widehat{f} \in C_0(\RR^d)$.
\end{theorem}
\begin{proof}
    For any $\xi \in \RR^d$,
    %
    \[ |\widehat{f}(\xi)| = \left| \int f(x) e(- \xi \cdot x)\; dx \right| \leq \int |f(x)| |e(- \xi \cdot x)|\; dx = \| f \|_{L^1(\RR^d)}. \]
    %
    If $\chi_I$ is the characteristic function of an $n$ dimensional box, i.e.
    %
    \[ I = [a_1,b_1] \times \dots \times [a_n,b_n] = I_1 \times \dots \times I_n, \]
    %
    then
    %
    \[ \widehat{\chi_I}(\xi) = \int_I e(- \xi \cdot x) = \prod_{k = 1}^n \int_{a_k}^{b_k} e(- \xi_k x_k) = \prod_{k = 1}^n \widehat{\chi_{I_k}}(\xi_k). \]
    %
    where
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) = \begin{cases} \frac{e(- \xi_k a_k) - e(- \xi_k b_k)}{2 \pi i \xi_k} & \xi_k \neq 0, \\ b_k - a_k & \xi_k = 0. \end{cases} \]
    %
    L'Hopital's rule shows $\widehat{\chi_{I_k}}$ is a continuous function. We also have the upper bound
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) \lesssim_{I_k} (1 + |\xi_k|)^{-1} \]
    %
    for all $\xi_k \in \RR$, which implies that
    %
    \[ \widehat{\chi_I}(\xi) = \prod \widehat{\chi_{I_k}}(\xi_k) \lesssim_I \prod \frac{1}{1 + |\xi_k|} \lesssim_n \frac{1}{1 + |\xi|}. \]
    %
    Thus $\widehat{\chi_I}(\xi) \to 0$ as $|\xi| \to \infty$. But this implies the Fourier transform of any step function is continuous and vanishes at $\infty$. Since step functions are dense in $L^1(\RR^d)$, a density argument then gives the result for all integrable functions.
\end{proof}

The space
%
\[ \mathbf{A}(\RR^d) = \left\{ \widehat{f}: f \in L^1(\RR^d) \right\} \]
%
is called the \emph{Fourier algebra}. The last theorem shows $\mathbf{A}(\RR^d) \subset C_0(\RR^d)$, but it is {\it not} the case that $\mathbf{A}(\RR^d) = C_0(\RR^d)$. Current research cannot give a satisfactory description of the elements of $\mathbf{A}(\RR^d)$, and a simple characterization is unlikely. The next lemma will be used to show $\mathbf{A}(\RR^d) \neq C_0(\RR^d)$.

\begin{lemma}
    For any $0 \leq a < b < \infty$, independantly of $a$ and $b$,
    %
    \[ \left| \int_a^b \frac{\sin x}{x} \right| = O(1). \]
\end{lemma}
\begin{proof}
    Since $\| \sin(x)/x \|_{L^\infty(\RR)} \leq 1$, we may assume $b > 1$, for otherwise we obtain a trivial bound. This also implies
    %
    \begin{align*}
        \left| \int_a^b \frac{\sin x}{x}\; dx \right| \leq 1 + \left| \int_1^b \frac{\sin x}{x}\; dx \right|.
    \end{align*}
    %
    An integration by parts then shows that
    %
    \[ \left| \int_1^b \frac{\sin x}{x}\; dx \right| \leq \left| \left( \cos 1 - \frac{\cos b}{b} \right) \right| + \left| \int_1^b \frac{\cos x}{x^2}\; dx \right| \lesssim 1. \qedhere \]
\end{proof}

\begin{theorem}
    $\mathbf{A}(\RR) \neq C_0(\RR)$. In particular, $\mathbf{A}(\RR)$ does not contain any odd functions $g$ in $C_0(\RR)$ such that
    %
    \[ \limsup_{b \to \infty} \left| \int_1^b \frac{g(\xi)}{\xi}\; d\xi \right| = \infty. \]
\end{theorem}
\begin{proof}
    Suppose $f \in L^1(\RR)$, and $\widehat{f} \in C_0(\RR)$ is an odd function. Then we know
    %
    \[ \widehat{f}(\xi) = -i \int_{-\infty}^\infty f(x) \sin(2 \pi \xi x)\; dx. \]
    %
    If $b \geq 1$, an application of Fubini's theorem shows that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| = \left| \int_{-\infty}^\infty f(x) \left( \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right)\; dx \right|. \]
    %
    But
    %
    \[ \left| \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right| = \left| \int_{2 \pi x}^{2 \pi b x} \frac{\sin \xi}{\xi}\; d\xi \right| \lesssim 1. \]
    %
    Thus we obtain that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| \lesssim \| f \|_{L^1(\RR)}. \]
    %
    For instance, this implies that there is no $f \in L^1(\RR)$ such that
    %
    \[ \widehat{f}(\xi) = \text{sgn}(\xi) \frac{|\sin(2 \pi \xi)|}{\log | \xi |} \]
    %
    for all $\xi \in \RR$, since
    %
    \[ \lim_{b \to \infty} \int_1^b \frac{|\sin(2 \pi \xi)|}{\xi \log |\xi|} = \infty. \qedhere \]
\end{proof}

On the other hand, for a finite measure $\mu$ on $\RR^d$, we can define the Fourier transform to be the continuous function
%
\[ \widehat{\mu}(\xi) = \int_{\RR^d} e^{-2 \pi i \xi \cdot x} d\mu(x). \]
%
In this case, the family of continuous functions which are the Fourier transforms of finite measures is precisely the family of $f \in C(\RR^d)$ which are \emph{positive definite}, in the sense that for each $x_1,\dots,x_N \in \RR^d$ and $\xi_1,\dots,\xi_N \in \CC$,
%
\[ \sum_{i,j} f(x_i - x_j) \xi_i \xi_j \geq 0. \]
%
The theorem, proved by Bochner, is best addressed in the more general case of harmonic analysis on locally compact abelian groups, and so we leave the proof of this for another time.

Elementary properties of integration give the following relations among the Fourier transforms of functions on $\RR^d$. They are strongly related to the translation invariance of the Lebesgue integral on $\RR^d$:
%
\begin{itemize}
    \item If $f^*(x) = \overline{f(x)}$ is the conjugate of a function $f$, then
    %
    \[ \widehat{f^*}(\xi) = \int \overline{f(x)} e(- x \cdot \xi)\; dx = \overline{\int f(x) e(x \cdot \xi)} = \overline{\widehat{f}(-\xi)}. \]
    %
    If $f$ is real, the formula above says $\widehat{f}(\xi) = \overline{\widehat{f}(-\xi)}$, and so if we define $a(\xi) = \text{Re}(\widehat{f}(\xi))$, $b(\xi) = \text{Im}(\widehat{f}(\xi))$, then formally we have
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi = 2 \int_0^\infty a(\xi) \cos(2 \pi \xi x) - b(\xi) \sin(2 \pi \xi x)\; d\xi. \]
    %
    Thus the Fourier representation formula expresses the function $f$ as an integral in sines and cosines.
    
    \item There is a duality between translation and frequency modulation. For $y \in \RR^d$, we define $(T_y f)(x) = f(x - y)$. If $\xi \in \RR^d$, then we define $(M_\xi f)(x) = e(\xi \cdot x) f(x)$. We then find that
    %
    \begin{align*}
        \widehat{T_y f}(\xi) &= \int f(x - y) e(- \xi \cdot x)\; dx\\
        &= e(- \xi \cdot y) \int f(x) e(- \xi \cdot x)\; dx = (M_{-y} \widehat{f})(\xi).
    \end{align*}
    %
    and
    %
    \begin{align*}
        \widehat{M_\xi f}(\eta) = \int e(\xi \cdot x) f(x) e(- \eta \cdot x)\; dx = \widehat{f}(\eta - \xi) = (T_\xi \widehat{f})(\eta).
    \end{align*}
    %
    Thus we conclude $\mathcal{F} \circ T_y = M_{-y} \circ \mathcal{F}$, and $\mathcal{F} \circ M_\xi = T_\xi \circ \mathcal{F}$.

    \item Let $T: \RR^d \to \RR^d$ be an invertible linear transformation. Then a change of variables $y = Tx$ gives
    %
    \begin{align*}
        \widehat{f \circ T}(\xi) &= \int f(Tx) e(-\xi \cdot x)\; dx\\
        &= \frac{1}{|\det(T)|} \int f(y) e(- \xi \cdot T^{-1}y)\; dy\\
        &= \frac{1}{|\det(T)|} \int f(y) e(- T^{-T} \xi \cdot y)\; dy\\
        &= \frac{1}{|\det(T)|} (\widehat{f} \circ T^{-T})(\xi).
    \end{align*}
    %
    Thus we conclude that if $T^*: L^1(\RR^d) \to L^1(\RR^d)$ is the operator defined by setting $T^*(f) = f \circ T$, then 
    %
    \[ \mathcal{F} \circ T^* = \frac{1}{|\det(T)|} \cdot (T^{-T})^* \circ \mathcal{F}. \]

    \item As a special case of the theorem above, if $a \in \RR$ and $\text{Dil}_a: L^1(\RR^d) \to L^1(\RR^d)$ is the operator defined by setting
    %
    \[ (\text{Dil}_a f)(x) = f(ax), \]
    %
    then
    %
    \[ \widehat{\text{Dil}_a f} = a^{-d} \cdot \text{Dil}_{1/a}\widehat{f} \]
    %
    If we dilate by a small value of $a$, then the values of $f$ are traced over more slowly, so $D_a f$ has smaller frequencies. But the magnitude of the Fourier transform over these frequencies is increased to compensate.

    \item Another special case is that if $R \in O_n(\RR)$, then $\widehat{f \circ R}(\xi) = \widehat{f}(R \xi)$, i.e. $\mathcal{F} \circ R^* = R^* \circ \mathcal{F}$. In particular, if $f$ is a radial function, so $f \circ R = f$ for any $R$, then $\widehat{f}(R \xi) = \widehat{f}(\xi)$ for any $R \in O_n(\RR)$, so $\widehat{f}$ is also a radial function. If $f$ is even, so $f(x) = f(-x)$ for all $x$, then $\widehat{f}(\xi) = \widehat{f}(-\xi)$ for all $\xi$, so $\widehat{f}$ is even. Similarily, if $f$ is odd, then $\widehat{f}$ is odd.

    \item Given $f,g \in L^1(\RR^d)$, we define the convolution
    %
    \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
    %
    This convolution possesses precisely the same properties as convolution on $\TT$. Most importantly for us,
    %
    \[ \mathcal{F}(f * g) = \mathcal{F}(f) \cdot \mathcal{F}(g), \]
    %
    so convolution in phase space is just a product in frequency space.
\end{itemize}

Just as with Fourier series, we have a duality between decay of a function and smoothness of it's transform. We say $f$ has a derivative $f_k$ in $L^p(\RR^d)$ if the family of functions
%
\[ (\Delta_h f)(x) = \frac{f(x + h e_k) - f(x)}{h} \]
%
converge in $L^p(\RR^d)$ to $f_k$. In the modern language of partial differential equations, $f_k$ is known as the \emph{weak derivative} of $f$. Intuitively, this means that the approximations of $f$ to it's derivative quantitatively converge in the mean to the function $f_k$. Note, however, that even if $f$ has a pointwise partial derivative $f_k$, the differences $\Delta_h f$ may not converge to $f_k$ fast enough to conclude that $f$ has a weak derivative. It is fairly easy to prove using the mean value theorem that if $\Delta_h f$ converges to $f_k$ in the $L^\infty$ norm, and $f$ has compact support, then $f$ has a weak derivative in all other $L^p$ spaces. If $f$ is not compactly supported, but decays rapidly at $\infty$, then the classical derivative may be a weak derivative. In particular, this is true of a Schwartz function, i.e. a function lying in the space
%
\[ \mathcal{S}(\RR^d) = \{ f \in C^\infty(\RR^d): |(D_\alpha f)(x)| \lesssim_{\alpha,N} |x|^{-N}\ \text{for all $N, \alpha, x$} \} \]
%
which is often a natural space to consider the relation of the Fourier transform to various analytical operations.

\begin{theorem}
    If $f \in L^1(\RR^d)$, and $x_k f \in L^1(\RR^d)$, then $\widehat{f}$ has a weak derivative in the $L^\infty$ norm, and $\widehat{f}_k(\xi) = - 2 \pi i (x_k f)^\ft(\xi)$.
\end{theorem}
\begin{proof}
    Note that a change of variables implies
    %
    \[ (\Delta_h \widehat{f})(\xi) = \int f(x) \frac{e(-h x_k) - 1}{h} e(- \xi \cdot x)\; dx = \widehat{g_h}(\xi), \]
    %
    where
    %
    \[ g_h(x) = f(x) \frac{e(h x_k) - 1}{h}. \]
    %
    Note that
    %
    \[ \left| \frac{e(h x_k) - 1}{h} \right| = O(1 + |x_k|). \]
    %
    Since $x_k f$ is integrable, we can apply the dominated convergence theorem. Because $(e(h x_k) - 1)/h$ tends to $-2 \pi i x_k f(x)$ as $h \downarrow 0$, the function $g_h$ tends to $-2\pi i x_k f$ in $L^1(\RR^d)$. Taking Fourier transforms, we conclude that $\Delta_h \widehat{f} = \widehat{g_h}$ converges uniformly to $(-2 \pi i x_k f)^\ft(\xi)$.
\end{proof}

\begin{remark}
    In particular, the Fourier transform of a compactly supported function lies in $C^\infty(\RR^d)$, and has weak derivatives of all orders, in all the $L^p$ spaces.
\end{remark}

%\begin{remark}
%   If $f$ no longer has compact support, but $D_k f$ vanishes rapidly at infinity, then we can normally still establish that $D_k f$ is the derivative of $f$ in $L^1(\RR^n)$. Indeed, suppose $|(D_k f)(x)| \leq g(|x|)$, where $g$ is an increasing function with $\int_0^\infty t^{n-1} g(t) < \infty$, then surely $\Delta_h f$ converges to $D_k f$ in $L^1$ on any compact set, which implies that for any $M$, using the mean value theorem again,
    %
%   \begin{align*}
%       \int_{\RR^n} &|(\Delta_h f)(x) - D_k f(x)|\; dx \leq o_M(1) + \int_{|x| > M} |(\Delta_h f)(x)| + |D_k f(x)| \\
%       &\leq o_M(1) + O \left( \int_{|x| > M} g(|x| + |h|)\; dx \right) = o_M(1) + O \left( \int_M^\infty t^{n-1}g(t)\; dt \right)\\
%   \end{align*}
    %
%   If we choose $M$ large enough that the big $O$ term is $\leq \varepsilon$, then we find $\| \Delta_h f - D_k f \|_1 \leq \varepsilon + o_M(1)$, and taking $\varepsilon \to 0$ shows the convergence. This shows the derivatives exist if, for instance, $f$ is a Schwarz function, since then $|D_k f(x)| \lesssim 1/(1 + |x|^{n+1})$.
%\end{remark}

\begin{theorem}
    If $f$ has a weak derivative $f_k$ in the $L^1$ norm, $\widehat{f_k}(\xi) = 2 \pi i \xi_k \widehat{f}(\xi)$.
\end{theorem}
\begin{proof}
    It suffices to note that
    %
    \[ \widehat{\Delta_h f}(\xi) = \frac{e(h \xi_k) - 1}{h} \widehat{f}(\xi). \]
    %
    Since $\Delta_h f \to f_k$ in $L^1$, $\widehat{\Delta_h f} \to \widehat{f_k}$ uniformly, and in particular, converges to $\widehat{f_k}$ pointwise. But we know $\widehat{\Delta_h f}$ converges pointwise to $2 \pi i \xi_k \widehat{f}(\xi)$.
\end{proof}

%\begin{theorem}
%   If $X$ is a homogenous space of functions, the $f * K_\delta$ converges to $f$ in the norm associated with $X$.
%\end{theorem}
%\begin{proof}
%   Given a continuous function function $F: \TT \to X$, we define the formal Riemann integral of functions as
    %
%   \[ \int_{\TT} F(x)\; dx = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N F(2 \pi /N) \]
    %
%   which exists for the same reason the Riemann integral of a continuous real valued function exists. Now we can consider the formal function theoretic convolution
    %
%   \[ \int_{\TT} K_\delta(x) f_x\; dx \]
    %
%   This is equal to $K_\delta * f$, because the $L^1$ norm lower bounds the norm on $X$, so that the limit with respect to the $L^1$ norm is the same as with respect to the norm on $X$, and
    %
%   \[ s \]
    %
%   \[ \int_{\TT} K_\delta(x) f_x\; dx - f = \int_0^{2\pi} K_\delta(x)[f_x - f]\; dx \]
    %
%   If we choose 
%\end{proof}
%
%More generally, if we equip a translation invariant subspace of $L^1(\RR^n)$ with a norm lower bounded up to a constant by the $L^1$ norm which turns the space into a Banach space, then $f * K_\delta$ converges to $f$ in that norm. If in addition, the $K_\delta$ satisfy $|K_\delta(x)| \lesssim \delta^{-n}$, and $|K_\delta(x)| \lesssim \delta/|x|^{n+1}$, then $f * K_\delta$ converges to $f$ almost everywhere. 

\section{Alternative Summation Methods}

As we might expect from the Fourier series theory, the formula
%
\[ f(x) = \int \widehat{f}(\xi) e(\xi \cdot x)\; dx \]
%
does not hold for every integrable $f$, nor even for all continuous $f$. In particular, the Fourier transform of $f$ need not even lie in $L^1(\RR^d)$, so the integral formula may not even make sense. Nonetheless, just as with Fourier series, one can obtain general results by `dampening' the integration.

\begin{example}
    Even if $f$ is a non integrable function, the functions $f(x) e^{-\delta |x|}$ may be integrable for $\delta > 0$. If this is the case, we say $f$ is \emph{Abel summable} to a value $A$ if
    %
    \[ \lim_{\delta \to 0} \int_{\RR^d} f(x) e^{-\delta |x|}\; dx = A \]
    %
    For each $\delta > 0$ and $f \in L^1(\RR^d)$, we let
    %
    \[ (A_\delta f)(x) = \int_{\RR^d} \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|}\; d\xi. \]
    %
    Thus $A_\delta f$ represents the Abel sums of the Fourier inversion formula.
\end{example}

If $f \in L^1(\RR^d)$, then the dominated convergence theorem implies that
%
\[ \int_{\RR^d} f(x) e^{-\delta |x|}\; dx \to \int_{\RR^d} f(x)\; dx. \]
%
so $f$ is Abel summable. However, $f$ may be Abel summable even if $f$ is not integrable. For instance, if $f(x) = \sin(x)/x$, then $f$ is not integrable, yet $f$ is Abel summable to $\pi$ over the real line.

\begin{example}
    Similarily, we can consider the Gauss sums
    %
    \[ \int f(x) e^{-\delta |x|^2}\; dx \]
    %
    We say $f$ is Gauss summable to if these values converge as $\delta \to 0$. For $f \in L^1(\RR^d)$, we let
    %
    \[ (G_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|^2}\; d\xi. \]
    %
    Then as $\delta \to 0$, $G_\delta f$ represents the Gauss sums of the Fourier inversion formula.
\end{example}

\begin{example}
    For $d = 1$, we can also consider the Fej\'{e}r sums
    %
    \[ (\sigma_\delta f)(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi \cdot x) \left( \frac{\sin(\delta \pi \xi)}{\delta \pi \xi} \right)^2\; d\xi, \]
    %
    which are analogous to the Fej\'{e}r sums in the periodic setting.
\end{example}

\begin{example}
    In basic calculus, the integral of a function $f$ over the entire real line is defined as
    %
    \[ \int_{-\infty}^\infty f(x)\; dx = \lim_{R \to \infty} \int_{-R}^R f(x)\; dx. \]
    %
    These integrals can be written as the integral of $f \chi_{[-R,R]}$, and so in a generalized sense, we can integrate a function $f$ if $f \chi_{[-R,R]}$ is integrable for each $N$, and the integrals of these functions converge as $t \to \infty$. Thus we study
    %
    \[ (S_R f)(x) = \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{example}

Abel summability is more general than the piecewise limit integral considered in the last example, as the next lemma proves.

\begin{lemma}
    Suppose $f \in L^1_{\text{loc}}(\RR)$, that
    %
    \[ \lim_{R \to \infty} \int_{-R}^R f(x)\; dx \]
    %
    exists, and that $f(x) e^{-\delta x^2}$ is absolutely integrable for each $\delta > 0$. Then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int_{-\infty}^\infty f(x) e^{-\delta |x|^2} = \lim_{R \to \infty} \int_{-R}^R f(x)\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{R \to \infty} \int_{-R}^R f(x)\; dx = A. \]
    %
    For each $x \geq 0$, write
    %
    \[ F(x) = \int_{-x}^x f(x)\; dx. \]
    %
    Then $F$ is continuous and differentiable almost everywhere, and $F(x) \to A$ as $x \to \infty$. We know that $F'(x) = f(x) + f(-x)$, and an integration by parts gives for each $s > 0$,
    %
    \begin{align*}
        \int_{-s}^s f(x) e^{-\delta x^2}\; dx &= \int_0^s [f(x) + f(-x)] e^{-\delta x^2}\; dx\\
        &= F(s) e^{-\delta s^2} + 2 \delta \int_0^s x F(x) e^{-\delta x^2}\; dx.
    \end{align*}
    %
    Taking $s \to \infty$, using the fact that $F$ is bounded so that $F(s) e^{-\delta s^2} \to 0$, we conclude
    %
    \[ \int_{-\infty}^\infty f(x) e^{-\delta x^2}\; dx = 2 \delta \int_0^\infty x F(x) e^{-\delta x^2}\; dx. \]
    Given $\varepsilon > 0$, fix $t$ such that $|F(s) - A| \leq \varepsilon$ for $s \geq t$. Then
    %
    \begin{align*}
        \left| \int f(x) e^{-\delta x^2}\; dx - A \right| &\leq 2 \delta \left| \int_0^t x F(x) e^{-\delta x^2}\; dx \right|\\
        &\quad + 2 \delta \varepsilon \left| \int_t^\infty x e^{-\delta x^2} \right|\\
        &\quad + \left| 2 \delta A \int_t^\infty x e^{-\delta x^2}\; dx - A \right|.
    \end{align*}
    %
    The first and second components of this upper bound can each be made smaller than $\varepsilon$ for small enough $\delta$. And
    %
    \[ 2 \delta \int_t^\infty x e^{-\delta x^2}\; dx = e^{-\delta t^2} \]
    %
    So the third term is equal to $|A| |1 - e^{-\delta t^2}|$ and so for small enough $\delta$, we can also bound this by $\varepsilon$. Thus we have shown for small enough $\delta$ that
    %
    \[ \left| \int f(x) e^{-\delta x^2}\; dx - A \right| \leq 3 \varepsilon. \]
    %
    It now suffices to take $\varepsilon \to 0$.
\end{proof}

Abel summation is even more general than Gauss summation.

\begin{lemma}
    If $f$ is Gauss summable, and $f(x) e^{-\delta |x|}$ is absolutely integrable for each $\delta > 0$, then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = A. \]
    %
    If there existed constants $c_n$ and $\lambda_n$ such that $e^{-\delta |x|} = \sum c_n e^{-(\lambda_n \delta |x|)^2}$, this theorem would be easy. This is not exactly true, but we do have the {\it subordination principle}, which says
    %
    \[ e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\delta^2 |x|^2/4u}\; du. \]
    %
    This formula, which is proved using basic complex analysis, is shown later on in this chapter. Applying Fubini's theorem, this means that
    %
    \[ \int f(x) e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du. \]
    %
    For any fixed $t > 0$, we certainly have
    %
    \[ \lim_{\delta \to 0} \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du = A \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \]
    %
    And this is equal to $A(1 + o(1))$ as $t \to 0$. And now we calculate
    %
    \[ \int_0^t \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; du \leq \left\| \frac{e^{-u}}{\sqrt{\pi u}} \right\|_{L^1[0,t]} \left\| \int f(x) e^{-\delta^2 |x|^2/4u} \right\|_{L^\infty[0,t]} \]
    %
    The left norm tends to zero as $t \to 0$. And as $u \downarrow 0$, the dominated convergence theorem implies that
    %
    \[ \int f(x) e^{-\delta |x|^2/4u} \to 0. \]
    %
    This completes the proof.
\end{proof}

For any family of functions $\Phi_\delta$, we can consider the `$\Phi$ sums'
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
and the corresponding Fourier transform operators
%
\[ S_\delta(f,\Phi)(x) = \int \widehat{f}(x) e(\xi \cdot x) \Phi_\delta(\xi)\; d\xi. \]
%
We say $f$ is $\Phi$ summable to a value if
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
converges. In all the examples we will consider, we construct $\Phi$ sums by fixing a function $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and defining $\Phi_\delta(x) = \Phi(\delta x)$. When this is the case $f(x) \Phi_\delta(x)$ converges to $f(x)$ pointwise for each $x$ as $\delta \to 0$. Thus if $f \in L^1(\RR^d)$, the dominated convergence theorem implies that $f$ is $\Phi$ summable to it's usual integral. We now use these summability kernels to understand the Fourier summation formula.

\begin{theorem}[The Multiplication Formula]
    If $f,g \in L^1(\RR^d)$,
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \widehat{f}(\xi) g(\xi)\; dx. \]
\end{theorem}
\begin{proof}
    If $f, g \in L^1(\RR^d)$, then $\widehat{f}$ and $\widehat{g}$ are bounded, continuous functions on $\RR^d$. In particular, $\widehat{f} g$ and $f \widehat{g}$ are integrable. A simple use of Fubini's theorem gives
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \int f(x) g(\xi) e(- \xi \cdot x)\; dx\; d\xi = \int g(\xi) \widehat{f}(\xi)\; d\xi. \qedhere \]
\end{proof}

If $\Phi$ is integrable, then the multiplication formula shows
%
\begin{align*}
    S_\delta(f,\Phi) &= \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) d\xi\\
    &= \int f(x) (M_x (\delta_\delta \Phi))^\ft(x)\; dx = \delta^{-n} \int f(x) \cdot \widehat{\Phi} \left( \frac{x - y}{\delta} \right)\; dx.
\end{align*}
%
Thus if we define $K^\Phi_\delta(x) = \delta^{-n} \widehat{\Phi}(-x/\delta)$, then $S_\delta(f,\Phi) = K^\Phi_\delta * f$. Thus we have expressed the summation operators as convolution operations.

We now recall some notions of convolution kernels that help us approximate functions. Recall that if a family of kernels $\{ K_\delta \}$ satisfies
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item The values $\{ \| K_\delta \|_{L^1(\RR^d)} \}$ are uniformly bounded in $\delta$.

    \item For any $\varepsilon > 0$,
    %
    \[ \lim_{\delta \to 0} \int_{|\xi| \geq \varepsilon} |K_\delta(\xi)|\; d\xi \to 0. \]
\end{itemize}
%
then the family forms a \emph{good kernel}. If this is the case, then $f * K_\delta$ converges to $f$ in the $L^p$ norms if $f \in L^p(\RR^d)$, and converges to $f$ uniformly if $f$ is continuous and bounded. If we have the stronger conditions that
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item $\| K_\delta \|_{L^\infty(\RR^d)} \lesssim 1/\delta^d$.
    \item For any $\delta > 0$ and $\xi \in \RR^d$,
    %
    \[ |K_\delta(\xi)| \lesssim \frac{\delta}{|\xi|^{d+1}}. \]
\end{itemize}
%
then the family $\{ K_\delta \}$ is an approximation to the identity, and so $(K_\delta * f)(x)$ converges to $f(x)$ for any $x$ in the Lebesgue set of $f$.

\begin{example}
    We obtain the {\it Fej\'{e}r kernel} $F_\delta$ from the initial function
    %
    \[ F(x) = \left( \frac{\sin \pi x}{\pi x} \right)^2 \]
    %
    Using contour integration, we now show
    %
    \[ \widehat{F}(\xi) = \begin{cases} 1 - |\xi| & : |\xi| \leq 1\\ 0 &: |\xi| > 1 \end{cases} \]
    %
    Since this functions is compactly supported, with total mass one, it is easy to see the corresponding Kernel $K^F_\delta$ are an approximation to the identity. Thus $\sigma_\delta f$ converges to $f$ in all the manners described above.

    Since $F$ is an even function, $\widehat{F}$ is even, and so we may assume $\xi \geq 0$. We initially calculate
    %
    \[ \widehat{F}(\xi) = \int_{-\infty}^\infty \left( \frac{\sin(\pi x)}{\pi x} \right)^2 e(- \xi x)\; dx = \frac{1}{\pi} \int_{-\infty}^\infty \left( \frac{\sin x}{x} \right)^2 e(- 2 \xi x) \; dx. \]
    %
    Now we have
    %
    \[ (\sin z)^2 = \left( \frac{e(z) - e(-z)}{2i} \right)^2 = \frac{(2 - e^{2iz}) - e^{-2iz}}{4}. \]
    %
    This means
    %
    \begin{align*}
        \frac{(\sin z)^2}{z^2} e^{- 2 i \xi z} &= \frac{2e^{-2 i \xi z} - e^{-2(\xi + 1) i z}) - e^{-2(\xi - 1)iz}}{4z^2 } = \frac{f_\xi(z) + g_\xi(z)}{4}.
    \end{align*}
    %
    For $\xi \geq 0$, $f_\xi(z)$ is $O_\xi(1/|z|^2)$ in the lower half plane, because if $\text{Im}(z) \leq 0$,
    %
    \[ |2e^{-2 i \xi z} - e^{-2(\xi + 1) z}| \leq 2e^{2\xi} + e^{2(\xi + 1)} = O_\xi(1). \]
    %
    For $\xi \geq 1$, $g_\xi(z)$ is also $O_\xi(1/|z|^2)$ in the lower half plane, because
    %
    \[ |e^{-2(\xi - 1)iz}| \leq e^{2(\xi - 1)}.  \]
    %
    Now since $(\sin x/x)^2 e^{-2 i \xi x}$ can be extended to an entire function on the entire complex plane, which is bounded on any horizontal strip, we can apply Cauchy's theorem and take limits to conclude that
    %
    \begin{align*}
        \widehat{F}(\xi) = \frac{1}{\pi} \int_{-\infty}^\infty \frac{(\sin x)^2}{x^2} e^{-2 i \xi x}\; dx &= \frac{1}{\pi} \int_{-\infty}^{\infty} \frac{(\sin (x - iy)^2}{(x - iy)^2} e^{-2 i \xi x  -2 \xi y}\; dx\\
        &= \frac{1}{4 \pi} \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx.
    \end{align*}
    %
    If $\xi \geq 1$, the functions $f_\xi$ and $g_\xi$ are both negligible in the lower half plane, and have no poles in the lower half plane, so if we let $\gamma$ denote the curve of length $2 \pi n$ travelling anticlockwise along the lower semicircle with vertices $-n - iy$ and $n - iy$, then because $|z| \geq n$ on $\gamma$,
    %
    \begin{align*}
        \int_{-n}^n f_\xi(x - iy) + g_\xi(x - iy)\; dx &= \int_\gamma f_\xi(z) + g_\xi(z)\; dz\\
        &= \text{length}(\gamma) \| f_\xi + g_\xi \|_{L^\infty(\gamma)}\\
        &= (2 \pi n) O_\xi(1/n^2) = O_\xi(1/n),
    \end{align*}
    %
    and so we conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx = 0. \]
    %
    This means $\widehat{F}(\xi) = 0$. If $0 \leq \xi \leq 1$, then $f_\xi$ is still small in the lower half plane, so we can conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy)\; dx = 0. \]
    %
    But $g_\xi$ is now small in the upper half plane. For $\text{Im}(z) \geq -y$,
    %
    \[ |e^{-2(\xi - 1)iz}| = |e^{2(1 - \xi)iz}| \leq e^{2(1 - \xi)y}, \] 
    %
    so $g_\xi(z) = O_\xi(1/|z|^2)$ in the half plane above the line $\RR - iy$. The only problem now is that $g_\xi$ has a pole in this upper half plane, at the origin. Taking Laurent series here, we find that the residue at this point is $2i(\xi - 1)$. Thus, if we let $\gamma$ be the curve obtained from travelling anticlockwise about the upper semicircle with vertices $-n - iy$ and $n - iy$, then $|z| \geq n - y$ on this curve, and the residue theorem tells us that
    %
    \[ \int_{-n}^n g_\xi(x - iy)\; dx + \int_\gamma g_\xi(z)\; dz = 2\pi i (2i(\xi - 1)) = 4 \pi (1 - \xi), \]
    %
    and we now find that, as with the evaluation of the previous case,
    %
    \[ \int_\gamma g_\xi(z)\; dz \leq (2 \pi n) O_{\xi,y}(1/n^2) = O_{\xi,y}(1/n). \]
    %
    Taking $n \to \infty$, we conclude
    %
    \[ \int_{-\infty}^\infty g_\xi(x - iy)\; dx = 4 \pi (1 - \xi), \]
    %
    and putting this all together, we conclude that $\widehat{F}(\xi) = 1 - \xi$.
%   It is interesting in this particular case to note that
    %
%   \begin{align*}
%       \int_{-1}^1 (1 - |\xi|) e^{2 \pi i\xi x}\; d\xi &= 2 \int_0^1 (1 - \xi) \cos(2 \pi \xi x)\; d\xi\\
%       &= 2 \left( \left. \frac{(1 - \xi) \sin(2 \pi \xi x)}{2 \pi x} - \frac{\cos(2 \pi \xi x)}{(2 \pi x)^2} \right|_0^1 \right)\\
%       &= 2 \frac{1 - \cos(2 \pi x)}{(2 \pi x)^2} = \frac{\sin^2(\pi x)}{(\pi x)^2} = F(x)
%   \end{align*}
    %
%   which is exactly the inversion formula we want for all $L^1$ functions.
\end{example}

\begin{example}
    In the next paragraph, we calculate that if $\Phi(x) = e^{-\pi |x|^2}$, then $\widehat{\Phi} = \Phi$. Thus if we define the \emph{Weirstrass kernel} by
    %
    \[ W_\delta(\xi) = \delta^{-d} e^{-\pi |x|^2/\delta^2}, \]
    %
    then $G_\delta(f) = W_\delta * f$. Since the family $\{ W_\delta \}$ is an approximation to the identity, this shows $G_\delta(f)$ converges to $f$ in all the appropriate senses.

    Since $\Phi$ breaks onto products of exponentials over each coordinate, it suffices to calculate the Fourier transform in one dimension, from which we can obtain the general transform by taking products. In the one dimensional case, since $\Phi'(x) = -2 \pi x e^{- \pi x^2}$ is integrable, we conclude that $\widehat{\Phi}$ is differentiable, and
    %
    \[ (\widehat{\Phi})'(\xi) = (- 2 \pi i \xi \Phi)^\ft(\xi) = i (\Phi')^\ft(\xi) = i (2 \pi i \xi) \widehat{\Phi}(\xi) = - 2 \pi \xi \widehat{\Phi}(\xi) \]
    %
    The uniqueness theorem for ordinary differential equations says that since
    %
    \[ \widehat{\Phi}(0) = \int_{-\infty}^\infty e^{- \pi x^2} = 1 = \Phi(0) \]
    %
    Thus we must have $\widehat{\Phi} = \Phi$.
\end{example}

\begin{example}
    The Fourier transform of the function $e^{- |x|}$ is the \emph{Poisson kernel}
    %
    \[ P(\xi) = \frac{\Gamma((d+1)/2)}{\pi^{(d+1)/2} (1 + |\xi|^2)^{(d+1)/2}} \]
    %
    Later on we show the corresponding scaled kernel $\{ P_\delta \}$ is an approximation to the identity, and thus $A_\delta f = P_\delta * f$ converges to $f$ in all appropriate senses.

    The Abel kernel $A_\delta$ on $\RR^d$ is obtained from the initial function $A(x) = e^{-2 \pi |x|}$. The calculation of the Fourier transform of this function indicates a useful principle in analysis: one can reduce expressions involving $e^{-x}$ into expressions involving $\smash{e^{-x^2}}$ using the subordination principle. In particular, for $\beta > 0$ we have the formula
    %
    \[ e^{-\beta} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du \]
    %
    We establish this by letting $v = \sqrt{u}$, so
    %
    \[ \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du = \frac{2}{\sqrt{\pi}} \int_0^\infty e^{-v^2 - \beta^2/4v^2}\; dv = \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-(v - \beta/2v)^2}\; dv \]
    %
    But the map $v \mapsto v - \beta/2v$ is measure preserving by Glasser's master theorem, so this integral is
    %
    \[ \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-v^2}\; dv = e^{-\beta} \]
    %Because using the theory of residues,
    %
    %\begin{align*}
    %   e^{-\beta} &= \frac{2}{\pi} \int_0^\infty \frac{\cos \beta x}{1 + x^2} = \frac{1}{\pi} \int_{-\infty}^\infty \frac{e^{\beta i x}}{1 + x^2}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_{-\infty}^\infty e^{\beta i x} \int_0^\infty e^{-u} e^{-ux^2}\; du\; dx\\
    %   &= \frac{1}{\pi} \int_0^\infty e^{-u} \int_{-\infty}^\infty e^{-ux^2} e^{\beta i x}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_0^\infty \sqrt{\pi/u} e^{-u} e^{-\beta^2/4u}\; du
    %\end{align*}
    %
    In tandem with Fubini's theorem, this formula implies
    %
    \begin{align*}
        \widehat{A}(\xi) &= \int_{\RR^d} e^{-2 \pi |x|} e^{- 2 \pi i \xi \cdot x}\; dx = \int_{\RR^d} \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{- |\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; du\; dx\\
        &= \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int_{\RR^d} e^{-|\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; dx\; du = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} (\text{Dil}_{(\pi^{1/2}/u^{1/2})} \Phi)^\ft(\xi)\; du\\
        &= \frac{1}{\pi^{(d + 1)/2}} \int_0^\infty e^{-u} u^{(d-1)/2} e^{- u|\xi|^2}\; du
    \end{align*}
    %
    Setting $v = (1 + |\xi|^2) u$, we conclude that since by definition,
    %
    \[ \int_0^\infty e^{-v} v^{(d-1)/2} = \Gamma \left( \frac{d+1}{2} \right) \]
    %
    \[ \widehat{A}(\xi) = \frac{\Gamma((d+1)/2)}{[\pi(1 + |\xi|^2)]^{(d+1)/2}} \]
    %
    Thus the Abel mean is the Fourier inverse of the Poisson kernel on the upper half plane $\mathbf{H}^{d+1}$. We note that the Poisson summation formula shows that for $d = 1$, the Poisson kernel on $\TT$ is the periodization of the Poisson kernel on $\RR$.

    In order to conclude $\{ P_\delta \}$ is a good kernel, it now suffices to verify that
    %
    \[ \int_{\RR^d} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = \frac{\pi^{(d+1)/2}}{\Gamma((d+1)/2)} \]
    %
    The right hand side is half the surface area of the unit sphere in $\RR^{d+1}$. Denoting the surface area of the unit sphere in $\RR^{d+1}$ by $S_d$, and switching to polar coordinates, we find that
    %
    \[ \int_{\RR^d} \frac{d\xi}{(1 + |\xi|^2)^{(d+1)/2}} = S_{d-1} \int_0^\infty \frac{r^{d-1}}{(1 + r^2)^{(d+1)/2}}\; dr \]
    %
    Setting $r = \tan u$, we find
    %
    \[ \int_0^\infty \frac{r^{d-1}}{(1 + r^2)^{(d+1)/2}}\; dr = \int_0^{\pi/2} (\sin u)^{d-1} du \]
    %
    But we can now show by induction that
    %
    \[ \frac{S_d}{2} = S_{d-1} \int_0^{\pi/2} (\sin u)^{d-1}\; du. \]
    %
    Using the values $S_0 = 2$, $S_1 = 2\pi$, and $S_2 = 4\pi$, the theorem certainly holds for $d = 1$ and $d = 2$. For $d > 2$, integration by parts and induction shows that
    %
    \begin{align*}
        S_{d-1} \int_0^{\pi/2} (\sin u)^{d-1}\; du &= S_{d-1} \frac{d-2}{d-1} \int_0^{\pi/2} (\sin u)^{d-3}(t)\; dt.\\
        &= \frac{d-2}{d-1} \frac{S_{d-1} S_{d-2}}{2S_{d-3}}\\
        &= \frac{d-2}{d-1} \frac{\pi^{d/2} \pi^{d/2-1/2}}{\pi^{d/2-1}} \frac{\Gamma(d/2 - 1)}{\Gamma(d/2) \Gamma(d/2 - 1/2)}\\
        &= \frac{\pi^{d/2+1/2}}{\Gamma(d/2 + 1/2)} = \frac{S_d}{2}.
    \end{align*}
    %
    Thus our theorem is complete.
\end{example}

\begin{example}
    We note that
    %
    \[ \int_{-R}^R e(- \xi x)\; dx = \frac{e(- \xi R) - e(\xi R)}{-2 \pi i \xi} = \frac{\sin(2 \pi \xi R)}{\pi \xi}. \]
    %
    so the Fourier transform of $\chi_{[-R,R]}$ is the \emph{Dirichlet kernel}
    %
    \[ D_R(\xi) = \frac{\sin(2 \pi \xi R)}{\pi \xi} \]
    %
    We note that $D_R \not \in L^1(\RR)$. Thus $D_R$ is {\it not} a good kernel, which makes the convergence rates of $S_R f$ more subtle. Nonetheless, $D_R$ does lie in $L^p(\RR)$ for all $p \in (1,\infty]$, and is \emph{uniformly bounded} in $L^p(\RR)$ for all $p \in (1,\infty)$, a fact we will prove later.
    %
%    \[ \int_{|\xi| \geq 1/R} \left| \frac{\sin(2 \pi \xi R)}{\pi \xi} \right|^p \lesssim \int_{1/R}^\infty \frac{1}{|\xi|^p} = R^{p-1} \]
%    \[ \int_{|\xi| \leq 1/R} \left| \frac{\sin(2 \pi \xi R)}{\pi \xi} \right|^p \lesssim_p R^{p-1} \]
    This is enough to conclude that for all $p \in (1,\infty)$, $S_R f \to f$ in $L^p(\RR)$.
\end{example}

Thus we now know there are a large examples of functions $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and such that for any $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x). \]
%
If $\widehat{f}$ is integrable, then the bound $| \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) | \leq \| \Phi \|_\infty | \widehat{f}(\xi) |$ implies that we can use the dominated convergence theorem to conclude that for any point $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x) = \int \widehat{f}(\xi) e(\xi \cdot x) \]
%
Thus the inversion theorem holds pointwise almost everywhere.

\begin{theorem}
    If $f$ and $\widehat{f}$ are elements of $L^1(\RR^d)$, then for any $x$ in the Lebesgue set of $f$,
    %
    \[ f(x) = \int_{\RR^d} \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{theorem}

\begin{remark}
    We note that if $f \in L^1(\RR^d)$, $\widehat{f} \geq 0$, and $f$ is continuous at the origin, then the Fourier inversion formula and the monotone convergence theorem implies that
    %
    \[ f(0) = \lim_{\delta \to 0} \int_{\RR^d} \widehat{f}(\xi) e^{-\delta \xi}\; d\xi = \int_{\RR^d} \widehat{f}(\xi)\; d\xi. \]
    %
    Thus $\widehat{f}$ is integrable, and so the Fourier inversion theorem holds.

    As a particular example of this remark, if $f \in L^1(\RR^d)$ then we can define the autocorrelation function
    %
    \[ R(x) = \int_{\RR^d} f(y + x) f(y)\; dy, \]
    %
    then $R \in L^1(\RR^d)$ and $\widehat{R}(\xi) = |\widehat{f}(\xi)|^2$. Thus $R$ is continuous at the origin if and only if $\widehat{R}$ is integrable, which, using the $L^2$ theory we develop in the next section, holds if and only if $f \in L^2(\RR^d)$.
\end{remark}

It is often useful to note that if the Fourier transform of an integrable function is non-negative, then it's Fourier transform is automatically integrable.

\begin{theorem}
   If $f \in L^1(\RR)$ is continuous at the origin, and $\widehat{f} \geq 0$, then $\widehat{f}$ is integrable.
\end{theorem}
\begin{proof}
   This follows because
    %
   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \]
    %
   By Fatou's lemma,
    %
   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \geq \int \liminf_{\delta \to 0} \widehat{f}(\xi) e^{-\delta |x|} = \int \widehat{f}(\xi) \]
    %
   so $\widehat{f}$ is finitely integrable.
\end{proof}

Note that this implies that we obtain the general inversion theorem, so in particular, it is only continuous functions, and functions almost everywhere equal to continuous functions, which can have non-negative Fourier transforms.

We define, for any integrable $f: \RR^n \to \RR$, the \emph{inverse} Fourier transform
%
\[ \widecheck{f}(x) = \int f(\xi) e(\xi \cdot x)\; d\xi \]
%
The inverse transform is also denoted by $\mathcal{F}^{-1}(f)$. The last theorem says that $\mathcal{F}^{-1}$ really is the inverse operator to the operator $\mathcal{F}$, at least on the set of functions $f$ where $\widehat{f}$ is integrable. In particular, this is true if $f$ has weak derivatives in the $L^1$ norm for any multi-index $|\alpha| \leq n+1$, and so the Fourier inversion formula holds for sufficiently smooth functions.

\begin{corollary}
    If $f \in C(\RR)$ is integrable and $\widehat{f} \in L^1(\RR)$, $S_R f \to f$ uniformly.
\end{corollary}
\begin{proof}
    The dominated convergence theorem implies that for each $x \in\RR$,
    %
    \[ f(x) = \int_{\RR} \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} (S_R f)(x). \]
    %
    And
    %
    \[ \int_{|x| \geq R} \widehat{f}(\xi) e(\xi \cdot x) \leq \int_{|x| \geq R} |\widehat{f}(\xi)|\; d\xi = o(1). \]
    %
    so the pointwise convergence is uniform in $x$.
\end{proof}

\begin{remark}
    This theorem also generalizes to $\RR^d$. Here, the operators $S_R$ are no longer canonically defined, but if we consider any increasing nested family of sets $B_R$ with $\lim B_R = \RR^n$, then the corresponding operators
    %
    \[ S_R f = \int_{B_R} \widehat{f}(\xi) e(\xi \cdot x) \]
    %
    also converge uniformly to $f$.
\end{remark}

\begin{corollary}
    The map $\mathcal{F}: L^1(\RR^d) \to C_0(\RR^d)$ is injective.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\widehat{f}$ is certainly integrable. But this means that the Fourier inversion theorem can apply, giving that for almost every point $x$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(x) e(\xi \cdot x) = 0. \]
    %
    Thus $f = 0$ almost everywhere.
\end{proof}

The corollary above is often underestimated in utility. Even if the Fourier inversion theorem doesn't hold, we can still view the Fourier transform as another way to represent a function, since the Fourier transform does not lose any information. For instance, it can be used very easily to verify identities involving convolutions.

\begin{corollary}
    For any $\delta_1, \delta_2$,
    %
    \[ W_{\delta_1 + \delta_2} = W_{\delta_1} * W_{\delta_2}\quad\text{and}\quad P_{\delta_1 + \delta_2} = P_{\delta_1} * P_{\delta_2}. \]
\end{corollary}
\begin{proof}
    We recall that
    %
    \[ W_{\delta_1 + \delta_2} = \mathcal{F}(e^{-(\delta_1 + \delta_2) |x|^2}). \]
    %
    But $e^{-(\delta_1 + \delta_2) |x|^2} = e^{-\delta_1 |x|^2} e^{-\delta_2 |x|^2}$ breaks into a product, which allows us to calculate
    %
    \[ \mathcal{F}(e^{-\pi \delta_1 |x|^2} e^{-\pi \delta_2 |x|^2}) = \mathcal{F}(e^{-\pi \delta_1 |x|^2}) * \mathcal{F}(e^{-\pi \delta_2 |x|^2}) = W_{\delta_1} * W_{\delta_2}.  \]
    %
    Thus $W_{\delta_1} * W_{\delta_2} = W_{\delta_1 + \delta_2}$. Similarily, $P_{\delta_1 + \delta_2}$ is the Fourier transform of $e^{-(\delta_1 + \delta_2)|x|}$, which breaks into a product, whose individual Fourier transforms are $P_{\delta_1}$ and $P_{\delta_2}$.
\end{proof}

Many of the other convergence statements for Fourier series hold in the case of the Fourier transform. For instance, a non-periodic variant of the De la Vallee Poisson kernel shows that if $f \in L^1(\RR)$ and $\widehat{f}(\xi) = O(1/|\xi|)$, then $S_R f$ converges uniformly to $f$. But for the purpose of novelty, we move on to other concepts.

\section{The $L^2$ Theory}

One integral component of Fourier series on $L^2(\TT^d)$ is Plancherel's equality
%
\[ \sum_{n \in \ZZ^d} |\widehat{f}(n)|^2 = \int_{\TT^d} |f(x)|^2\; dx \]
%
On $\RR^d$, we would like to justify that
%
\[ \int_{\RR^d} |\widehat{f}(\xi)|^2\; d\xi = \int_{\RR^d} |f(x)|^2\; dx \]
%
However, on the non-compact Euclidean space, a general element of $L^2(\RR^d)$ is not necessarily integrable, so we cannot take it's Fourier transform using the integral formula. Nonetheless, we can take the Fourier transform of an element of $L^1(\RR^d) \cap L^2(\RR^d)$, and we find the equation holds.

\begin{theorem}
    If $f \in L^1(\RR^d) \cap L^2(\RR^d)$, then $\| \widehat{f} \|_{L^2(\RR^d)} = \| f \|_{L^2(\RR^d)}$.
\end{theorem}
\begin{proof}
    The theorem is an easy consequence of the multiplication formula, since
    %
    \[ |\widehat{f}(\xi)| = \widehat{f}(\xi) \overline{\widehat{f}}(\xi), \]
    %
    and
    %
    \[ \left( \overline{\widehat{f}} \right)^\ft(\xi) = \overline{(f^\ft)^\ft(-\xi)} = \overline{f(\xi)}. \]
    %
    This implies
    %
    \[ \int_{\RR^d} |\widehat{f}(\xi)|^2\; d\xi = \int_{\RR^d} \widehat{f}(\xi) \overline{\widehat{f}(\xi)}\; d\xi = \int_{\RR^d} f(x) \overline{f(x)}\; dx = \int_{\RR^d} |f(x)|^2\; dx. \qedhere \]
\end{proof}

A simple interpolation argument leads to the following corollary, which is a variant of the Hausdorff-Young inequality for functions on $\RR^n$.

\begin{corollary} If $f \in L^1(\RR^n) \cap L^p(\RR^n)$ for $1 \leq p \leq 2$, then
    %
    \[ \| \widehat{f} \|_{L^q(\RR^n)} \leq \| f \|_{L^p(\RR^n)}, \]
    %
    where $2 \leq q \leq \infty$ is the conjugate of $p$.
\end{corollary}

Though the integral formula of an element of $L^2(\RR^n)$ does not make sense, the bounds above provide a canonical way to define the Fourier transform of an element of $L^p(\RR^n)$, for $1 \leq p \leq 2$. The space $L^1(\RR^n) \cap L^p(\RR^n)$ is a dense subset of $L^p(\RR^n)$, so we can use the Hahn-Banach theorem to define the Fourier transform $\mathcal{F}: L^p(\RR^n) \to L^q(\RR^n)$ as the {\it unique} bounded operator agreeing with the integral formula on the common domain. The extended Fourier transform on $L^2(\RR^n)$ is still unitary, because the multiplication formula extends to $L^2(\RR^n)$, so that
%
\[ (\mathcal{F}(f),g) = \int \widehat{f}(\xi) \overline{g(\xi)}\; d\xi = \int f(x) \overline{\widehat{g}(-\xi)}\; dx = (f,\mathcal{F}^{-1}(g)). \]
%
Thus the adjoint of $\mathcal{F}$ is $\mathcal{F}^{-1}$, which means exactly that $\mathcal{F}$ is unitary. It is true that for $d = 1$ we have a formula
%
\[ \widehat{f}(\xi) = \lim_{A,B \to \infty} \int_{-A}^B f(x) e^{- 2 \pi i \xi \cdot x}\; dx \]
%
for almost every $\xi \in \RR$, but this is a very difficult theorem to prove (it is a result known as Carleson's theorem).

Unlike in the case of Fourier series, where the $L^2$ theory gives an isometry between $L^2(\TT^d)$ and $L^2(\ZZ^d)$, in the case of the Fourier transform the Fourier transform gives a unitary operator from $L^2(\RR^d)$ to itself, and thus we can consider the spectral theory of such an operator. The Fourier inversion formula implies that the Fourier transform has order four. Thus the only eigenfunctions of the Fourier transform correspond to eigenvalues in $\{ 1, -1, i, -i \}$. We have seen $e^{- \pi x^2}$ is an eigenfunction with eigenvalue one. If we consider the family of all \emph{Hermite polynomials}
%
\[ H_n(x) = \frac{(-1)^n}{n!} e^{\pi x^2} \frac{d^n}{dx^n} \left( e^{- \pi x^2} \right). \]
%
One can also see that
%
\[ \sum_{n = 0}^\infty (-t)^n/n! \]
\[ \sum_{n = 0}^\infty H_n(x) \frac{t^n}{n!} = e^{- \pi x^2 - (2\pi)^{1/2} tx + t^2} \]
%
TODO PROVE ORTHOGONALITY AND COMPLETENESS.

which satisfy $\widehat{H_n} = (-i)^n H_n$, then we obtain an orthonormal basis of eigenfunctions. In higher dimensions, a basis of eigenfunctions for $L^2(\RR^d)$ is given by taking tensor products of Hermite polynomials.


\section{The Hausdorff-Young Inequality}

For functions on $\TT$, it is unclear how to provide examples which show why the Hausdorff-Young inequality cannot be extended to give results for $p > 2$. Over $\RR$, we can provide examples which explicitly indicate the tightness of the appropriate constants by applying symmetry arguments.

\begin{example}
    Given $f \in L^1(\RR)$, let $f_r(x) = f(rx)$. Then we find $\widehat{f_r}(\xi) = r^{-d} \widehat{f}(\xi/r)$, and so
    %
    \[ \| f_r \|_{L^p(\RR^d)} = r^{-d/p} \| f \|_{L^p(\RR^d)} \quad \text{and} \quad \| \widehat{f_r} \|_{L^q(\RR^d)} = r^{d/q-d} \| \widehat{f} \|_{L^q(\RR^d)}. \]
    %
    In order for a bound to hold in terms of $p$ and $q$ uniformly for all values of $r$, we need $r^{-d/p} = r^{d/q-d}$, which means $1/q + 1/p = 1$, so $p$ and $q$ must be conjugates of one another. In the case of $\TT$, a function analogous to $f_r$ can only be defined for small value of $r$, and a uniform estimate can then only hold if $1/p + 1/q \geq 1$.
\end{example}

\begin{example}
    Consider the family of functions $f_s(x) = s^{-d/2} e^{- \pi |x|^2/s}$, where $s = 1 + it$ for some $t \in \RR$. One can easily calcluate using analytic continuation and the Fourier transform for the Gaussian that $\widehat{f_s}(\xi) = e^{- \pi s |\xi|^2}$. We calculate
    %
    \[ \| f_s \|_{L^p(\RR^d)} = |s|^{-d/2} \left( \int e^{- (p/|s|^2) \pi |x|^2}\; dx \right)^{1/p} = |s|^{d/p - d/2} p^{-d/p} \]
    %
    whereas $\| \widehat{f_s} \|_q = q^{-d/2}$. Thus to be able  compare the two quantities as $t \to \infty$, we need $d/p - d/2 \leq 0$, so $p \leq 2$. As $t \to \infty$, $\smash{|f_s(x)| \sim t^{-d/2} e^{-\pi |x/t|^2}}$, so the $t$ gives us a decay in $f_s$. However, when we take the Fourier transform the $t$ only corresponds to oscillatory terms. Thus we need $p \leq 2$ so that the decay in $t$ isn't too important in relation to the overall width of the function. One can obtain analogous examples in $\TT^d$ to this example, by applying the Poisson summation formula to the functions $f_s$ and noting that the $L^p$ and $L^q$ norms also follows approximately the same formulas as above.
\end{example}

The Hausdorff-Young inequality shows that the Fourier transforms narrowly supported functions into a function with small magnitude. But the example above shows that the Fourier transform is not so good at transforming functions with small magnitude into functions which are narrowly supported, because the Fourier transform can absorb the small magnitude into an oscillatory property not reflected in the norms. Some kind of way of measuring oscillation needs to be considered to get a tighter control on the function. Of course, in hindsight, we should have never expected too much control of the Fourier transform in terms of the $L^p$ norms, since the Fourier transform measures the oscillatory nature of the input function, and oscillatory properties of a function in phase space are not very well reflected in the $L^p$ norms, except when applying certain orthogonality properties with an $L^2$ norm, or destroying the oscillation with an $L^\infty$ norm.

\section{The Poisson Summation Formula}

We now show a connection between the Fourier transform on $\RR$, and the Fourier transform on $\TT$. If $f$ is a function on $\RR$, there are two ways of obtaining a `periodic' version of $f$ on $\TT$. Firstly, we can define, for each $x \in \TT$,
%
\[ f_1(x) = \sum_{n = -\infty}^\infty f(x + 2 \pi n), \]
%
which is a well defined element of $C^\infty(\TT)$. Secondly, we can define
%
\[ f_2(x) = \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(x), \]
%
The Poisson summation formula says that, under an appropriate regularity condition so that we can interpret these formulas correctly, they give the same function.

\begin{theorem}
    Suppose $f \in L^1(\RR^d)$. Then the series
    %
    \[ \sum_{n \in \ZZ^d} T_n f \]
    %
    converges absolutely in $L^1[0,1]^d$ to a function $g \in L^1[0,1]^d$ with $\widehat{g}(n) = \widehat{f}(n)$ for each $n \in \ZZ^d$.
\end{theorem}
\begin{proof}
    The fact that the sum converges absolutely in $L^1[0,1]$ follows because
    %
    \[ \sum_{n \in \ZZ^d} \| T_n f \|_{L^1[0,1]} = \| f \|_{L^1(\RR^d)}. \]
    %
    But the absolute convergence in $L^1$ also justifies the calculation that for each $n \in \ZZ^d$
    %
    \begin{align*}
        \int_{[0,1]^d} \sum_{m \in \ZZ^d} (T_n f)(x) e^{2 \pi nix}\; dx &= \sum_{m \in \ZZ^d} \int_{[0,1]^d} f(x + m) e^{2 \pi n i (x + m)}\; dx\\
        &= \int_{\RR^d} f(x) e^{2 \pi n i x}\; dx = \widehat{f}(n). \qedhere
    \end{align*}
\end{proof}

In particular, we can obtain a more powerful version of this result if we assume that there is $\delta > 0$ such that
%
\[ |f(x)| \lesssim \frac{1}{1 + |x|^{1 + \delta}} \quad\text{and}\quad |\widehat{f}(\xi)| \lesssim \frac{1}{1 + |x|^{1 + \delta}}. \]
%
Then we see that the two functions
%
\[ g_1(x) = \sum_{n \in \ZZ} f(x + n) \quad\text{and}\quad g_2(x) = \sum_{n \in \ZZ} \widehat{f}(n) e^{2 \pi n i x} \]
%
are continuous functions on $\TT$ with the same Fourier coefficients. It thus follows that $g_1 = g_2$, i.e. that for each $x \in \RR$,
%
\[ \sum_{n \in \ZZ} f(x + n) = \sum_{n \in \ZZ} \widehat{f}(n) e^{2 \pi n i x}. \]
%

\begin{theorem}
    If $f \in \mathcal{S}(\RR)$, then
    %
    \[ \sum_{n = -\infty}^\infty f(x + n) = \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(x). \]
\end{theorem}
\begin{proof}
    TODO
\end{proof}

TODO: Also prove this statement under the assumption that f is continuous with $|f(t)|, |\widehat{f}(t)| \lesssim (1 + |t|)^{-(1 + \delta)}$ for some $\delta > 0$ (with the series converging uniformly), or pointwise assuming $f$ has bounded variation and $f(t) = [f(t+) + f(t-)]/2$ for all $t \in \RR$.  

\section{Shannon-Nyquist Sampling Theorem}

Consider a band limited function $f \in L^2(\RR)$, such that $\widehat{f}$ is supported on $[-R,R]$. Then basic considerations tell us that $f \in C^\infty(\RR)$. Then we can take a Fourier series, together with the fact that by the inversion formula,
%
\[ \frac{1}{2R} \int_{-R}^R \widehat{f}(\xi) e^{- \pi i n \xi / R}\; d\xi = \frac{f(- \pi n / R)}{2R}. \]
%
to conclude that
%
\[ \widehat{f}(\xi) \sim \sum_{n \in \ZZ} \frac{f(\pi n / R)}{2 R} e^{- \pi i n \xi / R} \]
%
where the right hand side converges to the left hand side in $L^2[-R,R]$. But this means that if we know the sequence $\{ f(\pi n / R) : n \in \ZZ \}$, then we know $\widehat{f}$, and thus $f$. In particular, if a function is band limited then it can be reconstructed from a few discrete, regularly spaced samples of itself.

\begin{remark}
    The \emph{Nyquist spacing} is the spacing $\pi/R$, and theoretically is sufficiently to reconstruct any function in $L^2(\RR)$ band limited on $[-R,R]$. On the other hand, in practice we cannot obtain the infinite sequence $\{ f(\pi n / R) : n \in \ZZ \}$, in which case a more fine spacing for sampling is often more useful, i.e. it is often better to \emph{oversample}.
\end{remark}

On the other hand, we should not hope to reconstruct $f$ perfectly if we \emph{undersample}. Indeed, one often obtains \emph{aliasing} when reconstructing $f$, i.e. finding an aliased function $g$ with the same values at the sample points. This holds, for instance, when taking a video of a wheel or turbine spinning at two slow a framerate.

\begin{remark}
    More generally, in a distributional sense, if $m$ is a tempered distribution and $\widehat{m}$ is supported on $[-R,R]$. This means
    %
    \[ \sum_{n = -\infty}^\infty T_{2Rn} \widehat{m} \]
    %
    is a periodic function with Fourier transform
    %
    \[ \frac{1}{2R} \sum_{n = -\infty}^\infty \delta_{1/2N} \cdot m. \]
    %
    Thus from the sequence $\{ \delta_{1/2N} m \}$ one can infer the distribution $\widehat{m}$, and thus the distribution $m$. Thus we see that the Nyquist sampling theorem is closely connected to the periodization of a function.  
\end{remark}

\section{Radial Functions}

Suppose $f \in L^1(\RR^d)$ is a radial function. Then $\widehat{f}$ is also a radial function. In particular, if we let
%
\[ \| u \|_{L^1([0,\infty), r^{d-1})} = \int_0^\infty r^{d-1} u(r)\; dr \]
%
then we have a transform $u \mapsto \tilde{u}$ from $L^1([0,\infty), r^{d-1})$ to $L^\infty[0,\infty)$ where if $f(x) = u(|x|)$, then $\widehat{f}(\xi) = \tilde{u}(|\xi|)$. In particular, we calculate quite simply that
%
\[ \tilde{u}(s) = V_d \int_0^\infty r^{d-1} u(r) \left( \int_{S^{d-1}} e^{-2 \pi i x_1 s}\; dx \right). \]
%
If one recalls the Bessel functions $\{ J_s \}$, then we have
%
\[ \tilde{u}(s) = 2\pi s^{1 - d/2} \int_0^\infty r^{d/2} u(r) J_{d/2-1}(2 \pi s r)\; dr. \]
%
If one recalls some Bessel function asymptotics, then one can actually gain some interesting results for the \emph{averaging operator}
%
\[ Af(x) = \fint_{S^{d-1}} f(x-y)\; d\sigma(y) \]
%

\begin{example}
    Suppose $f_R(x) = \mathbf{I}_{|x| \leq R}$. Then
    %
    \[ \widehat{f}(\xi) = 2 \pi |\xi|^{1-d/2} \int_0^R r^{d/2} J_{d/2-1}(2 \pi s r)\; dr. \]
    %
    The 
\end{example}





\section{Poisson Integrals}

s



\chapter{Applications of the Fourier Transform}

\section{Applications to Partial Differential Equations}

Just as the Fourier series can be used to obtain periodic solutions to certain partial differential equations, the Fourier transform can be used to obtain more general solutions to partial differential equations on $\RR^d$. To begin with, we study the heat equation on $\RR^d$, i.e. we study solutions to the partial differential equation
%
\[ \frac{\partial u}{\partial t} = \Delta u \]
%
Formally taking Fourier transforms in the spatial variable gives
%
\[ \frac{\partial \widehat{u}(\xi,t)}{\partial t} = - 4 \pi^2 |\xi|^2 \widehat{u}(\xi,t) \]
%
which, if we are given $u(x,0) = f(x)$, gives that
%
\[ \widehat{u}(\xi,t) = \widehat{f}(\xi) e^{- 4 \pi^2 |\xi|^2 t}. \]
%
Thus, taking the inverse Fourier transform, we might expect the solution to the heat equation to be given by the formula
%
\[ u(x,t) = (H_t * f)(x) \]
%
where
%
\[ H_t(x) = \frac{1}{(4 \pi t)^{d/2}} e^{- |x|^2 / 4 t}. \]
%
The rapid decay of $H_t$ for large $x$ shows that for any $1 \leq p \leq \infty$ and $f \in L^p(\RR^d)$, $u$ is well defined by this formula, lies in $C^\infty(\TT^d)$, and solves the heat equation, with the appropriate norm convergence as $t \to 0$. However, in this case it is not so easy to conclude that $u$ is the unique solution to this equation satisfying the initial conditions, since one cannot necessarily take the Fourier transform of $u$.

We can get slightly more results if we consider the \emph{steady state} heat equation on the upper half plane $\mathbf{H}^d$, i.e. we study functions $u(x,t)$, for $x \in \RR^d$ and $t > 0$, such that $\Delta u = 0$, subject to the initial condition that $u(x,0) = f(x)$. Working formally with the Fourier transform leads to the equation
%
\[ \widehat{u}(\xi,t) = e^{-2 \pi t |\xi| x} \widehat{f}(\xi) \]
%
Thus $u(x,t) = (f * P_t)(x)$, where $P_t$ is the Poisson kernel. If $f \in L^1(\RR^d)$, it is easy to see that 


\section{Sums of Random Variables}

TODO

We now switch to an application of harmonic analysis to studying sums of random variables probability theory. If $X$ is a random vector, it's probabilistic information is given by it's distribution on $\RR^n$, which can be seen as a measure $\mathbf{P}_X$ on $\RR^n$, with $\mathbf{P}_X(E) = \mathbf{P}(X \in E)$. Given two independant random vectors $X$ and $Y$, $\mathbf{P}_{X+Y}$ is the convolution $\mathbf{P}_X * \mathbf{P}_Y$ between the measures $\mathbf{P}_X$ and $\mathbf{P}_Y$, in the sense that
%
\[ \mathbf{P}_{X+Y}(E) = \int \chi_E(x+y)\; d\mathbf{P}_X(x)\; d\mathbf{P}_Y(y) \]
%
If $d\mathbf{P}_X = f_X \cdot dx$ and $d\mathbf{P}_Y = f_Y \cdot dx$, then $d(\mathbf{P}_X * \mathbf{P}_Y) = (f_X * f_Y) \cdot dx$ is just the normal convolution of functions. This is why harmonic analysis becomes so useful when analyzing sums of independant random variables.

It is useful to express the Fourier transform in a probabilistic language. Given a random variable $X$,
%
\[ \widehat{\mathbf{P}_X}(\xi) = \int e^{i \xi \cdot x} d\mathbf{P}_X(x) \]
%
Thus the natural Fourier transform of a random vector $X$ is the {\emph characteristic function} $\varphi_X(\xi) = \mathbf{E}(e^{i \xi \cdot X})$. It is a continuous function for any random variable $X$. We can also express the properties of the Fourier transform in a probabilistic language.

\begin{lemma}
    Let $X$ and $Y$ be independant random variables. Then
    %
    \begin{itemize}
        \item $\varphi_X(0) = 1$, and $|\varphi_X(\xi)| \leq 1$ for all $\xi$.

        \item (Symmetry) $\varphi_X(\xi) = \overline{\varphi_X(-\xi)}$.

        \item (Convolution) $\varphi_{X+Y} = \varphi_X \varphi_Y$.

        \item (Translation and Dilation) $\varphi_{X+a}(\xi) = e^{i a \cdot \xi} \varphi_X(\xi)$, and $\varphi_{\lambda X}(\xi) = \varphi_X(\lambda \xi)$.

        \item (Rotations) If $R \in O(n)$ is a rotation, then $\varphi_{R(X)}(\xi) = \varphi_X(R(X))$.
    \end{itemize}
\end{lemma}

Using the Fourier inversion formula, if $\varphi_X$ is integrable, then $X$ is a continuous random variable, with density
%
\[ f(x) = \int e^{- i \xi x} \varphi_X(\xi)\; d\xi \]
%
In particular, if $\varphi_X = \varphi_Y$, then $X$ and $Y$ are identically distributed. This already gives interesting results.

\begin{theorem}
    If $X$ and $Y$ are independant normal distributions, then $aX + bY$ is normally distributed.
\end{theorem}
\begin{proof}
    Since $\varphi_{aX+bY}(\xi) = \varphi_X(a \xi) \varphi_Y(b \xi)$, it suffices to show that the product of two such characteristic functions is the characteristic function of a normal distribution. If $X$ has mean $\mu$ and covariance matrix $\Sigma$, then $X \cdot \xi$ has mean $\mu \cdot \xi$ and variance $\xi^T \Sigma \xi$, and one calculates that $\mathbf{E}[e^{i \xi \cdot X}] = e^{- i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ using similar techniques to the Fourier transform of a Gaussian. One verifies that the class of functions of the form $e^{-i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ is certainly closed under multiplication and scaling, which completes the proof. 
\end{proof}

Now we can prove the celebrated central limit theorem. Note that if

\begin{theorem}
    Let $X_1, \dots, X_N$ be independant and identically distributed with mean zero and variance $\sigma^2$. If $S_N = X_1 + \dots + X_N$, then
    %
    \[ \mathbf{P}(S_N \leq \sigma \sqrt{N} t) \to \Phi(t) = \frac{1}{\sqrt{2x}} \int_{-\infty}^t e^{-y^2/2}\; dy \]
\end{theorem}
\begin{proof}
    We calculate that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = \varphi_X(\xi/\sigma \sqrt{N})^N \]
    %
    Define $R_n(x) = e^{ix} - 1 - (ix) - (ix)^2/2 - \dots - (ix)^n/n!$. Then because of oscillation and the fundamental theorem of calculus,
    %
    \[ |R_0(x)| = \left| i \int_0^x e^{iy}\; dy \right| \leq \min(2,|x|) \]
    %
    Next, since $R_{n+1}'(x) = i R_n$,
    %
    \[ R_{n+1}(x) = i  \int_0^x R_n(y)\; dy \]
    %
    This gives that $|R_n(x)| \leq \min(2|x|^n/n!,|x|^{n+1}/(n+1)!)$. In particular, we conclude
    %
    \[ |\varphi_X(\xi) - 1 - \sigma^2 \xi^2/2| = |\mathbf{E}(R_2(\xi X))| \leq \mathbf{E}|R_2(\xi X)| \leq |\xi|^2 \mathbf{E} \left( \min \left( |X|^2, |\xi X|^3/6 \right) \right) \]
    %
    By the dominated convergence theorem, as $\xi \to 0$, $\varphi_X(\xi) = 1 - \xi^2 \sigma^2/2 + o(\xi^2)$. But this means that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = (1 - \xi^2 / 2 N + o(\xi^2/\sigma^2 N))^N = \exp(-\xi^2/2) \]
    %
    This implies the random variables converge weakly to a normal distribution.
\end{proof}


\section{The Wirtinger Inequality on an Interval}

\begin{theorem}
    Given $f \in C^1[-\pi,\pi]$ with $\int_{-\pi}^\pi f(t) dt = 0$,
    %
    \[ \int_{-\pi}^\pi |f(t)|^2 \leq \int_{-\pi}^\pi |f'(t)|^2 \]
\end{theorem}
\begin{proof}
    Consider the fourier series
    %
    \[ f(t) \sim \sum a_n e_n(t)\ \ \ \ \ f'(t) \sim \sum in a_n e_n(t) \]
    %
    Then $a_0 = 0$, and so
    %
    \[ \int_{-\pi}^\pi |f(t)|^2\ dt = 2 \pi \sum |a_n|^2 \leq 2 \pi \sum n^2 |a_n|^2 = \int_{-\pi}^\pi |f'(t)|^2\ dt \]
    %
    equality holds here if and only if $a_i = 0$ for $i > 1$, in which case we find
    %
    \[ f(t) = A e_n(t) + \overline{A} e_n(-t) = B \cos(t) + C \sin(t) \]
    %
    for some constants $A \in \CC$, $B,C \in \RR$.
\end{proof}

\begin{corollary}
    Given $f \in C^1[a,b]$ with $\int_a^b f(t)\ dt = 0$,
    %
    \[ \int_a^b |f(t)|^2 dt \leq \left(\frac{b-a}{\pi}\right)^2 \int_a^b |f'(t)|^2\ dt \]
\end{corollary}

\section{Energy Preservation in the String equation}

Solutions to the string equation are

If $u(t,x)$

\section{Harmonic Functions} 

The study of a function $f$ defined on the real line can often be understood by extending it's definition holomorphically to the complex plane. Here we will extend this tool, establishing that a large family of functions $f$ defined on $\RR^n$ can be understood by looking at a {\it harmonic} function on the upper half plane $\mathbf{H}^{n+1}$, which approximates $f$ at it's boundary. This is a form of the Dirichlet problem, which asks, given a domain and a function on the domain's boundary, to find a function harmonic on the interior of the domain which `agrees' with the function on the boundary, in one of several senses. As we saw in our study of harmonic functions on the disk in the study of Fourier series, we can study such harmonic functions by convolving $f$ with an appropriate approximation to the identity which makes the function harmonic in the plane. In this case, we shall use the Poisson kernel for the upper half plane.

\begin{theorem}
    If $f \in L^p(\RR^n)$, for $1 \leq p \leq \infty$, and $u(x,y) = (f * P_y)(x)$, where
    %
    \[ P_y(x) = \frac{\Gamma((n+1)/2)}{\pi^{(n+1)/2}} \frac{1}{(1 + |x|^2)^{(n+1)/2}} \]
    %
    then $u$ is harmonic in the upper half plane, $u(x,y) \to f(x)$ for almost every $x$, and $u(\cdot,y)$ converges to $f$ in $L^p$ as $y \to 0$, with $\| u(\cdot,y) \|_{L^p(\RR^n)} \leq \| f \|_{L^p(\RR^n)}$. If, instead, $f$ is a continuous and bounded function, then $u(\cdot,y)$ converges to $f$ locally uniformly as $y \to 0$.
\end{theorem}
\begin{proof}
    The almost everywhere convergence and convergence in norm follow from the fact that $P_y$ is an approximation to the identity. The fact that $u$ is harmonic follows because
    %
    \[ u_{xx}(x,y) = (f * P_y'')(x)\ \ \ \ \ u_{yy} = (f * ) \]
\end{proof}










\chapter{Finite Character Theory}

Let us review our achievements so far. We have found several important families of functions on the spaces we have studied, and shown they can be used to approximate arbitrary functions. On the circle group $\TT$, the functions take the form of the power maps $\phi_n: z \mapsto z^n$, for $n \in \ZZ$. The important properties of these functions is that
%
\begin{itemize}
    \item The functions are orthogonal to one another.
    \item A large family of functions can be approximated by linear combinations of the power maps.
    \item The power maps are multiplicative: $\phi_n(zw) = \phi_n(z) \phi_n(w)$.
\end{itemize}
%
The existence of a family with these properties is not dependant on much more than the symmetry properties of $\TT$, and we can therefore generalize the properties of the fourier series to a large number of groups. In this chapter, we consider a generalization to any finite abelian group.

The last property of the power maps should be immediately recognizable to any student of group theory. It implies the exponentials are homomorphisms from the circle group to itself. This is the easiest of the three properties to generalize to arbitrary groups; we shall call a homomorphism from a finite abelian group to $\TT$ a {\emph character}. For any abelian group $G$, we can put all characters together to form the character group $\Gamma(G)$, which forms an abelian group under pointwise multiplication $(fg)(z) = f(z)g(z)$. It is these functions which are `primitive' in synthesizing functions defined on the group.

\begin{example}
    If $\mu_N$ is the set of $N$th roots of unity, then $\Gamma(\mu_N)$ consists of the power maps $\phi_n: z \mapsto z^n$, for $n \in \ZZ$. Because
    %
    \[ \phi(\omega)^N = \phi(\omega^N) = \phi(1) = 1 \]
    %
    we see that any character on $\mu_N$ is really a homomorphism from $\mu_N$ to $\mu_N$. Since the homomorphisms on $\mu_N$ are determined by their action on this primitive root, there can only be at most $N$ characters on $\mu_N$, since there are only $N$ elements in $\mu_N$. Our derivation then shows us that the $\phi_N$ enumerate all such characters, which completes our proof. Note that since $\phi_n \phi_m = \phi_{n+m}$, and $\phi_n = \phi_m$ if and only if $n - m$ is divisible by $N$, this also shows that $\Gamma(\mu_N) \cong \mu_N$.
\end{example}

\begin{example}
    The group $\ZZ_N$ is isomorphic to $\mu_N$ under the identification $n \mapsto \omega^n$, where $\omega$ is a primitive root of unity. This means that we do not need to distinguish functions `defined in terms of $n$' and `defined in terms of $\omega$', assuming the correspondance $n = \omega^n$. This is exactly the same as the correspondence between functions on $\TT$ and periodic functions on $\RR$. The characters of $\ZZ_n$ are then exactly the maps $n \mapsto \omega^{kn}$. This follows from the general fact that if $f: G \to H$ is an isomorphism of abelian groups, the map $f^*: \phi \mapsto \phi \circ f$ is an isomorphism from $\Gamma(H)$ to $\Gamma(G)$.
\end{example}

\begin{example}
    If $K$ is a finite field, then the set $K^*$ of non-zero elements is a group under multiplication. A rather sneaky algebraic proof shows the existence of elements of $K$, known as primitive elements, which generate the multiplicative group of all numbers. Thus $K$ is cyclic, and therefore isomorphic to $\mu_N$, where $N = |K| - 1$. The characters of $K$ are then easily found under the correspondence.
\end{example}

\begin{example}
    For a fixed $N$, the set of invertible elements of $\ZZ_N$ form a group under multiplication, denoted $\ZZ_N^*$. Any character from $\ZZ_N^*$ is valued on the $\varphi(N)$'th roots of unity, because the order of each element in $\ZZ_N^*$ divides $\varphi(N)$. The groups are in general non-cyclic. For instance, $\ZZ_8^* \cong \ZZ_2^3$. However, we can always break down a finite abelian group into cyclic subgroups to calculate the character group; a simple argument shows that $\Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H)$, where we identify $(f,g)$ with the map $(x,y) \mapsto f(x)g(y)$.
\end{example}

\section{Fourier Analysis on Cyclic Groups}

We shall start our study of abstract Fourier analysis by looking at Fourier analysis on $\mu_N$. Geometrically, these points uniformly distribute themselves over $\TT$, and therefore $\mu_N$ provides a good finite approximation to $\TT$. Functions from $\mu_N$ to $\CC$ are really just functions from $[n] = \{ 1, \dots, n \}$ to $\CC$, and since $\mu_N$ is isomorphic to $\ZZ_N$, we're really computing the Fourier analysis of finite domain functions, in a way which encodes the translational symmetry of the function relative to translational shifts on $\ZZ_N$.

There is a trick which we can use to obtain quick results about Fourier analysis on $\mu_N$. Given a function $f: [N] \to \CC$, consider the $N$-periodic function on the real line defined by
%
\[ g(t) = \sum_{n = 1}^N f(n) \chi_{(n-1/2,n+1/2)}(t) \]
%
Classical Fourier analysis of $g$ tells us that we can expand $g$ as an infinite series in the functions $e(n/N)$, which may be summed up over equivalence classes modulo $N$ to give a finite expansion of the function $f$. Thus we conclude that every function $f: [N] \to \CC$ has an expansion
%
\[ f(n) = \sum_{m = 1}^N \widehat{f}(m) e(nm) \]
%
where $\widehat{f}(m)$ are the coefficients of the {\emph finite Fourier transform} of $f$. This method certainly works in this case, but does not generalize to understand the expansion of general finite abelian groups.

The correct generalization of Fourier analysis is to analyze the set of complex valued `square integrable functions' on the domain $[N]$. We consider the space $V$ of all maps $f: [N] \to \CC$, which can be made into an inner product space by defining
%
\[ \langle f, g \rangle = \frac{1}{N} \sum_{n = 1}^N f(n) \overline{g(n)} \]
%
We claim that the characters $\phi_n: z \mapsto z^n$ are orthonormal in this space, since
%
\[ \langle \phi_n, \phi_m \rangle = \frac{1}{N} \sum_{k = 1}^N \omega^{k(n-m)} \]
%
If $n = m$, we may sum up to find $\langle \phi_n, \phi_m \rangle = 1$. Otherwise we use a standard summation formula to find
%
\[ \sum_{k = 1}^N \omega^{k(n-m)} = \omega^{n-m} \frac{\omega^{N(n-m)} - 1}{\omega^{n-m} -1} \]
%
Since $\omega^{N(n-m)} = 1$, we conclude the sum is zero. This implies that the $\phi_n$ are orthonormal, hence linearly independent. Since $V$ is $N$ dimensional, this implies that the family of characters forms an orthogonal basic for the space. Thus, for any function $f: [N] \to \CC$, we have, if we set $\widehat{f}(m) = \langle f, \phi_m \rangle$, then
%
\[ f(n) = \sum_{m = 1}^N \langle f, \phi_m \rangle \phi_m(n) = \sum_{m = 1}^N \widehat{f}(m) e(mn/N) \]
%
This calculation can essentially be applied to an arbitrary finite abelian group to obtain an expansion in terms of Fourier coefficients.

\section{An Arbitrary Finite Abelian Group}

It should be easy to guess how we proceed for a general finite abelian group. Given some group $G$, we study the character group $\Gamma(G)$, and how $\Gamma(G)$ represents general functions from $G$ to $\CC$. We shall let $V$ be the space of all such functions from $G$ to $\CC$, and on it we define the inner product
%
\[ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
%
If there's any justice in the world, these characters would also form an orthonormal basis.

\begin{theorem}
    The set $\Gamma(G)$ of characters is an orthonormal set.
\end{theorem}
\begin{proof}
    If $e$ is a character of $G$, then $|e(a)| = 1$ for each $a$, and so
    %
    \[ \langle e, e \rangle = \frac{1}{|G|} \sum_{a \in G} |e(a)| = 1 \]
    %
    If $e \neq 1$ is a non-trivial character, then $\sum_{a \in G} e(a) = 0$. To see this, note that for any $b \in G$, the map $a \mapsto ba$ is a bijection of $G$, and so
    %
    \[ e(b) \sum_{a \in G} e(a) = \sum_{a \in G} e(ba) = \sum_{a \in G} e(a) \]
    %
    Implying either $e(b) = 1$, or $\sum_{a \in G} e(a) = 0$. If $e_1 \neq e_2$ are two characters, then
    %
    \[ \langle e_1, e_2 \rangle = \frac{1}{|G|} \sum_{a \in G} \frac{e_1(a)}{e_2(a)} = 0 \]
    %
    since $e_1/e_2$ is a nontrivial character.
\end{proof}

Because elements of $\Gamma(G)$ are orthonormal, they are linearly independent over the space of functions on $G$, and we obtain a bound $|\Gamma(G)| \leq |G|$. All that remains is to show equality. This can be shown very simply by applying the structure theorem for finite abelian groups. First, note it is true for all cyclic groups. Second, note that if it is true for two groups $G$ and $H$, it is true for $G \times H$, because
%
\[ \Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H) \]
%
since a finite abelian group is a finite product of cyclic groups, this proves the theorem. This seems almost like sweeping the algebra of the situation under the rug, however, so we will prove the statement only using elementary linear algebra. What's more, these linear algebraic techniques generalize to the theory of unitary representations in harmonic analysis over infinite groups.

\begin{theorem}
    Let $\{ T_1, \dots, T_n \}$ be a family of commuting unitary matrices. Then there is a basis $v_1, \dots, v_m \in \CC^m$ which are eigenvectors for each $T_i$.
\end{theorem}
\begin{proof}
    For $n = 1$, the theorem is the standard spectral theorem. For induction, suppose that the $T_1, \dots, T_{k-1}$ are simultaneously diagonalizable. Write
    %
    \[ \CC^m = V_{\lambda_1} \oplus \dots \oplus V_{\lambda_l} \]
    %
    where $\lambda_i$ are the eigenvalues of $T_k$, and $V_{\lambda_i}$ are the corresponding eigenspaces. Then if $v \in V_{\lambda_i}$, and $j < k$,
    %
    \[ T_k T_j v = T_j T_k v = \lambda_i T_j v \]
    %
    so $T_j(V_{\lambda_i}) = V_{\lambda_i}$. Now on each $V_{\lambda_i}$, we may apply the induction hypotheis to diagonalize the $T_1, \dots, T_{k-1}$. Putting this together, we simultaneously diagonalize $T_1, \dots, T_k$.
\end{proof}

This theorem enables us to prove the character theory in a much simpler manner. Let $V$ be the space of complex valued functions on $G$, and define, for $a \in G$, the map $(T_a f)(b) = f(ab)$. $V$ has an orthonormal basic consisting of the $\chi_a(b) = N [a = b]$, for $a \in G$. In this basis, we comcpute $T_a \chi_b = \chi_{ba^{-1}}$, hence $T_a$ is a permutation matrix with respect to this basis, hence unitary. The operators $T_a$ commute, since $T_aT_b = T_{ab} = T_{ba} = T_b T_a$. Hence these operators can be simultaneously diagonalized. That is, there is a family $e_1, \dots, e_n \in V$ and $\lambda_{an} \in \TT$ such that for each $a \in G$, $T_a e_n = \lambda_{an} f_n$. We may assume $e_n(1) = 1$ for each $n$ by normalizing. Then, for any $a \in G$, we have $f_n(a) = f_n(a \cdot 1) = \lambda_{an} f_n(1) = \lambda_{an}$, so for any $b \in G$, $f_n(ab) = \lambda_{an} f_n(b) = f_n(a) f_n(b)$. This shows each $f_n$ is a character, completing the proof. We summarize our discussion in the following theorem.

\begin{theorem}
    Let $G$ be a finite abelian group. Then $\Gamma(G) \cong G$, and forms an orthonormal basis for the space of complex valued functions on $G$. For any function $f: G \to \CC$,
    %
    \[ f(a) = \sum_{e \in \Gamma(G)} \langle f, e \rangle\ e(a) = \sum_{e \in \Gamma(G)} \hat{f}(e) e(a)\ \ \ \ \ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
    %
    In this context, we also have Parseval's theorem
    %
    \[ \| f(a) \|^2 = \sum_{e \in \hat{G}} |\widehat{f}(e)|^2\ \ \ \ \ \langle f, g \rangle = \sum_{e \in \hat{G}} \widehat{f}(e) \overline{\widehat{g}(e)} \]
\end{theorem}

\section{Convolutions}

There is a version of convolutions for finite functions, which is analogous to the convolutions on $\RR$. Given two functions $f,g$ on $G$, we define a function $f * g$ on $G$ by setting
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(b) g(b^{-1} a) \]
%
The mapping $b \mapsto ab^{-1}$ is a bijection of $G$, and so we also have
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(ab^{-1}) g(b) = (g * f)(a) \]
%
For $e \in \Gamma(G)$,
%
\begin{align*}
    \widehat{f * g}(e) &= \frac{1}{|G|} \sum_{a \in G} (f*g)(a) \overline{e(a)}\\
    &= \frac{1}{|G|^2} \sum_{a,b \in G} f(ab) g(b^{-1}) \overline{e(a)}
\end{align*}
%
The bijection $a \mapsto ab^{-1}$ shows that
%
\begin{align*}
    \widehat{f*g}(e) &= \frac{1}{|G|^2} \sum_{a,b} f(a) g(b^{-1}) \overline{e(a)} \overline{e(b^{-1})}\\
    &= \frac{1}{|G|} \left( \sum_a f(a) \overline{e(a)} \right) \frac{1}{|G|} \left( \sum_b g(b) \overline{e(b)} \right)\\
    &= \widehat{f}(e) \widehat{g}(e)
\end{align*}
%
In the finite case we do not need approximations to the identity, for we have an identity for convolution. Define $D: G \to \CC$ by
%
\[ D(a) = \sum_{e \in \Gamma(G)} e(a) \]
%
We claim that $D(a) = |G|$ if $a = 1$, and $D(a) = 0$ otherwise. Note that since $|G| = |\Gamma(G)|$, the character space of $\Gamma(G)$ is isomorphic to $G$. Indeed, for each $a \in G$, we have the maps $\widehat{a}: e \mapsto e(a)$, which is a character of $\Gamma(G)$. Suppose $e(a) = 1$ for all characters $e$. Then $e(a) = e(1)$ for all characters $e$, and for any function $f: G \to \CC$, we have $f(a) = f(1)$, implying $a = 1$. Thus we obtain $|G|$ distinct maps $\widehat{a}$, which therefore form the space of all characters. It therefore follows from a previous argument that if $a \neq 1$, then
%
\[ \sum_{e \in \Gamma(G)} e(a) = 0 \]
%
Now $f * D = f$, because
%
\[ \widehat{D}(e) = \frac{1}{|G|} \sum_{a \in G} D(a) \overline{e(a)} = \overline{e}(1) = 1 \]
%
$D$ is essentially the finite dimensional version of the Dirac delta function, since it has unit mass, and acts as the identity in convolution.

\section{The Fast Fourier Transform}

The main use of the fourier series on $\mu_n$ in applied mathematics is to approximate the Fourier transform on $\TT$, where we need to compute integrals explicitly. If we have a function $f \in L^1(\TT)$, then $f$ may be approximated in $L^1(\TT)$ by step functions of the form
%
\[ f_n(t) = \sum_{k = 1}^{n} a_k \mathbf{I}(x \in (2 \pi (k-1) / n, 2 \pi k / n)) \]
%
And then $\widehat{f_n} \to \widehat{f}$ uniformly. The Fourier transform of $f_n$ is the same as the Fourier transform of the corresponding function $k \mapsto a_k$ on $\ZZ_n$, and thus we can approximate the Fourier transform on $\TT$ by a discrete computation on $\ZZ_n$. Looking at the formula in the definition of the discrete transform, we find that we can compute the Fourier coefficients of a function $f: \ZZ_n \to \CC$ in $O(n^2)$ addition and multiplication operations. It turns out that there is a much better method of computation which employs a divide and conquer approach, which works when $n$ is a power of 2, reducing the calculation to $O(n \log n)$ multiplications. Before this process was discovered, calculation of Fourier transforms was seen as a computation to avoid wherever possible.

To see this, consider a particular division in the group $\ZZ_{2n}$. Given $f: \ZZ_{2n} \to \CC$, define two functions $g,h: \ZZ_n \to \CC$, defined by $g(k) = f(2k)$, and $h(k) = f(2k + 1)$. Then $g$ and $h$ encode all the information in $f$, and if $\nu = e(\pi/n)$ is the canonical generator of $\ZZ_{2n}$, we have
%
\[ \hat{f}(m) = \frac{\hat{g}(m) + \hat{h}(m) \nu^m}{2} \]
%
Because
%
\begin{align*}
    \frac{1}{2n} \sum_{k = 1}^{n} \left( g(k) \omega^{-km} + h(m) \omega^{-km} \nu^m \right) &= \frac{1}{2n} \sum_{k = 1}^n f(2k) \nu^{-2km} + f(2k + 1) \nu^{-(2k+1)m}\\
    &= \frac{1}{2n} \sum_{k = 1}^{2n} f(k) \nu^{-km}
\end{align*}
%
This is essentially a discrete analogue of the Poission summation formula, which we will generalize later when we study the harmonic analysis of abelian groups. If $H(m)$ is the number of operations needed to calculate the Fourier transform of a function on $\mu_{2^n}$ using the above recursive formula, then the above relation tells us $H(2m) = 2H(m) + 3 (2m)$. If $G(n) = H(2^n)$, then $G(n) = 2G(n-1) + 3 2^n$, and $G(0) = 1$, and it follows that
%
\[ G(n) = 2^n + 3 \sum_{k = 1}^n 2^{k} 2^{n-k} = 2^n(1 + 3n) \]
%
Hence for $m = 2^n$, we have $H(m) = m(1 + 3 \log (m)) = O(m \log m)$. Similar techniques show that one can compute the inverse Fourier transform in $O(m \log m)$ operations (essentially by swapping the root $\nu$ with $\nu^{-1}$).

\section{Dirichlet's Theorem}

We now apply the theory of Fourier series on finite abelian groups to prove Dirichlet's theorem.

\begin{theorem}
    If $m$ and $n$ are relatively prime, then the set
    %
    \[ \{ m + kn : k \in \mathbf{N} \} \]
    %
    contains infinitely many prime numbers.
\end{theorem}

An exploration of this requries the Riemann-Zeta function, defined by
%
\[ \zeta(s) = \sum_{n = 1}^\infty \frac{1}{n^s} \]
%
The function is defined on $(1,\infty)$, since for $s > 1$ the map $t \mapsto 1/t^s$ is decreasing, and so
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \leq 1 + \int_{1}^\infty \frac{1}{t^s} = 1 + \lim_{n \to \infty} \frac{1}{s-1} \left[1 - 1/n^{s-1} \right] = 1 + \frac{1}{s-1} \]
%
The series converges uniformly on $[1+\varepsilon, N]$ for any $\varepsilon > 0$, so $\zeta$ is continuous on $(1,\infty)$. As $t \to 1$, $\zeta(t) \to \infty$, because $n^s \to n$ for each $n$, and if for a fixed $M$ we make $s$ close enough to $1$ such that $|n/n^s - 1|<  1/2$ for $1 \leq n \leq M$, then
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \geq \sum_{n = 1}^M \frac{1}{n^s} = \sum_{n = 1}^M \frac{1}{n} \frac{n}{n^s} \geq \frac{1}{2} \sum_{n = 1}^M \frac{1}{n} \]
%
Letting $M \to \infty$, we obtain that $\sum_{n = 1}^\infty \frac{1}{n^s} \to \infty$ as $s \to 1$.

The Riemann-Zeta function is very good at giving us information about the prime integers, because it encodes much of the information about the prime numbers.

\begin{theorem}
    For any $s > 1$,
    %
    \[ \zeta(s) = \prod_{p\ \text{prime}} \frac{1}{1 - p^s} \]
\end{theorem}
\begin{proof}
    The general idea is this -- we may write
    %
    \[ \prod_{p\ \text{prime}} \frac{1}{1 - p^s} = \prod_{p\ \text{prime}} (1 + 1/p^{s} + 1/p^{2s} + \dots) \]
    %
    If we expand this product out formally, enumating the primes to be $p_1, p_2, \dots$, we find
    %
    \[ \prod_{p \leq n} (1 + 1/p^s + 1/p^{2s} + \dots) = \sum_{n_1, n_2, \dots = 0}^\infty \frac{1}{p_1^{n_1}} \]
\end{proof}









\chapter{Complex Methods}

In this chapter, we illustrate the intimate connection between the Fourier transform on the real line, and complex analysis. We have already seen some aspects of this for Fourier analysis on the Torus, with the connection between power series of analytic functions on the unit disk. The main theme is that if $f$ is a function initially defined on the real line, then the problem of extending the function to be analytic on a neighbourhood of this line is connected to to the Fourier transform of $f$ decaying very rapidly (for instance, exponential decay).

\section{Fourier Transforms of Holomorphic Functions}

For each $a > 0$, let $S_a = \{ x + iy: |y| < a \}$ denote the horizontal strip of width $2a$. The next theorem says that functions extendable to be holomorphic on the strip have exponential Fourier decay.

\begin{theorem}
    Let $f: S_a \to \CC$ be holomorphic, integrable on each horizontal line in the strip, such that $f(x + iy) \to 0$ as $|x| \to \infty$. Then if $\widehat{f}$ is the Fourier transform of the restriction of $f$ to the real line, then for each $b < a$,
    %
    \[ |\widehat{f}(\xi)| \lesssim_b e^{-2 \pi b |\xi|}. \]
\end{theorem}
\begin{proof}
    For any $b < a$, $R$, and $\xi > 0$, consider the contour $\gamma_R$ on the rectangle with corners $-R$, $R$, $-R-ib$, and $R-ib$. As $R \to \infty$, the integral along the vertical lines of the rectangle tends to zero as $R \to \infty$, so we conclude that
    %
    \begin{align*}
        \int_{-\infty}^\infty f(x)e^{-2\pi i x \xi}\; dx &= \int_{-\infty}^\infty f(x-ib)e^{- 2 \pi i (x - ib) \xi}\; dx\\
        &= e^{-2 \pi i b \xi} \int_{-\infty}^\infty f(x-ib) e^{- 2 \pi i \xi x}\; dx = e^{-2 \pi i b \xi} \widehat{f_b}(\xi)
    \end{align*}
    %
    where $f_b(x) = f(x - ib)$. But $|\widehat{f_b}(\xi)| \leq \| f_b \|_{L^\infty(\RR)} \lesssim_b 1$, which implies that
    %
    \[ |\widehat{f}(\xi)| \lesssim_b e^{-2 \pi i b \xi}. \]
    %
    A similar estimate when $\xi < 0$ completes the argument.
\end{proof}

It follows that $\widehat{f}$ has exponential decay if $f$ satisfies the hypothesis of the theorem. Thus we can always apply the inverse Fourier transform to conclude
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi. \]
%
Conversely, if $f$ is \emph{any} integrable function with $|\widehat{f}(\xi)| \lesssim e^{-2 \pi a |\xi|}$, then $\widehat{f}$ is integrable so the Fourier inversion formula holds. If we define
%
\[ f(x + iy) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{-2 \pi \xi y} e^{2 \pi i \xi x}\; d\xi, \]
%
then this gives a holomorphic extension of $f$ which is well defined on $S_a$.

Pushing this result to an extreme leads to the Paley-Wiener theorem, which gives precise conditions when a function has a compactly supported Fourier transform.

\begin{theorem}
    A function $f: \RR \to \CC$ is bounded, integrable, and continuous. Then $f$ extends to an entire function on the complex plane, such that for all $z$,
    %
    \[ |f(z)| \lesssim e^{2 \pi M |z|}, \]
    %
    if and only if $\widehat{f}$ is supported on $[-M,M]$.
\end{theorem}
\begin{proof}
    If $\widehat{f}$ is supported on $[-M,M]$, then the Fourier inversion formula comes into play, telling us that for all $x \in \RR$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi = \int_{-M}^M \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi. \]
    %
    But then we can clearly extend $f$ to an entire function by defining
    %
    \[ f(z) = \int_{-M}^M \widehat{f}(\xi) e^{2 \pi i \xi z}\; d\xi, \]
    %
    and then $|f(z)| \leq e^{2 \pi i M |z|} \| \widehat{f} \|_{L^1[-M,M]} \lesssim e^{2 \pi i M |z|}$.

    Conversely, suppose $f$ is an entire function such that for all $z \in \CC$,
    %
    \[ |f(z)| \leq A g(x) e^{2 \pi M |y|}, \]
    %
    where $g \geq 0$ is integrable on $\RR$. We also assume that $f(x + iy) \to 0$ uniformly as $x \to -\infty$, independently of $y$. Then a contour shift down guarantees that for any $y$,
    %
    \begin{align*}
        \widehat{f}(\xi) &= \int_{-\infty}^\infty f(x) e^{-2 \pi i \xi x}\; dx\\
        &= \int_{-\infty}^\infty f(x - iy) e^{-2 \pi i \xi (x - iy)}\; dx\\
        &\leq A e^{2 \pi M y - 2 \pi \xi y} \int_{-\infty}^\infty g(x) \; dx \lesssim e^{2 \pi (M y - \xi y)}.
    \end{align*}
    %
    If $\xi > M$, then taking $y \to \infty$ shows $\widehat{f}(\xi) = 0$. A contour shift up instead gives $\widehat{f}(\xi) = 0$ if $\xi < -M$. Thus the proof is completed in this case.

    Now suppose the weaker condition
    %
    \[ |f(z)| \leq A e^{2 \pi M |y|}. \]    
    %
    For each $\varepsilon > 0$, let
    %
    \[ f_\varepsilon(z) = \frac{f(z)}{(1 - i\varepsilon z)^2}. \]
    %
    Then $f_\varepsilon$ is analytic in the lower half plane. Moreover,
    %
    \[ |f_\varepsilon(x + iy)| \lesssim_\varepsilon \frac{A e^{2\pi M |y|}}{1 + x^2}. \]
    %
    Thus we can apply the previous shifting techniques to show that $\widehat{f_\varepsilon}(\xi) = 0$ for $\xi > M$. For $x \in \RR$, we have $|f_\varepsilon(x)| \leq |f(x)|$, and since $f_\varepsilon \to f$ pointwise as $\varepsilon \to 0$, we can apply the dominated convergence theorem to imply $\widehat{f_\varepsilon}(\xi) \to \widehat{f}(\xi)$ for each $\xi$. In particular, we find $\widehat{f}(\xi) = 0$ for $\xi > M$. A similar technique with the family of functions
    %
    \[ f_\varepsilon(z) = \frac{f(z)}{(1 + i\varepsilon z)^2}, \] 
    %
    show that $\widehat{f}(\xi) = 0$ for $\xi < -M$.

    Finally, it suffices to show that the condition
    %
    \[ |f(z)| \lesssim e^{2\pi M |z|} \]
    %
    implies $|f(x + iy)| \lesssim e^{2 \pi M |y|}$. To prove this, we can apply a version of the Phragm\'{e}n-Lindel\"{o}f on the quandrant $\{ x + iy: x, y > 0 \}$. Let $g(z) = f(z) e^{-2 \pi i M y}$. Then we have
    %
    \[ |g(x)| = |f(x)| \leq \| f \|_{L^\infty(\RR)}, \]
    %
    and
    %
    \[ |g(iy)| = |f(iy)| e^{-2 \pi i M y} \leq A. \]
    %
    Since $g$ has at most exponential growth on the quadrant, we can apply the Phragm\'{e}n-Lindel\"{o}f to conclude $|g(z)| \leq \max(A, \| f \|_{L^\infty(\RR)})$ for all $z$ on the quandrant. A similar argument works for the other quadrants. Thus we conclude that for all $z \in \CC$
    %
    \[ |f(z)| \leq \max(A, \| f \|_{L^\infty(\RR)}) e^{2 \pi i M |y|}, \]
    %
    and so we can apply the previous cases to conclude that $\widehat{f}$ is supported on $[-M,M]$.
\end{proof}

\begin{remark}
    The Paley-Wiener theorem has several variants. For instance, if $f$ is continuous, integrable, and $\widehat{f}$ is integrable, and we further assume that $\widehat{f}(\xi) = 0$ for all $\xi < 0$, then for $z = x + iy$, we can define
    %
    \[ f(z) = \int_0^\infty \widehat{f}(\xi) e^{2 \pi i \xi z} = \int_0^\infty \widehat{f}(\xi) e^{- 2 \pi \xi y} e^{2 \pi i \xi x} \]
    %
    to extend $f$ to an analytic function in the upper half-plane, i.e. for $y > 0$, which is also continuous and bounded for $y \geq0$. Conversely, similar techniques to those above enable us to show that if $f$ is continuous, integrable, $\widehat{f}$ is integrable, and we can extend $f$ to an analytic function on the open upper half plane, which is continuous and bounded on the closed half plane, then contour shifting shows that $\widehat{f}(\xi) = 0$ for $\xi < 0$.
\end{remark}

\section{Classical Theorems by Contours}

We now prove some classical theorems of Fourier analysis using techniques of harmonic analysis, given that the functions we study have holomorphic extensions to tubes.

\begin{theorem}
    Let $f: S_b \to \CC$ be holomorphic. Then for any $x \in \RR$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; dx, \]
    %
    where $\widehat{f}$ is the Fourier transform of $f$ restricted to the real-axis.
\end{theorem}
\begin{proof}
    As in the last theorem, the sign of $\xi$ matters. We write
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e^{-2 \pi i \xi x} = \int_0^\infty \widehat{f}(\xi) e^{- 2 \pi i \xi x} + \widehat{f}(-\xi) e^{2 \pi i \xi x}. \]
    %
    Now if $b < a$, we can apply a contour integral argument to conclude that
    %
    \begin{align*}
        \widehat{f}(\xi) &= \int_{-\infty}^\infty f(x - ib) e^{-2 \pi i \xi (x - ib)}\; dx\\
        &= \int_{-\infty}^\infty f(x + ib) e^{2 \pi i \xi (x + ib)}\; dx.
    \end{align*}
    %
    Thus by Fubini's theorem, for each $x_0 \in \RR$,
    %
    \begin{align*}
        \int_0^\infty \widehat{f}(\xi) e^{2 \pi i \xi x_0} &= \int_0^\infty \int_{-\infty}^\infty f(x - ib) e^{2 \pi i \xi [x_0 - (x - ib)]}\; dx\; d\xi\\
        &= \int_{-\infty}^\infty f(x - ib) \left( \int_0^\infty e^{2 \pi i \xi [x_0 - (x - ib)]}\; d\xi \right)\; dx\\
        &= \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{f(x - ib)}{(x - ib) - x_0}\; dx.
    \end{align*}
    %
    Similarily, another application of Fubini's theorem implies
    %
    \begin{align*}
        \int_0^\infty \widehat{f}(-\xi) e^{-2 \pi i \xi x_0}\; d\xi &= \int_0^\infty \int_{-\infty}^\infty f(x + ib) e^{-2 \pi i \xi [x_0 - (x + ib)]}\; dx\; d\xi\\
        &= \int_{-\infty}^\infty f(x + ib) \int_0^\infty e^{-2 \pi i \xi [x_0 - (x + ib)]}\; d\xi\; dx\\
        &= \frac{-1}{2 \pi i} \int_{-\infty}^\infty \frac{f(x + ib)}{[(x + ib) - x_0]}\; dx.
    \end{align*}
    %
    In particular, we conclude that
    %
    \[ \int \widehat{f}(\xi) e^{2 \pi i \xi x_0} = \frac{1}{2\pi i} \int_\gamma \frac{f(z)}{z - x_0}, \]
    %
    where $\gamma$ is the path traces over the two horizontal strips $x + ib$ and $x - ib$. Approximating this integral by rectangles, and then apply Cauchy's theorem, we find this value is equal to $f(x)$.
\end{proof}

We can also prove the Poisson summation formula.

\begin{theorem}
    Let $f: S_a \to \CC$ be holomorphic. Then
    %
    \[ \sum_{n \in \ZZ} f(n) = \sum_{n \in \ZZ} \widehat{f}(n), \]
    %
    where $\widehat{f}$ is the Fourier transform of $f$ restricted to the real line.
\end{theorem}
\begin{proof}
    The function
    %
    \[ \frac{f(z)}{e^{2 \pi i z} - 1} \]
    %
    is meromorphic, with simple poles on $\ZZ$, with reside equal to $f(n)$ at each $n \in \ZZ$. If we apply the Residue theorem to a curve $\gamma_N$ travelling around the rectangle connecting the points $N+1/2-ib$, $N+1/2+ib$, $-N-1/2+ib$, and $-N-1/2-ib$, then we conclude
    %
    \[ \sum_{|n| \leq N} f(n) = \int_{\gamma_N} \frac{f(z)}{e^{2 \pi i z} - 1}\; dz. \]
    %
    These values converge to $\sum_{n \in \ZZ} f(n)$ as $N \to \infty$. But this means that
    %
    \[ \sum_n f(n) = \int_\gamma \frac{f(z)}{e^{2 \pi i z} - 1}\; dz, \]
    %
    where $\gamma$ is the two horizontal strips at $b$ and $-b$. Now we use the expansion
    %
    \[ \frac{1}{z - 1} = \sum_{n = 1}^\infty z^{-n}, \]
    %
    for $|z| > 1$, to conclude
    %
    \begin{align*}
        \int_{-\infty}^\infty \frac{f(x - ib)}{e^{2 \pi i (x - ib)} - 1}\; dx &= \int_{-\infty}^\infty \sum_{n = 1}^\infty \frac{f(x - ib)}{e^{2 \pi n i (x - ib)}}\; dx\\
        &= \sum_{n = 1}^\infty \int_{-\infty}^\infty f(x - ib) e^{-2 \pi n i (x - ib)}\; dx = \sum_{n = 1}^\infty \widehat{f}(n),
    \end{align*}
    %
    where we have performed a contour shift at the end. Similarily, we use the expansion
    %
    \[ \frac{1}{z - 1} = - \sum_{n = 0}^\infty z^n, \]
    %
    to conclude that
    %
    \begin{align*}
        - \int_{-\infty}^\infty \frac{f(x + ib)}{e^{2 \pi i (x + ib)} - 1} &= \int_{-\infty}^\infty \sum_{n = 0}^\infty f(x + ib) e^{2 \pi i (x + ib)}\; dx\\
        &= \sum_{n = 0}^\infty \widehat{f}(-n).
    \end{align*}
    %
    Combining these two calculations completes the proof.
\end{proof}

\section{The Laplace Transform}

We now look at things from the dual perspective. Instead of looking at whether a function can be extended to a holomorphic function, we look at whether the Fourier transform can be extended to a holomorphic function. For a function $x: \RR \to \RR$, this gives rise to the \emph{Laplace transform}
%
\[ X(z) = \int_{-\infty}^\infty x(t) e^{- z t}\; dt, \]
%
also denoted by $(\mathcal{L}x)(z)$. For $\xi \in \RR$, $X(i\xi) = \widehat{x}(\xi)$ operates as the usual Fourier transform (slightly rescaled from the version in our notes). But the Laplace transform can also be extended to not-necessarily integrable functions. Given $x$, we can define $X(z)$ for any $z = x + iy$ such that
%
\[ \int e^{-xt} |f(t)|\; dt < \infty. \]
%
It is simple to see this forms a vertical tube in the complex plane, called the \emph{region of convergence} for the Laplace transform. For a particular vertical tube $I \subset \CC$, we let $\mathcal{E}(I)$ be the collection of all functions $x$ whose region of convergence for the Dirichlet transform contains $I$.

\begin{example}
    Let
    %
    \[ H(x) = \begin{cases} 0 &: x < 0, \\ 1/2 &: x = 0, \\ 1 &: x > 0. \end{cases} \]
    %
    The function $H$ is called the \emph{Heavyside Step Function}. It's region of convergence consists of the right-most half plane, i.e. all $\omega + i\xi$, where $\omega > 0$. And if $z = \omega + i\xi$, we calculate that
    %
    \[ \mathcal{L}(H)(z) = \int_0^\infty e^{- z t}\; dt = z^{-1}. \]
    %
    We note that even though the integral formula does not define the Laplace transform of $H$ in the right-most half plane, we \emph{can} analytically continue $\mathcal{L}(H)$ to a meromorphic function on the entire complex plane.
\end{example}

\begin{example}
    Similarily, an integration by parts shows that for $z = \omega + i\xi$ with $\omega > 0$, we have
    %
    \[ \mathcal{L}(tH)(z) = \int_0^\infty t e^{-zt} = \int_0^\infty \frac{e^{-zt}}{z} = z^{-2}. \]
    %
    Against, $\mathcal{L}(tH)$ extends to a meromorphic function on the entire complex plane.
\end{example}

\begin{comment}
    The Laplace transform is useful because it connects the study of the Fourier transform of a function to the study of certain complex analytic functions. For simplicity, we work with functions on the half-line, which eliminates some symmetry at the cost of a more simple theory. For a function $f: [0,\infty) \to \CC$, and $z \in \CC$, we study the integral transform
%
\[ (\mathcal{L} f)(z) = \int_{-\infty}^\infty f(t) e^{-zt}\; dt. \]
%
In some senses, the Laplace transform is a more general version of the Fourier transform. Indeed, we find
%
\[ (\mathcal{L} f)(\omega + i \xi) = \widehat{f e^{- \omega t}}(\xi). \]
%
Thus the Laplace transform of $Lf$ at a particular value $\omega$ measures a weighted frequency representation of $f$. A major advantage is that $Lf$ is defined as the integral of $f$ against a holomorphic function, and in particular, is often a holomorphic function, which enables us to use techniques of complex analysis.

We fix $f \in L^1(\RR)$, andse $f$ is supported on $[-N,\infty)$ for some large $N$. Then for any $\omega \geq 0$,
%
\[ \int_{-\infty}^\infty |f(t)| e^{-\omega t} < \infty. \]
%
Thus the integral
%
\[ \int f(t) e^{-zt}\; dt \]
%
is defined as an absolutely convergent integral for all $z = \omega + i\xi$ with $\omega \geq 0$. Thus we can define the Laplace transform $(\mathcal{L} f)(z)$ for all $z$ in the closed right half-plane. If $\gamma$ is a closed curve in the open right half-plane, and $f \in L^1(\RR)$, then Fubini's theorem implies that
%
\begin{align*}
    \int_\gamma \mathcal{L} f\; dz &= \int_0^1 (\mathcal{L} f)(\gamma(s)) \gamma'(s)\; ds\\
    &= \int_0^1 \int_0^\infty f(t) e^{- \gamma(s) t} \gamma'(s)\; dt\; ds\\
    &= \int_0^\infty f(t) \left( \int_\gamma e^{-zt}\; dz \right)\; dt = \int_0^\infty 0\; dt = 0.
\end{align*}
%
Thus Morera's theorem implies $\mathcal{L} f$ is analytic in the open right half-plane. The Dominated convergence theorem also implies $\mathcal{L} f$ is continuous in the closed half-plane. If we also assume that $f$ is compactly supported, then the Laplace $\mathcal{L} f$ is defined everywhere, and is an entire function.
\end{comment}

\begin{comment}
We often study functions supported on $[0,\infty)$, in which case it suffices to analyze the `one sided' Laplace transform
%
\[ (\mathcal{L} f)(\omega + i\xi) = \int_0^\infty f(x) e^{-2 \pi (\omega + i \xi)t}\; dt. \]
%
The reason for this is quite simple. The Laplace transform is often used to analyze certain convolution operators $Tf = f * g$. One views the function $f(t)$ as a certain signal, with amplitudes varying over a time period. Most often, $T$ is an operator which is computed `online'; we think of feeding in the signal $f(t)$ in real time, and then produce $(Tf)(t)$ at the same time. For example, the operator $Tf = f * H$, where $H$ is the heavyside step function, is defined so that
%
\[ (Tf)(t) = \int_{-\infty}^t f(s)\; ds, \]
%
so $(Tf)(t)$ can be produced given only knowledge of $f$ up to time $t$. In general, $(Tf)(t)$ depends only on $f$ up to time $t$ if and only if $g$ is supported on $[0,\infty)$. As expected, we will show $\mathcal{L}(f * g) = \mathcal{L}f \cdot \mathcal{L}g$ so in many senses it suffices to analyze the Laplace transform of a function defined on a half line.


To rigorously study the Laplace transform, we look at a nice family of functions for which the transform is particularly well behaved. For each $\alpha \in \RR$, we let $\mathcal{E}_\alpha$ be the collection of all functions $f$ supported on $[0,\infty)$ such that $f e^{- \alpha t} \in L^1(\RR^d)$. Then if $\omega \geq \alpha$, and $\xi \in \RR$, $(\mathcal{L}f)(\omega + i\xi)$ is well defined by the integral formula. Moreover, for $\omega > \alpha$, $\mathcal{L} f$ is actually an \emph{analytic} function, with
%
\[ (\mathcal{L}f)'(\omega + i \xi) = - 2\pi \cdot \mathcal{L}(tf)(\omega + i\xi). \]
%
This can be established by a simple approximation argument. The dominated convergence theorem also implies that $\mathcal{L}f$ is continuous on the closed half plane defined by $\omega \geq \alpha$.
\end{comment}

What distinguishes the Laplace transform from the Fourier transform is the ability to use techniques of complex analysis. If $x$ has region of convergence $I$, then $X$ is continuous on $I$, and analytic on $I^\circ$. We can even calculate an explicit formula for the derivative As expected from the Fourier transform of the derivative, if $y(t) = tx(t)$, and $Y$ is the Laplace transform of $y$, then $X'(z) = -Y(z)$. One can verify this quite simply by taking limits of the derivatives of the analytic integrals
%
\[ \int_{-N}^N x(t) e^{-zt}\; dt, \]
%
as $N \to \infty$. Like the Fourier transform, the Laplace transform is symmetric under modulation, translation, and polynomial multiplication:
%
\begin{itemize}
    \item If $w \in \CC$, and $x$ is a function, set $y(t) = e^{wt} x(t)$. Then if $z$ is in the region of convergence for $x$, $z - w$ is in the region of convergence for $y$, and $X(z) = Y(z-w)$.

    \item If $x$ has region of convergence $I$, then the region of convergence for $y(t) = tx(t)$ contains $I^\circ$, and $Y(z) = -X(z)$.

    \item If $x$ has region of convergence $I$, $t_0 \in \RR$, and we set $y(t) = x(t + t_0)$, then $y$ has region of convergence $I$, and $Y(z) = e^{zt_0} X(z)$.

    \item For a function $x$, define
    %
    \[ (\Delta_s x)(t) = \frac{x(t + s) - x(t)}{s}. \]
    %
    If $\omega$ is fixed, if
    %
    \[ \lim_{s \to 0} \int |(\Delta_s x)(t) - x'(t)| e^{-\omega t}\; dt = 0, \]
    %
    if $y(t) = x'(t)$, and if $z = \xi + i \omega$ for some $\xi \in \RR$, then $Y(z) = z X(z)$.

    In particular, this is true if $x$ is supported on $[-N,\infty)$ for some $N$, has a continuous derivative $x'$, and there is $\omega_0 < \omega$ such that
    %
    \[ \lim_{t \to \infty} x(t) e^{-\omega_0 t} = \lim_{t \to \infty} x'(t) e^{-\omega_0 t} = 0. \]
    %
%    It will be useful to consider functions $f$ with $f(t) = 0$ for $t < 0$, such that $f$ is continuously differentiable for $t > 0$, since such functions can be used to solve ordinary differential equations, but such that
    %
%    \[ f(0+) = \lim_{t \to 0^+} f(t) \]
    %
%    exists and is finite. Then $f'$ is defined everywhere but the origin, and an integration by parts tells us that
    %
%    \[ (\mathcal{L} f')(z) = z \cdot (\mathcal{L} f)(z) - f(0+). \]
    %
%    More generally, $(\mathcal{L} f^{(n)})(z) = z^n \cdot (\mathcal{L} f)(z)$
\end{itemize}

\begin{remark}
    It will be interesting for us to consider functions $x$ supported on $[-N,\infty)$ which have a piecewise continuous derivative $x'$ except at finitely many points $t_1, \dots, t_N$, such that the left and right-hand limits exist at each $t_i$. For each $i \in \{ 1, \dots, N \}$, we let
    %
    \[ A_i = x(t_i+) - x(t_i-) \quad\text{and}\quad B_i = x'(t_i+) - x'(t_i-). \]
    %
    If $y(t) = x'(t)$, we calculate a relation between the Laplace transforms of $X$ and $Y$ at $z = \omega + i\xi$ such that there exists $\omega_0 < \omega$ such that
    %
    \[ \lim_{t \to \infty} x(t) e^{-\omega_0 t} = \lim_{t \to \infty} x'(t) e^{-\omega_0 t} = 0. \]
    %
    We consider the function
    %
    \[ x_1(t) = x(t) - \sum_{i = 1}^N A_i H(t - t_i) - \sum_{i = 1}^N B_i (t - t_i) H(t - t_i). \] 
    %
    Then $x_1$ is continuous everywhere, and moreover, has a continuous derivative. We have
    %
    \[ x_1'(t) = x'(t) - \sum_{i = 1}^N B_i H(t - t_i). \]
    %
    Thus if $\omega > 0$, and $z = \omega + i \xi$, if $y_1(t) = x_1'(t)$, we find
    %
    \[ Y_1(z) = z X_1(z). \]
    %
    Now
    %
    \[ Y_1(z) = Y(z) - \sum_{i = 1}^N \frac{B_i e^{-i z t_i}}{iz} \]
    %
    and
    %
    \[ X_1(z) = X(z) - \sum_{i = 1}^N \frac{A_i e^{-i z t_i}}{iz} + \sum_{i = 1}^N \frac{B_i e^{-i z t_i}}{z^2}. \]
    %
    Thus, rearranging, we conclude
    %
    \[ Y(z) = z X(z) - \sum_{i = 1}^N A_i e^{-i z t_i} \]
    %
    We can carry this through recursively to higher order derivatives. For each $k$, we set $A^k_i = f^{(k)}(t_i+) - f^{(k)}(t_i-)$. Then if $y(t) = f^{(n)}(t)$, then
    %
    \[ Y(z) = z^n X(z) - \sum_{k = 0}^{n-1} \sum_{i = 1}^N z^{n-1-k} A^k_i e^{-izt_i}. \]
    %
    This is very useful when wants to solve differential equations, provided the solutions to those differential equations do not grow faster than exponentially.
\end{remark}

\begin{example}
    Suppose we wish to find a formula for the unique real-valued function $x: [0,\infty) \to \RR$ such that $x''(t) - x'(t) - 6x(t) = 5e^{3t}$ for $t \geq 0$, such that $x(0) = 6$ and $x'(0) = 1$. Such a function increases at most exponentially, since it is linear, so we may take the Laplace transform of each sides to conclude that if $X$ is the Laplace transform of $x$, then
    %
    \[ \mathcal{L}(x'')(z) = z^2 X(z) - 6z - 1 \quad\text{and}\quad \mathcal{L}(x')(z) = z X(z) - 6. \]
    %
    Thus we conclude
    %
    \[ [z^2 X(z) - 6z - 1] - [zX(z) - 6] - (6X) = \frac{5}{z - 3}. \]
    %
    Thus
    %
    \[ X(z) = \frac{(3z - 4)(2z - 5)}{(z - 3)^2(z+2)} = \frac{3.6}{z + 2} + \frac{2.4}{z - 3} + \frac{1}{(z - 3)^2}. \]
    %
    But this implies that for $t \geq 0$, $x(t) = 3.6 e^{-2t} + 2.4 e^{3t} + te^{3t}$. In particular, we note that the pole of $X$ determines the large scale behaviour of $X$, i.e. for large $t$, and for any $\varepsilon > 0$,
    %
    \[ e^{(3 - \varepsilon)t} \lesssim_\varepsilon x(t) \lesssim_\varepsilon e^{(3 + \varepsilon)t}. \]
    %
    In the next section, we generalize this situation to give asymptotics of functions whose Laplace transforms extend to meromorphic functions on the complex plane.
\end{example}

\section{Asymptotics via the Laplace Transform}

For simplicity, in this chapter we study integrable functions $x: [0,\infty) \to \RR$, whose Laplace transform is thus well defined on the closed, right half-plane. If the Fourier transform of $x$ is integrable, then we can apply the inversion formula to conclude that for each $t \in \RR$,
%
\[ x(t) = \int_{-\infty}^\infty X(i\xi) e^{i \xi t}\; d\xi. \]
%
Now suppose that $X$ can be analytically continued to a holomorphic function $X(\omega + i\xi)$ for all $\omega \geq -\varepsilon$ which is continuous at the boundary, such that, uniformly for $\omega \in [-\varepsilon,0]$,
%
\[ \lim_{|\xi| \to \infty} X(\omega + i\xi) = 0. \]
%
Then a contour shift argument implies that for each $t$,
%
\[ x(t) = \lim_{R \to \infty} \int_{-R}^R X(-\varepsilon + i\xi) e^{(-\varepsilon + i\xi) t}\; d\xi = e^{-\varepsilon t} \lim_{R \to \infty} \int_{-R}^R X(-\varepsilon + i\xi) e^{i \xi t}\; d\xi. \]

For simplicity, we study functions supported on $[0,\infty)$. The region of convergence for such functions then takes the form of a half plane. For a given $a \in \RR$, we let $\mathcal{E}_a$ be the set of functions whose region of convergence contains $\omega + i\xi$ for all $\omega > a$.

\begin{theorem}
    Suppose $x: [0,\infty) \to \RR$ is a continuous function such that some $\omega$,
    %
    \[ \int |x(t)| e^{-\omega t}\; dt < \infty. \]
    %
\end{theorem}
\begin{proof}
    Since $|X(u + iv)| \to 0$ uniformly as $v \to \infty$, we can shift the Fourier inversion formula
    %
    \[ x(t) = \lim_{R \to \infty} \frac{1}{2\pi} \int_{-R}^R X(\omega + i\xi) e^{(\omega + i\xi)t}\; d\xi \]
    %
    (where the $2\pi$ comes up from our rescaling of the Fourier transform) to conclude that
    %
    \[ x(t) = \lim_{R \to \infty} \frac{1}{2\pi} \]
    %
    \[ X(z) = \lim_{} \]
\end{proof}














