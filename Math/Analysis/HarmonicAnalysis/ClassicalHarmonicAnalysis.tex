    %% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Classical Fourier Analysis}

Deep mathematical knowledge often arises hand in hand with the characterization of symmetry. Nowhere is this more clear than in the foundations of harmonic analysis, where we attempt to understand mathematical `signals' by the `frequencies' from which they are composed. In the mid 18th century, problems in mathematical physics led D. Bernoulli, D'Alembert, Lagrange, and Euler to consider periodic functions representable as a trigonometric series
%
\[ f(t) = A + \sum_{m = 1}^\infty B_n \cos(2 \pi mt) + C_n \sin(2 \pi mt). \]
%
In his book, Th\'{e}orie Analytique de la Chaleur, published in 1811, Joseph Fourier had the audacity to announce that {\it all} functions were representable in this form, and used it to sove linear partial differential equations in physics. His conviction is the reason the classical theory of harmonic analysis is often named Fourier analysis, where we analyze the degree to which Fourier's proclamation holds, as well as it's paired statement on the real line, that a function $f$ on the real line can be written as
%
\[ f(t) = \int_{-\infty}^\infty A(\xi) \cos(2 \pi \xi t) + B(\xi) \sin(2 \pi\xi t)\; d\xi. \]
%
for some functions $A$ and $B$ on the line.

In the 1820s, Poisson, Cauchy, and Dirichlet all attempted to form rigorous proofs that `Fourier summation' holds for all functions. Their work is responsible for most of the modern subject of analysis we know today. In particular, it is essential to utilize all the convergence techniques developed through the rigorous study of analysis. Under pointwise convergence, the representation of a function by Fourier series need not be unique. Uniform convergence is more useful, and uniform convergence holds for all smooth functions, but does not hold if we only assume a function is continuous. Thus we must introduce more subtle methods.

\chapter{Introduction}

One fundamental family of oscillatory functions in mathematics are the trigonometric functions
%
\[ f(t) = A \cos(st) + B \sin(st) = C \cos(st + \phi). \]
%
The value $\phi$ is the \emph{phase} of the oscillation, $C$ is the \emph{amplitude}, and $s/2\pi$ is the \emph{frequency} of the oscillation. These oscillatory functions occur in many situations; for instance, in the study of the solution of the harmonic oscillator. The main topic of Fourier analysis is to study how well one may represent a general function as an analytical combination of these trigonometric functions. In the periodic setting, we fix a function $f: \RR \to \CC$ such that $f(x + 1) = f(x)$ for all $x \in \RR$, and try and find coefficients $\{ A_m \}$, $\{ B_m \}$, and $C$ such that
%
\[ f(t) \sim C + \sum_{m = 1}^\infty A_m \cos(2 \pi mt) + B_m \sin(2 \pi mt). \]
%
In the continuous setting, we fix a function $f: \RR \to \CC$, trying to find values $A(s)$, $B(s)$, and $C$ such that
%
\[ f(t) \sim C + \int_0^\infty A(s) \cos(2 \pi st) + B(s) \sin(2 \pi st)\; ds. \]
%
The main contribution of Fourier was a method to formally find a reliable choice of coefficients which represents $f$. This choice is given by the \emph{Fourier transform} of $f$ in the continuous case, and the \emph{Fourier series} in the discrete case.

\section{Obtaining the Fourier Coefficients}

A \emph{formal trigonometric series} is a formal sum of the form
%
\[ C + \sum_{m = 1}^\infty A_m \cos(2\pi mt) + B_m \sin(2\pi mt). \]
%
It was natural, in several mathematical and physical questions in the 19th century, to find \emph{trigonometric expansions} for a given function $f$, i.e. to find a family of coefficients $\{ A_m \}$, $\{ B_m \}$, and $C$ such that for each $t \in \RR$,
%
\[ f(t) = C + \sum_{m = 1}^\infty A_m \cos(2 \pi m t) + B_m \sin(2 \pi m t), \]
%
where the latter sum is assumed to be convergent pointwise for each $t \in \RR$. It is a \emph{very difficult question} to characterize which functions $f$ admit a trigonometric expansion. Nonetheless, Fourier found a way to \emph{formally} associate a formal trigonometric series with any integrable periodic function. If the function is differentiable, then the trigonometric series gives a trigonometric expansion for the function. But even if this series does not give a trigonometric expansion for this function, the series itself still reflects many important properties of the function, which are of interest independent of their convergence to the function $f$.

\section{Orthogonality}

The key technique Fourier realized could be used to come up with a canonical trigonometric series for a function is \emph{orthogonality}. Note that the various frequencies of sine functions are orthogonal to one another, in the sense that
%
\[ \int_0^1 \sin(2 \pi mt) \sin(2\pi nt) = \int_0^1 \cos(2 \pi mt) \cos(2 \pi nt) = \begin{cases} 0 & : m \neq n, \\ 1/2 & : m = n, \end{cases} \]
%
and for any $m,n \in \ZZ$,
%
\[ \int_0^1 \sin(2 \pi mt) \cos(2 \pi nt) = 0. \]
%
This means that for a finite trigonometric sum
%
\[ f(t) = C + \sum_{m = 1}^N A_m \cos(2 \pi mt) + B_m \sin(2 \pi mt), \]
%
we have
%
\[ C = \int_0^1 f(t)\; dt, \]
\[ A_m = 2 \int_0^1 f(t) \cos(2 \pi mt)\; dt, \quad\text{and}\quad B_m = 2 \int_{-\pi}^\pi f(t) \sin(2 \pi mt)\; dt. \]
%
The important thing to notice is that these quantities are defined even if $f$ is given a priori, without recourse to a trigonometric polynomial. Thus given \emph{any} periodic integrable function $f$, we might hope to find a trigonometric expansion for $f$ by considering the trigonometric series given by the values $\{ A_m \}$, $\{ B_m \}$, and $C$ defined as above. Unlike when $f$ is a trigonometric polynomial, we can have infinitely many non-zero coefficients.

There is an additional choice of oscillatory functions, which replaces the sine and cosine with a single family of trigonometric functions, and thus gives a more notationally convenient analysis. For each $\xi \in \RR$, and each $t \in \RR$, we consider the function
%
\[ e_\xi(t) = e^{2 \pi \xi i t}. \]
%
For each integer $n \in \ZZ$, $e_n$ is periodic with period 1. Applying orthogonality again, we find
%
\[ \int_0^1 e_n(t) \overline{e_m(t)}\; dt = \int_0^1 e_{n-m}(t) = \begin{cases} 0 & : m \neq n, \\ 1 & : m = n. \end{cases}  \]
%
Thus we can use orthogonality to find a natural choice of an expansion
%
\[ f \sim \sum_{n \in \ZZ} D_n e^{2 \pi nit} \]
%
for an integrable, periodic function $f$, i.e. by setting
%
\[ L_n = \int_0^1 f(t) \overline{e_n(t)}\; dt = \int_0^1 f(t) e^{- 2 \pi i n t}\; dt. \]
%
Euler's formula $e^{nit} = \cos(nt) + i \sin(nt)$ gives an equivalence between expansions in complex exponentials, and expansions in sines and cosines. Thus the values $\{ A_m, B_m, C : m \geq 0 \}$ can be recovered from the values of $\{ D_m : m \in \ZZ \}$, and vice versa. Moreover, we have
%
\[ C + \sum_{m = 1}^N A_m \cos(2 \pi m t) + B_m \sin(2 \pi m t) = \sum_{|n| \leq N} D_n e_\xi(t). \]
%
Thus the convergence properties of these series is identical, provided we take the \emph{symmetric} partial sums of complex exponentials. Because of it's elegance, unifying the three families of coefficients, the expansion by complex exponentials is the most standard used in Fourier analysis today.

To summarize, we have shown a periodic integrable function $f: \RR \to \CC$ gives rise to a formal trigonometric series
%
\[ \sum_{m \in \ZZ} C_m e_m(t). \]
%
This is the \emph{Fourier series} of $f$. Because we will be concentrating on the Fourier series of a function, it is worth reserving a particular notation. Given a periodic, integrable function $f$, and an integer $m \in \ZZ$, we set
%
\[ \widehat{f}(m) = \int_0^1 f(t) \overline{e_m(t)}\; dt. \]
%
The Fourier series representation in terms of complex exponentials will be our choice throughout the rest of these notes. No deep knowledge of the complex numbers is used here.

\section{The Fourier Transform}

For a non-periodic function $f: \RR \to \CC$, a natural analogue to an expansion in a trigonometric series
%
\[ \sum C_m e_m(t) \]
%
would be an expansion as a \emph{trigonometric integral}, i.e. a formal expression of the form
%
\[ \int a(\xi) e_\xi(t). \]
%
Let us say a function $f$ \emph{admits a trigonometric expansion} if there exists a locally integrable function $a$ such that
%
\[ f(t) = \lim_{N \to \infty} \int_{|\xi| \leq N} a(\xi) e_\xi(t)\; d\xi. \]
%
Again, a characterization of the type of functions which admit a trigonometric expansion is very difficult, but we can still get away with trying to find a method to obtain an expansion using some kind of orthogonality. The functions $\{ e_\xi \}$ are not even integrable on $\RR$, let alone orthogonal. But if $f$ is an integrable function on the real line, then for each $R > 0$, we can consider the functions $g_R: [0,1] \to \CC$ by setting $g_R(s) = f(R(s-1/2))$. We note that formally, we calculate that for $R \geq |t|$,
%
\begin{align*}
    f(t) &= g_R(t / R + 1/2)\\
    &\sim \sum_{m \in \ZZ} \widehat{g_N}(m) e^{2 \pi m i (t/N + 1/2)}\\
    &=  \sum_{m \in \ZZ} (-1)^m \left( \int_0^1 f(N(s-1/2)) e^{-2 \pi mis}\; ds \right) e^{2 \pi (m/N) it}\\
    &= \sum_{m \in \ZZ} \frac{1}{N} \left( \int_{-N/2}^{N/2} f(s) e^{-2\pi (m/N) i s}\; ds \right) e^{(m/N)it}.
\end{align*}
% u = N(s - 1/2)
% du = Nds
%
If we take $N \to \infty$, the exterior sum operates like a Riemann sum, so we might expect
%
\[ f(t) \sim \int_{-\infty}^\infty \left( \int_{-\infty}^\infty f(s) e^{-2 \pi \xi is}\; ds \right) e^{2 \pi \xi i t}\; d\xi. \]
%
The interior integral defines the \emph{Fourier transform} of the function $f$, given for each $\xi \in \RR$ as
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(s) e^{- 2 \pi \xi is}\; ds. \]
%
Thus the resultant \emph{Fourier inversion formula} takes the form
%
\[ f(t) \sim \int_{-\infty}^\infty \widehat{f}(\xi) e_\xi(t)\; d\xi. \]
%
As the \emph{limit} of a discrete series defined in terms of orthogonality, the Fourier transform possesses many of the same properties at the Fourier series. But the non-compactness causes issues which are not present in the case of Fourier series, and so the Fourier series theory is often a simpler theory to begin with.

\section{Multidimensional Theory}

Finally, we note that the Fourier series and Fourier transform are not relegated to a one dimensional theory. If $f: \RR^d \to \CC$ is periodic, in the sense that
%
\[ f(x + n) = f(x) \quad \text{for each $x \in \RR^d$ and $n \in \ZZ^d$}, \]
%
then we can consider the natural higher dimensional Fourier series
%
\[ f(x) \sim \sum_{n \in \ZZ^d} \widehat{f}(n) e_n(x) \] 
%
where for each $\xi \in \RR^d$, $e_\xi: \RR^d \to \CC$ is the function $e_\xi(x) = e^{2 \pi i \xi \cdot x}$, and
%
\[ \widehat{f}(n) = \int_{[0,1]^d} f(t) \overline{e_n(t)}\; dt \]
%
Similarily, for $f: \RR^d \to \CC$, we can consider the Fourier inversion formula
%
\[ f(t) \sim \int_{\RR^d} \widehat{f}(\xi) e_\xi(x)\; d\xi \]
%
where for each $\xi \in \RR^d$,
%
\[ \widehat{f}(\xi) = \int_{\RR^d} f(t) \overline{e_\xi(t)} \]
%
The basic theory of Fourier series and the Fourier transform in one dimension extends naturally to higher dimensions, as do the basic theories of orthogonality. On the other hand, the basic theory of convergence in higher dimensions requires much greater regularity in higher dimensions than the one dimensional theory, and many fundamental questions about the convergence of Fourier series here have much more nuance than in the lower dimensional theory, with many questions about such questions still open today.

%
%\begin{example}
%    This method can be used to find all harmonic functions $f$ on a rectangle $[0,\pi] \times [0,1]$, such that $f(0,y) = f(\pi,y) = 0$. Let us first attempt to find all separable solutions $f(x,y) = u(x) v(y)$. Then the equations defining harmonic functions tell us that
%    %
%    \[ u''v + v''u = 0 \]
%    %
%    or
%    %
%    \[ \frac{u''}{u} = - \frac{v''}{v} = - \lambda^2 \]
%    %
%    (we assume the constant factor is negative, since the constraints on $u$ would force $f$ to be trivial otherwise). Then we have
%    %
%    \[ u'' = - \lambda^2 u \]
%    %
%    so $u(x) = A \cos(\lambda x) + B \sin(\lambda x)$. The constraints that $u(0) = u(\pi) = 0$ force $A = 0$, and $\lambda \in \ZZ$. We may similarily solve the equation
%    %
%    \[ v'' = \lambda^2 v \]
%    %
%    to conclude $v(y) = M e^{\lambda y} + N e^{- \lambda y}$, so we obtain the solution set
%    %
%    \[ f(x,y) = \sin(n x) (Ae^{n y} + Be^{-ny}) \]
%    %
%    where $n \in \ZZ$, $A,B \in \RR$.

%    Now suppose we can write
%    %
%    \[ f(x,y) = \sum_{n = -\infty}^\infty \sin(nx) (A_n e^{ny} + B_n e^{-ny}) \]
%    %
%    Then
%    %
%    \[ f_0(x) = \sum_{n = -\infty}^\infty (A_n + B_n) \sin(nx) \]
%    \[ f_1(x) = \sum_{n = -\infty}^\infty (A_n e^n + B_n e^{-n}) \sin(nx) \]
%    %
%    So if $\widehat{f_0}$ and $\widehat{f_1}$ denote the sine coefficients of $f_0$ and $f_1$, then
%    %
%    \[ A_n + B_n = \widehat{f_0}(n)\ \ \ \ \ A_n e^n + B_n e^{-n} = \widehat{f_1}(n) \]
%    %
%    \[ A_n = \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} \]
%    %
%    \[ B_n = \widehat{f_0}(n) - \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} = \frac{e^n \widehat{f_0}(n) - \widehat{f_1}(n)}{e^n - e^{-n}} \]
%    %
%    Thus
%    %
%    \begin{align*}
%        f(x,y) &= \sum_{n = -\infty}^\infty \sin(nx) \left( \frac{(\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}) e^{ny} + (e^n \widehat{f_0}(n) - \widehat{f_1}(n)) e^{-ny}}{e^n - e^{-n}} \right)\\
%        &= \sum_{n = -\infty}^\infty \frac{\sin(nx)}{e^n - e^{-n}} [(e^{n(1-y)} - e^{n(y-1)}) \widehat{f_0}(n) + (e^{ny} - e^{-ny}) \widehat{f_1}(n)]\\
%        &= \sum_{n = -\infty}^\infty \left( \frac{\sinh n(1-y)}{\sinh n} \widehat{f_0}(n) + \frac{\sinh ny}{\sinh n} \widehat{f_1}(n) \right) \sin(nx)
%    \end{align*}
%\end{example}

%
%First, define the circle group $\TT$ to be the set of complex numbers $z$ with $|z| = 1$. Functions from $\TT$ to $\RR$ naturally correspond to $2 \pi$-periodic functions; given $g: \TT \to \RR$, the correspondence is given by the equation $f(t) = g(e^{it})$. Thus, when defining $2\pi$ periodic functions, we shall make no distinction between a function `defined in terms of $t$' and a function `defined in terms of $z$', after making the explicit identification $z = e^{it}$. Then an expansion of the form
%
%\[ f(t) = \sum_{k = 0}^\infty A_k \cos(kt) + \sum B_k \sin(kt) \]
%
%leads to an expansion
%
%\begin{align*}
%    f(z) &= \sum_{k = 0}^\infty A_k \Re[z^k] + B_k \Im[z^k]\\
%    &= \sum_{k = 0}^\infty A_k \left( \frac{z^k + z^{-k}}{2} \right) - i B_k \left( \frac{z^k - z^{-k}}{2} \right) = \sum_{k = -\infty}^\infty C_k z^k
%\end{align*}
%
%so a Fourier expansion on $[0,2\pi]$ is really just a power series expansion on the circle in disguise.
%
%Thus expanding a real-valued function in the exponentials $e_n(t) = e^{nit}$ is the same as expanding the function in terms of sines and cosines. The complex exponentials $e_n$ have the same orthogonality properties as $\sin$ and $\cos$, so given a function $f$, the coefficients $C_n$ can be found by the expansion
%
%\[ C_n = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_n(-t) dt \]

\section{Examples of Expansions}

Before we get to the real work, let's start by computing some examples of Fourier series and examples of the Fourier transform. We also illustrate the convergence properties of these series, the general theory of which we shall study later.

\begin{example}
    Consider the function $f: [0,\pi] \to \RR$ defined by $f(x) = x(\pi - x)$. Then a series of integration by parts gives that
    %
    \[ \int x(\pi - x) \sin(nx) = \frac{x(\pi - x) \cos(nx)}{n} + \frac{(\pi - 2x) \sin(nx)}{n^2} - \frac{2\cos(nx)}{n^3}. \]
    %
    Thus
    %
    \[ \frac{2}{\pi} \int_0^\pi x(\pi - x) \sin(nx) = \frac{4(1 - \cos(n\pi))}{n^3} = \begin{cases} \frac{8}{\pi n^3} & n\ \text{odd}, \\ 0 & n\ \text{even}. \end{cases}  \]
    %
    Thus we have a formal representation
    %
    \[ f(x) \sim \sum_{n\ \text{odd}} \frac{8 \sin(nx)}{\pi n^3}. \]
    %
    This sum converges absolutely and uniformly for all $x \in [0,\pi]$. If we extend the domain of $f$ to $[-\pi,\pi]$ by making $f$ odd, then
    %
    \[ \widehat{f}(n) = \begin{cases} \frac{4}{\pi i n^3} & : n\ \text{odd}, \\ 0 & : n\ \text{even}. \end{cases} \]
    %
    In this case, we still have
    %
    \[ f(x) \sim \sum_{\substack{n\ \text{odd}\\ n > 0}} \frac{4}{\pi i n^3} [e_n(x) - e_n(-x)] = \sum_{n\ \text{odd}} \frac{8 \sin(nx)}{\pi n^3}. \]
    %
    This sum converges absolutely and uniformly for all $x \in [-\pi,\pi]$.
\end{example}

\begin{example}
    The tent function
    %
    \[ f(x) = \begin{cases} 1 - \frac{|x|}{\delta} & : |x| < \delta, \\ 0 & : |x| \geq \delta. \end{cases} \]
    %
    is even, and therefore has a purely real Fourier expansion
    %
    \[ \widehat{f}(0) = \frac{\delta}{2\pi},\quad\widehat{f}(n) = \frac{1 - \cos(n\delta)}{\delta \pi n^2}. \]
    %
    Thus we obtain an expansion
    %
    \[ f(x) = \frac{\delta}{2\pi} + \sum_{n \neq 0} \frac{1 - \cos(n\delta)}{\delta \pi n^2} e_n(x) = \frac{\delta}{2 \pi} + 2 \sum_{n = 1}^\infty \frac{1 - \cos(n\delta)}{\delta \pi n^2} \cos(nx). \]
    %
    This sum also converges absolutely and uniformly on the entire real line.
\end{example}

\begin{example}
    Consider the characteristic function
    %
    \[ \chi_{(a,b)}(x) = \begin{cases} 1 & : x \in (a,b), \\ 0 & : x \not \in (a,b), \end{cases} \]
    %
    for $(a,b) \subset [-\pi,\pi]$. Then
    %
    \[ \widehat{\chi}_{(a,b)}(n) = \frac{1}{2\pi} \int_a^b e_n(-x) = \frac{e_n(-a) - e_n(-b)}{2\pi i n}. \]
    %
    Hence we may write
    %
    \begin{align*}
        \chi_{(a,b)}(x) &= \frac{b-a}{2\pi} + \sum_{n \neq 0} \frac{e_n(-a) - e_n(-b)}{2 \pi i n} e_n(x)\\
        &= \frac{b-a}{2\pi} + \sum_{n = 1}^\infty \frac{\sin(nb) - \sin(na)}{\pi n} \cos(nx) + \frac{\cos(na) - \cos(nb)}{\pi n} \sin(nx).
    \end{align*}
    %
    This sum does not converge absolutely for any value of $x$ (except when $a$ and $b$ are chosen trivially). To see this, note that
    %
    \[ \left|\frac{e_n(-b) - e_n(-a)}{2 \pi n}\right| = \left| \frac{1 - e_n(b-a)}{2 \pi n} \right| \geq \left| \frac{\sin(n(b-a))}{2 \pi n} \right|, \]
    %
    so that it suffices to show $\sum |\sin(nx)| n^{-1} = \infty$ for every $x \not \in \pi \ZZ$. This follows because the values of $|\sin(nx)|$ are often large, so that we may apply the divergence of $\sum n^{-1}$. First, assume $x \in (0,\pi/2)$. If
    %
    \[ m \pi - x/2 < nx < m \pi + x/2 \]
    %
    for some $m \in \ZZ$, then
    %
    \[ m \pi + x/2 < (n+1)x < m \pi + 3x/2 < (m+1) \pi - x/2. \]
    %
    Thus if $nx \in (-x/2,x/2) + \pi \ZZ$, $(n+1)x \not \in (-x/2,x/2) + \pi \ZZ$. For $y$ outside of $(-x/2,x/2) + \pi \ZZ$, we have $|\sin(y)| > |\sin(x/2)|$, and therefore for any $n$,
    %
    \[ \frac{|sin(nx)|}{n} + \frac{|\sin((n+1)x)|}{n+1} > \frac{|\sin(x/2)|}{n+1}. \]
    %
    This means
    %
    \begin{align*}
        \sum_{n = 1}^\infty \frac{|\sin(nx)|}{n} &= \sum_{n = 1}^\infty \frac{|\sin(2nx)|}{2n} + \frac{|\sin((2n+1)x)|}{2n+1}\\
        &> |\sin(x/2)| \sum_{n = 1}^\infty \frac{1}{2n+1} = \infty
    \end{align*}
    %
    In general, we may replace $x$ with $x - k \pi$, with no effect to the values of the sum, so we may assume $0 < x < \pi$. If $\pi/2 < x < \pi$, then
    %
    \[ \sin(nx) = \sin(n(\pi - x)), \]
    %
    and $0 < \pi - x < \pi/2$, completing the proof, except when $x = \pi$, in which case
    %
    \[ \sum_{n = 1}^\infty \left| \frac{1 - e_n(\pi)}{2 \pi n} \right| = \sum_{n\ \text{even}} \left| \frac{1}{\pi n} \right| = \infty. \]
    %
    Thus the convergence of a Fourier series need not be absolute.
\end{example}

\begin{comment}
\begin{example}
    We can often find formulas for certain Fourier summations from taking the corresponding power series. This is because if we set $z = e^{it}$, then
    %
    \[ \sum_{n = -\infty}^\infty a_n e^{nit} = \sum_{n = -\infty}^\infty a_n z^n \]
    %
    becomes a Laurent series in $z$. For instance, we have a power series expansion
    %
    \[ \log \left( \frac{1}{1-x} \right) = \sum_{k = 1}^\infty \frac{z^k}{k}. \]
    %
    This converges pointwise for every $z \in \mathbf{D}$ but $z = 1$. Thus for $x \not \in 2 \pi \ZZ$,
    %
    \begin{align*}
        \sum_{k = 1}^\infty \frac{\cos(kx)}{k} &= \Re \left( \log \left( \frac{1}{1 - e^{ix}} \right) \right) = -\frac{1}{2} \log(2 - 2\cos(x)),\\
        \sum_{k = 1}^\infty \frac{\sin(kx)}{k} &= \Im \left( \log \left( \frac{1}{1 - e^{ix}} \right) \right) = \arctan \left( \frac{\sin(x)}{1 - \cos(x)} \right).
    \end{align*}
    %
    Here we agree that $\arctan(\pm \infty) = \pm \pi/2$. One can check that, indeed, the Fourier series of these two functions corresponds precisely to these summations. If a power series' radius of convergence exceeds $1$, then it is likely that the corresponding Fourier series taken on the circle will be pleasant, whereas if the power series' radius is equal to $1$, we can expect nasty behaviour on the boundary, which actually works in our benefit because it enables us to represent more pathological functions by means of a Fourier series.
\end{example}
\end{comment}



\chapter{Fourier Series}

Let us now focus on the theory of \emph{Fourier series} we introduced in the last chapter. We write $\TT = \RR / \ZZ$, so that a function $f: \TT \to \CC$ is a complex-valued periodic function on the real line. We then have a metric on $\TT$ given by setting $d(t,s) = |t - s|$, where $|t| = \min_{n \in \ZZ} |t + n|$ for $t \in \TT$. The Lebesgue measure on $\RR$ induces a natural Borel measure on $\TT$, such that for any periodic function $f: \TT \to \CC$,
%
\[ \int_{\TT} f(t)\; dt = \int_0^1 f(t)\; dt. \]
%
It will also be of interest to consider the higher dimensional torii $\TT^d = \RR^d / \ZZ^d$, which naturally has the induced product metric and measure from $\TT$. For each $f \in L^1(\TT^d)$, we associate the \emph{formal trigonometric series}
%
\[ \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot t} \]
%
where for each $n \in \ZZ^d$,
%
\[ \widehat{f}(n) = \int_{\TT^d} f(t) e^{-2\pi i n \cdot t}\; dt. \]
%
If the sequence $\{ \widehat{f}(n) : n \in \ZZ^d \}$ is absolutely summable, then one can interpret the formal trigonometric series nonformally as an infinite series, and we would then hope that for each $t \in \TT^d$,
%
\[ f(t) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n t}. \]
%
It turns out that, under the assumption of absolute summability, this equation does hold provided $f$ is a continuous function on $\TT^d$. We will eventually see that the condition that the Fourier series of $f$ is absolutely summable under the assumption that $f \in C^\infty(\TT^d)$. We will be able to prove these facts immediately after we prove some basic symmetry properties of the Fourier series.

\section{Basic Properties of Fourier Series}

One of the most important properties of the Fourier series is that the coefficients are controlled by reasonable transformations. A basic, but unappreciated property of the Fourier transform is \emph{linearity}: For any two functions $f$ and $g$, if $h = f + g$, then $\widehat{h} = \widehat{f} + \widehat{g}$. Linearity is \emph{essential} to most methods in this book; many problems about nonlinear transforms remain unsolved. The Fourier series is also stable under various transformations which occur in analysis, which makes the Fourier series tractable to analyze, and therefore useful. We summarize these properties here:
%
\begin{itemize}
    \item Given $f \in L^1(\TT^d)$, define $\text{Conj} f, \text{Ref} f \in L^1(\TT^d)$ by setting $\text{Conj}f(x) = \overline{f(x)}$ and $\text{Ref} f(x) = f(-x)$. Then
    %
    \[ \widehat{\text{Conj} f} = (\text{Conj} \circ \text{Ref}) \widehat{f}. \]
    %
    and
    %
    \[ \widehat{\text{Ref} f} = \text{Ref} \widehat{f}. \]
    %
    As a corollary, if $f$ is real-valued, then
    %
    \[ \widehat{f} = \widehat{\text{Conj} f} = (\text{Conj} \circ \text{Ref}) \widehat{f} \]
    %
    In other words, for each $n \in \ZZ^d$,
    %
    \[ \widehat{f}(n) = \overline{\widehat{f}(-n)}. \]
    %
    It also follows from the reflection symmetry that if $f \in L^1(\TT^d)$ is odd, then $\widehat{f}$ is odd, and if $f \in L^1(\TT^d)$ is even, $\widehat{f}$ is even.

    \item For each $s \in \RR^d$, and $m \in \ZZ^d$, and any $f \in L^1(\TT^d)$, define the translation and frequency modulation operators $\text{Trans}_s$ and $\text{Mod}_m$ by setting
    %
    \[ (\text{Trans}_s f)(t) = f(t - s) \quad\text{and}\quad (\text{Mod}_m f)(t) = e_m(t) f(t). \]

    %
    Similarily, for each function $C: \ZZ^d \to \CC$, for each $m \in \ZZ^d$ and $\xi \in \RR$, define
    %
    \[ (\text{Trans}_m C)(n) = C(n - m) \quad\text{and}\quad (\text{Mod}_\xi C)(n) = e_\xi(n) C(n). \]
    %
    Then for any $f \in L^1(\TT^d)$, $\widehat{\text{Trans}_s f} = \text{Mod}_{-s} \widehat{f}$, and $\widehat{\text{Mod}_m f} = \text{Trans}_{-m} \widehat{f}$.

    \item An easy integration by parts shows that if $f \in C^\infty(\TT^d)$, then for any $k \in \{ 1, \dots, d \}$,
    %
    \[ \widehat{D^k f}(n) = 2 \pi i n_k \widehat{f}(n) \]
    %
    for each $n \in \ZZ^d$. The proof follows from an easy integration by parts, so the claim is actually true for any $f \in L^1(\TT^d)$ with a weak derivative $D^k f$ in $L^1(\TT^d)$. Iterating this argument shows that, assuming the required weak derivatives exist,
    %
    \[ \widehat{D^\alpha f}(n) = (2 \pi i n)^\alpha \widehat{f}(n). \]
\end{itemize}

\begin{remark}
    We note that if $f \in L^1(\TT)$ is even, then $\widehat{f}$ is even, so formally
    %
    \[ f(t) \sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) + e_{-m}(t)] \sim \widehat{f}(0) + 2 \sum_{m = 1}^\infty \widehat{f}(m) \cos(mt). \]
    %
    Moreover,
    %
    \[ \widehat{f}(m) = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) \cos(mt)\; dt \]
    %
    If $f$ is an odd function, then the fact that $\widehat{f}$ is odd implies formally that
    %
    \[ f(t) \sim \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) - e_{-m}(t)] = 2i \sum_{m = 1}^\infty \widehat{f}(m) \sin(mt). \]
    %
    Thus we get a sine expansion, and moreover,
    %
    \[ \widehat{f}(m) = \frac{1}{2\pi i} \int_{-\pi}^\pi f(t) \sin(mt)\; dt. \]
    %
    This is one way to reduce the study of complex exponentials back to the study of sines and cosines, since every function can be written as a sum of an even and an odd function.
\end{remark}

\section{Unique Representation}

To study the convergence properties of Fourier series, we begin by studying whether a function is uniquely determined by it's Fourier coefficients, which would be certainly true if the Fourier series held. However, such a statement is clearly cannot be true for all $f \in L^1(\TT^d)$, since the Fourier coefficients of a function depend only on the \emph{distributional} properties of $f$, i.e. those that can be obtained through integration. In particular, if two integrable functions $f$ and $g$ agree on a set of measure zero, then they have the same Fourier coeffients depends only on the equivalence class of $f$ in $L^1(\TT^d)$, with functions identified if they are equal almost everywhere. Nonetheless, if $f \in C(\TT^d)$ then there is no way to edit $f$ on a set of measure zero while preserving continuity. Thus we can hope for unique Fourier coefficients in the setting of continuous functions.

\begin{theorem}
    Suppose $f \in L^1(\TT^d)$. If $\widehat{f}(n) = 0$ for all $n \in \ZZ^d$, then $f$ vanishes at all it's continuity points.
\end{theorem}
\begin{proof}
    It suffices to prove that if $f \in L^1(\TT^d)$ is continuous at the origin, then $f(0) = 0$. We treat the real-valued case first. For every trigonometric polynomial $g(x) = \sum a_n e_n(-x)$, we have
    %
    \[ \int_{\TT} f(x) g(x) dx = \sum a_n \widehat{f}(n) = 0. \]
    %
    Suppose that $f$ is continuous at zero, and assume without loss of generality that $f(0) > 0$. Pick $\delta > 0$ such that if $|x| \leq \delta$, $f(x) > f(0)/2$. Consider the trigonometric polynomial
    %
    \[ g(x) = \prod_{k = 1}^d [\varepsilon + \cos(2 \pi x_k)] = \prod_{k = 1}^d \left[ \varepsilon + \frac{e^{2 \pi i x_k} + e^{- 2 \pi i x_k}}{2} \right], \]
    % (1 + e)^{d-1}(e + cos(2 pi delta))
    and where $\varepsilon > 0$ is small enough that if $|x| \geq \delta$, then $g(x) \leq B < 1$. We can then choose $0 < \eta < \delta$ such that if $|x| < \eta$, $g(x) \geq A > 1$. Finally, if $\delta$ is sufficiently small, we also have $g(x) > 0$ if $0 \leq |x| \leq \delta$. The series of trigonometric polynomials $g_n(x) = g(x)^n$ satisfy
    %
    \begin{align*}
        \left| \int_{\TT^d} g_n(x) f(x) dx \right| &\geq \int_{|x| \leq \delta} g_n(x) f(x) dx - \left| \int_{|x| \geq \delta} g_n(x) f(x) dx \right|.
    \end{align*}
    %
    H\"{o}lder's inequality guarantees that as $n \to \infty$,
    %
    \[ \left| \int_{|x| \geq \delta} g_n(x) f(x) dx \right| \lesssim B^n. \]
    %
    On the other hand,
    %
    \[ \left| \int_{|x| \leq \delta} g_n(x) f(x) dx \right| \geq \int_{|x| < \delta/2} g_n(x) f(x) \gtrsim A^n. \]
    %
    Thus we conclude
    %
    \[ 0 = \left| \int_0^1 g_n(x) f(x) dx \right| \gtrsim A^n - B^n. \]
    %
    For suitably large values of $n$, the right hand side is positive, whereas the left hand side is zero, which is impossible. By contradiction, we conclude $f(0) = 0$. In general, if $f$ is complex valued, then we may write $f = u + iv$, where
    %
    \[ u(x) = \frac{f(x) + \overline{f(x)}}{2}\ \ \ \ v(x) = \frac{f(x) - \overline{f(x)}}{2i}. \]
    %
    The Fourier coefficients of $\overline{f}$ all vanish, because the coefficients of $f$ vanish, and so we conclude the coefficients of $u$ and $v$ vanish. $f$ is continuous at $x$ if and only if $u$ and $v$ are continuous at $x$, so we can apply the real-valued case to complete the proof in the case of complex values.
\end{proof}

\begin{corollary}
    If $f,g \in C(\TT^d)$ and $\widehat{f} = \widehat{g}$, then $f = g$.
\end{corollary}
\begin{proof}
    Then $f - g$ is continuous with vanishing Fourier coefficients.
\end{proof}

\begin{corollary}
    If $f \in C(\TT^d)$ and $\widehat{f} \in L^1(\ZZ^d)$, then for each $x \in \ZZ^d$,
    %
    \[ f(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x} \]
\end{corollary}
\begin{proof}
    Since $\widehat{f} \in L^1(\ZZ^d)$, the sum
    %
    \[ g(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x} \]
    %
    converges \emph{uniformly}. In particular, this implies that $g$ is a continuous function. Moreover, it allows us to conclude that $\widehat{g}(n) = \widehat{f}(n)$ for each $n \in \ZZ$. But this means $f = g$.
\end{proof}

In the next section we will show that if $f \in C^m(\TT^d)$, then
%
\[ \widehat{f}(n) = O( \langle n \rangle^{-m} ). \]
%
In particular, if $m \geq d + 1$, then the Fourier series of $f$ is integrable. Moreover, if $f \in C^\infty(\TT)$, then using the Fourier series equation for the derivative of a function, for each multi-index $\alpha$, we conclude that for all $x \in \RR^d$
%
\[ (D^\alpha f)(x) = \sum_{n \in \ZZ^d} (2 \pi i n)^\alpha \widehat{f}(n) e^{2 \pi i n \cdot x}. \]
%
On the other hand, suppose $\{ a_n : n \in \ZZ^d \}$ such that $|a_n| \lesssim_m \langle n \rangle^{-m}$ for all $m > 0$, then the infinite sum
%
\[ \sum_{n \in \ZZ^d} a_n e^{2 \pi i n \cdot x} \]
%
and all it's derivatives converge uniformly to an infinitely differentiable function with the Fourier coefficients $\{ a_n \}$. Thus there is a perfect duality between infinitely differentiable functions and arbitrarily fast decaying sequences of integers. In more advanced contexts, like distribution theory, this duality is very useful for studying the Fourier transform in a much more general setting.

\section{Quantitative Bounds on Fourier Coefficients}

There are various reasons why one would not be completely satisfied by the convergence result above. Unlike with the case of a Taylor series, the Fourier series can be applied to a much more general family of situations. There is no hope of the Fourier series being integrable \emph{and} obtaining a pointwise convergence result unless we are dealing with continuous functions, because any absolutely summable trigonometric series sums up to a continuous function. Thus we must analyze non-integrable families of coefficients if we are to obtain deeper convergence properties of the Fourier series for non-continuous functions.

On the other hand, in practical contexts, one might argue that the functions dealt with can be assumed arbitrarily smooth, so the picture established in the last section seems rather complete. However, even if this is true it is still important to study more \emph{qualitative questions} about the Fourier series. Instead of taking the infinite Fourier series, we take a finite sum. For a function $f \in L^1(\TT)$, it is most natural to consider the partial sums
%
\[ S_N f(x) = \sum_{n = -N}^N \widehat{f}(n) e^{2 \pi i n x}. \]
%
In higher dimensions, no canonical `cutoff' exists. Two possible options are \emph{spherical summation}
%
\[ \sum_{|n| \leq N} \widehat{f}(n) e_n \]
%
and \emph{square summation}
%
\[ \sum_{n_1, \dots, n_d = -N}^N \widehat{f}(n) e_n. \]
%
We will see that these two types of summations can have subtle differences in the higher dimensional theory. Right now, we consider a family of operators that contain both of these operators; we consider an increasing family of sets $\{ E_N \}$ in $\ZZ^d$ with $\lim_{N \to \infty} E_N = \ZZ^d$, and we then define
%
\[ S_N f = \sum_{n \in E_N} \widehat{f}(n) e_n \]
%
for $f \in L^1(\TT^d)$. A natural question now is whether $S_N f$ is \emph{qualitatively similar} to the function $f$ globally rather than just pointwise. The most natural way to measure how similar two functions are from the perspective of analysis is via measuring the differences with respect to a suitable \emph{norm}. For instance, under the assumptions of the last section, we not only get pointwise convergence at each point, but \emph{uniform convergence}.

%If $E_N$ is a symmetric set for each $N$, then $S_N f$ will be real-valued if $f$ is real-valued, but this isn't of particular importance to us in the sequel.

\begin{theorem}
    Suppose $f \in C(\TT^d)$ and $\widehat{f} \in L^1(\ZZ^d)$. Then
    %
    \[ \lim_{N \to \infty} \| S_N f - f \|_{L^\infty(\RR)}. \]
    %
    In other words, $S_N f$ converges \emph{uniformly} to $f$ instead of pointwise.
\end{theorem}
\begin{proof}
    We know that for each $x \in \TT^d$,
    %
    \[ f(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x}. \]
    %
    A simple application of the triangle inequality shows that
    %
    \[ |f(x) - S_N f(x)| \leq \sum_{n \not \in E_N} |\widehat{f}(n)|. \]
    %
    Since the Fourier coefficients are absolutely summable, for each $\varepsilon > 0$, there is $N_0$ such that for $N \geq N_0$,
    %
    \[ \sum_{N \not \in E_N} |\widehat{f}(n)| \leq \varepsilon, \]
    %
    and thus $\| f - S_N f \|_{L^\infty(\TT^d)} \leq \varepsilon$.
\end{proof}

Another question one might ask is the \emph{rate of convergence} of the function $f$. In this situation, things are quite bad even in the setting of the previous setting. For general elements of $C(\TT)$ with integrable Fourier coefficients, the convergence of $\| f - S_N f \|_{L^\infty(\TT^d)}$ as $N \to \infty$ can be \emph{as slow as any convergent sequence}.

\begin{theorem}
    Let $\{ a_n : n \in \ZZ^d \}$ be any sequence of coefficients with $\lim_{|n| \to \infty} a_n = 0$. Then there exists $f \in C(\TT^d)$ such that $\widehat{f} \in L^1(\ZZ^d)$, but $\widehat{f}(n) = a_n$ for infinitely many $n \in \ZZ^d$.
\end{theorem}
\begin{proof}
    For each $1 \leq k < \infty$, pick $n_k$ such that $|a_{n_k}| \leq 1/2^k$ and such that the family $\{ n_k \}$ is distinct. Then define
    %
    \[ f(x) = \sum_{k = 1}^\infty a_{n_k} e^{2 \pi i n_k \cdot x}. \]
    %
    The absolute convergence of the right hand side shows $f \in C(\TT^d)$, and that $\widehat{f}(n_k) = a_{n_k}$ for each $1 \leq k \leq \infty$.
\end{proof}

A natural question is whether we \emph{can} get quantitative convergence results for functions under additional assumptions. For instance, do we get faster convergence rates if $\| f \|_{L^\infty(\TT^d)}$ is small (i.e. we have uniform control on the magnitude of $f$) rather than just if $\| f \|_{L^1(\TT^d)}$ is small.

\begin{example}
    If we consider a square wave $\chi_I$ for some interval $I$, then the techniques of the following section allow us to prove that
    %
    \[ \| \chi_I - S_N \chi_I \|_{L^2(\TT)} \sim 1/\sqrt{N}, \]
    %
    independently of $I$. This means that if we want to simulate square waves with a musical instrument up to some square mean error $\varepsilon$, then we will need about $1/\varepsilon^2$ different notes to represent the sound accurately. Thus a piano with 88 keys can only approximate square waves slightly better than a keyboard with 20 keys. If $f \in C^{m+1}(\TT^d)$, then we will see
    %
    \[ \| f - S_N f \|_{L^2(\TT)} \lesssim 1/N^{m/2}, \]
    %
    so we require significantly less notes to simulate this sound, i.e. $\varepsilon^{-2/m}$. In this case a piano can simulate these sounds much more accurately.
\end{example}

Another question is whether $S_N f$ is stable under pertubations. For instance, if we replace $f$ with a function $g$ close to $f$ the original function, is $S_N f$ close to $S_N g$? This is of interest in many partical applications, where error terms are inherently present. If an operator is unstable under pertubations that it is unpractical to use it in an application to a real life situation. Again, the best way to measure the error terms are using an appropriate norm space.

These examples show that working with certain norms is an important way to understand the deeper properties of the Fourier series. It is an important property of norm spaces that most questions are equivalent to questions in the \emph{completion} of that norm space. For instance, if one wants to use the norm $\| \cdot \|_{L^1(\TT^d)}$ to analyze the space $C(\TT^d)$, most questions are equivalent to questions about the completion of $C(\TT^d)$, i.e. the space $L^1(\TT^d)$ of all integrable functions. Moreover, working in the completion of a space enables us to employ many functional analysis arguments which make working with the more general space essential to many modern arguments. Despite the fact that we will be analyzing functions that one never deals with in `practical situations', using these functions is a useful tool to determine the quantitative behaviour of more regular functions with respect to a norm.

\section{Boundedness of Partial Sums}

One initial equation which might summarize how well behaved the Fourier series is with respect to suitable norms would be to obtain an estimate of the form $\smash{\| \widehat{f} \|_{L^q(\ZZ^d)} \lesssim \| f \|_{L^p(\TT^d)}}$ for particular values of $p$ and $q$. This does not explicitly answer a question about convergence, but still shows that the Fourier series is stable under small pertubations in the norm on $L^p(\TT^d)$. The first inequality we give is trivial, but tight for general $L^1$ functions, i.e. for the functions $f(t) = e_n(t)$.

\begin{theorem}
    For any $f \in L^1(\TT^d)$, $\| \widehat{f} \|_{L^\infty(\TT^d)} \leq \| f \|_{L^1(\TT^d)}$.
\end{theorem}
\begin{proof}
    We just take absolute values into the oscillatory integral defining the Fourier coefficients, calculating that for any $n \in \ZZ^d$,
    %
    \[ |\widehat{f}(n)| = \left| \int_{\TT^d} f(t) \overline{e_n(t)} \right| \leq \int_{\TT^d} |f(t)| = \| f \|_{L^1(\TT^d)}, \]
    %
    which was the required bound.
\end{proof}

This proof doesn't really take any deep features of the Fourier coefficients. The same bound holds for any integral
%
\[ \int_{\TT} f(t) K(t)\; dt, \]
%
where $|K(t)| \leq 1$ for all $t$. But the bound is still tight, which might be explained by the fact that the Fourier series gives oscillatory information which is not immediately present in the $L^1$ norms of the phase spaces, other than by taking a naive absolute bound into the $L^1$ norm. The only $L^p$ norm where we can get a completely satisfactory bound is for $p = 2$, where we can use Hilbert space techniques; this should be expected to be very useful since orthogonality was implicitly used to define the Fourier series.

\begin{theorem}
    For any function $f \in L^2(\TT^d)$, $\| \widehat{f} \|_{L^2(\ZZ^d)} = \| f \|_{L^2(\TT^d)}$.
\end{theorem}
\begin{proof}
    With respect to the normalized inner product on the space $L^2(\TT^d)$,the calculations of the last chapter tell us that the exponentials $\{ e_n : n \in \ZZ^d \}$ are an orthonormal family of functions, in the sense that for distinct pair $n,m \in \ZZ^d$, $(e_n,e_m) = 0$ and $(e_n,e_n) = 1$. Since $\smash{\widehat{f}(n) = (f,e_n)}$, we apply Bessel's inequality to conclude
    %
    \[ \| \widehat{f} \|_{L^2(\ZZ^d)} \leq \| f \|_{L^2(\TT^d)}. \]
    %
    The exponentials $\{ e_n \}$ are actually an orthonormal basis for $L^2(\TT^d)$; there are many ways to see this (the Stone-Weirstrass theorem, for instance). The most convenient way for us will be to note that if $f \in C^\infty(\TT^d)$, then we have shown that if $(f,e_n) = 0$ for all $n \in \ZZ^d$, then $f = 0$. But $S_N f$ converges to $f$ in $L^2(\TT^d)$ (it actually converges uniformly), and so
    %
    \begin{align*}
        \| f \|_{L^2(\TT^d)} &= \lim_{N \to \infty} \| S_N f \|_{L^2(\TT^d)} = \lim_{N \to \infty} \left( \sum_{n \in E_N} |\widehat{f}(n)|^2 \right)^{1/2}\\
        &= \left( \sum_{n \in \ZZ^d} |\widehat{f}(n)|^2 \right)^{1/2} = \| \widehat{f} \|_{L^2(\ZZ^d)}.
    \end{align*}
    %
    This is Parseval's inequality for $C^\infty(\TT^d)$. Now a density argument will give the general result. If $f \in L^2(\TT^d)$ is a general element, then for each $\varepsilon > 0$ we can find $f_\varepsilon \in C^\infty(\TT^d)$ such that $\| f_\varepsilon - f \|_{L^2(\TT^d)} \leq \varepsilon$. Then Bessel's inequality
    %
    \[ | \| f \|_{L^2(\TT^d)} - \| \widehat{f} \|_{L^2(\TT^d)} | \leq | \| f \|_{L^2(\TT^d)} - \| f_\varepsilon \|_{L^2(\TT^d)}| + | \| \widehat{f_\varepsilon} \|_{L^2(\ZZ^d)} - \| \widehat{f} \|_{L^2(\ZZ^d)}| \leq 2 \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the proof.
\end{proof}

This equality makes the Hilbert space $L^2(\TT^d)$ often the best place to understand Fourier expansion techniques, and general results are often achieved by reduction to this well understood case. For instance, the inequality above, combined with the trivial inequality, is easily interpolated using the Riesz-Thorin technique to give the Hausdorff Young inequality.

\begin{theorem}
    If $1 \leq p \leq 2$, and $f \in L^p(\TT^d)$, then $\| \widehat{f} \|_{L^{p^*}(\ZZ^d)} \leq \| f \|_{L^p(\TT^d)}$.
\end{theorem}

It might be surprising to note that the Hausdorff Young inequality essentially completes the bounds on the Fourier series with respect to the $L^p$ norms. There is no interesting result one can obtain for $p > 2$ other than the obvious inequality
%
\[ \| \widehat{f} \|_{L^2(\ZZ^d)} \leq \| f \|_{L^2(\TT^d)} \leq \| f \|_{L^p(\TT^d)}. \]
%
Thus we can control the magnitude of the Fourier coefficients in terms of the width of the original function, but we are limited in our ability to control the width of the Fourier coefficients in terms of the magnitudes of the original function. This makes sense, because the $L^p$ norm of $f$ measures fairly different aspects of the function than the $L^q$ norm of the Fourier transform of $f$. It is only in the case of the $L^2$ norm where results are precise, and where $p$ is small that we can take a trivial bound, that we get an inequality like the Hausdorff Young result.

\section{Asymptotic Decay of Fourier Series}

The next result, known as Riemann-Lebesgue lemma, shows that the Fourier series of any integrable function decays, albeit arbitrarily slowly. The proof we give is an instance of an important principle in Functional analysis that we will use over and over again. Suppose for each $n$, we have a bounded operator $T_n: X \to Y$ between norm spaces, and we want to show that for each $x \in X$, $\lim_{n \to \infty} T_n(x) = T(x)$, where $T$ is another bounded operator. Suppose there is a dense set $X_0 \subset X$ such that for each $x_0 \in X_0$, $\lim_{n \to \infty} T_n(x_0) = T(x_0)$, and the family of operators $\{ T_n \}$ are {\it uniformly} bounded in operator norm. Then for any $x \in X$,
%
\begin{align*}
    \| T_n(x) - T(x) \| &\leq \| T_n(x) - T_n(x_0) \| + \| T_n(x_0) - T(x_0) \| + \| T(x_0) - T(x) \|.
\end{align*}
%
If we choose $x_0$ such that $\| x - x_0 \| \leq \varepsilon$, then for $n$ large enough we find that $\| T_n(x) - T(x) \| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, this means that $T_n(x) \to T(x)$ as $n \to \infty$. If we are working in a Banach space, the uniform boundedness says obtaining a uniform operator norm bound on $\{ T_n \}$ is the \emph{only} way to obtain this convergence.

The advantage of the principle is that it is suitably abstract, and can thus be used very flexibly. But the disadvantage is that it is a very soft analytical argument, and cannot be used to obtain results on the rate of convergence of $T_n(x)$ to $T(x)$. Here is a simple application.

\begin{lemma}[Riemann-Lebesgue]
    If $f \in L^1(\TT^d)$, then $\widehat{f}(n) \to 0$ as $|n| \to \infty$.
\end{lemma}
\begin{proof}
    We claim the lemma is true for the characteristic function $\chi_I$ of a cube $I$. If $I = [a_1,b_1] \times \dots \times [a_d,b_d]$, then it is simple to calculate that
    %
    \[ \widehat{\chi_I}(n) = \prod_{k = 1}^d \frac{e_n(-b_k) - e_n(-a_k)}{-in} = O(1/n) \]
    %
    By linearity of the integral, the Fourier transform of any step function vanishes at $\infty$. But if
    %
    \[ \Lambda_n(f) = \widehat{f}(n), \]
    %
    then
    %
    \[ |\Lambda_n f| \leq \| \widehat{f} \|_{L^\infty(\TT)} \leq \| f \|_{L^1(\TT)}, \]
    %
    which shows that the sequence of functionals $\{ \Lambda_n \}$ are uniformly bounded as linear functions on $L^1(\TT^d)$. Since $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for any step function $f$, and the step functions are dense in $L^1(\TT^d)$, we conclude that
    %
    \[ \lim_{|n| \to \infty} \Lambda_n(f) = 0 \]
    %
    for all $f \in L^1(\TT^d)$.
\end{proof}

Even though the Fourier series of any step function decays at a rate $O(1/n)$, it is {\it not} true that a general Fourier series decays at a rate of $O(1/n)$. For instance, we have shown that there are continuous functions whose Fourier decay is arbitrarily slow. This is precisely the penalty for using a soft type analytical argument. Nonetheless, for smoother functions, we can obtain a uniform decay rate, which is our goal in the next section.

\section{Smoothness and Decay}

The next theorem obtains sharper bounds for smoother functions, and is an instance of a general phenomenon relating the duality because decay and smoothness in phase and frequency space.

\begin{theorem}
    If $f \in C^m(\TT^d)$, then for each $n \in \ZZ^d$,
    %
    \[ |\widehat{f}(n)| \lesssim_{d,m} |n|^{-m} \max_{1 \leq i \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}. \]
\end{theorem}
\begin{proof}
    We have
    %
    \[ \widehat{\partial_i^m f}(\xi) = (2 \pi i \xi_i)^m \widehat{f}(\xi). \]
    %
    Thus
    %
    \[ |\widehat{f}(\xi)| \leq \frac{|\partial_i^m f|(\xi)|}{(2\pi |\xi_i|)^m} \leq \frac{\| \partial_i^m f \|_{L^1(\TT^d)}}{(2 \pi |\xi_i|)^m}. \]
    %
    But taking infima over all $1 \leq i \leq d$, we find
    %
    \[ |\widehat{f}(\xi)| \leq \frac{\max_{1 \leq k \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}}{[2 \pi \max |\xi_i| |]^m} \leq \frac{d^{1/2}}{(2\pi)^m} \frac{\max_{1 \leq i \leq d} \| \partial_i^m f \|_{L^1(\TT^d)}}{|\xi|^m}. \qedhere \]
\end{proof}

On the other hand, if $|\widehat{f}(n)| \lesssim 1/|n|^{d+m}$, it is easy to see from the pointwise convergence of the Fourier series that $f \in C^m(\RR^d)$. Note, however, that the introduction of the factor of $d$ here gives a large gap between obtaining decay from smoothness and smoothness and decay when $d$ is large, which is often a tricky problem to control when studying problems using harmonic analysis.

If $0 < \alpha < 1$, we say a function $f$ is \emph{H\"{o}lder continuous} of order $\alpha$ if there exists a constant $A$ such that $|f(x + h) - f(x)| \leq A |h|^\alpha$ for all $x, h \in \TT^d$. We define
%
\[ \| f \|_{C^{0,\alpha}(\TT^d)} = \sup_{x,h \in \TT^d} \frac{|f(x + h) - f(x)}{|h|^\alpha}. \]
%
Then the space $C^{0,\alpha}(\TT^d)$ of all functions satisfying a H\"{o}lder condition of order $\alpha$ forms a Banach space.

\begin{theorem}
    If $f \in C^{0,\alpha}(\TT^d)$, then $|\widehat{f}(n)| \lesssim_d \| f \|_{C^{0,\alpha}(\TT^d)} |n|^{-\alpha}$ for all $n \in \ZZ^d$.
\end{theorem}
\begin{proof}
    Fix $n \in \ZZ^d$. Then there is some $k \in \{ 1, \dots, d \}$ such that $|n_k| \gtrsim_d |n|$.  We calculate that by periodicity,
    %
    \[ \widehat{f}(n) = - \int_{\TT^d} f(x + e_k/n_k) \overline{e_n(x)}\; dx, \]
    %
    so
    %
    \[ \widehat{f}(n) = \frac{1}{2} \int_{\TT^d} [f(x) - f(x + e_k/n_k)] \overline{e_n(x)}\; dx. \]
    %
    Thus taking in absolute values and applying H\"{o}lder continuity gives
    %
    \[ |\widehat{f}(n)| \leq \frac{\| f \|_{C^{0,\alpha}(\TT^d)}}{2 |n_k|^\alpha} \lesssim_d \frac{\| f \|_{C^{0,\alpha}(\TT^d)}}{|n|^\alpha}. \qedhere \]
\end{proof}

We also have a weaker converse statement, which shows $f$ is H\"{o}lder continuous if it's Fourier series decays fast enough.

\begin{theorem}
    Fix $f \in L^1(\TT^d)$. Then
    %
    \[ \| f \|_{C^{0,\alpha}(\TT^d)} \lesssim_d \sup_{n \in \ZZ^d} |n|^{d + \alpha} |\widehat{f}(n)|. \]
\end{theorem}
\begin{proof}
    Let $A = \sup_{n \in \ZZ^d} |n|^{d+\alpha} |\widehat{f}(n)|$. Then $\widehat{f} \in L^1(\ZZ^d)$, so the Fourier inversion formula implies that for almost every $x \in \TT^d$,
    %
    \[ f(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x}. \]
    %
    Then for $|h| < 1$,
    %
    \[ f(x + h) - f(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x} \left( e^{2 \pi i n \cdot h} - 1 \right). \]
    %
    Now $|e^{2 \pi i n \cdot h} - 1| \lesssim \min(1, |n| |h|)$, so
    %
    \begin{align*}
        \left| \sum_{ |n| \leq 1/|h|} \widehat{f}(n) e^{2 \pi i n \cdot x} \left( e^{2 \pi i n \cdot h} - 1 \right) \right| &\leq A|h| \sum_{|n| \leq 1/|h|} \frac{1}{|n|^{d - 1 + \alpha}} \lesssim_d A |h| |h|^{\alpha - 1} = A |h|^\alpha
    \end{align*}
    %
    and
    %
    \begin{align*}
        \left| \sum_{ |n| \geq 1/|h|} \widehat{f}(n) e^{2 \pi i n \cdot x} \left( e^{2 \pi i n \cdot h} - 1 \right) \right| &\leq 2A \sum_{|n| \geq 1/|h|} 1/|n|^{d + \alpha}\\
        &\lesssim_d 2A |h|^\alpha.
    \end{align*}
    %
    Combining these two calculations shows that
    %
    \[ |f(x+h) - f(x)| \lesssim_d A |h|^\alpha,  \]
    %
    so $\| f \|_{C^{0,\alpha}(\TT^d)} \lesssim_d A$.
\end{proof}

\begin{remark}
    Suppose that $\mu$ is a finite Borel measure on $\TT^d$, for which we write $\mu \in M(\TT^d)$. Then one can define the Fourier series of $\mu$ by setting
    %
    \[ \widehat{\mu}(n) = \int_{\TT^d} e^{-2 \pi i n \cdot x} d\mu(x). \]
    %
    If $\mu$ is absolutely continuous with respect to the normalized Lebesgue measure on $\TT$, and $d\mu = f dx$, then $\widehat{\mu} = \widehat{f}$, so this is an extension of the Fourier series from integrable functions to finite measures. One can verify that
    %
    \[ \| \widehat{\mu} \|_{L^\infty(\ZZ^d)} \leq \| \mu \|_{M(\TT^d)}. \]
    %
    If $\delta$ is the Dirac delta measure at the origin, i.e. $\mu(E) = 1$ if $0 \in E$, and $\mu(E) = 0$ otherwise, then for all $n$,
    %
    \[ \widehat{\delta}(n) = 1. \]
    %
    Thus the Fourier series of $\delta$ has no decay at all. Once can view this as saying functions are `smoother' than measures, and therefore have a Fourier decay. Indeed, it is not too difficult to prove that a finite Borel measure $\mu$ on $\TT^d$ is absolutely continuous with respect to the Lebesgue measure if and only if
    %
    \[ \lim_{|y| \to 0} \int_{\RR^d} d|\mu(x + y) - \mu(x)| \to 0, \]
    %
    (we show that integrable functions satisfy this property in the next section) which shows that integrable functions are precisely the measures such that, in a certain sense, $\mu(x + y) \approx \mu(x)$ for small $y$.
\end{remark}

\section{Convolution and Kernel Methods}

The notion of the convolution of two functions $f$ and $g$ is a key tool in Fourier analysis, both as a way to regularize functions, and as an operator that transforms nicely when we take Fourier series. Given $f,g \in L^1(\TT^d)$, we define
%
\[ (f * g)(x) = \int_{\TT^d} f(y) g(x-y)\; day. \]
%
Thus we smear the values of $g$ with respect to a density function $f$.

\begin{lemma}
    For any $1 \leq p < \infty$, and $f \in L^p(\TT^d)$,
    %
    \[ \lim_{h \to 0} \text{Trans}_h f = f \]
    %
    in $L^p(\TT^d)$.
\end{lemma}
\begin{proof}
    If $f$ is $C^1(\TT^d)$, then $|f(x + h) - f(x)| \lesssim_f h$ uniformly in $x$, implying that $\| \text{Trans}_h f - f \|_{L^p(\TT^d)} \leq \| \text{Trans}_hf - f \|_{L^\infty(\TT^d)} \lesssim_f h$, and so $\text{Trans}_h f \to f$ in all the spaces $L^p(\TT^d)$. We have $\| \text{Trans}_h f \|_{L^p(\TT^d)} = \| f \|_{L^p(\TT^d)}$, so the operators $\{ \text{Trans}_h \}$ are uniformly bounded. Since $C^1(\TT^d)$ is dense in $L^p(\TT^d)$ for $1 \leq p < \infty$, we conclude that $\lim_{h \to 0} \text{Trans}_h f = f$ for all $f \in L^p(\TT^d)$.
\end{proof}

\begin{theorem}
    Convolution has the following properties:
    %
    \begin{itemize}
        \item If $f \in L^p(\TT^d)$ and $g \in L^q(\TT^d)$, for $1/p + 1/q = 1$, then $f * g$ is uniformly continuous.

        \item If $f \in L^p(\TT^d)$ and $g \in L^q(\TT^d)$, and if we define $r$ so that $1/r = 1/p + 1/q - 1$, with $1 \leq r \leq \infty$, then $f * g$ is well-defined by the convolution integral formula almost everywhere, and
        %
        \[ \| f * g \|_{L^r(\TT^d)} \leq \| f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}. \]
        %
        This is known as {\it Young's inequality} for convolutions.

        \item Convolution is a commutative, associative, bilinear operation.

        \item If $f,g \in L^1(\TT)$, then $\widehat{f * g} = \widehat{f} \widehat{g}$.

        \item If $f$ has a weak derivative $D^kf$ in $L^1(\TT^d)$, then $f * g$ has a weak derivative in $L^1(\TT^d)$, and $D^k(f * g) = D^k f * g$. Thus convolution is `additively smoothing'. In particular, if $f \in C^k(\TT^d)$ and $g \in C^l(\TT^d)$, then $f * g \in C^{k+l}(\TT^d)$.

        \item If $f$ is supported on $E \subset \TT^d$, and $g$ on $F \subset \TT^d$, then $f * g$ is supported on $E + F$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Suppose $f \in L^p(\TT^d)$, and $g \in L^q(\TT^d)$, then
    %
    \begin{align*}
        |(f * g)(t - h) - (f * g)(t)| &\leq \int_{\TT^d} |f(t-h-s) - f(t-s)| |g(s)|\; ds\\
        &\leq \| f_h - f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}.
    \end{align*}
    %
    The right hand side is a bound independent of $t$ and converges to zero as $h \to 0$, so $f * g$ is uniformly continuous. Applying H\"{o}lder's inequality again gives that $\| f * g \|_{L^\infty(\TT^d)} \leq \| f \|_{L^p(\TT^d)} \| g \|_{L^q(\TT^d)}$. If $f \in L^p(\TT^d)$, and $g \in L^1(\TT^d)$, we use Minkowski's inequality to conclude that
    %
    \begin{align*}
        \| f * g \|_{L^p(\TT^d)} &= \left( \int_{\TT^d} \left| \int_{\TT^d} f(t-s)g(s)\; ds \right|^p\; dt \right)^{1/p}\\
        &\leq \int_{\TT^d} \left( \int_{\TT^d} |f(t-s)g(s)|^p\; dt \right)^{1/p}\; ds\\
        &= \int_{\TT^d} g(s) \| f \|_{L^p(\TT^d)}\; ds = \| f \|_{L^p(\TT^d)} \| g \|_{L^1(\TT^d)}.
    \end{align*}
    %
    Thus $f * g$ is finite almost everywhere. The inequality also implies that
    %
    \[ \| f * g \|_{L^p(\TT^d)} \leq \| f \|_{L^1(\TT^d)} \| g \|_{L^p(\TT^d)} \]
    %
    if $f \in L^1(\TT^d)$, and $g \in L^p(\TT^d)$. But now implying Riesz-Thorin interpolation gives the general Young's inequality. Elementary applications of change of coordinates and Fubini's theorem establish the commutativity and associativity of convolution for functions $f, g \in L^1(\TT^d)$.
    %
    %But $L^1(\TT) \cap L^p(\TT)$ is dense in $L^p(\TT)$. Since $f * g = g * f$ for a dense family of functions, and convolution is continuous from $L^p(\TT) \times L^q(\TT) \to L^r(\TT)$, we obtain the identity for the more general families of functions.
    Similarily, one can apply Fubini's theorem to obtain associativity for $f,g,h \in L^1(\TT^d)$. To obtain the product identity for the Fourier series, we can apply Fubini's theorem to write
    %
    \begin{align*}
        \widehat{f * g}(n) &= \int_{\TT^d} (f * g)(t) e_n(-t)\ dt\\
        &= \int_{\TT^d} \int_{\TT^d} f(s)g(t-s) e_n(-t)\ ds\ dt\\
        &= \int_{\TT^d} f(s) \int_{\TT^d} (L_{-s}g)(t) e_n(-t)\ dt\ ds\\
        &= \int_{\TT^d} f(s) e_n(-s) \widehat{g}(n)\ ds\\
        &= \widehat{f}(n) \widehat{g}(n),
    \end{align*}
    %
    and this is exactly the identity required. To calculate the weak derivative of $f * g$, we fix $\phi \in C^\infty(\TT^d)$, and calculate using two applications of Fubini's theorem that
    %
    \begin{align*}
        \int_{\TT^d} (f' * g)(t) \phi(t)\; dt &= \int_{\TT^d} \int_{\TT^d} f'(t-s) g(s) \phi(t)\; ds\; dt\\
        &= \int_{\TT^d} g(s) \int_{\TT^d} f'(t-s) \phi(t)\; dt\; ds\\
        &= - \int_{\TT^d} g(s) \int_{\TT^d} f(t-s) \phi'(t)\; dt\; ds\\
        &= - \int_{\TT^d} \left( \int_{\TT^d} g(s) f(t-s)\; ds \right) \phi'(t)\; dt\\
        &= - \int_{\TT^d} (f * g)(t) \phi'(t)\; dt.
    \end{align*}
    %
    If $f = 0$ a.e outside $E$, and $g = 0$ a.e. outside $F$, then $(f * g)(t)$ can be nonzero only when there is a set $G$ of positive measure such that for any $s \in G$, $f(s) \neq 0$ and $g(t-s) \neq 0$. But this means that $E \cap G \cap (t-F)$ has positive measure, so that there is $s \in E$ such that $t-s \in F$, meaning that $t \in E + F$.
\end{proof}

\begin{example}
    Given a function $f \in L^1(\TT^d)$ we define the \emph{autocorrelation function}
    %
    \[ R(\tau) = \int_{\TT^d} f(t + \tau) \overline{f(t)}\; dt. \]
    %
    Then $R$ is the convolution of $f(t)$ with $g(t) = \overline{f(-t)}$. Thus for $f \in L^1(\TT^d)$, $R \in L^1(\TT^d)$, and
    %
    \[ \widehat{R}(n) = \widehat{f}(n) \overline{\widehat{f}(n)} = |\widehat{f}(n)|^2. \]
    %
    The function $\widehat{R}$ is known as the \emph{power spectrum} of $f$.
\end{example}

We know that suitably smooth functions have convergent Fourier series. The advantage of convolution is if we want to study the properties of any integrable function $f$, then for any function $u \in C^\infty(\TT)$, $f * u$ will be smooth, and if we choose $u$ appropriately, we can let $f * u$ approximate $f$. In terms of Fourier analysis, provided that $\widehat{u}$ is close to one, $(f*u)^\ft$ will be close to $\widehat{f}$, and so we might expect $f * u$ to be close to $f$. If we can establish the convergence properties on the convolution $f * g$, then we can probably obtain results about $f$. From the frequency side, $\sum \widehat{f}(n) e_n$ might not converge, but $\sum a_n \widehat{f}(n) e_n$ might converge for a suitably fast decaying sequence $a_n$. But if $a_n$ is close to one, this sequence might still reflect properties of the original sequence.

To make rigorous the idea of approximating the Fourier series of a function, we introduce families of \emph{good kernels}. A good kernel is a sequence of integrable functions $\{ K_n \}$ on $\TT$ bounded in $L^1$ norm, for which
%
\[ \int_{\TT} K_n(t) = 1. \]
%
so that integration against $K_n$ operates essentially like an average, and for any $\delta > 0$,
%
\begin{equation} \label{goodkerneldecaycondition}
    \lim_{n \to \infty} \int_{|t| > \delta} |K_n(t)| \to 0.
\end{equation}
%
Thus the functions $\{ K_n \}$ become concentrated at the origin as $n \to \infty$. If in addition, we have an estimate $\| K_n \|_{L^\infty(\TT^d)} \lesssim n^d$, we say it is an \emph{approximation to the identity}.

\begin{example}
    The simplest way to obtain a good kernel is to fix $K \in L^1(\TT^d)$ with
    %
    \[ \int_{\TT^d} K(x)\; dx = 1, \]
    %
    and to define
    %
    \[ K_n(x) = \begin{cases} n^d \cdot K(nx) &: |x_1|, \dots, |x_d| \leq 1/n, \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Then $\| K_n \|_{L^1(\TT)} = 1$ for all $n > 0$, and $K_n$ is eventually supported on every small ball around the origin, which implies \eqref{goodkerneldecaycondition}. If $K \in L^\infty(\TT^d)$, then the resulting sequence $\{ K_n \}$ is also an approximation to the identity.
\end{example}

\begin{theorem}
    Let $\{ K_n \}$ be a good kernel. Then
    %
    \begin{itemize}
        \item $(K_n * f)(t) \to f(t)$ for any continuity point $t$ of $f$.
        \item $(K_n * f) \to f$ uniformly if $f \in C(\TT^d)$, and $K_n * f$ converges to $f$ in $L^p(\TT^d)$ if $f \in L^p(\TT^d)$, for $1 \leq p < \infty$.
        \item If $K_n$ is an approximation to the identity, $(K_n * f)(t) \to f(t)$ for all $t$ in the Lebesgue set of $f$.
    \end{itemize}
\end{theorem}
\begin{proof}
    The operators $T_nf = K_n * f$ are uniformly bounded as operators on $L^p(\TT)$. Basic analysis shows that $(K_n * f)(t) \to f(t)$ at each point $t$ where $f$ is continuous, and converges uniformly to $f$ if $f$ is in $C(\TT^d)$. But a density argument allows us to conclude that $K_n * f \to f$ in $L^p(\TT)$ for each $f \in L^p(\TT^d)$, for $1 \leq p < \infty$. To obtain pointwise convergence for $t$ in the Lebesgue set of $f$, we calculate
    %
    \[ |(K_n * f)(t) - f(t)| \leq \int_{\TT^d} |f(t - s) - f(t)| |K_n(s)|\; ds. \]
    %
    Let $A(\delta) = \delta^{-d} \int_{|s| < \delta} |f(t-s) - f(t)|$. Then as $\delta \to 0$, $A(\delta) \to 0$ because $t$ is in the Lebesgue set of $f$. And we find that for each $k$, since $|K_n(s)| \lesssim n^d$,
    %
    \[ \int_{2^k/n < |t| < 2^{k+1}/n} |f(t-s) - f(t)| |K_n(s)| \lesssim \frac{A(2^{k+1}/n)}{2^{d(k+1)}}. \]
    %
    Thus we have a bound
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim_d \sum_{k = 0}^\infty \frac{A(2^k/n)}{2^{dk}}. \]
    %
    Because $f$ is integrable, $A$ is continuous, and hence bounded. This means that for each $m$,
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim_d \sum_{k = 0}^m \frac{A(2^k/n)}{2^{dk}} + \| A \|_\infty \sum_{k = m}^\infty \frac{1}{2^{dk}} = \sum_{k = 0}^m \frac{A(2^k/n)}{2^{dk}} + O_d\left( 1/2^{dm} \right). \]
    %
    For any fixed $m$, the finite sum tends to zero as $n \to \infty$, so we obtain that $|(K_n * f)(t) - f(t)| = o(1) + O_d(1/2^m)$. Taking $m \to \infty$ proves the result.
\end{proof}

As mentioned above, if $u \in C^\infty(\TT)$, then for any $f \in L^1(\TT)$, $f * u \in C^\infty(\TT)$, and we have $D^\alpha(f * u) = f * D^\alpha u$. Thus we can use Young's inequality to bound $D^\alpha(f * u)$ in terms of $f$ and $D^\alpha u$. Thus in some contexts, it is useful to find out how smooth we can make $u$, while still being able to approximate a non-smooth function $f$ with $f * u$. If we fix $u \in C^\infty(\TT)$ supported on an interval of length $1/4$ centered at the origin, then for $0 < \varepsilon < 1$, we can define $u_\varepsilon(t) = u(t/\varepsilon)$ for $|t| \leq \varepsilon$, and $u_\varepsilon(t) = 0$ for $|t| > \varepsilon$. Such a function will lie in $C^\infty(\TT)$, be supported on an interval of length $2\varepsilon$ interval centered at the origin. Such a function satisfies estimates of the form $\| D^k u_\varepsilon \|_{L^\infty(\TT)} \lesssim_k \varepsilon^{-k}$. Roughly speaking, this is pretty much the best we can do for a function with such small support. $u \in C^\infty(\TT)$ is supported on $|t| \leq \varepsilon$, and $\int_{\TT} u(t)\; dt = 1$, then the mean value theorem can be used to show that $\| D^k u \|_{L^\infty(\TT)} \gtrsim_k \varepsilon^{-k}$ for all $k > 0$.

\section{The Dirichlet Kernel}

For simplicity, let us now focus exclusively on the case $d = 1$ with the canonical summation operators $S_N$. For $f \in L^1(\TT)$, we calculate that
%
\[ (S_Nf)(t) = \sum_{n = -N}^N \widehat{f}(n) e_n(t) = \int_{\TT^d} f(x) \left( \sum_{n = -N}^N e_n(t - x) \right)\; dx.  \]
%
The bracketed part of the final term in the equation is independent of the function $f$, and is therefore key to understanding the behaviour of the sums $S_N$. We call it the \emph{Dirichlet kernel}, denoted $D_N$. Thus
%
\[ D_N(t) = \sum_{n = -N}^N e_n(t) \]
%
and so $S_N f = f * D_N$. Thus analyzing this convolution is \emph{key} to understanding the partial summation operators.

\begin{remark}
    In the higher dimensional case, we can consider the operators
    %
    \[ K_N(t) = \sum_{n \in E_N} e_n(t). \]
    %
    The behaviour of these functions is highly dependant on the choice of the sets $E_N$, and we thus leave the higher dimensional analysis for another time.
\end{remark}

\begin{theorem}
    For any integer $N$ and $t \in \TT$,
    %
    \[ D_N(t) = \frac{\sin(2\pi(N+1/2)t)}{\sin(\pi t)}. \]
\end{theorem}
\begin{proof}
    By the geometric series summation formula, we may write
    %
    \begin{align*}
        D_N(t) &= 1 + \sum_{n = 1}^N e_n(t) + e_n(-t) = 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + e(-t) \frac{e_N(-t) - 1}{e(-t) - 1}\\
        &= 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + \frac{e_N(-t) - 1}{1 - e(t)} = \frac{e_{N+1}(t) - e_N(-t)}{e(t) - 1}\\
        &= \frac{e_{N+1/2}(t) - e_{N+1/2}(-t)}{e_{1/2}(t) - e_{1/2}(-t)} = \frac{\sin(2 \pi (N + 1/2)t)}{\sin(\pi t)}. \qedhere
    \end{align*}
\end{proof}

If $D_N$ was a good kernel, then we would obtain that the partial sums of $S_N$ converge uniformly. This initially seems a good strategy, because $\int D_N(t) = 1$. However, we find
%
\begin{align*}
    \int_{\TT^d} |D_N(t)| &= \int_0^1 \left| \frac{\sin(2 \pi (N + 1/2)t)}{\sin(\pi t)}\; dt \right|\\
    &\gtrsim \int_0^1 \frac{|\sin(2 \pi (N+1/2) t)|}{\sin(\pi t)}\; dt\\
    &\gtrsim \int_0^1 \frac{|\sin(2 \pi (N+1/2) t)|}{t}\; dt\\
    &= \int_0^{2 \pi N + \pi} \frac{|\sin(t)|}{t}\; dt\\
    &\gtrsim \sum_{n = 0}^N \frac{1}{t}\; dt \gtrsim \log(N).
\end{align*}
%
Thus the $L^1$ norm of $D_N$ grows, albeit slowly, to $\infty$. This reflects the fact that $D_N$ oscillates very frequently, and also that the pointwise convergence of the Fourier series is much more subtle than that provided by good kernels. In fact, a simple functional analysis argument shows that pointwise convergence of Fourier series fails for continuous functions.

\begin{theorem}
    There exists $f \in C(\TT)$ such that $(S_N f)(0)$ diverges as $N \to \infty$.
\end{theorem}
\begin{proof}
    If we consider the linear functionals $\Lambda_N f = (S_N f)(0) = (f * D_N)(0)$ on $C(\TT)$. If we let $f_N$ be a continuous function approximating $\text{sgn}(D_N)$ for each $N$, then $|\Lambda_N f_N| \gtrsim \log N \cdot \| f_N \|_{L^\infty(\TT)}$. This implies that $\| \Lambda_N \| \to \infty$ as $N \to \infty$. The uniform boundedness principle thus implies that there exists a {\it single} function $f \in C(\TT)$ such that $\sup |\Lambda_N f| = \infty$, so $(S_N f)(0)$ diverges as $N \to \infty$.
\end{proof}

The situation is even worse than this for general integrable functions. In 1927, Andrey Kolmogorov constructed an integrable function whose Fourier series diverges everywhere. But there is some hope. In 1928, Marcel Riesz showed, using the \emph{boundedness of the Hilbert transform}, discussed later in these notes, that if $1 < p < \infty$, and $f \in L^p(\TT)$, that $S_N f$ converges in the $L^p$ norm to $f$. After another half century of the development of harmonic analysis, in 1966, Carleson proved that for each $f \in L^p(\TT)$, for $1 < p \leq \infty$, the Fourier series of $f$ converges almost everywhere to $f$. The multivariate picture is more complicated and many questions remain open today; tensoring shows that if $S_N$ is \emph{square summation}, then $S_N f$ converges to $f$ in $L^p(\TT^d)$, and in 1970 Charles Fefferman showed that for square summation $S_N f$ converges to $f$ almost everywhere. On the other hand, in 1971 Charles Fefferman showed that for spherical summation the \emph{only} place we have norm convergence is in $L^2(\TT^d)$. The problem of almost everywhere convergence remains open.

\section{Countercultural Methods of Summation}

We now interpret our convergence of series according to a different kernel, so we do get a family of good kernels, and therefore we obtain pointwise convergence for suitable reinterpretations of partial sums. One reason why the Dirichlet kernel fails to be a good kernel is that the Fourier coefficients of the kernel have a sharp drop -- the coefficients are either equal to one or to zero. If we mollify, then we will obtain a family of good kernels. And the best way to do this is to alter our summation methods slightly.

The standard method of summation suffices for much of analysis. Given a sequence $a_0, a_1, \dots$, we define the infinite sum as the limit of partial sums. Some sums, like $\sum_{k = 1}^\infty k$, obviously diverge, whereas other sums, like $\sum 1/n$, `just' fail to converge because they grow suitably slowly towards infinity over time. We encountered such a sum in the study of trigonometric series via the trigonometric expansion associated with the characteristic function i.e.
%
\[ \chi_{(-a,+a)}(x) \sim \frac{a}{\pi} + \sum_{n = 1}^\infty \frac{2 \sin(n a)}{n \pi} \cos(nx), \]
%
which we saw did not converge pointwise for any value of $x$. This tempts us to try and make sense of the right hand side as a `divergent series'. There are several methods of assigning values to divergent series. For example, since the time of Euler, a new method of summation developed by Cesaro had been introduced which `regularized' certain divergent series so that a value could be assigned to them. Rather than considering limits of partial sums, we consider limits of averages of sums, known as Cesaro means. Letting $s_n = \sum_{k = 0}^n a_k$, we define the Cesaro means
%
\[ \sigma_n = \frac{s_0 + \dots + s_n}{n+1}, \]
%
A sequence $\{ a_k \}$ is \emph{Cesaro summable} to some value $\sigma$ if $\sigma_n$ converge to $\sigma$ as $n \to \infty$. If the series is summable in the usual manner, then the Cesaro sum exists. However, the Cesaro summation is stronger than normal convergence.

\begin{example}
In the sense of Cesaro, we have $1 - 1 + 1 - 1 + \dots = 1/2$, which reflects the fact that the partials sums do `converge', but to two different numbers $0$ and $1$, which the series oscillates between, and the Cesaro means average these two points of convergence out to give a single method of convergence.
\end{example}

There is actually a \emph{system} of Cesaro summation, which allows us to sum more and more divergent series. For each $l \geq 0$, we consider the \emph{$(C,l)$ means} $\sigma^l_k$ of a sequence $\{ a_k \}$ by setting $\sigma^0_n = a_1 + \dots + a_n$, and for $l \geq 1$, defining
%
\[ \sigma^l_n = \frac{\sigma^{l-1}_1 + \dots + \sigma^{l-1}_n}{n}. \]
%
The $(C,1)$ means are just the usual Cesaro means defined above. A series is then $(C,l)$ summable if the associated $(C,l)$ means converge. We can actually extend this method to a theory of $(C,\alpha)$ means by noticing that
%
\[ \sigma^l_n = \sum_{k = 1}^n \binom{n}{k} \binom{n + l}{k}^{-1} a_k, \]
%
and so we can define the $(C,\alpha)$ means for any $\alpha \in \RR - \{ -1, -2, \dots \}$ by setting
%
\[ \sigma^\alpha_n = \sum_{k = 1}^n \binom{n}{k} \binom{n + \alpha}{k}^{-1} a_k. \]
%
We can then define $(C,\alpha)$ convergence, which get progressively weaker as $\alpha \to \infty$.

Another notion of regularization sums emerged from the theory of power series, a method called \emph{Abel summation}. Given a sequence $\{ a_k \}$, we can consider the power series $\sum a_k r^k$. Under suitably weak conditions, i.e. by the root or ratio test, this series is well defined for $|r| < 1$, and we can consider the Abel means $A_r = \sum a_k r^k$, and ask if $\lim_{r \to 1} A_r$ exists, which should be `almost like' $\sum a_k$. If this limit exists, we call it the Abel sum of the sequence.

\begin{example}
    In the Abel sense, we have $1 - 2 + 3 - 4 + 5 - \dots = 1/4$, because
    %
    \[ \sum_{k = 0}^\infty (-1)^k (k + 1) z^k = \frac{1}{(1 + z)^2}. \]
    % 1, -1, 2, -2, 3, -3,
    The partial sums are given by
    %
    \[ s_n = (-1)^{n+1} \lceil n/2 \rceil \]
    %
    and clearly do not converge. The Cesaro sums
    %
    % 1         1
    % 0
    % 2 / 3     2
    % 0
    % 3 / 5     3
    % 0
    % 4 / 7     4
    % 0
    % 5 / 9     5
    \[ \sigma_n = \begin{cases} \frac{m}{2m - 1} & : n = 2m - 1 \\ 0 &: n = 2m \end{cases}  - n^{-1} \sum_{k = 1}^n (-1)^k \lceil k/2 \rceil \]
    %
    also do not converge, i.e. because the sequence oscillates between a sequence converging to $1/2$, and a sequence which is equal to zero.
\end{example}

Abel summation is always more general than Cesaro summation, a result provided in 1880, due to Frobenius.

\begin{theorem}
    A Cesaro summable sequence is Abel summable.
\end{theorem}
\begin{proof}
    Let $\{ a_k \}$ be a Cesaro summable sequence, which we may without loss of generality assume converges to $0$. Now $(n + 1)\sigma_n - n \sigma_{n-1} = s_n$, so
    %
    \[ (1 - r)^2 \sum_{k = 0}^n (k + 1) \sigma_k r^k = (1 - r) \sum_{k = 0}^n s_k r^k = \sum_{k = 0}^n a_k r^k \]
    %
    As $n \to \infty$, the left side tends to a well defined value for $r < 1$, hence the same is true for $\sum_{k = 0}^n a_k r^k$. Given $\varepsilon > 0$, let $N$ be large enough that $|\sigma_n| < \varepsilon$ for $n > N$, and let $M$ be a bound for all $|\sigma_n|$. Then
    %
    \begin{align*}
        \left| (1 - r)^2 \sum_{k = 0}^\infty (k + 1) \sigma_k r^k \right| &\leq (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) |\sigma_k| r^k + \varepsilon \sum_{k = N+1}^\infty (k + 1) r^k \right)\\
        &= (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) (|\sigma_k| - \varepsilon) r^k + \varepsilon \left[ \frac{r^{n+1}}{1-r} + \frac{1}{(1 - r)^2} \right] \right)\\
        &\leq (1 - r)^2 M \sum_{k = 0}^N (k + 1) r^k + \varepsilon r^{n+1} (1 - r) + \varepsilon\\
        &\leq (1 - r)^2 M \frac{(N+1)(N+2)}{2} + \varepsilon r^{n+1} (1 - r) + \varepsilon
    \end{align*}
    %
    Fixing $N$, and letting $r \to 1$, we may make the complicated sum on the end as small as possible, so the absolute value of the infinite sum is less than $\varepsilon$. Thus the Abel limit converges to zero.
\end{proof}

\begin{remark}
    For any $\alpha$, $(C,\alpha)$ summability implies Abel summability, though the proof is somewhat more technical.
\end{remark}

\section{Fejer Summation}

Note that the Cesaro means of the Fourier series of $f$ are given by
%
\[ \sigma_N(f) = \frac{S_0(f) + \dots + S_{N-1}(f)}{N} = f * \left( \frac{D_0 + \dots + D_{N-1}}{N} \right) = f * F_N, \]
%
where we have introduced a new kernel $F_N$, called the \emph{Fejer kernel}. Here, we have a simple formula for the Cesaro means, i.e.
%
\[ F_N(x) = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) e_n(t) = \frac{1}{N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)}. \]
%
Thus the oscillations of the Dirichlet kernel are slightly dampened, and as a result, we can easily see that $F_N$ is an approximation to the identity.

\begin{theorem}[Fej\'{e}r's Theorem] For any $f \in L^1(\TT)$,
    \begin{itemize}
        \item $(\sigma_N f)(x) \to f(x)$ for all $x$ in the Lebesgue set of $f$.
        \item $\sigma_N f \to f$ uniformly if $f \in C(\TT)$.
        \item $\sigma_N f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\TT)$.
    \end{itemize}

\end{theorem}

If we look at the Fourier expansion of the trigonometric polynomial $\sigma_N(f)$, viewing $\sigma_N$ as a \emph{Fourier multiplier operator}, we see that
%
\[ \sigma_N f = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) \widehat{f}(n) e_n. \]
%
Thus the Fourier coefficients are slowly added to the expansion, rather than a sharp cutoff as with ordinary Dirichlet summation. This is one reason for the nice convergence properties the kernel has as compared to the Dirichlet kernel.

\begin{corollary}
    If $f \in L^1(\TT)$ and $\widehat{f} = 0$, then $f = 0$ almost everywhere.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\sigma_N f = 0$ for all $N$. But $\sigma_N f \to f$ in $L^1(\TT)$, which means that $f = 0$ in $L^1(\TT)$, so $f = 0$ almost everywhere.
\end{proof}

This corollary is often more useful than the more technical convergence statements due to it's relative simplicity. We will later see this result is also true for $d > 1$, via use of the Poisson summation formula for the Fourier transform.

\begin{example}
    We say $f \in L^1(\TT^d)$ is \emph{band limited} if it's Fourier series is supported on finitely many points. If $\{ S_N \}$ is defined as before, and $N$ is suitably large that $E_N$ contains the support of $\widehat{f}$, then
    %
    \[ \widehat{f} = \widehat{f} \cdot \Ind_{E_N} = \widehat{f} \widehat{K_N} = \widehat{f * K_N}. \]
    %
    It thus follows from the previous result that $f = f * K_N$ almost everywhere. But this means that, modified on a set of measure zero, $f \in C^\infty(\TT^d)$.
\end{example}

\section{Abel Summation}

Let us now consider the Abel sum of the Fourier integrals. We begin by focusing on the one-dimensional case, as in the last section. Thus for $f \in L^1(\TT)$ we have
%
\[ A_r(f) = \sum_{n = -\infty}^\infty \widehat{f}(n) r^n e_n(t). \]
%
Thus, if we define the {\it Poisson kernel}
%
\[ P_r(t) = \sum_{n = -\infty}^\infty r^{|n|} e_n(t) \]
%
For each $r < 1$, this series converges uniformly for $t \in \TT$, so $P_r$ is a well-defined continuous function, and the uniform convergence shows that $A_r(f) = P_r * f$. As with the Fejer kernel, the family $\{ P_r \}$ is \emph{also} a good kernel as $r \to 1$. To see this, we can apply an infinite geometric series summation to obtain that
%
\begin{align*}
    \sum r^{|n|} e_n(t) &= 1 + \frac{re(t)}{1 - re(t)} + \frac{re(-t)}{1 - re(-t)} = 1 + \frac{2r \cos 2 \pi t - 2r^2}{(1 - re(t))(1 - re(-t))}\\
    &= 1 + \frac{2r \cos 2\pi t - 2r^2}{1 - 2r \cos 2\pi t + r^2} = \frac{1 - r^2}{1 - 2r \cos 2 \pi t + r^2}.
\end{align*}
%
As $r \to 1$, the function concentrates at the origin, because as $r \to 1$, if $\delta \leq |t| \leq \pi$, then $1 - \cos 2\pi t$ is bounded away from the origin, so
%
\begin{align*}
    \left| \frac{1 - r^2}{1 - 2r \cos 2\pi t + r^2} \right| &= \left| \frac{1 + r}{(1+(1-2\cos 2\pi t)r) + 2(1 - \cos 2\pi t) r^2/(1-r)} \right|\\
    &= O \left( \frac{1 - r}{1 - \cos 2\pi t} \right) = O_\delta(1 - r).
\end{align*}
%
Moreover,
%
\[ \| P_r \|_{L^\infty(\TT)} \leq \frac{1 - r^2}{1 - 2r + r^2} \leq \frac{2}{1 - r}. \]
%
Thus the Poisson kernel is an approximation to the identity; the oscillation in the kernel cancels out as $r \to 1$.

\begin{theorem}
    For any $f \in L^1(\TT)$,
    %
    \begin{itemize}
        \item $(A_r f)(t) \to f(t)$ for all $x$ in the Lebesgue set of $f$.
        \item $A_r f \to f$ uniformly if $f \in C(\TT)$.
        \item $A_r f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\TT)$.
    \end{itemize}
\end{theorem}

The Poisson kernel is not a trigonometric polynomial, and therefore not quite as easy to work with as the F\'{e}jer kernel. However, it is the real part of the Cauchy kernel
%
\[ \frac{1 + re^{2 \pi it}}{1 - re^{2 \pi it}}, \]
%
and therefore links the study of trigonometric series and the theory of analytic functions. We will see the kernel return when we study application of harmonic analysis to partial differential equations.

\section{The De la Valle\'{e} Poisson Kernel}

By taking a kernel halfway between the Dirichlet kernel and the Fejer kernel, we can actually obtain important results about ordinary summation. For two integers $M > N$, we define
%
\[ \sigma_{N,M}(f) = \frac{M\sigma_M(f) - N\sigma_N(f)}{M-N}. \]
%
If we take a look at the Fourier expansion of $\sigma_{n,m} f$, we find
%
\[ \sigma_{N,M} f = \sum_{n = -M}^M \frac{M - |n|}{M-N} e_n - \sum_{n = -N}^N \frac{N - |n|}{M-N} e_n = S_N f + \sum_{|n| = N+1}^M \frac{M - |n|}{M - N} e_n. \]
%
So we still have a slow decay in the Fourier coefficients. And as a result, if we look at the associated De la Velle\'{e} Poisson kernel, we find that a suitable subsequence is an approximation to the identity. In particular, for any fixed integer $k$, the sequence $\sigma_{kN,(k+1)N}$ leads to a good kernel. More interestingly, if the Fourier coefficients of $f$ have some decay, then the De la Vall\'{e}e Poisson sum does not differ that much from the ordinary sum, which gives useful results.

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, then for any integers $N$ and $k$, if
    %
    \[ kN \leq M < (k+1)N, \]
    %
    then
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \lesssim 1/k. \]
    %
    Where the implicit constant is independent of $N$ and $k$.
\end{theorem}
\begin{proof}
    We just calculate that, since the Poisson sum has essentially the same weight for low term coefficients as the sum $S_M f$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \lesssim \sum_{kN \leq |n| < (k+1)N} |\widehat{f}(n)| \lesssim \sum_{n = kN}^{(k+1)N} \frac{1}{n} \leq \frac{N}{kN} = \frac{1}{k}. \qedhere \]
\end{proof}

\begin{corollary}
    If $f \in L^1(\TT)$ with $\widehat{f}(n) = O(|n|^{-1})$,
    %
    \begin{itemize}
        \item $S_Nf$ converges to $f$ in the $L^p$ norm for $1 \leq p < \infty$.
        \item $S_Nf$ converges uniformly to $f$ if $f \in C(\TT)$.
        \item $(S_N f)(x) \to f(x)$ for each Lebesgue point $x$ of $f$.
    \end{itemize}
\end{corollary}
\begin{proof}
    The idea is quite simple. Fix $N$. Given any $\varepsilon$, we can use the last theorem to find $k$ large enough such that if $kN \leq M < k(N+1)$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\TT)} \leq \varepsilon. \]
    %
    But this gives the first and second result, up to perhaps a $\varepsilon$ of error. The latter result is given by similar techniques.
\end{proof}

Let us briefly describe a more general way to formulate this argument. Fix a function $f: \TT \to \CC$, and let us suppose that for each $N$, we can find a trigonometric polynomial $P_N$ of degree $N$ such that $\| f - P_N \|_{L^\infty(\TT)} \leq \varepsilon_N$, then, since $S_N$ has operator norm $O(\log N)$ in the $L^\infty$ norm, and $S_N P_N = P_N$, we conclude that
%
\[ \| S_N f - P_N \|_{L^\infty(\TT)} \lesssim \log N \cdot \varepsilon_N. \]
%
But the triangle inequality thus implies that $\| S_N f - f \|_{L^\infty(\TT)} \lesssim \log N \cdot \varepsilon_N$. The De la Vall\'{e}e Poisson sum gives precisely such a polynomial if $|\widehat{f}(n)| \lesssim |n|^{-1}$, which is what allowed us to prove the required result. This gives convergence provided we can choose $\{ P_N \}$ such that $\varepsilon_N = o(\log N)$. Similar results hold in $L^1(\TT)$.

TODO: RESEARCH MORE INTO NONLINEAR APPROXIMATION BY POLYNOMIALS.

\section{Pointwise Convergence}

One way around around the blowup in the $L^1$ norm of $D_N$ is to consider only functions $f$ which provide a suitable dampening condition on the oscillation of $D_N$ near the origin. This is provided by smoothness of $f$, manifested in various ways. The first thing we note is that the convergence of $(S_N f)(t)$ for a \emph{fixed} $x_0$ depends only \emph{locally} on the function $f$.

\begin{lemma}[Riemann Localization Principle]
    If $f_0$ and $f_1$ agree in an interval around $t_0$, then
    %
    \[ (S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1). \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ X = \{ f \in L^1(\TT) : f(x) = 0\ \text{for almost every $x \in (t_0 - \varepsilon, t_0 + \varepsilon$)} \}. \]
    %
    Then $X$ is a closed subset of $L^1(\TT)$. Note that for all $x \in [-\pi,\pi]$,
    %
    \[ \sin(t/2) \gtrsim t \quad\text{and}\quad \sin((N+1/2)t) \leq 1. \]
    %
    Thus if $|t| \geq \varepsilon$,
    %
    \[ |D_N(t)| = \frac{|\sin(2 \pi (N+1/2)t)|}{|\sin(\pi t)|} \lesssim 1/\varepsilon. \]
    %
    In particular, by H\"{o}lder's inequality, the functionals $T_Nf = (S_N f)(t_0)$ are uniformly bounded on $X$, i.e. $\| T_N \| \lesssim 1/\varepsilon$. If $f$ is smooth, and vanishes on $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $T_N f \to 0$ as $N \to \infty$. But the space of such functions is dense in $X$, which implies that $T_N f \to 0$ for \emph{any} $f \in X$. Thus if $f_0, f_1$ are two functions that agree in $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $f_0 - f_1 \in X$, so $(S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1)$. In particular, the pointwise convergence properties of $f_0$ and $f_1$ are equivalent at the point $t_0$.
\end{proof}

Thus any result about the pointwise convergence of Fourier series must depend on the local properties of a function $f$. Here, we give two of the main criteria, which corresponds to the smoothness of a function about a point $x$: either $f$ is in a sense, `locally Lipschitz', or `locally of bounded variation'.

\begin{theorem}[Dini's Criterion]
    If there exists $\delta$ such that
    %
    \[ \int_{|t| < \delta} \left| \frac{f(x+t) - f(x)}{t} \right|\; dt < \infty, \]
    %
    then $(S_N f)(x) \to f(x)$.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $x = 0$ and $f(x) = 0$. Fix $\varepsilon > 0$, and pick $\delta_0$ such that
    %
    \[ \int_{|t| < \delta_0} \left| \frac{f(t)}{t} \right|\; dt < \varepsilon. \]
    %
    We have
    %
    \begin{align*}
        |(S_N f)(0)| &= \left| \left( \int_{|t| < \delta_0} + \int_{|t| \geq \delta_0} \right) f(t) D_N(t)\; dt \right|.
    \end{align*}
    %
    Now
    %
    \[ \int_{|t| \geq \delta_0} f(t) D_N(t)\; dt = (D_N * \left( \Ind_{|t| \geq \delta_0} f \right))(0) = S_N( \Ind_{|t| \geq \delta_0} f )(0) = o(1) \]
    %
    since $f \Ind_{|t| \geq \delta_0}$ vanishes in a neighbourhood of the origin. On the other hand, we note that $t/\sin(\pi t)$ is a bounded function on $\TT$, so
    %
    \begin{align*}
        \int_{|t| < \delta_0} f(t) D_N(t)\; dt &= \int_{|t| < \delta_0} \left( \sin(2 \pi (N + 1/2)t) \frac{f(t)}{t} \right) \left( \frac{t}{\sin(\pi t)} \right)\; dt\\
        &\lesssim \| f(t)/t \|_{L^1[-\delta_0,\delta_0]} \leq \varepsilon.
    \end{align*}
    %
    Thus, for suitably large $N$, $|(S_N f)(0)| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, the proof is complete.
\end{proof}

This proof applies, in particular, if $f$ is locally Lipschitz at $x$. Note the application of the Riemann Lebesgue lemma to show that to analyze the pointwise convergence of $(S_N f)(x)$, it suffices to analyze
%
\[ \lim_{N \to \infty} \int_{|t| < \delta} f(x+t) D_N(t)\; dt \]
%
for any fixed $\delta > 0$.

\begin{lemma}[Jordan's Criterion]
    If $f \in L^1(\TT)$ locally has bounded variation about $x$, then
    %
    \[ (S_N f)(x) \to \frac{f(x^+) + f(x^-)}{2}. \]
\end{lemma}
\begin{proof}
    By Riemann's localization principle, we may assume $f$ has bounded variation everywhere. Then without loss of generality, we may assume $f$ is an increasing function, since a bounded variation function is the difference of two monotonic functions. Since
    %
    \[ \int_{-1/2}^{1/2} D_N(t)\; dt = \int_0^{1/2} [f(x + t) + f(x - t)] D_N(t), \]
    %
    it suffices without loss of generality to show that
    %
    \[ \lim_{N \to \infty} \int_0^{1/2} f(x+t) D_N(t)\; dt = \frac{f(x+)}{2}. \]
    %
    Since $\int_0^{1/2} D_N(t) = 1/2$, this is equivalent to showing
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi [f(x + t) - f(x+)] D_N(t)\; dt = 0. \]
    %
    Because of this, we may assume without loss of generality that $x = 0$ and $f(x+) = 0$. Then by the mean value theorem for integrals (which only applies for monotonic functions), for each $N$, there exists $0 \leq \nu_N \leq 1/2$ such that
    %
    \begin{align*}
        \int_0^{1/2} f(t) D_N(t)\; dt &= \| f \|_\infty \int_{\nu_N}^{1/2} D_N(t)\; dt.
    \end{align*}
    %
    Now an integration by parts gives
    %
    \begin{align*}
        \int_{\nu_N}^{1/2} D_N(t) &\lesssim \int_{\nu_N}^{1/2} \frac{\sin((N + 1/2) t)}{t}\; dt = \int_{\nu_N/(N + 1/2)}^{1/2(N + 1/2)} \frac{\sin(t)}{t}\; dt \lesssim \frac{1}{N+1/2}.
    \end{align*}
    %
    Thus
    %
    \[ \int_0^{1/2} f(t) D_N(t) \lesssim \frac{1}{N + 1/2} \to 0. \qedhere \]
\end{proof}

\begin{remark}
    The calculations in this proof also show that if $f \in L^1(\TT)$ has bounded variation, then
    %
    \[ \widehat{f}(n) = O(1/|n|). \]
    %
    We have seen that this implies $S_N f$ converges to $f$ at every point on the Lebesgue set of $f$, $S_N f$ converges uniformly to $f$ if $f \in C(\TT)$, and for any $1 \leq p < \infty$, if $f \in L^p(\TT)$, $S_N f$ converges to $f$ in $L^p(\TT)$. Dirichlet's theorem says that the Fourier series of a continuous function $f$ with only finitely many maxima and minima converges uniformly to $f$ everywhere. Such a function has bounded variation, and so Dirichlet's theorem is an easy consequence of our discussion.
\end{remark}

Of course, applying various better decay rates leads to a more uniform version of this theorem. The decay of the Fourier series depends on the decay of the Fourier coefficients of $yg(y)$ and $g(y) \cos(y/2)(y/\sin(y/2))$. In particular, if these coefficients is $O(|n|^{-m})$, then the convergence rate is also $O(|n|^{-m})$. If this decay rate is independent of $x$ for suitable values of $x$, the convergence will be uniform over these values of $x$.

\begin{example}
    Consider the sawtooth function defined on $[-1/2,1/2)$ by $s(t) = t$, and then made periodic on the entire real line. We can easily calculate the Fourier series here, obtaining that
    %
    \[ s(t) = i \sum_{n \neq 0} \frac{(-1)^n e_n(t)}{2 \pi n} = -2 \sum_{n = 1}^\infty \frac{(-1)^n \sin(2 \pi nt)}{n}. \]
    %
    Thus for any $t \in (-1/2,1/2)$,
    %
    \[ \sum_{n = 1}^\infty \frac{(-1)^n \sin(2 \pi nt)}{n} = -t/2. \]
\end{example}

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, and $f(t_0-)$ and $f(t_0+)$ exist, then
    %
    \[ (S_N f)(t_0) \to \frac{f(t_0-) + f(t_0+)}{2}. \]
\end{theorem}
\begin{proof}
    The idea of our proof is to break $f$ into a nice continuous function, and the sawtooth function, where we already understand the convergence of Fourier series. Without loss of generality, let $t_0 = 1/2$. Define $g(t) = f(t) + (f(1+) - f(1-)) s(t) / 2$ on $(-1/2,1/2)$, where $s$ is the sawtooth function. Then
    %
    \[ \lim_{t \uparrow 1/2} g(t) = \lim_{t \downarrow -1/2} g(t) = \frac{f(1/2+) + f(1/2-)}{2}. \]
    %
    Thus $g$ can be defined on $\TT$ so it is continuous at $t_0$. Now we find $|\widehat{g}| \lesssim |\widehat{f}| + |\widehat{s}| = O(|n|^{-1})$, and so
    %
    \[ (S_N g)(1/2) \to \frac{f(1/2+) + f(1/2-)}{2}. \]
    %
    We also have $(S_N s)(1/2) \to 0$. Thus
    %
    \[ (S_N f)(1/2) = (S_N g)(1/2) - (S_N s)(1/2) \to \frac{f(1/2+) + f(1/2-)}{2}. \qedhere \]
\end{proof}

% Another way to fix the convergence is to use a more quantitative argument in terms of $L^p$ spaces. It is obvious that $S_N f \to f$ in any feasible norm if $f$ is a trigonometric polynomial, because if $f$ has degree $M$, then $S_N f = f$ for $N \geq M$. The Stone-Weirstrass theorem says that we can uniformly approximate any continuous function on $\TT$ by a trigonometric polynomial, so provided we can show that the operators $S_N$ are uniformly bounded in the $L^p$ norm for $1 \leq p < \infty$, we obtain convergence for all $f \in L^p(\TT)$. The fact that the $S_N$ are not bounded in the $L^\infty$ norm is why the Fourier series can diverge pointwise for continuous functions. In fact, the $S_N$ are not bounded as operators on $L^1(\TT)$, and as such, Fourier series do not converge in the $L^1$ norm. The reason for this is that if $\{ K_M \}$ is a good kernel, then $S_N(K_M) = D_N * K_M \to D_N$ as $M \to \infty$, and so as $M \to \infty$, we find $\| S_N(K_M) \|_{L^1(\TT)} = \Omega(\log N)$, hence $\| S_N \|_{L^1(\TT)}$ is unbounded. Later on, using the theory of conjugate functions, we will show that the operators $S_N$ are uniformly bounded in all $L^p(\TT)$ for $1 < p < \infty$, and so the Fourier series of any function $f \in L^p(\TT)$ converges to $f$ in the $L^p$ norm.

\section{Gibbs Phenomenon}

This isn't the end of our discussion about points of discontinuity. There is an interesting phenomenon which occurs locally around the point of discontinuity. If $f$ is continuous locally around a discontinuity point $t_0$, $S_N f \to f$ pointwise locally around $t_0$. Thus, being continuous, $S_N f$ must `jump' from $(S_N f)(t_0-)$ to $(S_N f)(t_0+)$ locally around $t_0$. Interestingly enough, we find that the jump is not precise, the jump is overshot and then must be corrected to the left and right of $t_0$. This is known as the {\it Gibb's phenomenon}, after the man who clarified the reason for why this phenomenon occured in physical measurements, first thought to be a defect in the equipment used to take measurements. Gibb's phenomenon is one instance where a series of functions $\{ f_n \}$ converges pointwise to some function $f$, whereas qualitatively with respect to the $L^\infty$ norm, the sequence $\{ f_n \}$ does not converge to $f$, precisely because of this overshooting.

\begin{theorem}
    Given a function $f$, continuous except at finitely many discontinuity points, one of which being some $t_0 \in \RR$, and such that
    %
    \[ |\widehat{f}(n)| \lesssim |n|^{-1}, \]
    %
    we have
    %
    \[ \lim_{N \to \infty} (S_N f)(t_0 \pm 1/N) = f(t_0 \pm ) \pm C \cdot \frac{f(t_0+) - f(t_0-)}{2}, \]
    %
    where
    %
    \[ C = 2 \pi \int_0^\pi \frac{\sin x}{x} \approx 16.610. \]
\end{theorem}
\begin{proof}
    First consider the jump function $s$, with $t_0 = 1/2$. Then
    %
    \begin{align*}
        (S_N s)(1/2 + 1/N) &= -2 \sum_{n = 1}^N \frac{\sin(2 \pi n/N)}{n} = -2  \sum_{n = 1}^N \frac{2 \pi }{N} \left( \frac{\sin(2 \pi n/N)}{2 \pi n / N} \right).
    \end{align*}
    %
    Here we're just taking averages of values of $\sin(x)/x$ at $x = 2\pi/N$, $x = 4\pi/N$, and so on and so forth up to $x = 2 \pi$. Thus is a Riemann sum, so as $N \to \infty$, we get that
    %
    \[ (S_N s)(\pi + 1/N) \to - 2 \int_0^{2\pi} \frac{\sin x}{x}. \]
    %
    The same calculations give
    %
    \[ (S_N s)(\pi - \pi/N) \to 2 \pi \int_0^\pi \frac{\sin x}{x}. \]
    %
    In general, given $f$, we can write $f = g + \sum \lambda_j h_j$, where $g$ is continuous, and $h_j$ is a translate of the sawtooth function. Then $S_N g$ converges to $g$ uniformly, and $S_N h_j \to 0$ for all $h_j$ uniformly in an interval outside of their discontinuity point. To see this, we note that an integration by parts gives
    %
    \[ \left| \int_{-\pi}^\pi D_N(y)[s(x-y) - s(x)]\; dy \right| \leq |G_N(x - \pi)|, \]
    %
    where $G_N(y) = -i \sum_{|n| \leq N} e_n(t)/n$, so $G_N' = D_N$. It now suffices to show $G_N(x - \pi) \to 0$ outside a neighbourhood of $\pi$. But if $A(u,t) = \sum_{|n| \leq u} e_n(t)$, summation by parts gives
    %
    \[ \sum_{|n| \leq N} \frac{e_n(t)}{n} = \frac{A(N,t)}{N} + \int_1^N \frac{A(u,t)}{u^2}. \]
    %
    Now a simple geometric sum shows $A(u,t) \lesssim 1/|e(t) - 1|$, so provided $d(t, 2 \pi \ZZ)$ is bounded below, the quantity above tends to zero uniformly. This gives the required result.
\end{proof}

\chapter{Applications of Fourier Series}

\section{Tchebychev Polynomials}

If $f$ is everywhere continuous, then for every $\varepsilon$, Fej\'{e}r's theorem says that we can find $N$ such that $\| \sigma_N(f) - f \| \leq \varepsilon$. But $\sigma_N f$ is just a trigonometric polynomial, and so we have shown that with respect to the $L^\infty$ norm, the space of trigonometric polynomials is dense in the space of all continuous functions.  Now if $f$ is a continuous function on $[0,\pi]$, then we can extend it to be even and $2\pi$ periodic, and then the trigonometric series $S_N(f)$ of $f$ will be a cosine series, hence $\sigma_N(f)$ will also be a cosine series, and so for each $\varepsilon$, we can find $N$ and coefficients $a_1, \dots, a_N$ such that
%
\[ \left| f(x) - \sum_{n = 1}^N a_n \cos(nx) \right| < \varepsilon. \]
%
Now we use a surprising fact. For each $n$, there exists a degree $n$ polynomial $T_n$ such that $\cos(nx) = T_n(\cos x)$. This is clear for $n = 0$ and $n = 1$. More generally, we can write
%
\begin{align*}
    \cos((m+1)x) &= \cos((m+1)x) + \cos((m-1)x) - \cos((m-1)x)\\
    &= \cos(mx + x) + \cos(mx - x) - \cos((m-1)x)\\
    &= 2 \cos x \cos(mx) - \cos((m-1)x).
\end{align*}
%
Thus we have the relation  $T_{m+1}(x) = 2xT_m(x) - T_{m-1}(x)$. These polynomials are known as {\emph Tchebyshev polynomials}, enabling us to move between `periodic coordinates' and standard Euclidean coordinates.

\begin{corollary}[Weirstrass]
    The polynomials are uniformly dense in $C[0,1]$.
\end{corollary}
\begin{proof}
    If $f$ is a continuous function on $[0,1]$, we can define $g(t) = f(|\cos(t)|)$. Then $g$ is even, and so for every $\varepsilon > 0$, we can find $a_1, \dots, a_N$ such that
    %
    \[ \left|g(t) - \sum_{n = 1}^N a_n \cos(nt) \right| = \left| g(t) - \sum_{n = 1}^N a_n T_n(\cos t) \right| < \varepsilon. \]
    %
    But if $x = \cos t$, for $\cos t \geq 0$, this equation says
    %
    \[ \left| f(x) - \sum_{n = 1}^N a_n T_n(x) \right| < \varepsilon, \]
    %
    and so we have uniformly approximated $f$ by a polynomial.
\end{proof}

Another proof uses the family of \emph{Landau kernels}
%
\[ L_n(x) = c_n \cdot \begin{cases} (1 - x^2)^n &: -1 \leq x \leq 1 \\ 0 &: |x| \geq 1 \end{cases} \]
%
where $c_n$ is chosen so that $\int_{-1}^1 L_n(x) = 1$. It is simple to show that the family $\{ L_n \}$ is a
%
\begin{align*}
    \int_{-1}^1 (1 - x^2)^n\; dx \geq &= \sum_{k = 0}^\infty \int_{1/2^{k+1} \leq |x| \leq 1/2^k} (1 - x^2)^n\\
    &\gtrsim \sum_{k = 0}^\infty \frac{(1 - 1/4^{k+1})^n}{2^k}\\
    &= \sum_{k = 0}^\infty \exp \left( n \log(1 - 1/4^{k+1}) - k \log(2) \right)\\
    &\geq \sum_{k = 0}^\infty \exp \left( -n / 4^k \right) / 2^k\\
    &\gtrsim \sum_{k = \log_4 n}^{\infty} 1/2^k \gtrsim 1/2^{\log_4 n} = 1/n^{1/2}
\end{align*}
%
Thus $\| L_n \|_{L^\infty(\RR)} \leq n^{1/2}$ which can be used to show the family $\{ L_n \}$ is an approximation to the identity. An important fact here is that if $f$ is supported on $[-1/2,1/2]$, then $L_N * f$ agrees with a polynomial on $[-1/2,1/2]$, which can be used to approximate $f$ by a polynomial on this region.


\section{Exponential Sums and Equidistribution}

The next result uses Fourier analysis to characterize the asymptotic distribution of a certain sequence $a_1, a_2, \dots$. In particular, it is most useful in determining when this distribution is distributed when we consider $2 \pi a_1, 2 \pi a_2, \dots$ as elements of $\TT$, i.e. so we only care about the fractional part of the numbers, or in other terms their behaviour modulo one. We say the sequence is {\it uniformly distributed} if for any interval $I \subset \TT$, $\# \{ 2 \pi a_n \in I : n \leq N \} \sim N |I|$ as $N \to \infty$. By approximating continuous functions by step functions, this implies that if $f: \TT \to \CC$ is continuous, then
%
\[ \frac{f(2 \pi a_1) + \dots + f(2 \pi a_N)}{N} \to \int_{\TT} f(t)\; dt. \]
%
It is the right hand side to which we can apply Fourier summation to obtain a very useful condition. We let $S_Nf$ denote the left hand side of the equation, and $Tf$ the right hand side.

\begin{theorem}[Weyl Condition]
    A sequence $a_1, a_2, \dots \in \TT$ is uniformly distributed if and only if for every $n$, as $N \to \infty$, $e_n(2 \pi a_1) + \dots + e_n(2 \pi a_N) = o(N)$.
\end{theorem}
\begin{proof}
    The condition in the theorem implies that for any trigonometric polynomial $f$, $S_Nf \to Tf$. The $S_N$ are uniformly bounded as functions on $L^\infty(\TT)$, and $T$ is a bounded functional on this space as well. But this means that $\lim S_N f = T f$ for all $f$ in $C(\TT)$, since this equation holds on the dense subset of trigonometric polynomials.
\end{proof}

This technique enables us to completely characterize the equidistribution behaviour of arithmetic sequences. Given a particular $\gamma$, we consider the equidistribution of the sequence $\gamma, 2 \gamma, \dots$, which depends on the irrationality of $\gamma$.

\begin{example}
    Let $\gamma$ be an arbitrary real number. Then for any $n$, if $e_n(2 \pi \gamma) \neq 1$,
    %
    \[ \sum_{m = 1}^N e_n(2 \pi m \gamma) = \frac{e_n(2 \pi (N + 1) \gamma) - 1}{e_n(2 \pi \gamma) - 1} \lesssim 1 = o(N). \]
    %
    If $\gamma$ is an irrational number, then $e_n(2 \pi \gamma) \neq 1$ for all $n$, which implies that $\gamma, 2\gamma, \dots$ is equidistributed. Conversely, if $e_n(2 \pi \gamma) = 1$ for some $n$, we have
    %
    \[ \sum_{m = 1}^N e_n(a_m) = N. \]
    %
    which is not $o(N)$, so the sequence $\gamma, 2\gamma, \dots$ is {\it not} equidistributed. If $\gamma$ is rational, there certainly is $n$ such that $n \gamma \in \ZZ$, and so $e_n(2 \pi \gamma) = 1$.
\end{example}

On the other hand, it is still an open research to characterize, for which $\gamma$ the sequence $\gamma, \gamma^2, \gamma^3, \dots$ is equidistributed. Here is an example showing that there are $\gamma$ for which the sequence is not equidistributed.

\begin{example}
    Let $\gamma$ be the golden ratio $(1 + \sqrt{5})/2$. Consider the sequence
    %
    \[ a_n = \left( \frac{1 + \sqrt{5}}{2} \right)^n + \left( \frac{1 - \sqrt{5}}{2} \right)^n = b_n + c_n. \]
    %
    Then one checks that $a_n$ is a kind of Fibonacci sequence, with $a_{n+1} = a_n + a_{n-1}$, and initial conditions $a_0 = 2$, $a_1 = 1$. One checks that $c_n$ is always negative for odd $n$, and positive for even $n$, and tends to zero as $n \to \infty$. Since $a_n$ is an integer, this means that $d(b_n, \ZZ) = d(\gamma^n, \ZZ) \to 0$. But this means that the average distribution of the $\gamma^n$ modulo one is concentrated at the origin.
\end{example}

\section{The Isoperimetric Inequality}

TODO

\section{The Poisson Equation}

Consider Poisson's equation
%
\[ \Delta u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial u^2}{\partial y^2} = 0 \]
%
on the unit disk. Solutions are called \emph{harmonic}. We can reduce this equation to a problem about Fourier series by writing
%
\[ u(re^{2 \pi it}) = \sum_{n = 0}^\infty a_n(r) e^{2 \pi n i t}. \]
%
We consider a boundary condition, that $u(e^{2 \pi i t}) = f(t)$ for some function $f(t)$ on $\TT$. Working formally, noting that in radial coordinates,
%
\[ \Delta u = \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} + \frac{1}{r^2} \frac{u}{t^2} \]
%
and then taking Fourier series on each side, we find that for each $n \in \ZZ$,
%
\[ a_n''(r) + a_n'(r)/r - 4\pi^2 n^2 a_n(t)/r^2 = 0. \]
%
The only \emph{bounded} solution to this differential equation subject to the initial condition $a_n(1) = \widehat{f}(n)$ is $a_n(t) = \widehat{f}(n) r^{|n|}$. Thus we might guess that
%
\[ u(re^{2 \pi i t}) = \sum_{n \in \ZZ} \widehat{f}(n) r^{|n|} e^{2 \pi n i t} = (P_r * f)(x), \]
%
where $P_r$ is the Poisson kernel. Working backwards through this calculation shows that if $f \in L^1(\TT)$, then the function $u(re^{2 \pi it}) = (P_r * f)(t)$ lies in $C^\infty(\mathbf{D})$ and
%
\[ \lim_{r \to 1} \int_{\TT} |u(re^{2 \pi i t}) - f(t)|\; dt = 0. \]
%
The next theorem shows this is the \emph{only} harmonic function with this propety.

\begin{theorem}
    Suppose $f \in L^1(\TT)$. Then the function $u: \mathbf{D}^\circ \to \CC$ defined for $r > 0$ and $t \in \TT$ by setting
    %
    \[ u(r e^{2 \pi i t}) = (A_r f)(t) \]
    %
    is the \emph{unique} harmonic function in $C^2(\mathbf{D}^\circ)$ such that
    %
    \[ \lim_{r \to 1} \int \left| u(re^{2 \pi i t}) - f(t) \right|\; dt = 0. \]
\end{theorem}
\begin{proof}
    Suppose $u \in C^2(\mathbf{D})$ is harmonic. Then we can find functions $a_n(r)$ for each $n \in \ZZ$ such that
    %
    \[ u(re^{it}) = \sum_{n = -\infty}^\infty a_n(r) e_n(t), \]
    %
    where
    %
    \[ a_n(r) = \int_{\TT} u(re^{it}) \overline{e_n(t)}\; dt. \]
    %
    Because $u \in C^2(\mathbf{D})$, we see that $a_n \in C^2((0,1))$ and $a_n(r)$ is bounded as $r \to 0$. Interchanging integrals shows that
    %
    \[ a_n''(r) + (1/r) a_n'(r) - (n^2/r^2) a_n(r) = 0. \]
    %
    This is an ordinary differential equation, whose only bounded solutions are given by $a_n(r) = A_n r^{|n|}$. If $u(re^{it}) \to f$ in the $L^1$ norm as $r \to 1$, then we conclude
    %
    \[ A_n = \lim_{r \to 1} \int_{\TT} u(re^{it}) \overline{e_n(t)}\; dt = \int_{\TT} f(t) \overline{e_n(t)} = \widehat{f}(n), \]
    %
    so
    %
    \[ u(re^{it}) = \sum \widehat{f}(n) r^{|n|} e_n(t). \qedhere \]
\end{proof}

In particular, the theorem above gives us a map from $L^1(\TT)$ to the space of harmonic functions on the interior of the unit disk. This is a very handy idea in classical harmonic analysis, and is exploited to it's fullest extent in the theory of Hardy spaces.

%If $u$ is only required to converge to $f$ {\it pointwise} on the boundary, then the function we found is no longer required to be unique. Below is an example of a function $u$ which tends to zero pointwise on the boundary, yet does not vanish on the interior of the unit disk.

%\begin{example}
%    If $P_r$ is the Poisson kernel, define $u(r,\theta) = P_r(\theta)$. Then $u$ is harmonic in the unit disk, because $\Delta u = (\Delta P_r)'' = 0$. We calculate
    %
%    \begin{align*}
%        u(r,t) &= \sum_{n = 1}^\infty in r^n [e_n(t) - e_n(-t)]\\
%        &= i \left[ \frac{r e(t)}{(re(t) - 1)^2} - \frac{r e(-t)}{(re(-t) - 1)^2} \right]\\
%        &= i \left[ \frac{re(-t) + r^{-1}e(t) - re(t) - r^{-1}e(-t)}{(re(t) - 1)^2(re(-t) - 1)^2} \right]\\
%        &= \frac{(r - r^{-1}) \sin(t)}{(re(t) - 1)^2(re(-t) - 1)^2}\\
%        &= \frac{(r^2 - 1) \sin(t)}{r (re(t) - 1)^2(re(-t) - 1)^2}
%    \end{align*}
    %
%    In this form, it is easy to see that for a fixed $t$, as $r \to 1$, $u(r,t) \to 0$. However, the denominator tells us this convergence isn't uniform.
%\end{example}

\section{The Heat Equation on a Torus}

Recall the heat equation. We are given an initial temperature distribution on $\TT^d$. We wish to study the propogation of this temperature over time. If we let $u(x,t)$ denote the temperature density at $x \in \TT^d$ and at time $t$, then this temperature evolves under the heat equation
%
\[ \frac{\partial u}{\partial t} = \Delta u. \]
%
We let $f(x) = u(x,0)$ denote the initial heat distribution. To solve this heat equation, we expand $u$ in a Fourier series, i.e. writing
%
\[ u(x,t) = \sum_{n \in \ZZ^d} a_n(t) e^{2 \pi i n \cdot x}. \]
%
We then formally find that for each $n \in \ZZ^d$,
%
\[ a_n'(t) = - 4 \pi^2 |n|^2 a_n(t), \]
%
which we can solve to give
%
\[ a_n(t) = \widehat{f}(n) e^{- 4 \pi^2 |n|^2 t}. \]
%
In particular, we would expect the solution to the heat equation would be given by letting
%
\[ u(x,t) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{-4 \pi^2 |n|^2 t} e^{2 \pi n i t}. \]
%
As with Poisson's equation on the disk, we can write this as
%
\[ u(x,t) = (H_t * f)(x) \]
%
where $H_t$ is the \emph{heat kernel}
%
\[ H_t(x) = \sum_{n \in \ZZ^d} e^{- 4 \pi^2 |n|^2 t} e^{2 \pi n i t}. \]
%
The rapid convergence of this sum implies that $H_t \in C^\infty(\TT^d)$ and that $\widehat{H_t}(n) = e^{-4\pi^2 |n|^2}$ for each $n \in \ZZ^d$. To study this partial differential equation, it suffices to study the heat kernel $H_t$. Unlike in the case of the Poisson kernel however, we have no explicit formula for the heat kernel, which makes the kernel a little harder to work with.

\begin{lemma}
    The family $\{ H_t : t > 0 \}$ is an approximation to the identity.
\end{lemma}
\begin{proof}
    The Poisson summation formula implies that
    %
    \[ H_t(x) = \frac{1}{(4 \pi t)^{d/2}} \sum_{n \in \ZZ^d} e^{- |x + n|^2 / 4 t}. \]
    %
    This shows that $H_t(x) \geq 0$, and that
    %
    \[ \int_{\TT^d} H_t(x) = \frac{1}{(4 \pi t)^{d/2}} \int_{\RR^d} e^{-|x|^2/4 t}\; dx = \int_{\RR^d} e^{-\pi |x|^2}\; dx = 1. \]
    %
    We claim that for $|x| \leq 1/2$,
    %
    \[ \left| H_t(x) - \frac{e^{- x^2/4t}}{(4 \pi t)^{d/2}} \right| \lesssim_d e^{-c/t}, \]
    %
    where $c > 0$ is a universal constant. To prove this, we note this difference is equal to
    %
    \begin{align*}
        (4 \pi t)^{-d/2} \left| \sum_{n \neq 0} e^{- |x + n|^2 / 4t} \right| &\lesssim t^{-d/2} \sum_{n \neq 0} e^{-c' |n|^2 / 4t}\\
        &\lesssim t^{-d/2} e^{-c'/2t} \sum_{n \neq 0} e^{-c'|n|^2/2}\\
        &\lesssim_d t^{-d/2} e^{-c'/2t} \lesssim_d e^{-c/t}.
    \end{align*}
    %
    This implies that for any fixed $\delta > 0$,
    %
    \begin{align*}
        \int_{|x| > \delta} H_t(x) &\lesssim t^{-d/2} \int_{|x| > \delta} e^{-|x|^2/4t}\; dx + e^{-c/t}\\
        &\lesssim_d t^{-d/2} e^{-\delta^2/4t} + e^{-c/t}
    \end{align*}
    %
    which tends to zero as $t \to \infty$. Thus we have proved that $H_t$ is an approximation to the identity.
\end{proof}

\begin{theorem}
    For any $f \in L^1(\TT^d)$, for $1 \leq p < \infty$. Then the function
    %
    \[ u(x,t) = (H_t * f)(x) \]
    %
    lies in $C^\infty(\TT^d \times (0,\infty))$, and for $t > 0$ solves the heat equation. Moreover, $u$ is the unique solution to the heat equation in $C^2(\TT^d \times (0,\infty))$ such that
    %
    \[ \lim_{t \to 0^+} \int_{\TT^d} \left| u(t,x) - f(x) \right|\; dx = 0. \]
\end{theorem}
\begin{proof}
    We have already shown the former statement by the fact that $\{ H_t : t > 0 \}$ is an approximation to the identity. To prove the latter statement, given $u \in C^2(\TT^d \times (0,\infty))$, we can take a Fourier series, letting
    %
    \[ a_n(t) = \int_{\TT^d} u(x,t) e^{-2 \pi i n \cdot x}\; dx. \]
    %
    Then $a_n \in C^2((0,\infty))$ and differentiation under the integral sign shows that $a_n'(t) = -4\pi^2 a_n(t)$, so that $a_n(t) = c_n e^{- 4 \pi^2 t}$ for some $c_n$. But $a_n(t) \to \widehat{f}(n)$ as $t \to 0$ uniformly in $n$ by the convergence assumption, so $c_n = \widehat{f}(n)$. But this implies that $u(x,t) = (H_t * f)(x)$ for each $x \in \TT^d$, since both sides have the same Fourier series for all $t > 0$.
\end{proof}

%Let us consider an example taken from Fourier's original work. Consider heat moving from above ground to below ground, and vice versa. If we let $H(t,y)$ denote the temperature at a depth $y$ into the ground at time $t$, for $y > 0$. Assuming that the material of the ground is homogenous, by choosing appropriate units, the differential equation becomes $H_t = H_{yy}$, a variant of the heat equation. We assume that the heat at the surface changes periodically over the days and seasons, so
%
%\[ H(t,0) = A \cos(2\pi t / D) + B \cos(2 \pi t/Y) + C, \]
%
%where $A,B,C$ are arbitrary constants, $D$ is the length of a day, and $Y$ is the length of a year, so $Y = 365 D$. In our calculation, we assume the regularity condition that $H \in L^\infty [0,\infty)^2$, so the temperature does not magnify infinitely at large depths or large times.

%To solve this equation, we use two tricks: linearity, and Fourier series. We can solve the heat equation by solving the three heat equations with initial conditions $H_D(t,0) = \cos(2\pi t/D)$, $H_Y(t,0) = \cos(2 \pi t/Y)$, and $H_C(t,0) = 1$, and then obtain a general solution by letting $H = A H_D + B H_Y + C H_C$. The third equation is easiest: we let $H_C(t,y) = 1$ for all $t$ and $y$. To solve the other equations, we can use variable separation. Assuming $H_D$ and $H_Y$ are bounded, this means we have
%
%\[ H_D(t,y) = \cos((2 \pi /D) t - (\pi / D)^{1/2} y) e^{- (\pi / D)^{1/2} y}, \]
%\[ H_Y(t,y) = \cos((2\pi/Y)t - (\pi/Y)^{1/2} y) e^{- (\pi/Y)^{1/2} y}. \]
%
%Thus the temperature in the ground splits into a daily heating effect $H_D$, a seasonal heating effect $H_Y$, and a constant temperature $H_C$. From these equations we get several interesting qualitative properties. As we go deeper into the ground, the temperature decays at a rate inversely dependant on the length of time, so even at small depths, the daily temperature becomes neglible, and only the seasonal temperature is important. Experimently, determining the constants in our equation, we determine this happens about half a foot into the ground. Next, the deeper we go in the ground, the more a `time lag' exists, where the seasonal temperature back in time has now travelled to the temperature at the current point in the ground. Experimentally, we determine that about 2-3 metres below ground, the temperature lags by six months. Fourier mentions this is a good depth to build a wine cellar which is cool during the summer months.

\begin{comment}
\section{Seafaring with Fourier}

Here we discuss two problems in seafaring that can be solved quite accurately with Fourier analysis, first done by Kelvin in the late 1800s. Consider first the problem in determining the error of compass measurement on a ship when taking an initial bearing at harbor travelling. Thus for each angle $\theta$, we consider an error $g(\theta)$ such that if, at an angle $\theta$, we take a measurement $f(\theta)$, then $f(\theta) = \theta + g(\theta)$. Often $g$ is up to 20 degrees, but it will suffice to know $g$ up to an angle of two or three degrees, since other systematic errors in travel disturb the angle the ship actually travels by this amount anyway. And thus experimentally we find it suffices to approximate $g$ by a degree four trigonometric polynomial, i.e. we subtitute $g$ for an approximate value
%
\[ g_1(\theta) = A_0 + A_1 \cos \theta + B_1 \sin \theta + A_2 \cos(2\theta) + B_2 \sin(2\theta). \]
%
We can obtain measurements $g(\theta)$ for certain values of $\theta$ by locating landmarks, and 6 measurements suffice to uniquely identify $g_1$ from all other degree five trigonometric polynomials.

Another seafaring problem is to determine the future height of the tide. We expect the height of the tides to be due to periodic forces in nature. If $h(t)$ is the height of the tide, we might expect by linearity of the wave equation that $h(t) = h_1(t) + h_2(t) + \dots$, where $h_1(t)$ is the height with relation to the rotation of the earth and the moon, $h_2(t)$ the height with respect to the rotation of the earth and the sun, and so on and so forth to more neglible values. Each $h_k$ is periodic with some period $\omega_k$. If we assume that each $h_k$ is a trigonometric polynomial, then there is a way to reduce the calculation of the coefficients to a certain integral formula which one can approximate by taking samples of the height of the tides over time. Unfortunately, one must take a large number of samples to obtain this integral formula, but Kelvin designed one of the first automated calculators to approximate this without hard work on the part of the navigator.

\begin{theorem}
    If $h(t) = \sum_{n = 1}^N A_n \cos(\omega_n t)$, where $\omega_1, \dots, \omega_n$ are distinct, then for any $S$,
    %
    \[ A_n = \lim_{T \to \infty} \frac{2}{T} \int_S^{S + T} h(t) \cos(\omega_n t)\; dt. \]
\end{theorem}
\begin{proof}
    We just change variables. If $2 \pi N / \omega_n < T \leq 2 \pi (N + 1)/\omega_n$,
    %
    \begin{align*}
        \int_S^{S+T} h(t) \cos(\omega_n t)\; dt &= N \int_0^{2 \pi/ \omega_n} h(t) \cos(\omega_n t)\; dt + O(1)\\
        &= \frac{N}{\omega_n} \int_0^{2 \pi} \left( \frac{1}{N} \sum_{n = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) \right) \cos(t)\; dt + O(1).
    \end{align*}
    %
    We calculate that
    %
    \[ \frac{1}{N} \sum_{n = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) = A_n \cos(t) + O(1), \]
    %
    and so
    %
    \[ \frac{2}{T} \int_S^{S+T} h(t) \cos(\omega_n t)\; dt = A_n + O(1/T). \]
    %
    and we then take $T \to \infty$.
\end{proof}

\end{comment}








\chapter{The Fourier Transform}

In the last few chapters, we discussed the role of analyzing the frequency decomposition of a periodic function on the real line. In this chapter, we explore the ways in which we may extend this construction to perform frequency analysis for not necessarily periodic functions on the real line, and more generally, in higher dimensional Euclidean space. The only periodic trigonometric functions on $[0,1]$ on the real line had integer frequencies of the form $2\pi n$, whereas on the real line periodic functions can have frequencies corresponding to any real number. The analogue of the discrete Fourier series formula
%
\[ f(x) = \sum_{k = -\infty}^\infty \widehat{f}(k) e^{2 \pi i k x} \]
%
is the Fourier inversion formula
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi, \]
%
where for each real number $\xi$, we define
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(x) e^{- 2 \pi i \xi x}\; dx. \]
%
The function $\widehat{f}$ is known as the {\emph Fourier transform} of the function $f$. It is also denoted by $\mathcal{F}(f)$. The role to which we can justify this formula is the main focus of this chapter. The fact that $\RR$ is non-compact and has infinite measure adds some difficulty to the study of the Fourier transform over the Fourier series. For instance, since $L^p(\RR^d)$ is not included in $L^q(\RR^d)$ for $p \neq q$, which makes it more difficulty to perform a qualitative analysis of convergence in this setting. Nonetheless, the Fourier transform has many properties as the Fourier series. We add an additional difficulty by also analyzing the Fourier transform on $\RR^d$, which, given $f: \RR^d \to \CC$, considers the quantities
%
\[ f(x) \sim \int_{\RR^d} \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\ d\xi,\quad\text{where}\quad \widehat{f}(\xi) = \int_{\RR^d} f(x) e^{- 2 \pi i \xi \cdot x}\; dx \]
%
for $\xi \in \RR^d$. The basic theory of the Fourier transform in one dimension is essentially the same as the theory of the Fourier transform in $d$ dimensions, though as $d$ increases certain more technical considerations such as pointwise convergence become more difficult to understand.

\section{Basic Calculations}

In order to interpret the Fourier transform as an absolutely convergent integral, we require that we are dealing with integrable assumptions. Thus we analyze functions in $L^1(\RR^d)$. During arguments, we can often assume additional regularity properties of $f$, and then apply density arguments to get the result in general. Most of the properties of the Fourier transform are exactly the same as for Fourier series. However, one novel phenomenon in the basic theory is that the Fourier transform of an integrable function is continuous and vanishes at $\infty$.

\begin{theorem}
    For any $f \in L^1(\RR^d)$, $\smash{\| \widehat{f} \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}}$, and $\widehat{f} \in C_0(\RR^d)$.
\end{theorem}
\begin{proof}
    For any $\xi \in \RR^d$,
    %
    \[ |\widehat{f}(\xi)| = \left| \int f(x) e(- \xi \cdot x)\; dx \right| \leq \int |f(x)| |e(- \xi \cdot x)|\; dx = \| f \|_{L^1(\RR^d)}. \]
    %
    If $\chi_I$ is the characteristic function of an $n$ dimensional box, i.e.
    %
    \[ I = [a_1,b_1] \times \dots \times [a_n,b_n] = I_1 \times \dots \times I_n, \]
    %
    then
    %
    \[ \widehat{\chi_I}(\xi) = \int_I e(- \xi \cdot x) = \prod_{k = 1}^n \int_{a_k}^{b_k} e(- \xi_k x_k) = \prod_{k = 1}^n \widehat{\chi_{I_k}}(\xi_k). \]
    %
    where
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) = \begin{cases} \frac{e(- \xi_k a_k) - e(- \xi_k b_k)}{2 \pi i \xi_k} & \xi_k \neq 0, \\ b_k - a_k & \xi_k = 0. \end{cases} \]
    %
    L'Hopital's rule shows $\widehat{\chi_{I_k}}$ is a continuous function. We also have the upper bound
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) \lesssim_{I_k} (1 + |\xi_k|)^{-1} \]
    %
    for all $\xi_k \in \RR$, which implies that
    %
    \[ \widehat{\chi_I}(\xi) = \prod \widehat{\chi_{I_k}}(\xi_k) \lesssim_I \prod \frac{1}{1 + |\xi_k|} \lesssim_n \frac{1}{1 + |\xi|}. \]
    %
    Thus $\widehat{\chi_I}(\xi) \to 0$ as $|\xi| \to \infty$. But this implies the Fourier transform of any step function is continuous and vanishes at $\infty$. Since step functions are dense in $L^1(\RR^d)$, a density argument then gives the result for all integrable functions.
\end{proof}

Elementary properties of integration give the following relations among the Fourier transforms of functions on $\RR^d$. They are strongly related to the translation invariance of the Lebesgue integral on $\RR^d$:
%
\begin{itemize}
    \item If $f^*(x) = \overline{f(x)}$ is the conjugate of a function $f$, then
    %
    \[ \widehat{f^*}(\xi) = \int \overline{f(x)} e^{-2 \pi i x \cdot \xi}\; dx = \overline{\int f(x) e^{2 \pi i \xi \cdot x}} = \overline{\widehat{f}(-\xi)}. \]
    %
    If $f$ is real, the formula above says $\widehat{f}(\xi) = \overline{\widehat{f}(-\xi)}$, and so if we define $a(\xi) = \text{Re}(\widehat{f}(\xi))$, $b(\xi) = \text{Im}(\widehat{f}(\xi))$, then formally we have
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi = 2 \int_0^\infty a(\xi) \cos(2 \pi \xi \cdot x) - b(\xi) \sin(2 \pi \xi \cdot x)\; d\xi. \]
    %
    Thus the Fourier representation formula expresses the function $f$ as an integral in sines and cosines.
    
    \item There is a duality between translation and frequency modulation. For $y \in \RR^d$, we define $(\text{Trans}_y f)(x) = f(x - y)$. If $\xi \in \RR^d$, then we define $(\text{Mod}_\xi f)(x) = e^{2 \pi i \xi \cdot x} f(x)$. We then find that
    %
    \begin{align*}
        \widehat{\text{Trans}_y f}(\xi) &= \int f(x - y) e^{-2\pi i \xi \cdot x}\; dx\\
        &= e^{- 2 \pi i \xi \cdot y} \int f(x) e^{- 2 \pi i \xi \cdot x}\; dx = (\text{Mod}_{-y} \widehat{f})(\xi).
    \end{align*}
    %
    and
    %
    \begin{align*}
        \widehat{\text{Mod}_\xi f}(\eta) = \int e^{2 \pi i \xi \cdot x} f(x) e(- \eta \cdot x)\; dx = \widehat{f}(\eta - \xi) = (\text{Trans}_\xi \widehat{f})(\eta).
    \end{align*}
    %
    Thus we conclude $\mathcal{F} \circ \text{Trans}_y = \text{Mod}_{-y} \circ \mathcal{F}$, and $\mathcal{F} \circ \text{Mod}_\xi = \text{Trans}_\xi \circ \mathcal{F}$.

    \item A very related property to the translational symmetry of the Fourier transform is related to the convolution
    %
    \[ (f * g)(x) = \int f(y) g(x-y)\; dy \]
    %
    of two functions $f,g \in L^1(\RR^d)$. This convolution possesses precisely the same properties as convolution on $\TT$. Most importantly for us,
    %
    \[ \mathcal{F}(f * g) = \mathcal{F}(f) \cdot \mathcal{F}(g), \]
    %
    so convolution in phase space is just a product in frequency space.

    Another related property to the translation symmetry is that the Fourier transform behaves well with respect to differentiation. If $f \in L^1(\RR^d)$ has a weak derivative $D^\alpha f \in L^1(\RR^d)$, then
    %
    \[ \widehat{D^\alpha f}(\xi) = (2 \pi i \xi)^\alpha \widehat{f}(\xi). \]
    %
    In particular, this is true if $f$ is a \emph{Schwartz function}, i.e. an element of
    %
    \[ \mathcal{S}(\RR^d) = \{ f \in C^\infty(\RR^d): |(D_\alpha f)(x)| \lesssim_{\alpha,N} |x|^{-N}\ \text{for all $N, \alpha, x$} \} \]
    %
    which is often a natural place to consider the Fourier transform. Conversely, if $f \in L^1(\RR^d)$, and $x^\alpha f \in L^1(\RR^d)$ for some multi-index $\alpha$, then $\widehat{f}$ has a weak derivative $D^\alpha \widehat{f}$ in $L^1(\RR^d)$, and
    %
    \[ D^\alpha \widehat{f}(\xi) = \widehat{(-2 \pi i x)^\alpha f}(\xi). \]
    %
    In particular, this means that the Fourier transform of a compactly supported element of $L^1(\RR^d)$ lies in $C^\infty(\RR^d)$, and all deriatives of the Fourier transform are integrable.

    \item Let $T: \RR^d \to \RR^d$ be an invertible linear transformation. Then a change of variables $y = Tx$ gives
    %
    \begin{align*}
        \widehat{f \circ T}(\xi) &= \int f(Tx) e^{-2 \pi i \xi \cdot x}\; dx\\
        &= \frac{1}{|\det(T)|} \int f(y) e^{-2 \pi i \xi \cdot T^{-1}y)}\; dy\\
        &= \frac{1}{|\det(T)|} \int f(y) e^{- 2 \pi i T^{-T} \xi \cdot y}\; dy\\
        &= \frac{1}{|\det(T)|} (\widehat{f} \circ T^{-T})(\xi).
    \end{align*}
    %
    Thus we conclude that if $T^*: L^1(\RR^d) \to L^1(\RR^d)$ is the operator defined by setting $T^*(f) = f \circ T$, then 
    %
    \[ \mathcal{F} \circ T^* = \frac{1}{|\det(T)|} \cdot (T^{-T})^* \circ \mathcal{F}. \]
    %
    This property indicates the `cotangent' and symplectic properties of the Fourier transform. One way to think of this property is that one can think of the frequency variable as `cotangent' to the spatial variable, since if we have a coordinate change $y = Tx$, and we define the `coordinatized' Fourier transforms $\mathcal{F}_x$ and $\mathcal{F}_y$ by setting
    %
    \[ \mathcal{F}_x f(\xi) = \int f(x) e^{-2 \pi i x \cdot \xi}\; dx \]
    %
    and
    %
    \[ \mathcal{F}_y f(\eta) = \int f(T^{-1}y) e^{-2 \pi i y \cdot \eta}\; dy, \]
    %
    then the transformation formula tells us that
    %
    \[ \mathcal{F}_y = \mathcal{F}_x \circ (T^{-1})^* = |\det(T)| \cdot (T^T)^* \circ \mathcal{F}_x, \]
    %
    i.e. $\mathcal{F}_y f(\eta) = |\det(T)| \cdot \mathcal{F}_x f(\xi)$, where $\eta = T^T \xi$. By interpreting $\xi$ and $\eta$ as \emph{cotangent} vectors to the $x$ and $y$ coordinates respectively, one can therefore use this symmetry property to define a version of the Fourier transform that is invariant under area preserving changes of coordinates.

    \item As a special case of the theorem above, if $a \in \RR$ and $\text{Dil}_a: L^1(\RR^d) \to L^1(\RR^d)$ is the operator defined by setting
    %
    \[ (\text{Dil}_a f)(x) = f(x/a), \]
    %
    then
    %
    \[ \widehat{\text{Dil}_a f} = a^d \cdot \text{Dil}_{1/a} \widehat{f} \]
    %
    As we increase $a$, the values of $f$ are traced over more quickly, and so it is natural for the support of $f$ to lie over larger frequencies. Note that this dilation preserves the $L^\infty$ norm of $f$, but the Fourier transform preserves the $L^1$ norm. We could have alternatively consider the $L^1$ preserving dilation $f \mapsto a^{-d} f(x/a)$, which on the frequency side of things preserves the $L^\infty$ norm. We can consider various magnitude adjustments; for instance, $f \mapsto a^{-d/2} f(x/a)$ preserves the $L^2$ norm in both space and frequency. But regardless, as we concentrate $f$ in a smaller neighborhood, $\widehat{f}$ is dilated so it's support lies in a larger and larger neighborhood.

    \item Another special case is that if $R \in O_n(\RR)$, then $\widehat{f \circ R}(\xi) = \widehat{f}(R \xi)$, i.e. $\mathcal{F} \circ R^* = R^* \circ \mathcal{F}$. In particular, if $f$ is a radial function, so $f \circ R = f$ for any $R$, then $\widehat{f}(R \xi) = \widehat{f}(\xi)$ for any $R \in O_n(\RR)$, so $\widehat{f}$ is also a radial function. If $f$ is even, so $f(x) = f(-x)$ for all $x$, then $\widehat{f}(\xi) = \widehat{f}(-\xi)$ for all $\xi$, so $\widehat{f}$ is even. Similarily, if $f$ is odd, then $\widehat{f}$ is odd. In particular, the space of radial functions is an \emph{invariant subspace} with respect to the Fourier transform, which becomes important in more advanced theories, such as the theory of spherical harmonics.
\end{itemize}

%\begin{theorem}
%    If $f \in L^1(\RR^d)$, and $x_k f \in L^1(\RR^d)$, then $\widehat{f}$ has a weak derivative in the $L^\infty$ norm, and $\widehat{f}_k(\xi) = - 2 \pi i (x_k f)^\ft(\xi)$.
%\end{theorem}
%\begin{proof}
%    Note that a change of variables implies
    %
%    \[ (\Delta_h \widehat{f})(\xi) = \int f(x) \frac{e^{-2\pi i h x_k} - 1}{h} e^{-2 \pi i \xi \cdot x}\; dx = \widehat{g_h}(\xi), \]
    %
%    where
    %
%    \[ g_h(x) = f(x) \frac{e^{2 \pi i h x_k} - 1}{h}. \]
    %
%    Note that
    %
%    \[ \left| \frac{e^{2 \pi i h x_k} - 1}{h} \right| = O(1 + |x_k|). \]
    %
%    Since $x_k f$ is integrable, we can apply the dominated convergence theorem. Because $(e^{2 \pi i h x_k} - 1)/h$ tends to $-2 \pi i x_k f(x)$ as $h \downarrow 0$, the function $g_h$ tends to $-2\pi i x_k f$ in $L^1(\RR^d)$. Taking Fourier transforms, we conclude that $\Delta_h \widehat{f} = \widehat{g_h}$ converges uniformly to $(-2 \pi i x_k f)^\ft(\xi)$.
%\end{proof}

%\begin{remark}
%   If $f$ no longer has compact support, but $D_k f$ vanishes rapidly at infinity, then we can normally still establish that $D_k f$ is the derivative of $f$ in $L^1(\RR^n)$. Indeed, suppose $|(D_k f)(x)| \leq g(|x|)$, where $g$ is an increasing function with $\int_0^\infty t^{n-1} g(t) < \infty$, then surely $\Delta_h f$ converges to $D_k f$ in $L^1$ on any compact set, which implies that for any $M$, using the mean value theorem again,
    %
%   \begin{align*}
%       \int_{\RR^n} &|(\Delta_h f)(x) - D_k f(x)|\; dx \leq o_M(1) + \int_{|x| > M} |(\Delta_h f)(x)| + |D_k f(x)| \\
%       &\leq o_M(1) + O \left( \int_{|x| > M} g(|x| + |h|)\; dx \right) = o_M(1) + O \left( \int_M^\infty t^{n-1}g(t)\; dt \right)\\
%   \end{align*}
    %
%   If we choose $M$ large enough that the big $O$ term is $\leq \varepsilon$, then we find $\| \Delta_h f - D_k f \|_1 \leq \varepsilon + o_M(1)$, and taking $\varepsilon \to 0$ shows the convergence. This shows the derivatives exist if, for instance, $f$ is a Schwarz function, since then $|D_k f(x)| \lesssim 1/(1 + |x|^{n+1})$.
%\end{remark}

%\begin{theorem}
%    If $f$ has a weak derivative $f_k$ in the $L^1$ norm, $\widehat{f_k}(\xi) = 2 \pi i \xi_k \widehat{f}(\xi)$.
%\end{theorem}
%\begin{proof}
%    It suffices to note that
    %
%    \[ \widehat{\Delta_h f}(\xi) = \frac{e(h \xi_k) - 1}{h} \widehat{f}(\xi). \]
    %
%    Since $\Delta_h f \to f_k$ in $L^1$, $\widehat{\Delta_h f} \to \widehat{f_k}$ uniformly, and in particular, converges to $\widehat{f_k}$ pointwise. But we know $\widehat{\Delta_h f}$ converges pointwise to $2 \pi i \xi_k \widehat{f}(\xi)$.
%\end{proof}

%\begin{theorem}
%   If $X$ is a homogenous space of functions, the $f * K_\delta$ converges to $f$ in the norm associated with $X$.
%\end{theorem}
%\begin{proof}
%   Given a continuous function function $F: \TT \to X$, we define the formal Riemann integral of functions as
    %
%   \[ \int_{\TT} F(x)\; dx = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N F(2 \pi /N) \]
    %
%   which exists for the same reason the Riemann integral of a continuous real valued function exists. Now we can consider the formal function theoretic convolution
    %
%   \[ \int_{\TT} K_\delta(x) f_x\; dx \]
    %
%   This is equal to $K_\delta * f$, because the $L^1$ norm lower bounds the norm on $X$, so that the limit with respect to the $L^1$ norm is the same as with respect to the norm on $X$, and
    %
%   \[ s \]
    %
%   \[ \int_{\TT} K_\delta(x) f_x\; dx - f = \int_0^{2\pi} K_\delta(x)[f_x - f]\; dx \]
    %
%   If we choose 
%\end{proof}
%
%More generally, if we equip a translation invariant subspace of $L^1(\RR^n)$ with a norm lower bounded up to a constant by the $L^1$ norm which turns the space into a Banach space, then $f * K_\delta$ converges to $f$ in that norm. If in addition, the $K_\delta$ satisfy $|K_\delta(x)| \lesssim \delta^{-n}$, and $|K_\delta(x)| \lesssim \delta/|x|^{n+1}$, then $f * K_\delta$ converges to $f$ almost everywhere. 

\section{The Fourier Algebra}

The space
%
\[ \mathbf{A}(\RR^d) = \left\{ \widehat{f}: f \in L^1(\RR^d) \right\} \]
%
is called the \emph{Fourier algebra}. The last theorem shows $\mathbf{A}(\RR^d) \subset C_0(\RR^d)$, but it is {\it not} the case that $\mathbf{A}(\RR^d) = C_0(\RR^d)$. Current research cannot give a satisfactory description of the elements of $\mathbf{A}(\RR^d)$, and a simple characterization is unlikely. The next lemma will be used to show $\mathbf{A}(\RR^d) \neq C_0(\RR^d)$.

\begin{lemma}
    For any $0 \leq a < b < \infty$, independently of $a$ and $b$,
    %
    \[ \left| \int_a^b \frac{\sin x}{x} \right| = O(1). \]
\end{lemma}
\begin{proof}
    Since $\| \sin(x)/x \|_{L^\infty(\RR)} \leq 1$, we may assume $b > 1$, for otherwise we obtain a trivial bound. This also implies
    %
    \begin{align*}
        \left| \int_a^b \frac{\sin x}{x}\; dx \right| \leq 1 + \left| \int_1^b \frac{\sin x}{x}\; dx \right|.
    \end{align*}
    %
    An integration by parts then shows that
    %
    \[ \left| \int_1^b \frac{\sin x}{x}\; dx \right| \leq \left| \left( \cos 1 - \frac{\cos b}{b} \right) \right| + \left| \int_1^b \frac{\cos x}{x^2}\; dx \right| \lesssim 1. \qedhere \]
\end{proof}

\begin{theorem}
    $\mathbf{A}(\RR) \neq C_0(\RR)$. In particular, $\mathbf{A}(\RR)$ does not contain any odd functions $g$ in $C_0(\RR)$ such that
    %
    \[ \limsup_{b \to \infty} \left| \int_1^b \frac{g(\xi)}{\xi}\; d\xi \right| = \infty. \]
\end{theorem}
\begin{proof}
    Suppose $f \in L^1(\RR)$, and $\widehat{f} \in C_0(\RR)$ is an odd function. Then we know
    %
    \[ \widehat{f}(\xi) = -i \int_{-\infty}^\infty f(x) \sin(2 \pi \xi x)\; dx. \]
    %
    If $b \geq 1$, an application of Fubini's theorem shows that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| = \left| \int_{-\infty}^\infty f(x) \left( \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right)\; dx \right|. \]
    %
    But
    %
    \[ \left| \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right| = \left| \int_{2 \pi x}^{2 \pi b x} \frac{\sin \xi}{\xi}\; d\xi \right| \lesssim 1. \]
    %
    Thus we obtain that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| \lesssim \| f \|_{L^1(\RR)}. \]
    %
    For instance, this implies that there is no $f \in L^1(\RR)$ such that
    %
    \[ \widehat{f}(\xi) = \text{sgn}(\xi) \frac{|\sin(2 \pi \xi)|}{\log | \xi |} \]
    %
    for all $\xi \in \RR$, since
    %
    \[ \lim_{b \to \infty} \int_1^b \frac{|\sin(2 \pi \xi)|}{\xi \log |\xi|} = \infty. \qedhere \]
\end{proof}

On the other hand, for a finite measure $\mu$ on $\RR^d$, we can define the Fourier transform to be the continuous function
%
\[ \widehat{\mu}(\xi) = \int_{\RR^d} e^{-2 \pi i \xi \cdot x} d\mu(x). \]
%
In this case, the family of continuous functions which are the Fourier transforms of finite measures is precisely the family of $f \in C(\RR^d)$ which are \emph{positive definite}, in the sense that for each $x_1,\dots,x_N \in \RR^d$ and $\xi_1,\dots,\xi_N \in \CC$,
%
\[ \sum_{i = 1}^N \sum_{j = 1}^N f(x_i - x_j) \xi_i \xi_j \geq 0. \]
%
The theorem, proved by Bochner, is best addressed in the more general case of harmonic analysis on locally compact abelian groups, and so we leave the proof of this for another time.

\section{Basic Convergence Properties}

As we might expect from the Fourier series theory, if $f \in C(\RR) \cap L^1(\RR^d)$ and $\widehat{f} \in L^1(\RR^d)$, then the formula
%
\[ f(x) = \int_{\RR^d} \widehat{f}(\xi) e(\xi \cdot x)\; dx \]
%
holds for all $x \in \RR^d$. Unlike in the case of the Fourier series, we cannot test our function against trigonometric polynomials. On the other hand, we have a multiplication formula which often comes in useful.

\begin{theorem}[The Multiplication Formula]
    If $f,g \in L^1(\RR^d)$,
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \widehat{f}(\xi) g(\xi)\; dx. \]
\end{theorem}
\begin{proof}
    If $f, g \in L^1(\RR^d)$, then $\widehat{f}$ and $\widehat{g}$ are bounded, continuous functions on $\RR^d$. In particular, $\widehat{f} g$ and $f \widehat{g}$ are integrable. A simple use of Fubini's theorem gives
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \int f(x) g(\xi) e(- \xi \cdot x)\; dx\; d\xi = \int g(\xi) \widehat{f}(\xi)\; d\xi. \qedhere \]
\end{proof}

In particular, if $f \in L^1(\RR^d)$ and $\widehat{f} = 0$, then for any $g \in L^1(\RR^d)$,
%
\[ \int_{\RR^d} f(x) \widehat{g}(x)\; dx = 0. \]
%
If $x_0$ is a continuity point of $f$, then it suffices to choose a function $g$ such that the majority of the mass of $\widehat{g}$ is concentrated at the point $x_0$. A natural choice here is to use a \emph{Gaussian function}.

Let $g(x) = e^{- \pi x^2}$. Then $g \in L^1(\RR)$. Then $g'(x) = - 2 \pi x g(x)$, and since $x g \in L^1(\RR)$,w e conclude that
%
\[ \frac{d \widehat{g}(\xi)}{d\xi} = - 2 \pi \xi \widehat{g}(\xi). \]
%
Since $\widehat{g}(0) = \int_{-\infty}^\infty e^{- \pi x^2} = 1$, we conclude from solving the ordinary differential equation that
%
\[ \widehat{g}(\xi) = e^{- \pi \xi^2} = g(\xi). \]
%
Tensorizing, it follows that if $g(x) = e^{-\pi |x|^2}$ is the element of $L^1(\RR^d)$, then
%
\[ \widehat{g}(\xi) = e^{- \pi |\xi|^2} = g(x). \]
%
In particular, if for $x_0 \in \RR^d$ and $\delta > 0$, we define
%
\[ g_{x_0,\delta}(\xi) = e^{- 2 \pi i x_0 \cdot \xi)} g(\delta \xi) \]
%
then the symmetries of the Fourier transform imply that
%
\[ \widehat{g_{x_0,\delta}}(\xi) = \delta^{-d} e^{-(\pi/\delta^2) |\xi - x_0|^2}. \]
%
Thus we conclude that if $\widehat{f} = 0$, then for any $x_0$ and $\delta$,
%
\[ \delta^{-d} \int_{\RR^d} f(x) e^{-(\pi/\delta^2) |\xi - x_0|^2} = 0. \]
%
A simple approximation as $\delta \to 0$ gives the following result.

\begin{theorem}
    Suppose $f \in L^1(\RR^d)$ and $\widehat{f} = 0$. Then $f$ vanishes at any of it's continuity points. In particular, if $f \in L^1(\RR^d) \cap C(\RR^d)$ and $\widehat{f} = 0$, then $f = 0$.
\end{theorem}

As in the case of the Fourier series, if $f \in L^1(\RR^d)$ and $\widehat{f} \in L^1(\RR^d)$, then the multiplication formula implies that for any $g \in L^1(\RR^d)$ with $\widehat{g} \in L^1(\RR^d)$,
%
\[ \int_{\RR^d} \widehat{\widehat{f}}(x) g(x)\; dx = \int_{\RR^d} \widehat{f}(\xi) \widehat{g}(\xi)\; d\xi = \int_{\RR^d} f(x) \widehat{\widehat{g}}(x)\; dx. \]
%
If $g = g_{x_0,\delta}$ for some $x_0$ and $\delta$, then it is simple to calculate that $\widehat{\widehat{g}}(x) = g(-x)$. Thus we conclude that for any such function,
%
\[ \int_{\RR^d} \widehat{\widehat{f}}(x) g(x)\; dx = \int_{\RR^d} f(-x) g(x)\; dx. \]
%
In particular, a similar approximation technique to the last theorem gives the Fourier inversion theorem.

\begin{theorem}
    Suppose $f \in L^1(\RR^d)$ and $\widehat{f} \in L^1(\RR^d)$. Then for any continuity point $x$ of $f$,
    %
    \[ f(x) = \int_{\RR^d} \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; dx. \]
    %
    In particular, if we also assume $f \in C(\RR^d)$, then the inversion formula holds everywhere.
\end{theorem}

\section{Alternative Summation Methods}

As with the Fourier series, we can obtain results for more general functions by `dampening' the integration factor. To do this, we consider `alternate integral' methods which can define the integral of a measurable function that is not necessarily absolutely integrable.

\begin{example}
    Even if $f$ is a non integrable function, the functions $f(x) e^{-\delta |x|}$ may be integrable for $\delta > 0$. If this is the case, we say $f$ is \emph{Abel summable} to a value $A$ if
    %
    \[ \lim_{\delta \to 0} \int_{\RR^d} f(x) e^{-\delta |x|}\; dx = A \]
    %
    For each $\delta > 0$ and $f \in L^1(\RR^d)$, we let
    %
    \[ (A_\delta f)(x) = \int_{\RR^d} \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|}\; d\xi. \]
    %
    Thus $A_\delta f$ represents the Abel sums of the Fourier inversion formula.
\end{example}

If $f \in L^1(\RR^d)$, then the dominated convergence theorem implies that
%
\[ \int_{\RR^d} f(x) e^{-\delta |x|}\; dx \to \int_{\RR^d} f(x)\; dx. \]
%
so $f$ is Abel summable. However, $f$ may be Abel summable even if $f$ is not integrable. For instance, if $f(x) = \sin(x)/x$, then $f$ is not integrable, yet $f$ is Abel summable to $\pi$ over the real line.

\begin{example}
    Similarily, we can consider the Gauss sums
    %
    \[ \int f(x) e^{-\delta |x|^2}\; dx \]
    %
    We say $f$ is Gauss summable to if these values converge as $\delta \to 0$. For $f \in L^1(\RR^d)$, we let
    %
    \[ (G_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|^2}\; d\xi. \]
    %
    Then as $\delta \to 0$, $G_\delta f$ represents the Gauss sums of the Fourier inversion formula.
\end{example}

\begin{example}
    For $d = 1$, we can also consider the Fej\'{e}r sums
    %
    \[ (\sigma_\delta f)(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi \cdot x) \left( \frac{\sin(\delta \pi \xi)}{\delta \pi \xi} \right)^2\; d\xi, \]
    %
    which are analogous to the Fej\'{e}r sums in the periodic setting.
\end{example}

\begin{example}
    In basic calculus, the integral of a function $f$ over the entire real line is defined as
    %
    \[ \int_{-\infty}^\infty f(x)\; dx = \lim_{R \to \infty} \int_{-R}^R f(x)\; dx. \]
    %
    These integrals can be written as the integral of $f \chi_{[-R,R]}$, and so in a generalized sense, we can integrate a function $f$ if $f \chi_{[-R,R]}$ is integrable for each $N$, and the integrals of these functions converge as $t \to \infty$. Thus we study
    %
    \[ (S_R f)(x) = \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{example}

Abel summability is more general than the piecewise limit integral considered in the last example, as the next lemma proves.

\begin{lemma}
    Suppose $f \in L^1_{\text{loc}}(\RR)$, that
    %
    \[ \lim_{R \to \infty} \int_{-R}^R f(x)\; dx \]
    %
    exists, and that $f(x) e^{-\delta x^2}$ is absolutely integrable for each $\delta > 0$. Then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int_{-\infty}^\infty f(x) e^{-\delta |x|^2} = \lim_{R \to \infty} \int_{-R}^R f(x)\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{R \to \infty} \int_{-R}^R f(x)\; dx = A. \]
    %
    For each $x \geq 0$, write
    %
    \[ F(x) = \int_{-x}^x f(x)\; dx. \]
    %
    Then $F$ is continuous and differentiable almost everywhere, and $F(x) \to A$ as $x \to \infty$. We know that $F'(x) = f(x) + f(-x)$, and an integration by parts gives for each $s > 0$,
    %
    \begin{align*}
        \int_{-s}^s f(x) e^{-\delta x^2}\; dx &= \int_0^s [f(x) + f(-x)] e^{-\delta x^2}\; dx\\
        &= F(s) e^{-\delta s^2} + 2 \delta \int_0^s x F(x) e^{-\delta x^2}\; dx.
    \end{align*}
    %
    Taking $s \to \infty$, using the fact that $F$ is bounded so that $F(s) e^{-\delta s^2} \to 0$, we conclude
    %
    \[ \int_{-\infty}^\infty f(x) e^{-\delta x^2}\; dx = 2 \delta \int_0^\infty x F(x) e^{-\delta x^2}\; dx. \]
    Given $\varepsilon > 0$, fix $t$ such that $|F(s) - A| \leq \varepsilon$ for $s \geq t$. Then
    %
    \begin{align*}
        \left| \int f(x) e^{-\delta x^2}\; dx - A \right| &\leq 2 \delta \left| \int_0^t x F(x) e^{-\delta x^2}\; dx \right|\\
        &\quad + 2 \delta \varepsilon \left| \int_t^\infty x e^{-\delta x^2} \right|\\
        &\quad + \left| 2 \delta A \int_t^\infty x e^{-\delta x^2}\; dx - A \right|.
    \end{align*}
    %
    The first and second components of this upper bound can each be made smaller than $\varepsilon$ for small enough $\delta$. And
    %
    \[ 2 \delta \int_t^\infty x e^{-\delta x^2}\; dx = e^{-\delta t^2} \]
    %
    So the third term is equal to $|A| |1 - e^{-\delta t^2}|$ and so for small enough $\delta$, we can also bound this by $\varepsilon$. Thus we have shown for small enough $\delta$ that
    %
    \[ \left| \int f(x) e^{-\delta x^2}\; dx - A \right| \leq 3 \varepsilon. \]
    %
    It now suffices to take $\varepsilon \to 0$.
\end{proof}

Abel summation is even more general than Gauss summation.

\begin{lemma}
    If $f$ is Gauss summable, and $f(x) e^{-\delta |x|}$ is absolutely integrable for each $\delta > 0$, then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = A. \]
    %
    If there existed constants $c_n$ and $\lambda_n$ such that $e^{-\delta |x|} = \sum c_n e^{-(\lambda_n \delta |x|)^2}$, this theorem would be easy. This is not exactly true, but we do have the {\it subordination principle}, which says
    %
    \[ e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\delta^2 |x|^2/4u}\; du. \]
    %
    This formula, which is proved using basic complex analysis, is shown later on in this chapter. Applying Fubini's theorem, this means that
    %
    \[ \int f(x) e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du. \]
    %
    For any fixed $t > 0$, we certainly have
    %
    \[ \lim_{\delta \to 0} \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du = A \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \]
    %
    And this is equal to $A(1 + o(1))$ as $t \to 0$. And now we calculate
    %
    \[ \int_0^t \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; du \leq \left\| \frac{e^{-u}}{\sqrt{\pi u}} \right\|_{L^1[0,t]} \left\| \int f(x) e^{-\delta^2 |x|^2/4u} \right\|_{L^\infty[0,t]} \]
    %
    The left norm tends to zero as $t \to 0$. And as $u \downarrow 0$, the dominated convergence theorem implies that
    %
    \[ \int f(x) e^{-\delta |x|^2/4u} \to 0. \]
    %
    This completes the proof.
\end{proof}

For any family of functions $\Phi_\delta$, we can consider the `$\Phi$ sums'
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
and the corresponding Fourier transform operators
%
\[ S_\delta(f,\Phi)(x) = \int \widehat{f}(x) e(\xi \cdot x) \Phi_\delta(\xi)\; d\xi. \]
%
We say $f$ is $\Phi$ summable to a value if
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
converges. In all the examples we will consider, we construct $\Phi$ sums by fixing a function $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and defining $\Phi_\delta(x) = \Phi(\delta x)$. When this is the case $f(x) \Phi_\delta(x)$ converges to $f(x)$ pointwise for each $x$ as $\delta \to 0$. Thus if $f \in L^1(\RR^d)$, the dominated convergence theorem implies that $f$ is $\Phi$ summable to it's usual integral. We now use these summability kernels to understand the Fourier summation formula.

\begin{theorem}[The Multiplication Formula]
    If $f,g \in L^1(\RR^d)$,
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \widehat{f}(\xi) g(\xi)\; dx. \]
\end{theorem}
\begin{proof}
    If $f, g \in L^1(\RR^d)$, then $\widehat{f}$ and $\widehat{g}$ are bounded, continuous functions on $\RR^d$. In particular, $\widehat{f} g$ and $f \widehat{g}$ are integrable. A simple use of Fubini's theorem gives
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \int f(x) g(\xi) e(- \xi \cdot x)\; dx\; d\xi = \int g(\xi) \widehat{f}(\xi)\; d\xi. \qedhere \]
\end{proof}

If $\Phi$ is integrable, then the multiplication formula shows
%
\begin{align*}
    S_\delta(f,\Phi) &= \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) d\xi\\
    &= \int f(x) (\text{Mod}_x (\delta_\delta \Phi))^\ft(x)\; dx = \delta^{-n} \int f(x) \cdot \widehat{\Phi} \left( \frac{x - y}{\delta} \right)\; dx.
\end{align*}
%
Thus if we define $K^\Phi_\delta(x) = \delta^{-d} \widehat{\Phi}(-x/\delta)$, then $S_\delta(f,\Phi) = K^\Phi_\delta * f$. Thus we have expressed the summation operators as convolution operations.

We now recall some notions of convolution kernels that help us approximate functions. Recall that if a family of kernels $\{ K_\delta \}$ satisfies
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item The values $\{ \| K_\delta \|_{L^1(\RR^d)} \}$ are uniformly bounded in $\delta$.

    \item For any $\varepsilon > 0$,
    %
    \[ \lim_{\delta \to 0} \int_{|\xi| \geq \varepsilon} |K_\delta(\xi)|\; d\xi \to 0. \]
\end{itemize}
%
then the family forms a \emph{good kernel}. If this is the case, then $f * K_\delta$ converges to $f$ in the $L^p$ norms if $f \in L^p(\RR^d)$, and converges to $f$ uniformly if $f$ is continuous and bounded. If we have the stronger conditions that
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item $\| K_\delta \|_{L^\infty(\RR^d)} \lesssim 1/\delta^d$.
    \item For any $\delta > 0$ and $\xi \in \RR^d$,
    %
    \[ |K_\delta(\xi)| \lesssim \frac{\delta}{|\xi|^{d+1}}. \]
\end{itemize}
%
then the family $\{ K_\delta \}$ is an approximation to the identity, and so $(K_\delta * f)(x)$ converges to $f(x)$ for any $x$ in the Lebesgue set of $f$. For a particular function $\Phi$, the family $\{ K_\delta^\Phi \}$ forms a good kernel as $\delta \to 0$ if $\widehat{\Phi} \in L^1(\RR^d)$ and $\int \widehat{\Phi}(\xi)\; d\xi = 1$, and forms an approximation to the identity if we assume in addition that $\Phi \in C^{d+1}(\RR^d)$. Thus we conclude that as $\delta \to 0$, if $\Phi$ satisfies the appropriate conditions then as $\delta \to 0$, the summations $S_\delta(f,\Phi)$ converge to $f$ in the appropriate sense as considered above.

\begin{example}
    We obtain the {\it Fej\'{e}r kernel} $F_\delta$ from the initial function
    %
    \[ F(x) = \left( \frac{\sin \pi x}{\pi x} \right)^2 \]
    %
    Using contour integration, we now show
    %
    \[ \widehat{F}(\xi) = \begin{cases} 1 - |\xi| & : |\xi| \leq 1\\ 0 &: |\xi| > 1 \end{cases} \]
    %
    Since this functions is compactly supported, with total mass one, it is easy to see the corresponding Kernel $K^F_\delta$ are an approximation to the identity. Thus $\sigma_\delta f$ converges to $f$ in all the manners described above.

    Since $F$ is an even function, $\widehat{F}$ is even, and so we may assume $\xi \geq 0$. We initially calculate
    %
    \[ \widehat{F}(\xi) = \int_{-\infty}^\infty \left( \frac{\sin(\pi x)}{\pi x} \right)^2 e(- \xi x)\; dx = \frac{1}{\pi} \int_{-\infty}^\infty \left( \frac{\sin x}{x} \right)^2 e(- 2 \xi x) \; dx. \]
    %
    Now we have
    %
    \[ (\sin z)^2 = \left( \frac{e(z) - e(-z)}{2i} \right)^2 = \frac{(2 - e^{2iz}) - e^{-2iz}}{4}. \]
    %
    This means
    %
    \begin{align*}
        \frac{(\sin z)^2}{z^2} e^{- 2 i \xi z} &= \frac{2e^{-2 i \xi z} - e^{-2(\xi + 1) i z}) - e^{-2(\xi - 1)iz}}{4z^2 } = \frac{f_\xi(z) + g_\xi(z)}{4}.
    \end{align*}
    %
    For $\xi \geq 0$, $f_\xi(z)$ is $O_\xi(1/|z|^2)$ in the lower half plane, because if $\text{Im}(z) \leq 0$,
    %
    \[ |2e^{-2 i \xi z} - e^{-2(\xi + 1) z}| \leq 2e^{2\xi} + e^{2(\xi + 1)} = O_\xi(1). \]
    %
    For $\xi \geq 1$, $g_\xi(z)$ is also $O_\xi(1/|z|^2)$ in the lower half plane, because
    %
    \[ |e^{-2(\xi - 1)iz}| \leq e^{2(\xi - 1)}.  \]
    %
    Now since $(\sin x/x)^2 e^{-2 i \xi x}$ can be extended to an entire function on the entire complex plane, which is bounded on any horizontal strip, we can apply Cauchy's theorem and take limits to conclude that
    %
    \begin{align*}
        \widehat{F}(\xi) = \frac{1}{\pi} \int_{-\infty}^\infty \frac{(\sin x)^2}{x^2} e^{-2 i \xi x}\; dx &= \frac{1}{\pi} \int_{-\infty}^{\infty} \frac{(\sin (x - iy)^2}{(x - iy)^2} e^{-2 i \xi x  -2 \xi y}\; dx\\
        &= \frac{1}{4 \pi} \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx.
    \end{align*}
    %
    If $\xi \geq 1$, the functions $f_\xi$ and $g_\xi$ are both negligible in the lower half plane, and have no poles in the lower half plane, so if we let $\gamma$ denote the curve of length $2 \pi n$ travelling anticlockwise along the lower semicircle with vertices $-n - iy$ and $n - iy$, then because $|z| \geq n$ on $\gamma$,
    %
    \begin{align*}
        \int_{-n}^n f_\xi(x - iy) + g_\xi(x - iy)\; dx &= \int_\gamma f_\xi(z) + g_\xi(z)\; dz\\
        &= \text{length}(\gamma) \| f_\xi + g_\xi \|_{L^\infty(\gamma)}\\
        &= (2 \pi n) O_\xi(1/n^2) = O_\xi(1/n),
    \end{align*}
    %
    and so we conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx = 0. \]
    %
    This means $\widehat{F}(\xi) = 0$. If $0 \leq \xi \leq 1$, then $f_\xi$ is still small in the lower half plane, so we can conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy)\; dx = 0. \]
    %
    But $g_\xi$ is now small in the upper half plane. For $\text{Im}(z) \geq -y$,
    %
    \[ |e^{-2(\xi - 1)iz}| = |e^{2(1 - \xi)iz}| \leq e^{2(1 - \xi)y}, \] 
    %
    so $g_\xi(z) = O_\xi(1/|z|^2)$ in the half plane above the line $\RR - iy$. The only problem now is that $g_\xi$ has a pole in this upper half plane, at the origin. Taking Laurent series here, we find that the residue at this point is $2i(\xi - 1)$. Thus, if we let $\gamma$ be the curve obtained from travelling anticlockwise about the upper semicircle with vertices $-n - iy$ and $n - iy$, then $|z| \geq n - y$ on this curve, and the residue theorem tells us that
    %
    \[ \int_{-n}^n g_\xi(x - iy)\; dx + \int_\gamma g_\xi(z)\; dz = 2\pi i (2i(\xi - 1)) = 4 \pi (1 - \xi), \]
    %
    and we now find that, as with the evaluation of the previous case,
    %
    \[ \int_\gamma g_\xi(z)\; dz \leq (2 \pi n) O_{\xi,y}(1/n^2) = O_{\xi,y}(1/n). \]
    %
    Taking $n \to \infty$, we conclude
    %
    \[ \int_{-\infty}^\infty g_\xi(x - iy)\; dx = 4 \pi (1 - \xi), \]
    %
    and putting this all together, we conclude that $\widehat{F}(\xi) = 1 - \xi$.
%   It is interesting in this particular case to note that
    %
%   \begin{align*}
%       \int_{-1}^1 (1 - |\xi|) e^{2 \pi i\xi x}\; d\xi &= 2 \int_0^1 (1 - \xi) \cos(2 \pi \xi x)\; d\xi\\
%       &= 2 \left( \left. \frac{(1 - \xi) \sin(2 \pi \xi x)}{2 \pi x} - \frac{\cos(2 \pi \xi x)}{(2 \pi x)^2} \right|_0^1 \right)\\
%       &= 2 \frac{1 - \cos(2 \pi x)}{(2 \pi x)^2} = \frac{\sin^2(\pi x)}{(\pi x)^2} = F(x)
%   \end{align*}
    %
%   which is exactly the inversion formula we want for all $L^1$ functions.
\end{example}

\begin{example}
    In the next paragraph, we calculate that if $\Phi(x) = e^{-\pi |x|^2}$, then $\widehat{\Phi} = \Phi$. Thus if we define the \emph{Weirstrass kernel} by
    %
    \[ W_\delta(\xi) = \delta^{-d} e^{-\pi |x|^2/\delta^2}, \]
    %
    then $G_\delta(f) = W_\delta * f$. Since the family $\{ W_\delta \}$ is an approximation to the identity, this shows $G_\delta(f)$ converges to $f$ in all the appropriate senses.

    Since $\Phi$ breaks onto products of exponentials over each coordinate, it suffices to calculate the Fourier transform in one dimension, from which we can obtain the general transform by taking products. In the one dimensional case, since $\Phi'(x) = -2 \pi x e^{- \pi x^2}$ is integrable, we conclude that $\widehat{\Phi}$ is differentiable, and
    %
    \[ (\widehat{\Phi})'(\xi) = (- 2 \pi i \xi \Phi)^\ft(\xi) = i (\Phi')^\ft(\xi) = i (2 \pi i \xi) \widehat{\Phi}(\xi) = - 2 \pi \xi \widehat{\Phi}(\xi) \]
    %
    The uniqueness theorem for ordinary differential equations says that since
    %
    \[ \widehat{\Phi}(0) = \int_{-\infty}^\infty e^{- \pi x^2} = 1 = \Phi(0) \]
    %
    Thus we must have $\widehat{\Phi} = \Phi$.
\end{example}

\begin{example}
    The Fourier transform of the function $e^{- |x|}$ is the \emph{Poisson kernel}
    %
    \[ P(\xi) = \frac{\Gamma \left( \frac{d+1}{2} \right)}{\pi^{\frac{d+1}{2}} (1 + |\xi|^2)^{\frac{d+1}{2}}} = \frac{2}{|S^d|} \frac{1}{(1 + |\xi|^2)^{\frac{d+1}{2}}}. \]
    %
    Later on we show the corresponding scaled kernel $\{ P_\delta \}$ is an approximation to the identity, and thus $A_\delta f = P_\delta * f$ converges to $f$ in all appropriate senses.

    The Abel kernel $A_\delta$ on $\RR^d$ is obtained from the initial function $A(x) = e^{-2 \pi |x|}$. The calculation of the Fourier transform of this function indicates a useful principle in analysis: one can reduce expressions involving $e^{-x}$ into expressions involving $e^{-x^2}$ using the subordination principle. In particular, for $\beta > 0$ we have the formula
    %
    \[ e^{-\beta} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du \]
    %
    We establish this by letting $v = \sqrt{u}$, so
    %
    \[ \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du = \frac{2}{\sqrt{\pi}} \int_0^\infty e^{-v^2 - \beta^2/4v^2}\; dv = \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-(v - \beta/2v)^2}\; dv \]
    %
    But the map $v \mapsto v - \beta/2v$ is measure preserving by Glasser's master theorem, so this integral is
    %
    \[ \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-v^2}\; dv = e^{-\beta} \]
    %Because using the theory of residues,
    %
    %\begin{align*}
    %   e^{-\beta} &= \frac{2}{\pi} \int_0^\infty \frac{\cos \beta x}{1 + x^2} = \frac{1}{\pi} \int_{-\infty}^\infty \frac{e^{\beta i x}}{1 + x^2}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_{-\infty}^\infty e^{\beta i x} \int_0^\infty e^{-u} e^{-ux^2}\; du\; dx\\
    %   &= \frac{1}{\pi} \int_0^\infty e^{-u} \int_{-\infty}^\infty e^{-ux^2} e^{\beta i x}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_0^\infty \sqrt{\pi/u} e^{-u} e^{-\beta^2/4u}\; du
    %\end{align*}
    %
    In tandem with Fubini's theorem, this formula implies
    %
    \begin{align*}
        \widehat{A}(\xi) &= \int_{\RR^d} e^{-2 \pi |x|} e^{- 2 \pi i \xi \cdot x}\; dx = \int_{\RR^d} \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{- |\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; du\; dx\\
        &= \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int_{\RR^d} e^{-|\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; dx\; du = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} (\text{Dil}_{(\pi^{1/2}/u^{1/2})} \Phi)^\ft(\xi)\; du\\
        &= \frac{1}{\pi^{(d + 1)/2}} \int_0^\infty e^{-u} u^{(d-1)/2} e^{- u|\xi|^2}\; du
    \end{align*}
    %
    Setting $v = (1 + |\xi|^2) u$, we conclude that since by definition,
    %
    \[ \int_0^\infty e^{-v} v^{(d-1)/2} = \Gamma \left( \frac{d+1}{2} \right) \]
    %
    \[ \widehat{A}(\xi) = \frac{\Gamma((d+1)/2)}{[\pi(1 + |\xi|^2)]^{(d+1)/2}} \]
    %
    Thus the Abel mean is the Fourier inverse of the Poisson kernel on the upper half plane $\mathbf{H}^{d+1}$. We note that the Poisson summation formula shows that for $d = 1$, the Poisson kernel on $\TT$ is the periodization of the Poisson kernel on $\RR$.

    In order to conclude $\{ P_\delta \}$ is a good kernel, it now suffices to verify that
    %
    \[ \int_{\RR^d} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = \frac{\pi^{(d+1)/2}}{\Gamma((d+1)/2)} \]
    %
    The right hand side is half the surface area of the unit sphere in $\RR^{d+1}$. Denoting the surface area of the unit sphere in $\RR^{d+1}$ by $|S^d|$, and switching to polar coordinates, we find that
    %
    \[ \int_{\RR^d} \frac{d\xi}{(1 + |\xi|^2)^{(d+1)/2}} = |S^{d-1}| \int_0^\infty \frac{r^{d-1}}{(1 + r^2)^{(d+1)/2}}\; dr \]
    %
    Setting $r = \tan u$, we find
    %
    \[ \int_0^\infty \frac{r^{d-1}}{(1 + r^2)^{(d+1)/2}}\; dr = \int_0^{\pi/2} (\sin u)^{d-1} du \]
    %
    But we can now show by induction that
    %
    \[ \frac{|S^d|}{2} = |S^{d-1}| \int_0^{\pi/2} (\sin u)^{d-1}\; du. \]
    %
    Using the values $|S^0| = 2$, $|S^1| = 2\pi$, and $|S^2| = 4\pi$, the theorem certainly holds for $d = 1$ and $d = 2$. For $d > 2$, integration by parts and induction shows that
    %
    \begin{align*}
        |S^{d-1}| \int_0^{\pi/2} (\sin u)^{d-1}\; du &= S_{d-1} \frac{d-2}{d-1} \int_0^{\pi/2} (\sin u)^{d-3}(t)\; dt.\\
        &= \frac{d-2}{d-1} \frac{S_{d-1} S_{d-2}}{2S_{d-3}}\\
        &= \frac{d-2}{d-1} \frac{\pi^{d/2} \pi^{d/2-1/2}}{\pi^{d/2-1}} \frac{\Gamma(d/2 - 1)}{\Gamma(d/2) \Gamma(d/2 - 1/2)}\\
        &= \frac{\pi^{d/2+1/2}}{\Gamma(d/2 + 1/2)} = \frac{|S^d|}{2}.
    \end{align*}
    %
    Thus our theorem is complete.
\end{example}

\begin{example}
    We note that
    %
    \[ \int_{-R}^R e^{- 2 \pi i \xi x}\; dx = \frac{e^{-2 \pi i \xi R} - e^{2 \pi i \xi R}}{-2 \pi i \xi} = \frac{\sin(2 \pi \xi R)}{\pi \xi}. \]
    %
    so the Fourier transform of $\chi_{[-R,R]}$ is the \emph{Dirichlet kernel}
    %
    \[ D_R(\xi) = \frac{\sin(2 \pi \xi R)}{\pi \xi} \]
    %
    We note that $D_R \not \in L^1(\RR)$. Thus $D_R$ is {\it not} a good kernel, which makes the convergence rates of $S_R f$ more subtle. Nonetheless, $D_R$ does lie in $L^p(\RR)$ for all $p \in (1,\infty]$, and is \emph{uniformly bounded} in $L^p(\RR)$ for all $p \in (1,\infty)$, a fact we will prove later.
    %
%    \[ \int_{|\xi| \geq 1/R} \left| \frac{\sin(2 \pi \xi R)}{\pi \xi} \right|^p \lesssim \int_{1/R}^\infty \frac{1}{|\xi|^p} = R^{p-1} \]
%    \[ \int_{|\xi| \leq 1/R} \left| \frac{\sin(2 \pi \xi R)}{\pi \xi} \right|^p \lesssim_p R^{p-1} \]
    This is enough to conclude that for all $p \in (1,\infty)$, $S_R f \to f$ in $L^p(\RR)$.
\end{example}

Thus we now know there are a large examples of functions $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and such that for any $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{2 \pi i \xi \cdot x} \Phi(\delta x). \]
%
If $\widehat{f}$ is integrable, then the bound $| \widehat{f}(\xi) e^{2 \pi i \xi \cdot x} \Phi(\delta \xi) | \leq \| \Phi \|_\infty | \widehat{f}(\xi) |$ implies that we can use the dominated convergence theorem to conclude that for any point $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x) = \int \widehat{f}(\xi) e(\xi \cdot x) \]
%
Thus the inversion theorem holds pointwise almost everywhere.

\begin{theorem}
    If $f$ and $\widehat{f}$ are elements of $L^1(\RR^d)$, then for any $x$ in the Lebesgue set of $f$,
    %
    \[ f(x) = \int_{\RR^d} \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{theorem}

\begin{remark}
    We note that if $f \in L^1(\RR^d)$, $\widehat{f} \geq 0$, and $f$ is continuous at the origin, then the Fourier inversion formula and the monotone convergence theorem implies that
    %
    \[ f(0) = \lim_{\delta \to 0} \int_{\RR^d} \widehat{f}(\xi) e^{-\delta \xi}\; d\xi = \int_{\RR^d} \widehat{f}(\xi)\; d\xi. \]
    %
    Thus $\widehat{f}$ is integrable, and so the Fourier inversion theorem holds.

    As a particular example of this remark, if $f \in L^1(\RR^d)$ then we can define the autocorrelation function
    %
    \[ R(x) = \int_{\RR^d} f(y + x) f(y)\; dy, \]
    %
    then $R \in L^1(\RR^d)$ and $\widehat{R}(\xi) = |\widehat{f}(\xi)|^2$. Thus $R$ is continuous at the origin if and only if $\widehat{R}$ is integrable, which, using the $L^2$ theory we develop in the next section, holds if and only if $f \in L^2(\RR^d)$.
\end{remark}

It is often useful to note that if the Fourier transform of an integrable function is non-negative, then it's Fourier transform is automatically integrable.

\begin{theorem}
   If $f \in L^1(\RR)$ is continuous at the origin, and $\widehat{f} \geq 0$, then $\widehat{f}$ is integrable.
\end{theorem}
\begin{proof}
   This follows because
    %
   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \]
    %
   By Fatou's lemma,
    %
   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \geq \int \liminf_{\delta \to 0} \widehat{f}(\xi) e^{-\delta |x|} = \int \widehat{f}(\xi) \]
    %
   so $\widehat{f}$ is finitely integrable.
\end{proof}

Note that this implies that we obtain the general inversion theorem, so in particular, it is only continuous functions, and functions almost everywhere equal to continuous functions, which can have non-negative Fourier transforms. Here is a related result. Here, without integrability constraints, the Fourier transform of $m \in L^\infty(\RR^d)$ will be taken in the sense of tempered distributions, introduced later on in the notes.

\begin{lemma} \label{positivel1linfinitylemma}
    If $m \in L^\infty(\RR^d)$, and $\widehat{m} \geq 0$, then $\| m \|_{L^\infty(\RR^d)} = \| \widehat{m} \|_{L^1(\RR^d)}$.
\end{lemma}
\begin{proof}
    Set $k = \widehat{m}$. The result is equivalent to showing that if $m \in L^\infty(\RR^d)$ and $\widehat{m} \geq 0$, then $\| m \|_{L^\infty(\RR^d)} = \| k \|_{L^1(\RR^d)}$. From this it then follows that for a general $p$,
    %
    \[ \| k \|_{L^1(\RR^d)} = \| m \|_{M^2} \leq \| m \|_{M^p} \leq \| m \|_{M^1} = \| k \|_{L^1(\RR^d)}. \]
    %
    Suppose first that $m$ is continuous. If $\Phi$ is the Gaussian function, and $\Phi_\delta(\xi) = \delta^{-d} \Phi(\xi / \delta)$ then the multiplication formula implies that
    %
    \[ \int m(\xi) \Phi_\delta(\xi - \xi_0) = \int k(x) \Phi(\delta \xi) e^{2 \pi i \xi_0 \cdot x}\; dx. \]
    %
    If $m$ is continuous, taking $\delta \to 0$ gives
    %
    \[ |m(\xi_0)| \leq \limsup_{\delta \to 0} \left| \int k(x) \Phi(\delta \xi) e^{2 \pi i \xi_0 \cdot x}\; dx \right| \leq \int k(x); dx \]
    %
    and by monotone convergence,
    %
    \[ m(0) = \lim_{\delta \to 0} \int k(x) \Phi(\delta \xi) = \int k(x)\; dx.  \]
    %
    Thus $\| m \|_{L^\infty(\RR^d)} = \| k \|_{L^1(\RR^d)}$.

    But now if we let $k_\varepsilon(x) = k(x) \Phi(\varepsilon x)$, and $m_\varepsilon = \widehat{k_\varepsilon} = m * \Phi_\varepsilon$, then $m_\varepsilon$ converges distributionally to $m$ as $\varepsilon \to 0$. Now $k_\varepsilon$ is non-negative, and Young's inequality implies $\| m_\varepsilon \|_{L^\infty(\RR^d)} \leq \| m \|_{L^\infty(\RR^d)}$. Thus
    %
    \[ \| m_\varepsilon \|_{L^\infty(\RR^d)} = \| k_\varepsilon \|_{L^1(\RR^d)}. \]
    %
    Taking $\varepsilon \to 0$ gives
    %
    \[ \lim_{\varepsilon \to 0} \| m_\varepsilon \|_{L^\infty(\RR^d)} = \| k \|_{L^1(\RR^d)}. \]
    %
    But now
    %
    \begin{align*}
        \| m \|_{L^\infty(\RR^d)} &\geq \lim_{\delta \to 0} \delta^{d/2} \| k * \Phi_\delta \|_{L^2(\RR^d)}\\
        &= \lim_{\delta \to 0} \lim_{\varepsilon \to 0} \delta^{d/2} \| k_\varepsilon * \Phi_\delta \|_{L^2(\RR^d)}.
    \end{align*}
    %
    These limits are both monotonic, so we can interchange them, thus getting that
    %
    \begin{align*}
        \lim_{\delta \to 0} \lim_{\varepsilon \to 0} \delta^{d/2} \| k_\varepsilon * \Phi_\delta \|_{L^2(\RR^d)} &= \lim_{\varepsilon \to 0} \lim_{\delta \to 0} \delta^{d/2} \| k_\varepsilon * \Phi_\delta \|_{L^2(\RR^d)}\\
        &= \lim_{\varepsilon \to 0} \| k_\varepsilon \|_{L^1(\RR^d)}\\
        &= \| k \|_{L^1(\RR^d)}.
    \end{align*}
    %
    This completes the proof.
\end{proof}

We define, for any integrable $f: \RR^n \to \RR$, the \emph{inverse} Fourier transform
%
\[ \widecheck{f}(x) = \int f(\xi) e(\xi \cdot x)\; d\xi \]
%
The inverse transform is also denoted by $\mathcal{F}^{-1}(f)$. The last theorem says that $\mathcal{F}^{-1}$ really is the inverse operator to the operator $\mathcal{F}$, at least on the set of functions $f$ where $\widehat{f}$ is integrable. In particular, this is true if $f$ has weak derivatives in the $L^1$ norm for any multi-index $|\alpha| \leq n+1$, and so the Fourier inversion formula holds for sufficiently smooth functions.

\begin{corollary}
    If $f \in C(\RR)$ is integrable and $\widehat{f} \in L^1(\RR)$, $S_R f \to f$ uniformly.
\end{corollary}
\begin{proof}
    The dominated convergence theorem implies that for each $x \in\RR$,
    %
    \[ f(x) = \int_{\RR} \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} (S_R f)(x). \]
    %
    And
    %
    \[ \int_{|x| \geq R} \widehat{f}(\xi) e(\xi \cdot x) \leq \int_{|x| \geq R} |\widehat{f}(\xi)|\; d\xi = o(1). \]
    %
    so the pointwise convergence is uniform in $x$.
\end{proof}

\begin{remark}
    This theorem also generalizes to $\RR^d$. Here, the operators $S_R$ are no longer canonically defined, but if we consider any increasing nested family of sets $B_R$ with $\lim B_R = \RR^n$, then the corresponding operators
    %
    \[ S_R f = \int_{B_R} \widehat{f}(\xi) e(\xi \cdot x) \]
    %
    also converge uniformly to $f$.
\end{remark}

\begin{corollary}
    The map $\mathcal{F}: L^1(\RR^d) \to C_0(\RR^d)$ is injective.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\widehat{f}$ is certainly integrable. But this means that the Fourier inversion theorem can apply, giving that for almost every point $x$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(x) e(\xi \cdot x) = 0. \]
    %
    Thus $f = 0$ almost everywhere.
\end{proof}

The corollary above is often underestimated in utility. Even if the Fourier inversion theorem doesn't hold, we can still view the Fourier transform as another way to represent a function, since the Fourier transform does not lose any information. For instance, it can be used very easily to verify identities involving convolutions.

\begin{corollary}
    For any $\delta_1, \delta_2$,
    %
    \[ W_{\delta_1 + \delta_2} = W_{\delta_1} * W_{\delta_2}\quad\text{and}\quad P_{\delta_1 + \delta_2} = P_{\delta_1} * P_{\delta_2}. \]
\end{corollary}
\begin{proof}
    We recall that
    %
    \[ W_{\delta_1 + \delta_2} = \mathcal{F}(e^{-(\delta_1 + \delta_2) |x|^2}). \]
    %
    But $e^{-(\delta_1 + \delta_2) |x|^2} = e^{-\delta_1 |x|^2} e^{-\delta_2 |x|^2}$ breaks into a product, which allows us to calculate
    %
    \[ \mathcal{F}(e^{-\pi \delta_1 |x|^2} e^{-\pi \delta_2 |x|^2}) = \mathcal{F}(e^{-\pi \delta_1 |x|^2}) * \mathcal{F}(e^{-\pi \delta_2 |x|^2}) = W_{\delta_1} * W_{\delta_2}.  \]
    %
    Thus $W_{\delta_1} * W_{\delta_2} = W_{\delta_1 + \delta_2}$. Similarily, $P_{\delta_1 + \delta_2}$ is the Fourier transform of $e^{-(\delta_1 + \delta_2)|x|}$, which breaks into a product, whose individual Fourier transforms are $P_{\delta_1}$ and $P_{\delta_2}$.
\end{proof}

Many of the other convergence statements for Fourier series hold in the case of the Fourier transform. For instance, a non-periodic variant of the De la Vallee Poisson kernel shows that if $f \in L^1(\RR)$ and $\widehat{f}(\xi) = O(1/|\xi|)$, then $S_R f$ converges uniformly to $f$. But for the purpose of novelty, we move on to other concepts.

\section{The $L^2$ Theory}

There are various differences in the $L^2$ for the Fourier transform vs the case of Fourier series. In the compact, periodic case, $L^2(\TT^d)$ is contained in $L^1(\TT^d)$ and can thus be viewed as a \emph{more regular} family of functions than the square integrable functions. In the noncompact case, $L^2(\RR^d)$ is not contained in $L^1(\RR^d)$, and thus is \emph{more regular} in some respects (we have more control over singularities), but we have less control on how spread out the function is. In particular, we often have to rely on density arguments, working in the space $L^1(\RR^d) \cap L^2(\RR^d)$, which is a dense subspace of $L^2(\RR^d)$.

One integral component of Fourier series on $L^2(\TT^d)$ is Plancherel's equality
%
\[ \sum_{n \in \ZZ^d} |\widehat{f}(n)|^2 = \int_{\TT^d} |f(x)|^2\; dx \]
%
Let us try and extend this to $\RR^d$. A natural formula is to expect that
%
\[ \int_{\RR^d} |\widehat{f}(\xi)|^2\; d\xi = \int_{\RR^d} |f(x)|^2\; dx. \]
%
In order to interpret the right hand side as a finite quantity, we must assume $f \in L^2(\RR^d)$, and to interpret the left hand side, we must assume $f \in L^1(\RR^d)$. A result of our calculation will show that under these assumptions, $\widehat{f} \in L^2(\RR^d)$, and that the formula holds.

\begin{theorem}
    If $f \in L^1(\RR^d) \cap L^2(\RR^d)$, then $\| \widehat{f} \|_{L^2(\RR^d)} = \| f \|_{L^2(\RR^d)}$.
\end{theorem}
\begin{proof}
    The theorem is an easy consequence of the multiplication formula, since
    %
    \[ |\widehat{f}(\xi)| = \widehat{f}(\xi) \overline{\widehat{f}}(\xi), \]
    %
    and
    %
    \[ \left( \overline{\widehat{f}} \right)^\ft(\xi) = \overline{(f^\ft)^\ft(-\xi)} = \overline{f(\xi)}. \]
    %
    This implies
    %
    \[ \int_{\RR^d} |\widehat{f}(\xi)|^2\; d\xi = \int_{\RR^d} \widehat{f}(\xi) \overline{\widehat{f}(\xi)}\; d\xi = \int_{\RR^d} f(x) \overline{f(x)}\; dx = \int_{\RR^d} |f(x)|^2\; dx. \qedhere \]
\end{proof}

A simple interpolation argument leads to the following corollary, which is a variant of the Hausdorff-Young inequality for functions on $\RR^d$.

\begin{corollary} If $f \in L^1(\RR^d) \cap L^p(\RR^d)$ for $1 \leq p \leq 2$, then
    %
    \[ \| \widehat{f} \|_{L^q(\RR^d)} \leq \| f \|_{L^p(\RR^d)}, \]
    %
    where $2 \leq q \leq \infty$ is the conjugate of $p$.
\end{corollary}

Another simple interpolation argument yields the following interesting weighted inequality, due to Paley, which allows one to get some information about the $L^p$ norm of the Fourier transform of an $L^p$ function.

\begin{corollary}
    If $1 < p \leq 2$, and let $r = (1 - p/p^*)^{-1} = (2-p)^{-1}$. Then if $f \in L^p(\RR^d)$, and $w \in L^{r,\infty}(\RR^d)$, then
    %
    \[ \| \widehat{f} \|_{L^p(\RR^d, w)} \lesssim_p \| f \|_{L^p(\RR^d)} \| w \|_{L^{r,\infty}(\RR^d)}^{1/p}. \]
    %
    Interpolating between the Hausdorff-Young inequality, we conclude that for an exponent $1 < p \leq 2$, then for $p \leq q \leq p^*$, if $r = (1 - q/p^*)^{-1}$, and if $w \in L^{r,\infty}(\RR^d)$, then
    %
    \[ \| \widehat{f} \|_{L^q(\RR^d,w)} \lesssim \| f \|_{L^p(\RR^d)} \| w \|_{L^{r,\infty}(\RR^d)}^{1/q}. \]
\end{corollary}
\begin{proof}
    We reformulate the bound into a form that is easier to interpolate. Define $g = w^r$. Then the inequality we want to prove is equivalent to the ienquality
    %
    \[ \left( \int |\widehat{f}(\xi)|^p |g(\xi)|^{2-p} \right)^{1/p} \lesssim \| f \|_{L^p(\RR^d)} \| g \|_{L^{1,\infty}(\RR^d)}^{2/p - 1}. \]
    %
    If we define the operator
    %
    \[ T_gf(\xi) = \widehat{f}(\xi) / g(\xi), \]
    %
    and $w_g(\xi) = g(\xi)^2$, then the problem is just to show that
    %
    \[ \| T_g f \|_{L^p(\RR^d,w_g)} \lesssim \| f \|_{L^p(\RR^d)} \| g \|_{L^{1,\infty}(\RR^d)}^{2/p - 1}. \]
    %
    The case $p = 2$ is just Parsevel's inequality. We claim for $p = 1$ we also have
    %
    \[ \| T_g f \|_{L^{1,\infty}(\RR^d,w_g)} \lesssim \| f \|_{L^1(\RR^d)} \| w \|_{L^{1,\infty}(\RR^d)}. \]
    %
    But this follows since we have a pointwise bound
    %
    \[ |Tf| \leq \| f \|_{L^1(\RR^d)} / |g|. \]
    %
    Thus the set
    %
    \[ \{ \xi \in \RR^d : |Tf(\xi)| \geq \alpha \} \]
    %
    is contained in
    %
    \[ \{ \xi \in \RR^d : |w(\xi)| \leq \| f \|_{L^1(\RR^d)} / \alpha \}, \]
    %
    But a simple computation shows that, if $m(s)$ is the measure of the set $\{ x : g(x) \geq s \}$, then
    %
    \begin{align*}
        \int_{w_g(\xi) \leq \sigma} g(\xi)\; d\xi &= - \int_0^\sigma s^2 m'(s)\; ds\\
        &\leq [\lim_{s \to 0} s^2 m(s) - \sigma^2 m(\sigma)] + 2 \int_0^\sigma s m(s)\; ds\\
        &\leq 2 \| g \|_{L^{1,\infty}(\RR^d)} \cdot \sigma.
    \end{align*}
    %
    Setting $\sigma = \| f \|_{L^1(\RR^d)} / \alpha$ yields the required result.
\end{proof}

Though the integral formula of an element of $L^2(\RR^d)$ does not make sense, the bounds above provide a canonical way to define the Fourier transform of an element of $L^p(\RR^d)$, for $1 \leq p \leq 2$. The space $L^1(\RR^d) \cap L^p(\RR^d)$ is a dense subset of $L^p(\RR^d)$, so we can use the Hahn-Banach theorem to define the Fourier transform $\mathcal{F}: L^p(\RR^d) \to L^q(\RR^d)$ as the {\it unique} bounded operator agreeing with the integral formula on the common domain. A more explicit way to define the Fourier transform is as the $L^2$ limit of the bounded Fourier transform operators; for each $f \in L^2(\RR^d)$, and $R > 0$, $f \Ind_{B_R} \in L^1(\RR^d)$, where $B_R$ is the ball of radius $R$ about the origin. It follows that if we define
%
\[ \mathcal{F}_R f (\xi) = \int_{|x| \leq R} f(x) e^{-2 \pi i \xi \cdot x}. \]
%
then since $\lim_{R \to \infty} \| \Ind_{B_R} f - f \|_{L^2(\RR^d)} = 0$, the $L^2$ continuity of the Fourier transform implies that $\mathcal{F}_R f$ converges to $\widehat{f}$ in $L^2(\RR^d)$.

The main way to obtain results about the Fourier transform of square integrable functions is by a density argument. For instance, suppose we wish to prove that for $f,g \in L^2(\RR^d)$,
%
\[ \int_{\RR^d} \widehat{f}(\xi) \widehat{g}(\xi)\; d\xi = \int_{\RR^d} f(x) g(x)\; dx. \]
%
This equality certainly holds by the multiplication formula if $f,\widehat{g} \in L^1(\RR^d) \cap L^2(\RR^d)$. We also find that both sides are continuous as bilinear functionals, by applying the Cauchy-Schwartz inequality and the isometry of the Fourier transform. Since any element $f$ of $L^2(\RR^d)$ can be approximated in the $L^2$ norm by an element of $L^1(\RR^d) \cap L^2(\RR^d)$, and since any element $g$ of $L^2(\RR^d)$ can be approximated by functions with $\widehat{g} \in L^1(\RR^d) \cap L^2(\RR^d)$, the theorem holds in general. In particular, this shows that the extension of the Fourier transform to $L^2(\RR^d)$ remains unitary.

Another approximation argument can be used to obtain convergence results in $L^2(\RR^d)$ for the Fourier transform. If we let
%
\[ S_\delta(f,\Phi) = \int \widehat{f}(\xi) e^{2 \pi i \xi \cdot x} \Phi(\delta \xi)\; d\xi \]
%
which is well defined for a particular function $\Phi \in L^2(\RR^d)$, then a density argument again shows that $S_\delta(f,\Phi) = K_\delta^\Phi * f$, where $K_\delta^\Phi$ is defined as in the last section. Provided that we also have $\Phi \in L^1(\RR^d)$ and $\int \widehat{\Phi}(\xi)\; d\xi = 1$, then we conclude that $S_\delta(f,\Phi) \to f$ in $L^2(\RR^d)$, and that if $\Phi \in C^{d+1}(\RR^d)$, then $S_\delta(f,\Phi) \to f$ almost everywhere. In particular, one can use the Gauss, Abel, and Fejer sums here to get $L^2$ convergence.

Unlike in the case of Fourier series, where the $L^2$ theory gives an isometry between $L^2(\TT^d)$ and $L^2(\ZZ^d)$, in the case of the Fourier transform the Fourier transform gives a unitary operator from $L^2(\RR^d)$ to itself, and thus we can consider the spectral theory of such an operator. The Fourier inversion formula implies that the Fourier transform has order four. Thus the only eigenfunctions of the Fourier transform correspond to eigenvalues in $\{ 1, -1, i, -i \}$. We have seen $e^{- \pi x^2}$ is an eigenfunction with eigenvalue one. If we consider the family of all \emph{Hermite polynomials}
%
\[ H_n(x) = \frac{(-1)^n}{n!} e^{\pi x^2} \frac{d^n}{dx^n} \left( e^{- \pi x^2} \right). \]
%
One can also see that
%
\[ \sum_{n = 0}^\infty (-t)^n/n! \]
\[ \sum_{n = 0}^\infty H_n(x) \frac{t^n}{n!} = e^{- \pi x^2 - (2\pi)^{1/2} tx + t^2} \]
%
TODO PROVE ORTHOGONALITY AND COMPLETENESS. which satisfy $\widehat{H_n} = (-i)^n H_n$, then we obtain an orthonormal basis of eigenfunctions. In higher dimensions, a basis of eigenfunctions for $L^2(\RR^d)$ is given by taking tensor products of Hermite polynomials.


\section{The Hausdorff-Young Inequality}

For functions on $\TT$, it is unclear how to provide examples which show why the Hausdorff-Young inequality cannot be extended to give results for $p > 2$. Over $\RR$, we can provide examples which explicitly indicate the tightness of the appropriate constants by applying symmetry arguments.

\begin{example}
    Given $f \in L^1(\RR)$, let $f_r(x) = f(rx)$. Then we find $\widehat{f_r}(\xi) = r^{-d} \widehat{f}(\xi/r)$, and so
    %
    \[ \| f_r \|_{L^p(\RR^d)} = r^{-d/p} \| f \|_{L^p(\RR^d)} \quad \text{and} \quad \| \widehat{f_r} \|_{L^q(\RR^d)} = r^{d/q-d} \| \widehat{f} \|_{L^q(\RR^d)}. \]
    %
    In order for a bound to hold in terms of $p$ and $q$ uniformly for all values of $r$, we need $r^{-d/p} = r^{d/q-d}$, which means $1/q + 1/p = 1$, so $p$ and $q$ must be conjugates of one another. In the case of $\TT$, a function analogous to $f_r$ can only be defined for small value of $r$, and a uniform estimate can then only hold if $1/p + 1/q \geq 1$.
\end{example}

If $p > 2$, then for the value $q$ with $1/p + 1/q = 1$, we have $q < p$. It is a principle of Littlewood that translation invariant operators cannot satisfy a $L^p$ to $L^q$ bound.

\begin{theorem}
    Suppose $T: L^p(\RR^d) \to L^q(\RR^d)$ is a translation invariant continuous operator, where $q < p$. Then $T = 0$.
\end{theorem}
\begin{proof}
    If $T$ was nonzero, we could pick some $f_0 \in L^p(\RR^d)$ such that $Tf_0 \neq 0$. Rescaling $T$ and $f_0$, we may assume without loss of generality that $\| f_0 \|_{L^p(\RR^d)} = \| Tf_0 \|_{L^q(\RR^d)} = 1$. Furthermore, by truncation we may assume that $f_0$ has compact support on some ball $B_R$. But then the supports of the functions $\text{Trans}_{2Rn} f_0$ and $f_0$ are disjoint for $n \in \ZZ^d$, so for any choice of coefficients $\{ a_n \}$,
    %
    \[ \left\| \sum_{n \in \ZZ^d} a_n \cdot \text{Trans}_{2R n} f_0 \right\|_{L^p(\RR^d)} = \left( \sum |a_n|^p \right)^{1/p}. \]
    %
    Assume that at most $N$ of the coefficients $a_n$ are nonzero. We cannot necessarily assume that $Tf_0$ has compact support but the majority of the mass of $Tf_0$ can still be concentrated on a compact set. For any $\varepsilon > 0$ we can choose $R$ large enough that
    %
    \[ \left( \int_{|x| \geq R} |Tf_0(x)|^q \right)^{1/q} \leq \varepsilon. \]
    %
    Now for each $B_R$ and $m \in \ZZ^d$,
    %
    \[ \left( \int_{x \in 2Rm + B_R} \left| \sum_{n \in \ZZ^d} a_n \text{Trans}_{2Rn} Tf_0(x) \right|^q\; dx \right)^{1/q} \geq \left( |a_m|^q - \varepsilon \sum_{n \neq m} |a_n|^q \right)^{1/q}. \]
    %
    If, for a \emph{fixed} sequence $\{ a_n \}$, we choose
    %
    \[ \varepsilon \leq \frac{0.5}{\max_{n \in \ZZ^d}|a_n| \cdot \left( \sum_{n \in \ZZ^d} |a_n|^q \right)^{1/q}}. \]
    %
    Then we find
    %
    \[ \left( \int_{x \in 2Rm + B_R} \left| \sum_{n \in \ZZ^d} a_n \text{Trans}_{2Rn} Tf_0(x) \right|^q\; dx \right)^{1/q} \geq 0.5^{1/q} |a_m| \]
    %
    and so summing over all $m$, we conclude that
    %
    \[ \| \sum_{n \in \ZZ^d} a_n \text{Trans}_{2Rn} Tf_0 \|_{L^q(\RR^d)} \geq 0.5^{1/q} \left( \sum_{n \in \ZZ^d} |a_n|^q \right)^{1/q}. \]
    %
    Thus we conclude that for \emph{any} sequence $\{ a_n \}$ in $l^q(\ZZ^d)$,
    %
    \[ \left( \sum_{n \in \ZZ^d} |a_n|^q \right)^{1/q} \lesssim_q \left( \sum_{n \in \ZZ^d} |a_n|^p \right)^{1/p}. \]
    %
    where the constant is independent of the sequence. For $q < p$ this is impossible.
\end{proof}

We can also provide a family of functions whose Fourier transforms contradict an extension of the Hausdorff Young inequality for $p > 2$.

\begin{example}
    Consider the family of functions $f_s(x) = s^{-d/2} e^{- \pi |x|^2/s}$, where $s = 1 + it$ for some $t \in \RR$. One can easily calcluate using analytic continuation and the Fourier transform for the Gaussian that $\widehat{f_s}(\xi) = e^{- \pi s |\xi|^2}$. We calculate
    %
    \[ \| f_s \|_{L^p(\RR^d)} = |s|^{-d/2} \left( \int e^{- (p/|s|^2) \pi |x|^2}\; dx \right)^{1/p} = |s|^{d/p - d/2} p^{-d/p} \]
    %
    whereas $\| \widehat{f_s} \|_q = q^{-d/2}$. Thus to be able  compare the two quantities as $t \to \infty$, we need $d/p - d/2 \leq 0$, so $p \leq 2$. As $t \to \infty$, $\smash{|f_s(x)| \sim t^{-d/2} e^{-\pi |x/t|^2}}$, so the $t$ gives us a decay in $f_s$. However, when we take the Fourier transform the $t$ only corresponds to oscillatory terms. Thus we need $p \leq 2$ so that the decay in $t$ isn't too important in relation to the overall width of the function. One can obtain analogous examples in $\TT^d$ to this example, by applying the Poisson summation formula to the functions $f_s$ and noting that the $L^p$ and $L^q$ norms also follows approximately the same formulas as above.
\end{example}

The Hausdorff-Young inequality shows that the Fourier transforms narrowly supported functions into a function with small magnitude. But the example above shows that the Fourier transform is not so good at transforming functions with small magnitude into functions which are narrowly supported, because the Fourier transform can absorb the small magnitude into an oscillatory property not reflected in the norms. Some kind of way of measuring oscillation needs to be considered to get a tighter control on the function. Of course, in hindsight, we should have never expected too much control of the Fourier transform in terms of the $L^p$ norms, since the Fourier transform measures the oscillatory nature of the input function, and oscillatory properties of a function in phase space are not very well reflected in the $L^p$ norms, except when applying certain orthogonality properties with an $L^2$ norm, or destroying the oscillation with an $L^\infty$ norm.

\section{Boundedness in $L^p$}

We restrict ourselves to the study of partial summation on the real line. In particular, we consider the partial summation operators
%
\[ S_R f(x) = \int_{-R}^R \widehat{f}(\xi) e^{2 \pi i \xi x}. \]
%
These operators are translation invariant, and we have $S_R f = D_R * f$, where
%
\[ D_R(\xi) = \frac{\sin(2 \pi \xi R)}{\pi \xi} \]
%
is the Dirichlet kernel. We are concerned with determining whether, given a general $f \in L^p(\RR^d)$, the functions $\{ S_R f \}$ converge to $f$ in the $L^p$ norm as $R \to \infty$. Since the result \emph{is} true if $f$ is a Schwartz function, it follows via the uniform boundedness theorem and a density arguemnt that we must establish a bound of the form
%
\[ \| S_R f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
which is uniform over all Schwartz $f$ and $R > 0$.

A tensorization argument shows that if we can establish such a bound on the real line, then an analogous result holds for the \emph{square summation} operators on $\RR^d$, i.e. the operators
%
\[ S_R f(x) = \int_{\max(|\xi_1|, \dots, |\xi_d|) \leq R} \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi. \]
%
On the other hand, the theory of summation operators $\{ S_R \}$ for \emph{other} regions of integration (e.g. the spherical summation operators obtained by integrating over $|\xi| \leq R$) is much more subtle.

To start with, we note that
%
\[ \| D_R \|_{L^1(\RR)} \sim \log R. \]
%
This implies that the operators $\{ S_R \}$ are \emph{not} uniformly bounded in $L^1(\RR)$. As with the case of the Dirichlet kernel on $\TT$, this implies the theory of partila summation for general functions in $L^1(\RR)$ can behave very erratically, i.e. there exists $f \in L^1(\RR)$ such that $\| S_R f \|_{L^1(\RR)} \to \infty$ as $R \to \infty$. By duality, partial summation is also not well behaved on $L^\infty(\RR)$, or even $C_b(\RR)$.

On the other hand, the operators $\{ S_R \}$ \emph{are} uniformly bounded in $L^p(\RR)$ for any $1 < p < \infty$, and so for any $f \in L^p(\RR)$, $\{ S_R f \}$ converges in $L^p(\RR)$ to $f$ as $R \to \infty$. We will not provide a complete proof of this fact here, relegating some parts of the proof to later parts of these notes. But we describe the general principles of the argument.

Marcel Riesz obtained the first proof of the $L^p$ boundedness of the operators $\{ S_R \}$ by reducing the study of the operators $\{ S_R \}$ to the study of a single operator, the \emph{Hilbert transform}
%
\[ Hf(x) = - i \pi \int_{-\infty}^\infty \text{sgn}(\xi) \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi. \]
%
The price we pay for reducing our study to a single operator is that this operator is highly \emph{singular}. The definition of the operator cannot be interpreted as a Lebesgue integral for general $f \in L^p(\RR^d)$, since the Fourier transform of a general $f$ need not be integrable on the real line. To begin the study of the Hilbert transform, we must therefore restrict our study to functions $f$ whose Fourier transforms are more well behaved; one can justify that the integral formula defines a bounded operator from $\SW(\RR)$ to $\EC(\RR)$. Since we can write
%
\[ \Ind(-R \leq \xi \leq R) = \frac{\text{sgn}(\xi - R) - \text{sgn}(\xi + R)}{2}, \]
%
for Schwartz $f$ we have
%
\[ S_R = \frac{i}{2 \pi} \left( \text{Mod}_{-R} \circ H \circ \text{Mod}_R - \text{Mod}_R \circ H \circ \text{Mod}_{-R} \right). \]
%
Thus if we could show that $H$ is bounded on $L^p(\RR)$, i.e. that
%
\[ \| Hf \|_{L^p(\RR)} \lesssim \| f \|_{L^p(\RR)}, \]
%
for all Schwartz $f$, then it follows that we have
%
\[ \| S_R f \|_{L^p(\RR)} \lesssim \| f \|_{L^p(\RR)}, \]
%
for all Schwartz $f$, uniformly in $R$, and the bound then follows by a density argument for all $f \in L^p(\RR)$.

We will not prove the boundedness of the Hilbert transform at this time, since it requires some more advanced techniques. The classical method involves some complex analysis, though it is now more conventional to analyze the Hilbert transform via the more modern \emph{Calderon-Zygmund theory of singular integrals}. We will see later on in these notes that, for Schwartz $f$, we can write the Hilbert transform as a singular integral of the form
%
\[ Hf(x) = \lim_{\varepsilon \to 0} \int \frac{f(y)}{x - y}\; dy. \]
%
The theory of such integrals will then give the $L^p$ boundedness we require.

\section{The Poisson Summation Formula}

We now show a connection between the Fourier transform on $\RR$, and the Fourier transform on $\TT$. If $f$ is a function on $\RR$, there are two ways of obtaining a `periodic' version of $f$ on $\TT$. Firstly, we can define, for each $x \in \TT$,
%
\[ f_1(x) = \sum_{n = -\infty}^\infty f(x + 2 \pi n), \]
%
which is a well defined element of $C^\infty(\TT)$. Secondly, we can define
%
\[ f_2(x) = \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(x), \]
%
i.e. projecting $f$ onto it's Fourier components that are periodic of degree one. The Poisson summation formula says that, under an appropriate regularity condition so that we can interpret these formulas correctly, they give the same function.

\begin{theorem}
    Suppose $f \in L^1(\RR^d)$. Then the series
    %
    \[ \sum_{n \in \ZZ^d} \text{Trans}_n f \]
    %
    converges absolutely in $L^1[0,1]^d$ to a function $g \in L^1[0,1]^d$ with the property that
    %
    \[ \widehat{g}(n) = \widehat{f}(n) \]
    %
    for each $n \in \ZZ^d$.
\end{theorem}
\begin{proof}
    The fact that the sum converges absolutely in $L^1[0,1]$ follows because
    %
    \[ \sum_{n \in \ZZ^d} \| \text{Trans}_n f \|_{L^1[0,1]} = \| f \|_{L^1(\RR^d)}. \]
    %
    But the absolute convergence in $L^1$ also justifies the calculation that for each $n \in \ZZ^d$
    %
    \begin{align*}
        \int_{[0,1]^d} \sum_{m \in \ZZ^d} (\text{Trans}_n f)(x) e^{2 \pi nix}\; dx &= \sum_{m \in \ZZ^d} \int_{[0,1]^d} f(x + m) e^{2 \pi n i (x + m)}\; dx\\
        &= \int_{\RR^d} f(x) e^{2 \pi n i x}\; dx = \widehat{f}(n). \qedhere
    \end{align*}
\end{proof}

We can obtain a much more powerful version of this result if we assume that there is $\delta > 0$ such that
%
\[ |f(x)| \lesssim \frac{1}{1 + |x|^{d + \delta}} \quad\text{and}\quad |\widehat{f}(\xi)| \lesssim \frac{1}{1 + |x|^{d + \delta}}. \]
%
Then we see that the two functions
%
\[ g_1(x) = \sum_{n \in \ZZ^d} f(x + n) \quad\text{and}\quad g_2(x) = \sum_{n \in \ZZ^d} \widehat{f}(n) e^{2 \pi i n \cdot x} \]
%
are continuous functions on $\TT^d$ with the same Fourier coefficients. It thus follows that $g_1 = g_2$, i.e. that for each $x \in \RR^d$,
%
\[ \sum_{n \in \ZZ} f(x + n) = \sum_{n \in \ZZ} \widehat{f}(n) e^{2 \pi n i x}. \]
%
In particular, this holds if $f \in \mathcal{S}(\RR)$. From a distributional standpoint, this result says that the tempered distribution $\sum_{n \in \ZZ^d} \delta_n$ is an eigendistribution of the Fourier transform, i.e. it is it's own Fourier transform.

TODO: Also prove this statement under the assumption that $f$ has bounded variation and $f(t) = [f(t+) + f(t-)]/2$ for all $t \in \RR$.

The Poisson summation formula can often be used as a method to prove that bounds for operators on $\RR^d$ imply bounds for analogous operators on $\TT^d$. For instance, we will prove in our notes on Fourier multipliers that if every point of $m$ is a Lebesgue point, and if
%
\[ Tf(x) = \int_{\RR^d} m(\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi \]
%
is the associated Fourier multiplier satisfying bounds of the form
%
\[ \| Tf \|_{L^p(\RR^d)} \leq A \| f \|_{L^p(\RR^d)}, \]
%
then if we consider the analogous Fourier multiplier on $\TT^d$, i.e.
%
\[ Tf(x) = \sum_{n \in \ZZ} m(n) \widehat{f}(n) e^{2 \pi i n \cdot x}, \]
%
for functions $f: \TT^d \to \CC$, then
%
\[ \| T f \|_{L^p(\TT^d)} \leq A \| f \|_{L^p(\TT^d)}. \]
%
In particular, this implies that the Hilbert transform
%
\[ Hf(x) = \sum_n \text{sgn}(n) \widehat{f}(n) e^{2 \pi i n x} \]
%
is bounded on $L^p(\TT)$ for all $1 < p < \infty$, and the partial Fourier summation operators
%
\[ S_N f(x) = \sum_{|n| \leq N} \widehat{f}(n) e^{2 \pi i n x} \]
%
are uniformly bounded in $N$ as operators on $L^p(\TT)$ for $1 < p < \infty$.

\section{Radial Functions}

Suppose $f \in L^1(\RR^d)$ is a radial function. Then $\widehat{f}$ is also a radial function. In particular, if we let
%
\[ \| u \|_{L^1([0,\infty), r^{d-1})} = \int_0^\infty r^{d-1} u(r)\; dr \]
%
then we have a transform $u \mapsto \tilde{u}$ from $L^1([0,\infty), r^{d-1})$ to $L^\infty[0,\infty)$ where if $f(x) = u(|x|)$, then $\widehat{f}(\xi) = \tilde{u}(|\xi|)$. In particular, we calculate quite simply that
%
\[ \tilde{u}(s) = V_d \int_0^\infty r^{d-1} u(r) \left( \int_{S^{d-1}} e^{-2 \pi i x_1 s}\; dx \right). \]
%
If one recalls the Bessel functions $\{ J_s \}$, then we have
%
\[ \tilde{u}(s) = 2\pi s^{1 - d/2} \int_0^\infty r^{d/2} u(r) J_{d/2-1}(2 \pi s r)\; dr. \]
%
If one recalls some Bessel function asymptotics, then one can actually gain some interesting results for the \emph{averaging operator}
%
\[ Af(x) = \fint_{S^{d-1}} f(x-y)\; d\sigma(y) \]
%

\begin{example}
    Suppose $f_R(x) = \Ind_{|x| \leq R}$. Then
    %
    \[ \widehat{f}(\xi) = 2 \pi |\xi|^{1-d/2} \int_0^R r^{d/2} J_{d/2-1}(2 \pi s r)\; dr. \]
    %
    The n TODO
\end{example}



\chapter{Applications of the Fourier Transform}

\section{Applications to Partial Differential Equations}

Just as the Fourier series can be used to obtain periodic solutions to certain partial differential equations, the Fourier transform can be used to obtain more general solutions to partial differential equations on $\RR^d$. To begin with, we study the heat equation on $\RR^d$, i.e. we study solutions to the partial differential equation
%
\[ \frac{\partial u}{\partial t} = \Delta u \]
%
Formally taking Fourier transforms in the spatial variable gives
%
\[ \frac{\partial \widehat{u}(\xi,t)}{\partial t} = - 4 \pi^2 |\xi|^2 \widehat{u}(\xi,t) \]
%
which, if we are given $u(x,0) = f(x)$, gives that
%
\[ \widehat{u}(\xi,t) = \widehat{f}(\xi) e^{- 4 \pi^2 |\xi|^2 t}. \]
%
Thus, taking the inverse Fourier transform, we might expect the solution to the heat equation to be given by the formula
%
\[ u(x,t) = (H_t * f)(x) \]
%
where
%
\[ H_t(x) = \frac{1}{(4 \pi t)^{d/2}} e^{- |x|^2 / 4 t}. \]
%
The rapid decay of $H_t$ for large $x$ shows that for any $1 \leq p \leq \infty$ and $f \in L^p(\RR^d)$, $u$ is well defined by this formula, lies in $C^\infty(\TT^d)$, and solves the heat equation, with the appropriate norm convergence as $t \to 0$. However, in this case it is not so easy to conclude that $u$ is the unique solution to this equation satisfying the initial conditions, since one cannot necessarily take the Fourier transform of $u$.

We can get slightly more results if we consider the \emph{steady state} heat equation on the upper half plane $\mathbf{H}^d$, i.e. we study functions $u(x,t)$, for $x \in \RR^d$ and $t > 0$, such that $\Delta u = 0$, subject to the initial condition that $u(x,0) = f(x)$. Working formally with the Fourier transform leads to the equation
%
\[ \widehat{u}(\xi,t) = e^{-2 \pi t |\xi| x} \widehat{f}(\xi) \]
%
Thus $u(x,t) = (f * P_t)(x)$, where $P_t$ is the Poisson kernel. If $f \in L^1(\RR^d)$, it is easy to see that 


\section{Shannon-Nyquist Sampling Theorem}

Often, in applications, one deals with band limited function, i.e. functions whose Fourier transforms are compactly supported. For simplicity, we work solely with functions $f$ on $\RR$ satisfying a decay condition
%
\[ |f(t)| \lesssim \frac{1}{(1 + |t|)^{1 + \delta}}. \]
%
It follows that $f \in L^p(\RR^d)$ for each $1 \leq p \leq \infty$. Suppose that in addition, $\widehat{f}$ is supported on $[-1/2,1/2]$. It follows that, $\widehat{f} \in L^p(\RR^d)$ for each $1 \leq p \leq \infty$. In particular, it follows that $f$ is smooth, if we alter it on a set of measure zero. Now taking Fourier series on $[-1/2,1/2]$, noting that $f \in L^1(\ZZ)$ because of it's decay, we find that for each $\xi \in \RR$,
%
\[ \widehat{f}(\xi) = \Ind(|\xi| \leq 1/2) \sum_{n = -\infty}^\infty f(n) e^{-2 \pi i n \xi}. \]
%
But now we conclude by the Fourier inversion formula that
%
\begin{align*}
    f(x) &= \int_{-1/2}^{1/2} \left( \sum_{n = -\infty}^\infty f(n) e^{-2 \pi i n \xi} \right) e^{2 \pi i \xi x}\; d\xi\\
    &= \sum_{n = -\infty}^\infty f(n) \int_{-1/2}^{1/2} e^{2 \pi i \xi (x-n)}\; d\xi\\
    &= \sum_{n = -\infty}^\infty f(n) \cdot \frac{\sin(\pi (x - n))}{\pi (x-n)}.
\end{align*}
%
In particular, we conclude that the function $f$ is uniquely determined by sampling it's values over the integers. In particular, if $N$ is large, and $|x| \leq N/2$
%
\[ \left| f(x) - \sum_{n = -N}^N f(n) \cdot \frac{\sin(\pi(x - n))}{\pi (x - n)} \right| \lesssim \frac{1}{N}, \]
%
where the implicit constant depends on the decay of $f$. If we sample on a more fine set of values, then we obtain faster convergence. To do this, we instead take the Fourier series of $\widehat{f}$ on $[-\lambda/2,\lambda/2]$, noting that
%
\[ \frac{1}{\lambda} \int_{-\lambda/2}^{\lambda/2} \widehat{f}(\xi) e^{2 \pi i n \xi / \lambda}\; d\xi = \frac{f(n/\lambda)}{\lambda} \]
%
so that
%
\[ \widehat{f}(\xi) = \chi(\xi) \sum_{n = -\infty}^\infty \frac{f(n/\lambda)}{\lambda} e^{-2 \pi n \xi / \lambda}. \]
%
where instead of being the indicator on $[-1/2,1/2]$, $\chi$ is the piecewise linear function equal to $1$ for $|\xi| \leq 1/2$, and vanishing for $|\xi| \geq \lambda/2$. One can calculate quite easily that
%
\[ \widehat{\chi}(x) = \frac{\cos(\pi x) - \cos(\lambda \pi x)}{\pi^2 (\lambda - 1) x^2}. \]
%
Thus it follows from the Fourier inversion formula that
%
\begin{align*}
    f(x) &= \sum_{n = -\infty}^\infty \frac{f(n/\lambda)}{\lambda} \int_{-\infty}^\infty \chi(\xi) e^{2 \pi i \xi (x-n/\lambda)}\; dx\\
    &= \sum_{n = -\infty}^\infty \frac{f(n/\lambda)}{\lambda} \widehat{\chi}(n/\lambda - x)\\
    &= \sum_{n = -\infty}^\infty f(n/\lambda) \frac{\cos(\pi (n / \lambda - x)) - \cos(\lambda \pi (n / \lambda - x))}{\pi^2 \lambda (\lambda - 1)(n/\lambda - x)^2}.
\end{align*}
%
It follows that if $|x| \leq N/2\lambda$, then
%
\[ \left| f(x) - \sum_{n = -N}^N f(n/\lambda) \frac{\cos(\pi (n / \lambda - x)) - \cos(\lambda \pi (n / \lambda - x))}{\pi^2 \lambda (\lambda - 1)(n/\lambda - x)^2} \right| \lesssim \left( 1 + \frac{1}{\lambda - 1} \right) \frac{1}{N^2}. \]
%
Thus the rate of convergence of this sum is much better if we \emph{oversample} by a large value $\Lambda$.

We should not expect $f$ to be obtainable exactly if we undersample, i.e. look at the coefficients $\{ f(n/\lambda) : n \in \mathbf{Z} \}$ for some $\lambda < 1$. Thus undersampling often yields artifacts in our reconstruction. For instance, when one takes a video of periodic motion travelling at a much greater frequency than the framerate of a video. To see why this is true, we consider a distributional formulation of the Nyquist sampling theorem.

\begin{theorem}
    For any $\lambda < 1$, there exists $f_1,f_2 \in \mathcal{S}(\RR)$, with $\widehat{f_1}$ and $\widehat{f_2}$ supported on $[-1/2,1/2]$, such that $f_1(n/\lambda) = f_2(n/\lambda)$ for any $n \in \ZZ$.
\end{theorem}
\begin{proof}
    Fix $f_0 \in \mathcal{S}(\RR)$. Then the Poisson summation formula, appropriately rescaled, tells us that for each $\xi \in \RR$,
    %
    \[ \sum_{n = -\infty}^\infty f(n/\lambda) e^{-2 \pi n i \xi} = \lambda^d \sum_{n = -\infty}^\infty \widehat{f}(\xi - \lambda n). \]
    %
    One can determine all the coefficients $\{ f(n/\lambda) \}$ if one knows the right hand side for all values $\xi \in \RR$. Thus if $f_1,f_2 \in \mathcal{S}(\RR)$ are distinct functions such that $\widehat{f_1}$ and $\widehat{f_2}$ are supported on $[-1/2,1/2]$, but are equal to one another at a periodization of scale $\lambda$, then $f_1(n/\lambda) = f_2(n/\lambda)$ for any $n \in \ZZ$. This is certainly possible if $\lambda < 1$.
\end{proof}

We can also get a discretized $L^2$ identity.

\begin{theorem}
    Suppose $f \in L^2(\RR)$ and $\widehat{f}$ is supported on $[-1/2,1/2]$. Then
    %
    \[ \sum_{n = -\infty}^\infty |f(n)|^2 = \int_{-\infty}^\infty |f(x)|^2\; dx. \]
\end{theorem}
\begin{proof}
    Poisson summation applied to $|f(x)|^2$ implies that
    %
    \[ \sum_{n = -\infty}^\infty |f(n)|^2 = \sum_{n = -\infty}^\infty \int_{-\infty}^\infty \widehat{f}(\xi) \overline{\widehat{f}(\xi - n)}\; dx = \int_{-1/2}^{1/2} |\widehat{f}(\xi)|^2\; dx = \int_{-\infty}^\infty |f(x)|^2\; dx. \]
\end{proof}






\section{The Uncertainty Principle}

The uncertainty principle is a \emph{constraint} placed on the Fourier transform, which prevents a function and it's transform from concentrating too tightly in space. Roughly speaking, the uncertainty principle is the heuristic that if $f$ is a function, and it's Fourier support is supported on a ball around the origin of radius $1/R$, then $f$ should be `locally constant' at a scale $R$, because intuitively, $f$ is only composed of waves oscillating at low frequencies, and so in particular, should have large mass on some ball of radius $R$. This principle is seen in various scenarios, and we describe some basic situations here. This property is fundamental to the transform. For instance, we already see it in the formula for the Fourier transform of the dilation of a function, i.e. that
%
\[ \mathcal{F} \circ \text{Dil}_t = t^d \cdot \text{Dil}_{1/t} \circ \mathcal{F}. \]
%
Thus dilation which shrinks the support of a function to a scale $t$, \emph{expands} the support of the Fourier transform of the function by $1/t$. Another, version is the \emph{Paley-Wiener theorem}: an exponentially decaying function must have a Fourier transform which is extendable to a holomorphic function on a neighborhood of the real line. The uncertainty principle appears because holomorphic functions cannot have support concentrated on small sets. Here we consider some other versions of the principle.

\subsection{The Heisenberg Uncertainty Principle}

The first version of the uncertainty principle we give here is the most famous, the \emph{Heisenberg uncertainty principle}, which is an $L^2$ instance of the heuristic, and has important implications in quantum mechanics.

\begin{theorem}[Heisenberg]
    Suppose $\psi \in \mathcal{S}(\RR)$. Then for any $x_0,\xi_0 \in \RR$,
    %
    \[ \left( \int_{-\infty}^\infty (x - x_0)^2 |\psi(x)|^2\; dx \right) \left( \int_{-\infty}^\infty (\xi - \xi_0)^2 |\widehat{\psi}(\xi)|^2\; d\xi \right) \geq \frac{1}{16 \pi^2} \left( \int_{-\infty}^\infty |\psi(x)|^2\; dx \right)^2. \]
    %
    Thus if $\psi$ has $L^2$ norm $A$, then for any $x_0$ and $\xi_0$, the $L^2$ norm of $(x - x_0) \psi$ and $(\xi - \xi_0) \psi$ cannot simultaneously both be $\lesssim A$.
\end{theorem}
\begin{proof}
    Normalizing, we may assume that $\int_{-\infty}^\infty |\psi(x)|^2\; dx = 1$ and that $x_0,\xi_0 = 0$. Integration by parts shows that
    %
    \begin{align*}
        1 &= \int_{-\infty}^\infty |\psi(x)|^2\; dx\\
        &= - \int_{-\infty}^\infty x \frac{d|\psi(x)|^2}{dx} = - \int_{-\infty}^\infty (x \psi'(x) \overline{\psi(x)} + x \overline{\psi'(x)} \psi(x))\; dx.
    \end{align*}
    %
    Thus
    %
    \begin{align*}
        1 &\leq 2 \int_{-\infty}^\infty |x| |\psi(x)| |\psi'(x)|\; dx\\
        &\leq 2 \left( \int_{-\infty}^\infty x^2 |\psi(x)|^2\; dx \right)^{1/2} \left( \int_{-\infty}^\infty |\psi'(x)|^2\; dx \right)^{1/2}\\
        &\leq 4 \pi \left( \int_{-\infty}^\infty x^2 |\psi(x)|^2\; dx \right)^{1/2} \left( \int_{-\infty}^\infty \xi^2 |\widehat{\psi}(\xi)|^2\; d\xi \right)^{1/2}. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    Taking $\psi$ to be a standard Gaussian function shows the constant $1 / 16 \pi^2$ in the Heisenberg uncertainty principle is tight.
\end{remark}

Let us explain the applications of this uncertainty principle in quantum mechanics. Unlike in classical mechanics, the position state of a particle is no longer given by a particular point, but instead given by a state function $\psi$ subject to the normalization condition
%
\[ \int_{-\infty}^\infty |\psi(x)|^2\; dx = 1. \]
%
It then follows that the position of a particle is nondeterministic, with $|\psi(x)|^2$ giving the probability density function of where the particle is located. If $x_0$ denotes the expected value of the particle, then the variance of the distribution is given by
%
\[ \sigma_x^2 = \int_{-\infty}^\infty |x - x_0|^2 |\psi(x)|^2\; dx. \]
%
On the other hand, the \emph{momentum} of the particule is also random, given in terms of a function $\phi$ such that the distribution of the momentum is given with density $|\varphi|^2$. Thus the variance of the momentum, if $\xi_0$ is the expectation, is equal to
%
\[ \sigma_\rho^2 = \int_{-\infty}^\infty |\rho - \rho_0|^2 |\varphi(\rho)|^2\; d\xi. \]
%
The relation between $\varphi$ and $\psi$ is given by the \emph{De-Broglie} relation, which informally says the momentum of a particle is proportional to it's frequency, and formally says that
%
\[ \varphi(\rho) = h^{-d/2} \int_{\RR^d} e^{- 2 \pi i \rho \cdot x / h} \psi(x)\; dx = h^{-d/2} \widehat{\psi}(\rho / h), \]
%
where $h > 0$ is Planck's constant. Thus Heisenberg's uncertainty principle tells us precisely that
%
\[ \sigma_x \cdot \sigma_\rho \geq h / 4 \pi = \hbar / 2. \]
%
Thus we have a fundamental limitation to the minimum possible uncertainty of the position and momentum of a particle.

We can also rephrase the uncertainty principle in terms of the differential operator
%
\[ L = x^2 - \frac{d^2}{dx^2}. \]
%
This operator is known as the \emph{Hermite operator}. Then for any $f \in \mathcal{S}(\RR)$,
%
\begin{align*}
    (Lf,f) &= \int_{-\infty}^\infty x^2 |f(x)|^2 - f''(x) \overline{f(x)}\; dx\\
    &= \int_{-\infty}^\infty x^2 |f(x)|^2\; dx + \int_{-\infty}^\infty |f'(x)|^2\; dx\\
    &= \int_{-\infty}^\infty x^2 |f(x)|^2\; dx + 4 \pi^2 \int_{-\infty}^\infty \xi^2 |\widehat{f}(\xi)|^2\; d\xi.
\end{align*}
%
The Heisenberg uncertainty principle thus implies that
%
\begin{align*}
    (f,f) &\leq 4 \pi \left( \int_{-\infty}^\infty x^2 |f(x)|^2\; dx \right)^{1/2} \left( \int_{-\infty}^\infty \xi^2 |\widehat{f}(\xi)|^2\; d\xi \right)^{1/2}\\
    &\leq \int_{-\infty}^\infty x^2 |f(x)|^2\; dx + 4 \pi^2 \int_{-\infty}^\infty \xi^2 |\widehat{f}(\xi)|^2\; d\xi = (Lf,f).
\end{align*}
%
Thus the operator $L - 1$ is formally positive definite. If we consider the operator
%
\[ Af = \frac{d}{dx} + x \quad\text{and}\quad A^* = - \frac{d}{dx} + x \]
%
then $A^*A = L - 1$. These two operators are called the \emph{annihilation} and \emph{creation} operators respectively.

The uncertainty principle is strongly connected to the \emph{noncommuting} natural of a certain natural pair of operators. Consider the \emph{position} operator
%
\[ Xf(x) = x f(x) \]
%
and the \emph{momentum} operator
%
\[ Df = (2 \pi i)^{-1} f'(x) \]
%
both continuous, self adjoint operators on $\mathcal{S}(\RR)$. Given an arbitrary self-adjoint operator $A$ on $\mathcal{S}(\RR)$, and $f \in \mathcal{S}(\RR)$ with $\| f \|_{L^2(\RR)} = 1$, we define the \emph{standard deviation} of the operator to be
%
\[ \sigma_A^2 f = \left( \langle Af, Af \rangle - \langle Af, f \rangle^2 \right)^{1/2} \]
%
%
For two self adjoint operators $A$ and $B$, the \emph{Robertson uncertainty relation} says that for any $f \in \mathcal{S}(\RR)$ with $\| f \|_{L^2(\RR)} = 1$,
%
\[ (\sigma_A^2 f) \cdot (\sigma_B^2 f) \geq \frac{1}{2} \int (AB - BA)f(x) \overline{f(x)}\; dx. \]
%
Since $[X,D]$ is the identity map, we see this version of the uncertainty principle implies the Heisenberg uncertainty principle given above as a special case.


\subsection{Bernstein's Inequality}

You can measure how `locally constant' a function is in terms of the smoothness of the function, i.e. if the derivative is small, then the function is roughly speaking, locally constant. Roughly speaking, if a function $f$ is constant at a scale $R$, then $Df$ should have magnitude on average equal to $1/R$. The Fourier transform of $Df$ is also supported on this ball, so we can iterate this argument, we should expect $D^kf$ to have magnitude on average equal to $1/R^k$. Formulating a precise version of the uncertainty principle here gives Bernstein's inequality. Let's begin with an $L^2$ version which is easiest to prove, since we have Plancherel.

\begin{lemma}
    If $f \in L^2(\RR^d)$ and $\widehat{f}$ is supported on a ball of radius $1/R$ about the origin, then for any multi-index $\alpha$,
    %
    \[ \| D^\alpha f \|_{L^2(\RR^d)} \leq (2 \pi / R)^{|\alpha|} \| f \|_{L^2(\RR^d)}. \]
\end{lemma}
\begin{proof}
    Plancherel tells us that
    %
    \[ \| D^\alpha f \|_{L^2(\RR^d)} = \| (2 \pi i \xi)^\alpha \widehat{f} \|_{L^2(\RR^d)}. \]
    %
    Since $\widehat{f}$ is supported on a ball of radius $R$, we conclude that on this support, $(2 \pi i \xi)^\alpha$ has magnitude at most $(2 \pi R)^{|\alpha|}$, and thus
    %
    \[ \| (2 \pi i \xi)^\alpha \widehat{f} \|_{L^2(\RR^d)} \leq (2 \pi / R)^{|\alpha|} \| \widehat{f} \|_{L^2(\RR^d)} = \| f \|_{L^2(\RR^d)}. \qedhere \]
\end{proof}

There is a version in more general $L^p$ spaces, but the proof is a little more technical.

\begin{lemma}
    If $f \in L^p(\RR^d)$ and $\widehat{f}$ is supported on a ball of radius $1/R$ about the origin, then for any multi-index $\alpha$, and any $q \leq p$,
    %
    \[ \| D^\alpha f \|_{L^p(\RR^d)} \lesssim R^{d(1/p - 1/q) - |\alpha|} \| f \|_{L^q(\RR^d)}. \]
\end{lemma}
\begin{proof}
    Choose a function $\psi \in \mathcal{S}(\RR^d)$ which has a compactly support Fourier transform which is equal to one on the ball of radius $1$ about the origin. If $\psi_R(x) = R^{-d} \psi(x / R)$, then the Fourier transform of $\psi_R$ is equal to one on a ball of radius $1/R$ about the origin. Now we have smoothness bounds on $\psi_R$, namely
    %
    \[ |(D^\alpha \psi_R)(x)| \lesssim_{\alpha,N} R^{-d-\alpha} (x/R)^{-N}. \]
    %
    Moreover, $f = f * \psi_R$, so the convolution should show that the smoothness of $\psi_R$ transfers to give the smoothness of $f$. More precisely, Young's inequality implies that if $1/p + 1 = 1/q + 1/r$, then
    %
    \begin{align*}
        \| D^\alpha f \|_{L^p(\RR^d)} &= \| f * D^\alpha \psi_R \|_{L^p(\RR^d)}\\
        &\lesssim \| f \|_{L^q(\RR^d)} \| D^\alpha \psi_R \|_{L^r(\RR^d)}\\
        &= R^{d(1/r - d) - \alpha} \| f \|_{L^q(\RR^d)}\\
        &= R^{d(1/p - 1/q) - \alpha} \| f \|_{L^q(\RR^d)}. \qedhere
    \end{align*}
\end{proof}

Here is another version of the inequality. Recall that for discrete quantities, $l^q \leq l^p$ for $p \leq q$. The uncertainty principle says that if the Fourier support of a function is concentrated, then it should be locally constant, and thus, roughly speaking, discrete. Thus we should expect that for such functions, we have $L^q \lesssim L^p$ for $p \leq q$. Making this precise leads to Bernstein's inequality. The result immediately follows from the last argument by taking $\alpha = 0$ in the last argument, but we give an independent argument that involves the $l^p$ and $l^q$ norms directly. First we prove a pointwise version of the uncertainty principle. Let $B$ and $B^*$ be \emph{dual ellipsoids}, i.e. ellipsoids with the same axes, and recipricol axis lengths. For a fixed $N > 0$, and a given ellipsoid $B$ with center $x_0$, axes given by vectors $v_1,\dots,v_d$, and axis lengths $r_1,\dots,r_d > 0$, define
%
\[ w_B(x) = \left\langle \sum_j \frac{|(x - x_0) \cdot v_j |^2}{r_j^2} \right\rangle^{-N}. \]
%
Then $w_B$ is concentrated on $B$.

\begin{lemma}
    Suppose $\widehat{f}$ is supported on a dual of an ellipsoid $B$. Then for any $x_0 \in B$, and any $x' \in B$,
    %
    \[ |f(x')| \lesssim_N \frac{1}{|B|} \int |f(x)| w_B(x)\; dx. \]
    %
    If $R > 0$, and $\widehat{f}$ is supported on a ball of radius $1/R$, then for $x_0 \in B$, and any $x$,
    %
    \[ |(D^\alpha f)(x)| \lesssim_{\alpha,N} R^{-|\alpha|} \left\langle \frac{x - x_0}{R} \right\rangle^d (Mf)(x_0). \]
\end{lemma}
\begin{proof}
    Applying rescaling and translation symmetries, assume $x_0 = 0$, and $R = 1$. We have $f = f * \psi$, where $\psi$ is as in the last argument. Thus
    %
    \[ |f(x')| \leq \int |f(x)| |\psi(x' - x)|\; dx. \]
    %
    Since $|x'| \leq 1$, $\langle x' - x \rangle \geq \langle x \rangle$, and so using the bound $|\psi(y)| \lesssim_N w(y)$, we conclude that
    %
    \[ |f(x')| \lesssim_N \int |f(x)| w(x)\; dx. \]
    %
    This proves the first inequality, for the second inequality, we may again assume $R = 1$ and $x_0 = 0$. We perform the same calculation, instead using the bound $\langle x' - x \rangle \geq \langle x \rangle$ for $|x| \geq 2 |x'|$, using a dyadic decomposition in $x$, and for $|x| \leq 2 |x'|$, using the trivial bound $\langle x' - x \rangle \geq 1$.
\end{proof}

\begin{remark}
    This calculation often suffices if $f$ is roughly speaking, a radial function, and the maximal averages of $f$ near $x_0$ occur on balls of radius $\sim R$. More detailed decompositions and calculations might be necessary if these conditions fail.
\end{remark}

The intuitive idea of the version of the proof using the fact that $l^q \leq l^p$ for $p \leq q$ intuitively precedes as follows. Without loss of generality, suppose that $\widehat{f}$ is supported on a ball of radius $1/R$ at the origin. An intuitive proof proceeds as follows: the uncertainty principle tells us that $f$ is locally constant on sidelength $O(R)$ cubes. Thus we can divide $\RR^d$ into an almost disjoint union of sidelength  cubes $\{ I_k : k \in \ZZ^d \}$, where $I_k$ has centre $R \cdot k$. Roughly speaking, we should be able to find constants $\{ c_k \}$ such that
%
\[ f \approx \sum c_k \chi_{I_k}. \]
%
It then follows that
%
\[ \| f \|_{L^q(\RR^d)} \approx R^{d/q} \| c \|_{l^q} \leq R^{d/q} \| c \|_{l^p} \approx R^{-(d/p - d/q)} \| f \|_{L^p(\RR^d)}.  \]
%
To make this argument work, we use the bound above. This result really says that for any ball $B_R$ of radius $R$,
%
\[ \| f \|_{L^\infty(B)} \lesssim_N R^{-d} \| f \|_{L^1(w_B)} \|. \]
%
Interpolation with the trivial inequalities
%
\[ \| f \|_{L^1(B)} \lesssim_N \| f \|_{L^1(w_B)} \quad\text{and}\quad \| f \|_{L^\infty(B)} \lesssim_N \| f \|_{L^\infty(w_B)} \]
%
gives that for $p \leq q$, $\| f \|_{L^q(B)} \lesssim_N R^{d(1/p-1/q)} \| f \|_{L^p(w_B)}$. This is not quite a local version of Bernstein's inequality, since $w_B$ is not compactly supported. But $w_B$ has Schwartz tails, so this is a \emph{pseudolocal} version of the inequality, which is often just as good in harmonic analysis. In particular, these bounds lead to another proof of the following lemma, by decomposing $\RR^d$ into a family of almost disjoint cubes $\{ I_k \}$ and then writing
%
\[ \| f \|_{L^q(\RR^d)} \sim \| \| f \|_{L^q(I_k)} \|_{l^q_k} \lesssim_N R^{d(1/p-1/q)} \| \| f \|_{L^p(w_{I_k})} \|_{l^p_k}. \]
%
The rapid decay of the weights $\{ w_{I_k} \}$ allows us to get a bound of the form
%
\[ \| \| f \|_{L^p(w_{I_k})} \|_{l^p_k} \lesssim \| \| f \|_{L^p(I_k)} \|_{l^p_k} \sim \| f \|_{L^p(\RR^d)}, \]
%
which completes the proof. More precisely, we have
%
\[ w_{I_k} \lesssim \sum_{m = 0}^\infty 2^{-Nm} \chi_{2^m I_k}. \]
%
The triangle inequality implies that
%
\[ \| f \|_{L^p(w_{I_k})} \lesssim \sum_{m = 0}^\infty 2^{-Nm} \sum_{m = 0}^\infty \| f \|_{L^p(2^m I_k)} \lesssim \sum_{m = 0}^\infty 2^{-Nm} \sum_{|a| \leq 2^m} \| f \|_{L^p(I_{k + a})}. \]
%
Finally, the triangle inequality then implies that
%
\begin{align*}
    \| \| f \|_{L^p(w_{I_k})} \|_{l^p_k} &\leq \sum_{m = 0}^\infty 2^{-Nm} \sum_{|a| \leq 2^m} \|  \| f \|_{L^p(I_{k+a})} \|_{l^p_k}\\
    &= \sum_{m = 0}^\infty 2^{-Nm} 2^{dm} \|  \| f \|_{L^p(I_{k+a})} \|_{l^p_k}\\
    &\sim \sum_{m = 0}^\infty 2^{-Nm} 2^{dm} \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Taking $N > d$ gives the required bound.

There are extensions of these results to \emph{ellipsoids} rather than balls. One can reformulate the uncertainty principle as follows: if $\widehat{f}$ is supported in the \emph{dual} of an ellipsoid $E$ (obtained by inverting the ellipse on each axis), then $f$ is locally constant of translates of the ellipsoid $E$. It is simple to obtain these results from the results above using balls, by using the way the Fourier transforms under changing coordinates linearly by an element of $GL(d)$. One can also use rectangles, and dual rectangles (we snuck in some applications using cubes instead of balls in the proofs above), since these shapes all have comparable size to their round counterparts.

\begin{comment}

\begin{lemma}
    Suppose $f \in L^q(\RR^d)$, and $\text{supp} \left(\widehat{f} \right)$ is contained in a ball of radius $1/R$. Then or $p \leq q$,
    %
    \[ \| f \|_{L^q(\RR^d)} \lesssim R^{-d(1/p - 1/q)} \| f \|_{L^p(\RR^d)}. \]
\end{lemma}
\begin{proof}
    
    %
    To make this argument more precise, we have $f = \sum f \chi_{I_k}$, and so
    %
    \begin{align*}
        \| f \|_{L^q(\RR^d)} = \| \| f \|_{L^q(I_k)} \|_{l^q_k}.
    \end{align*}
    %
    If we fix a large $N > d$, and define
    %
    \[ c_k = \frac{1}{R^d} \int |f(x)| w_N \left( \frac{x - k}{R} \right)\; dx \]
    %
    then the pointwise inequality we prove in the last result shows that
    %
    \[ \| f \|_{L^q(I_k)} \lesssim c_k R^{-d/q} \]
    %
    and so we find that
    %
    \[ \| f \|_{L^q(\RR^d)} \lesssim R^{-d/q} \| c \|_{l^q} \lesssim R^{-d/q} \| c \|_{l^p}. \]
    %
    Now decompose the integral defining $c_k$ into a ball of radius $R$ centered at $k$ (the `main term'), and annuli of radius $2^m R$ and thickness $O(2^m R)$ centered at $k$ (remainder terms), thus writing
    %
    \begin{align*}
        c_k = \sum_{m = 0}^\infty I_{k,m}.
    \end{align*}
    %
    On $|x - k| \leq R$, $w_N((x - k)/R) \sim 1$, and so H\"{o}lder's inequality says that
    %
    \[ I_{k,0} \lesssim \frac{1}{R^d} \int_{|x - R k| \leq R} |f(x)|\; dx \lesssim R^{-d/p} \| f \chi_k \|_{L^p(\RR^d)}. \]
    %
    Thus
    %
    \[ \| I_{k,0} \|_{l^p_k} \lesssim R^{-d/p} \| f \chi_k \|_{L^p(\RR^d)} \|_{l^p_k} \lesssim R^{-d/p} \| f \|_{L^p(\RR^d)}. \]
    %
    More generally, on $|x - k| \sim 2^m R$ we have $w_N((x-k)/R) \sim 2^{-Nm}$, and so we have
    %
    \begin{align*}
        I_{k,m} &\sim \frac{2^{-Nm}}{R^d} \int_{|x - k| \sim 2^m R} |f(x)|\; dx\\
        &\lesssim \sum_{|k' - k| \leq 2^m} 2^{-Nm}{R^d} \int_{|x - k'| \lesssim R} |f(x)|\; dx\\
        &\lesssim R^{-d/p} 2^{-Nm} \sum_{|k' - k| \leq 2^m} \| f \chi_{k'} \|_{L^p(\RR^d)}.
    \end{align*}
    %
    Thus
    %
    \begin{align*}
        \| I_{k,m} \|_{l^p_k} &\lesssim R^{-d/p} 2^{-Nm} \| \sum_{|a| \leq 2^m} \| f \chi_{k + a} \|_{L^p(\RR^d)} \|_{l^p_k}\\
        &\leq R^{-d/p} 2^{-Nm} \sum_{|a| \leq 2^m} \| \| f \chi_{k + a} \|_{L^p(\RR^d)} \|_{l^p_k}\\
        &\sim R^{-d/p} 2^{-Nm} \sum_{|a| \leq 2^m} \| f \|_{L^p(\RR^d)}\\
        &\sim R^{-d/p} 2^{m(d-N)} \| f \|_{L^p(\RR^d)}.
    \end{align*}
    %
    For $N > d$, we can sum this result in $m$, and conclude that
    %
    \[ \| c_k \|_{l^p_k} \leq \sum_{m = 0}^\infty \| I_{k,m} \|_{l^p_k} \lesssim R^{-d/p} \| f \|_{L^p(\RR^d)} \| 2^{m(d-N)} \|_{l^p_k} \lesssim R^{-d/p} \| f \|_{L^p(\RR^d)}. \qedhere \]
\end{proof}

\end{comment}




\section{Sums of Random Variables}

TODO

We now switch to an application of harmonic analysis to studying sums of random variables probability theory. If $X$ is a random vector, it's probabilistic information is given by it's distribution on $\RR^n$, which can be seen as a measure $\mathbf{P}_X$ on $\RR^n$, with $\mathbf{P}_X(E) = \mathbf{P}(X \in E)$. Given two independent random vectors $X$ and $Y$, $\mathbf{P}_{X+Y}$ is the convolution $\mathbf{P}_X * \mathbf{P}_Y$ between the measures $\mathbf{P}_X$ and $\mathbf{P}_Y$, in the sense that
%
\[ \mathbf{P}_{X+Y}(E) = \int \chi_E(x+y)\; d\mathbf{P}_X(x)\; d\mathbf{P}_Y(y) \]
%
If $d\mathbf{P}_X = f_X \cdot dx$ and $d\mathbf{P}_Y = f_Y \cdot dx$, then $d(\mathbf{P}_X * \mathbf{P}_Y) = (f_X * f_Y) \cdot dx$ is just the normal convolution of functions. This is why harmonic analysis becomes so useful when analyzing sums of independent random variables.

It is useful to express the Fourier transform in a probabilistic language. Given a random variable $X$,
%
\[ \widehat{\mathbf{P}_X}(\xi) = \int e^{i \xi \cdot x} d\mathbf{P}_X(x) \]
%
Thus the natural Fourier transform of a random vector $X$ is the {\emph characteristic function} $\varphi_X(\xi) = \mathbf{E}(e^{i \xi \cdot X})$. It is a continuous function for any random variable $X$. We can also express the properties of the Fourier transform in a probabilistic language.

\begin{lemma}
    Let $X$ and $Y$ be independent random variables. Then
    %
    \begin{itemize}
        \item $\varphi_X(0) = 1$, and $|\varphi_X(\xi)| \leq 1$ for all $\xi$.

        \item (Symmetry) $\varphi_X(\xi) = \overline{\varphi_X(-\xi)}$.

        \item (Convolution) $\varphi_{X+Y} = \varphi_X \varphi_Y$.

        \item (Translation and Dilation) $\varphi_{X+a}(\xi) = e^{i a \cdot \xi} \varphi_X(\xi)$, and $\varphi_{\lambda X}(\xi) = \varphi_X(\lambda \xi)$.

        \item (Rotations) If $R \in O(n)$ is a rotation, then $\varphi_{R(X)}(\xi) = \varphi_X(R(X))$.
    \end{itemize}
\end{lemma}

Using the Fourier inversion formula, if $\varphi_X$ is integrable, then $X$ is a continuous random variable, with density
%
\[ f(x) = \int e^{- i \xi x} \varphi_X(\xi)\; d\xi \]
%
In particular, if $\varphi_X = \varphi_Y$, then $X$ and $Y$ are identically distributed. This already gives interesting results.

\begin{theorem}
    If $X$ and $Y$ are independent normal distributions, then $aX + bY$ is normally distributed.
\end{theorem}
\begin{proof}
    Since $\varphi_{aX+bY}(\xi) = \varphi_X(a \xi) \varphi_Y(b \xi)$, it suffices to show that the product of two such characteristic functions is the characteristic function of a normal distribution. If $X$ has mean $\mu$ and covariance matrix $\Sigma$, then $X \cdot \xi$ has mean $\mu \cdot \xi$ and variance $\xi^T \Sigma \xi$, and one calculates that $\mathbf{E}[e^{i \xi \cdot X}] = e^{- i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ using similar techniques to the Fourier transform of a Gaussian. One verifies that the class of functions of the form $e^{-i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ is certainly closed under multiplication and scaling, which completes the proof. 
\end{proof}

Now we can prove the celebrated central limit theorem. Note that if

\begin{theorem}
    Let $X_1, \dots, X_N$ be independent and identically distributed with mean zero and variance $\sigma^2$. If $S_N = X_1 + \dots + X_N$, then
    %
    \[ \mathbf{P}(S_N \leq \sigma \sqrt{N} t) \to \Phi(t) = \frac{1}{\sqrt{2x}} \int_{-\infty}^t e^{-y^2/2}\; dy \]
\end{theorem}
\begin{proof}
    We calculate that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = \varphi_X(\xi/\sigma \sqrt{N})^N \]
    %
    Define $R_n(x) = e^{ix} - 1 - (ix) - (ix)^2/2 - \dots - (ix)^n/n!$. Then because of oscillation and the fundamental theorem of calculus,
    %
    \[ |R_0(x)| = \left| i \int_0^x e^{iy}\; dy \right| \leq \min(2,|x|) \]
    %
    Next, since $R_{n+1}'(x) = i R_n$,
    %
    \[ R_{n+1}(x) = i  \int_0^x R_n(y)\; dy \]
    %
    This gives that $|R_n(x)| \leq \min(2|x|^n/n!,|x|^{n+1}/(n+1)!)$. In particular, we conclude
    %
    \[ |\varphi_X(\xi) - 1 - \sigma^2 \xi^2/2| = |\mathbf{E}(R_2(\xi X))| \leq \mathbf{E}|R_2(\xi X)| \leq |\xi|^2 \mathbf{E} \left( \min \left( |X|^2, |\xi X|^3/6 \right) \right) \]
    %
    By the dominated convergence theorem, as $\xi \to 0$, $\varphi_X(\xi) = 1 - \xi^2 \sigma^2/2 + o(\xi^2)$. But this means that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = (1 - \xi^2 / 2 N + o(\xi^2/\sigma^2 N))^N = \exp(-\xi^2/2) \]
    %
    This implies the random variables converge weakly to a normal distribution.
\end{proof}


\section{The Wirtinger Inequality on an Interval}

\begin{theorem}
    Given $f \in C^1[-\pi,\pi]$ with $\int_{-\pi}^\pi f(t) dt = 0$,
    %
    \[ \int_{-\pi}^\pi |f(t)|^2 \leq \int_{-\pi}^\pi |f'(t)|^2 \]
\end{theorem}
\begin{proof}
    Consider the fourier series
    %
    \[ f(t) \sim \sum a_n e_n(t)\ \ \ \ \ f'(t) \sim \sum in a_n e_n(t) \]
    %
    Then $a_0 = 0$, and so
    %
    \[ \int_{-\pi}^\pi |f(t)|^2\ dt = 2 \pi \sum |a_n|^2 \leq 2 \pi \sum n^2 |a_n|^2 = \int_{-\pi}^\pi |f'(t)|^2\ dt \]
    %
    equality holds here if and only if $a_i = 0$ for $i > 1$, in which case we find
    %
    \[ f(t) = A e_n(t) + \overline{A} e_n(-t) = B \cos(t) + C \sin(t) \]
    %
    for some constants $A \in \CC$, $B,C \in \RR$.
\end{proof}

\begin{corollary}
    Given $f \in C^1[a,b]$ with $\int_a^b f(t)\ dt = 0$,
    %
    \[ \int_a^b |f(t)|^2 dt \leq \left(\frac{b-a}{\pi}\right)^2 \int_a^b |f'(t)|^2\ dt \]
\end{corollary}

\section{Energy Preservation in the String equation}

Solutions to the string equation are

If $u(t,x)$

\section{Harmonic Functions} 

The study of a function $f$ defined on the real line can often be understood by extending it's definition holomorphically to the complex plane. Here we will extend this tool, establishing that a large family of functions $f$ defined on $\RR^n$ can be understood by looking at a {\it harmonic} function on the upper half plane $\mathbf{H}^{n+1}$, which approximates $f$ at it's boundary. This is a form of the Dirichlet problem, which asks, given a domain and a function on the domain's boundary, to find a function harmonic on the interior of the domain which `agrees' with the function on the boundary, in one of several senses. As we saw in our study of harmonic functions on the disk in the study of Fourier series, we can study such harmonic functions by convolving $f$ with an appropriate approximation to the identity which makes the function harmonic in the plane. In this case, we shall use the Poisson kernel for the upper half plane.

\begin{theorem}
    If $f \in L^p(\RR^n)$, for $1 \leq p \leq \infty$, and $u(x,y) = (f * P_y)(x)$, where
    %
    \[ P_y(x) = \frac{\Gamma((n+1)/2)}{\pi^{(n+1)/2}} \frac{1}{(1 + |x|^2)^{(n+1)/2}} \]
    %
    then $u$ is harmonic in the upper half plane, $u(x,y) \to f(x)$ for almost every $x$, and $u(\cdot,y)$ converges to $f$ in $L^p$ as $y \to 0$, with $\| u(\cdot,y) \|_{L^p(\RR^n)} \leq \| f \|_{L^p(\RR^n)}$. If, instead, $f$ is a continuous and bounded function, then $u(\cdot,y)$ converges to $f$ locally uniformly as $y \to 0$.
\end{theorem}
\begin{proof}
    The almost everywhere convergence and convergence in norm follow from the fact that $P_y$ is an approximation to the identity. The fact that $u$ is harmonic follows because
    %
    \[ u_{xx}(x,y) = (f * P_y'')(x)\ \ \ \ \ u_{yy} = (f * ) \]
\end{proof}









\chapter{Partial Derivatives and Harmonic Functions}

\section{Conjugate Poisson Kernel}

Recall from our discussion of the Poisson kernel that for $f \in L^p(\RR)$ for $1 \leq p \leq \infty$, if we define
%
\[ u(x,t) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x - t |\xi|}\; d\xi \]
%
then we obtain a harmonic function on the upper half plane. TODO If we define
%
\[ \frac{\partial v}{\partial t} = (2 \pi i) \int_{-\infty}^\infty \widehat{f}(\xi) \xi e^{2 \pi i \xi x - t |\xi|}\; d\xi \]
\[ \frac{\partial v}{\partial x} = - |\xi| \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x - t |\xi|}\; d\xi. \]










\chapter{Finite Character Theory}

Let us review our achievements so far. We have found several important families of functions on the spaces we have studied, and shown they can be used to approximate arbitrary functions. On the circle group $\TT$, the functions take the form of the power maps $\phi_n: z \mapsto z^n$, for $n \in \ZZ$. The important properties of these functions is that
%
\begin{itemize}
    \item The functions are orthogonal to one another.
    \item A large family of functions can be approximated by linear combinations of the power maps.
    \item The power maps are multiplicative: $\phi_n(zw) = \phi_n(z) \phi_n(w)$.
\end{itemize}
%
The existence of a family with these properties is not dependant on much more than the symmetry properties of $\TT$, and we can therefore generalize the properties of the fourier series to a large number of groups. In this chapter, we consider a generalization to any finite abelian group.

The last property of the power maps should be immediately recognizable to any student of group theory. It implies the exponentials are homomorphisms from the circle group to itself. This is the easiest of the three properties to generalize to arbitrary groups; we shall call a homomorphism from a finite abelian group to $\TT$ a {\emph character}. For any abelian group $G$, we can put all characters together to form the character group $\Gamma(G)$, which forms an abelian group under pointwise multiplication $(fg)(z) = f(z)g(z)$. It is these functions which are `primitive' in synthesizing functions defined on the group.

\begin{example}
    If $\mu_N$ is the set of $N$th roots of unity, then $\Gamma(\mu_N)$ consists of the power maps $\phi_n: z \mapsto z^n$, for $n \in \ZZ$. Because
    %
    \[ \phi(\omega)^N = \phi(\omega^N) = \phi(1) = 1 \]
    %
    we see that any character on $\mu_N$ is really a homomorphism from $\mu_N$ to $\mu_N$. Since the homomorphisms on $\mu_N$ are determined by their action on this primitive root, there can only be at most $N$ characters on $\mu_N$, since there are only $N$ elements in $\mu_N$. Our derivation then shows us that the $\phi_N$ enumerate all such characters, which completes our proof. Note that since $\phi_n \phi_m = \phi_{n+m}$, and $\phi_n = \phi_m$ if and only if $n - m$ is divisible by $N$, this also shows that $\Gamma(\mu_N) \cong \mu_N$.
\end{example}

\begin{example}
    The group $\ZZ_N$ is isomorphic to $\mu_N$ under the identification $n \mapsto \omega^n$, where $\omega$ is a primitive root of unity. This means that we do not need to distinguish functions `defined in terms of $n$' and `defined in terms of $\omega$', assuming the correspondance $n = \omega^n$. This is exactly the same as the correspondence between functions on $\TT$ and periodic functions on $\RR$. The characters of $\ZZ_n$ are then exactly the maps $n \mapsto \omega^{kn}$. This follows from the general fact that if $f: G \to H$ is an isomorphism of abelian groups, the map $f^*: \phi \mapsto \phi \circ f$ is an isomorphism from $\Gamma(H)$ to $\Gamma(G)$.
\end{example}

\begin{example}
    If $K$ is a finite field, then the set $K^*$ of non-zero elements is a group under multiplication. A rather sneaky algebraic proof shows the existence of elements of $K$, known as primitive elements, which generate the multiplicative group of all numbers. Thus $K$ is cyclic, and therefore isomorphic to $\mu_N$, where $N = |K| - 1$. The characters of $K$ are then easily found under the correspondence.
\end{example}

\begin{example}
    For a fixed $N$, the set of invertible elements of $\ZZ_N$ form a group under multiplication, denoted $\ZZ_N^*$. Any character from $\ZZ_N^*$ is valued on the $\varphi(N)$'th roots of unity, because the order of each element in $\ZZ_N^*$ divides $\varphi(N)$. The groups are in general non-cyclic. For instance, $\ZZ_8^* \cong \ZZ_2^3$. However, we can always break down a finite abelian group into cyclic subgroups to calculate the character group; a simple argument shows that $\Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H)$, where we identify $(f,g)$ with the map $(x,y) \mapsto f(x)g(y)$.
\end{example}

\section{Fourier Analysis on Cyclic Groups}

We shall start our study of abstract Fourier analysis by looking at Fourier analysis on $\mu_N$. Geometrically, these points uniformly distribute themselves over $\TT$, and therefore $\mu_N$ provides a good finite approximation to $\TT$. Functions from $\mu_N$ to $\CC$ are really just functions from $[n] = \{ 1, \dots, n \}$ to $\CC$, and since $\mu_N$ is isomorphic to $\ZZ_N$, we're really computing the Fourier analysis of finite domain functions, in a way which encodes the translational symmetry of the function relative to translational shifts on $\ZZ_N$.

There is a trick which we can use to obtain quick results about Fourier analysis on $\mu_N$. Given a function $f: [N] \to \CC$, consider the $N$-periodic function on the real line defined by
%
\[ g(t) = \sum_{n = 1}^N f(n) \chi_{(n-1/2,n+1/2)}(t) \]
%
Classical Fourier analysis of $g$ tells us that we can expand $g$ as an infinite series in the functions $e(n/N)$, which may be summed up over equivalence classes modulo $N$ to give a finite expansion of the function $f$. Thus we conclude that every function $f: [N] \to \CC$ has an expansion
%
\[ f(n) = \sum_{m = 1}^N \widehat{f}(m) e(nm) \]
%
where $\widehat{f}(m)$ are the coefficients of the {\emph finite Fourier transform} of $f$. This method certainly works in this case, but does not generalize to understand the expansion of general finite abelian groups.

The correct generalization of Fourier analysis is to analyze the set of complex valued `square integrable functions' on the domain $[N]$. We consider the space $V$ of all maps $f: [N] \to \CC$, which can be made into an inner product space by defining
%
\[ \langle f, g \rangle = \frac{1}{N} \sum_{n = 1}^N f(n) \overline{g(n)} \]
%
We claim that the characters $\phi_n: z \mapsto z^n$ are orthonormal in this space, since
%
\[ \langle \phi_n, \phi_m \rangle = \frac{1}{N} \sum_{k = 1}^N \omega^{k(n-m)} \]
%
If $n = m$, we may sum up to find $\langle \phi_n, \phi_m \rangle = 1$. Otherwise we use a standard summation formula to find
%
\[ \sum_{k = 1}^N \omega^{k(n-m)} = \omega^{n-m} \frac{\omega^{N(n-m)} - 1}{\omega^{n-m} -1} \]
%
Since $\omega^{N(n-m)} = 1$, we conclude the sum is zero. This implies that the $\phi_n$ are orthonormal, hence linearly independent. Since $V$ is $N$ dimensional, this implies that the family of characters forms an orthogonal basic for the space. Thus, for any function $f: [N] \to \CC$, we have, if we set $\widehat{f}(m) = \langle f, \phi_m \rangle$, then
%
\[ f(n) = \sum_{m = 1}^N \langle f, \phi_m \rangle \phi_m(n) = \sum_{m = 1}^N \widehat{f}(m) e(mn/N) \]
%
This calculation can essentially be applied to an arbitrary finite abelian group to obtain an expansion in terms of Fourier coefficients.

\section{An Arbitrary Finite Abelian Group}

It should be easy to guess how we proceed for a general finite abelian group. Given some group $G$, we study the character group $\Gamma(G)$, and how $\Gamma(G)$ represents general functions from $G$ to $\CC$. We shall let $V$ be the space of all such functions from $G$ to $\CC$, and on it we define the inner product
%
\[ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
%
If there's any justice in the world, these characters would also form an orthonormal basis.

\begin{theorem}
    The set $\Gamma(G)$ of characters is an orthonormal set.
\end{theorem}
\begin{proof}
    If $e$ is a character of $G$, then $|e(a)| = 1$ for each $a$, and so
    %
    \[ \langle e, e \rangle = \frac{1}{|G|} \sum_{a \in G} |e(a)| = 1 \]
    %
    If $e \neq 1$ is a non-trivial character, then $\sum_{a \in G} e(a) = 0$. To see this, note that for any $b \in G$, the map $a \mapsto ba$ is a bijection of $G$, and so
    %
    \[ e(b) \sum_{a \in G} e(a) = \sum_{a \in G} e(ba) = \sum_{a \in G} e(a) \]
    %
    Implying either $e(b) = 1$, or $\sum_{a \in G} e(a) = 0$. If $e_1 \neq e_2$ are two characters, then
    %
    \[ \langle e_1, e_2 \rangle = \frac{1}{|G|} \sum_{a \in G} \frac{e_1(a)}{e_2(a)} = 0 \]
    %
    since $e_1/e_2$ is a nontrivial character.
\end{proof}

Because elements of $\Gamma(G)$ are orthonormal, they are linearly independent over the space of functions on $G$, and we obtain a bound $|\Gamma(G)| \leq |G|$. All that remains is to show equality. This can be shown very simply by applying the structure theorem for finite abelian groups. First, note it is true for all cyclic groups. Second, note that if it is true for two groups $G$ and $H$, it is true for $G \times H$, because
%
\[ \Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H) \]
%
since a finite abelian group is a finite product of cyclic groups, this proves the theorem. This seems almost like sweeping the algebra of the situation under the rug, however, so we will prove the statement only using elementary linear algebra. What's more, these linear algebraic techniques generalize to the theory of unitary representations in harmonic analysis over infinite groups.

\begin{theorem}
    Let $\{ T_1, \dots, T_n \}$ be a family of commuting unitary matrices. Then there is a basis $v_1, \dots, v_m \in \CC^m$ which are eigenvectors for each $T_i$.
\end{theorem}
\begin{proof}
    For $n = 1$, the theorem is the standard spectral theorem. For induction, suppose that the $T_1, \dots, T_{k-1}$ are simultaneously diagonalizable. Write
    %
    \[ \CC^m = V_{\lambda_1} \oplus \dots \oplus V_{\lambda_l} \]
    %
    where $\lambda_i$ are the eigenvalues of $T_k$, and $V_{\lambda_i}$ are the corresponding eigenspaces. Then if $v \in V_{\lambda_i}$, and $j < k$,
    %
    \[ T_k T_j v = T_j T_k v = \lambda_i T_j v \]
    %
    so $T_j(V_{\lambda_i}) = V_{\lambda_i}$. Now on each $V_{\lambda_i}$, we may apply the induction hypotheis to diagonalize the $T_1, \dots, T_{k-1}$. Putting this together, we simultaneously diagonalize $T_1, \dots, T_k$.
\end{proof}

This theorem enables us to prove the character theory in a much simpler manner. Let $V$ be the space of complex valued functions on $G$, and define, for $a \in G$, the map $(T_a f)(b) = f(ab)$. $V$ has an orthonormal basic consisting of the $\chi_a(b) = N [a = b]$, for $a \in G$. In this basis, we comcpute $T_a \chi_b = \chi_{ba^{-1}}$, hence $T_a$ is a permutation matrix with respect to this basis, hence unitary. The operators $T_a$ commute, since $T_aT_b = T_{ab} = T_{ba} = T_b T_a$. Hence these operators can be simultaneously diagonalized. That is, there is a family $e_1, \dots, e_n \in V$ and $\lambda_{an} \in \TT$ such that for each $a \in G$, $T_a e_n = \lambda_{an} f_n$. We may assume $e_n(1) = 1$ for each $n$ by normalizing. Then, for any $a \in G$, we have $f_n(a) = f_n(a \cdot 1) = \lambda_{an} f_n(1) = \lambda_{an}$, so for any $b \in G$, $f_n(ab) = \lambda_{an} f_n(b) = f_n(a) f_n(b)$. This shows each $f_n$ is a character, completing the proof. We summarize our discussion in the following theorem.

\begin{theorem}
    Let $G$ be a finite abelian group. Then $\Gamma(G) \cong G$, and forms an orthonormal basis for the space of complex valued functions on $G$. For any function $f: G \to \CC$,
    %
    \[ f(a) = \sum_{e \in \Gamma(G)} \langle f, e \rangle\ e(a) = \sum_{e \in \Gamma(G)} \hat{f}(e) e(a)\ \ \ \ \ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
    %
    In this context, we also have Parseval's theorem
    %
    \[ \| f(a) \|^2 = \sum_{e \in \hat{G}} |\widehat{f}(e)|^2\ \ \ \ \ \langle f, g \rangle = \sum_{e \in \hat{G}} \widehat{f}(e) \overline{\widehat{g}(e)} \]
\end{theorem}

\section{Convolutions}

There is a version of convolutions for finite functions, which is analogous to the convolutions on $\RR$. Given two functions $f,g$ on $G$, we define a function $f * g$ on $G$ by setting
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(b) g(b^{-1} a) \]
%
The mapping $b \mapsto ab^{-1}$ is a bijection of $G$, and so we also have
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(ab^{-1}) g(b) = (g * f)(a) \]
%
For $e \in \Gamma(G)$,
%
\begin{align*}
    \widehat{f * g}(e) &= \frac{1}{|G|} \sum_{a \in G} (f*g)(a) \overline{e(a)}\\
    &= \frac{1}{|G|^2} \sum_{a,b \in G} f(ab) g(b^{-1}) \overline{e(a)}
\end{align*}
%
The bijection $a \mapsto ab^{-1}$ shows that
%
\begin{align*}
    \widehat{f*g}(e) &= \frac{1}{|G|^2} \sum_{a,b} f(a) g(b^{-1}) \overline{e(a)} \overline{e(b^{-1})}\\
    &= \frac{1}{|G|} \left( \sum_a f(a) \overline{e(a)} \right) \frac{1}{|G|} \left( \sum_b g(b) \overline{e(b)} \right)\\
    &= \widehat{f}(e) \widehat{g}(e)
\end{align*}
%
In the finite case we do not need approximations to the identity, for we have an identity for convolution. Define $D: G \to \CC$ by
%
\[ D(a) = \sum_{e \in \Gamma(G)} e(a) \]
%
We claim that $D(a) = |G|$ if $a = 1$, and $D(a) = 0$ otherwise. Note that since $|G| = |\Gamma(G)|$, the character space of $\Gamma(G)$ is isomorphic to $G$. Indeed, for each $a \in G$, we have the maps $\widehat{a}: e \mapsto e(a)$, which is a character of $\Gamma(G)$. Suppose $e(a) = 1$ for all characters $e$. Then $e(a) = e(1)$ for all characters $e$, and for any function $f: G \to \CC$, we have $f(a) = f(1)$, implying $a = 1$. Thus we obtain $|G|$ distinct maps $\widehat{a}$, which therefore form the space of all characters. It therefore follows from a previous argument that if $a \neq 1$, then
%
\[ \sum_{e \in \Gamma(G)} e(a) = 0 \]
%
Now $f * D = f$, because
%
\[ \widehat{D}(e) = \frac{1}{|G|} \sum_{a \in G} D(a) \overline{e(a)} = \overline{e}(1) = 1 \]
%
$D$ is essentially the finite dimensional version of the Dirac delta function, since it has unit mass, and acts as the identity in convolution.

\section{The Fast Fourier Transform}

The main use of the fourier series on $\mu_n$ in applied mathematics is to approximate the Fourier transform on $\TT$, where we need to compute integrals explicitly. If we have a function $f \in L^1(\TT)$, then $f$ may be approximated in $L^1(\TT)$ by step functions of the form
%
\[ f_n(t) = \sum_{k = 1}^{n} a_k \Ind(x \in (2 \pi (k-1) / n, 2 \pi k / n)) \]
%
And then $\widehat{f_n} \to \widehat{f}$ uniformly. The Fourier transform of $f_n$ is the same as the Fourier transform of the corresponding function $k \mapsto a_k$ on $\ZZ_n$, and thus we can approximate the Fourier transform on $\TT$ by a discrete computation on $\ZZ_n$. Looking at the formula in the definition of the discrete transform, we find that we can compute the Fourier coefficients of a function $f: \ZZ_n \to \CC$ in $O(n^2)$ addition and multiplication operations. It turns out that there is a much better method of computation which employs a divide and conquer approach, which works when $n$ is a power of 2, reducing the calculation to $O(n \log n)$ multiplications. Before this process was discovered, calculation of Fourier transforms was seen as a computation to avoid wherever possible.

To see this, consider a particular division in the group $\ZZ_{2n}$. Given $f: \ZZ_{2n} \to \CC$, define two functions $g,h: \ZZ_n \to \CC$, defined by $g(k) = f(2k)$, and $h(k) = f(2k + 1)$. Then $g$ and $h$ encode all the information in $f$, and if $\nu = e(\pi/n)$ is the canonical generator of $\ZZ_{2n}$, we have
%
\[ \hat{f}(m) = \frac{\hat{g}(m) + \hat{h}(m) \nu^m}{2} \]
%
Because
%
\begin{align*}
    \frac{1}{2n} \sum_{k = 1}^{n} \left( g(k) \omega^{-km} + h(m) \omega^{-km} \nu^m \right) &= \frac{1}{2n} \sum_{k = 1}^n f(2k) \nu^{-2km} + f(2k + 1) \nu^{-(2k+1)m}\\
    &= \frac{1}{2n} \sum_{k = 1}^{2n} f(k) \nu^{-km}
\end{align*}
%
This is essentially a discrete analogue of the Poission summation formula, which we will generalize later when we study the harmonic analysis of abelian groups. If $H(m)$ is the number of operations needed to calculate the Fourier transform of a function on $\mu_{2^n}$ using the above recursive formula, then the above relation tells us $H(2m) = 2H(m) + 3 (2m)$. If $G(n) = H(2^n)$, then $G(n) = 2G(n-1) + 3 2^n$, and $G(0) = 1$, and it follows that
%
\[ G(n) = 2^n + 3 \sum_{k = 1}^n 2^{k} 2^{n-k} = 2^n(1 + 3n) \]
%
Hence for $m = 2^n$, we have $H(m) = m(1 + 3 \log (m)) = O(m \log m)$. Similar techniques show that one can compute the inverse Fourier transform in $O(m \log m)$ operations (essentially by swapping the root $\nu$ with $\nu^{-1}$).

\section{Dirichlet's Theorem}

We now apply the theory of Fourier series on finite abelian groups to prove Dirichlet's theorem.

\begin{theorem}
    If $m$ and $n$ are relatively prime, then the set
    %
    \[ \{ m + kn : k \in \mathbf{N} \} \]
    %
    contains infinitely many prime numbers.
\end{theorem}

An exploration of this requries the Riemann-Zeta function, defined by
%
\[ \zeta(s) = \sum_{n = 1}^\infty \frac{1}{n^s} \]
%
The function is defined on $(1,\infty)$, since for $s > 1$ the map $t \mapsto 1/t^s$ is decreasing, and so
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \leq 1 + \int_{1}^\infty \frac{1}{t^s} = 1 + \lim_{n \to \infty} \frac{1}{s-1} \left[1 - 1/n^{s-1} \right] = 1 + \frac{1}{s-1} \]
%
The series converges uniformly on $[1+\varepsilon, N]$ for any $\varepsilon > 0$, so $\zeta$ is continuous on $(1,\infty)$. As $t \to 1$, $\zeta(t) \to \infty$, because $n^s \to n$ for each $n$, and if for a fixed $M$ we make $s$ close enough to $1$ such that $|n/n^s - 1|<  1/2$ for $1 \leq n \leq M$, then
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \geq \sum_{n = 1}^M \frac{1}{n^s} = \sum_{n = 1}^M \frac{1}{n} \frac{n}{n^s} \geq \frac{1}{2} \sum_{n = 1}^M \frac{1}{n} \]
%
Letting $M \to \infty$, we obtain that $\sum_{n = 1}^\infty \frac{1}{n^s} \to \infty$ as $s \to 1$.

The Riemann-Zeta function is very good at giving us information about the prime integers, because it encodes much of the information about the prime numbers.

\begin{theorem}
    For any $s > 1$,
    %
    \[ \zeta(s) = \prod_{p\ \text{prime}} \frac{1}{1 - p^s} \]
\end{theorem}
\begin{proof}
    The general idea is this -- we may write
    %
    \[ \prod_{p\ \text{prime}} \frac{1}{1 - p^s} = \prod_{p\ \text{prime}} (1 + 1/p^{s} + 1/p^{2s} + \dots) \]
    %
    If we expand this product out formally, enumating the primes to be $p_1, p_2, \dots$, we find
    %
    \[ \prod_{p \leq n} (1 + 1/p^s + 1/p^{2s} + \dots) = \sum_{n_1, n_2, \dots = 0}^\infty \frac{1}{p_1^{n_1}} \]
\end{proof}













\chapter{Harmonic Functions}

In this chapter, we illustrate the intimate connection between the Fourier transform on the real line, and complex analysis, as well as connections to the theory of harmonic functions. We have already seen some aspects of this for Fourier analysis on the Torus, with the connection between power series of analytic functions on the unit disk. The main theme is that if $f$ is a function initially defined on the real line, then the problem of extending the function to be analytic on a neighbourhood of this line is connected to to the Fourier transform of $f$ decaying very rapidly (for instance, exponential decay).

\section{Harmonic Functions}

Fix a connected, open set $\Omega \subset \RR^d$. A function $u \in C^2(\Omega)$ is said to be \emph{harmonic} if $\Delta u = 0$ on $\Omega$. Examples include \emph{harmonic polynomials}, like all linear functions, and $u(x,y) = x^2 - y^2$. The mean value property of harmonic functions is essential to their study.

\begin{theorem}
    Let $u$ be harmonic on $\Omega \subset \RR^d$. Then for all $z \in \Omega$ and $0 < r < d(z, \partial \Omega)$,
    %
    \[ u(z) = \fint_{\TT} u(z + r e^{it})\; dt. \]
\end{theorem}
\begin{proof}
    One simply takes the derivative of the right hand side, applies the divergence theorem to see the derivative is zero, and then notes that the right hand side converges to $u(z)$ as $r \to 0$.
\end{proof}

In particular, it implies the maximum principle.

\begin{theorem}
    Let $u$ be harmonic on $\Omega$. If $u$ obtains an extremum on $\Omega$, then $u$ is constant.
\end{theorem}
\begin{proof}
    Suppose $u(z_0) \geq u(z)$ for all $z \in \Omega$. Applying the mean value property around $z_0$ shows that we must have $u(z) = u(z_0)$ for all $z$ with $|z - z_0| < d(z_0, \partial \Omega)$. Thus we conclude that the set
    %
    \[ S = \{ z \in \Omega: u(z) = u(z_0) \} \]
    %
    is open and closed, and thus equal to $\Omega$.
\end{proof}

\begin{remark}
    If $\Omega$ is bounded, and $u$ extends to a continuous function on the closure of $\Omega$, then the maximum principle says that for any $z \in \Omega$
    %
    \[ \min_{\partial \Omega} u(z) \leq u(z) \leq \max_{\partial \Omega} u(z), \]
    %
    and either side can only be an equality if $u$ is constant.
\end{remark}

\begin{remark}
    Note also that by replacing $u$ with $-u$ in the theorem, one can obtain a corresponding `minimum principle'
\end{remark}

The maximum principle gives us a uniqueness result for the Dirichlet problem on a bounded domain.

\begin{theorem}
    Let $\Omega$ be a bounded domain. If $u$ and $v$ are harmonic on $\Omega$, and extend to continuous functions on $\overline{\Omega}$ in such a way that $u = v$ on $\partial \Omega$, then $u = v$.
\end{theorem}

We also have a version of Louiville's theorem for harmonic functions.

\begin{theorem}
    If $u$ is harmonic on $\RR^d$ and bounded, then $u$ is constant.
\end{theorem}
\begin{proof}
    Fix $x \in \RR^d$. Then for any $r > 0$,
    %
    \[ u(x) = \frac{1}{r^n} \int_{|y| \leq r} u(y)\; dy. \]
    %
    But this means that for any $x_1,x_2 \in \RR^d$, if $B_1$ and $B_2$ are the balls of radius $r$ around $x_1$ and $x_2$,
    %
    \[ |u(x_1) - u(x_2)| \lesssim \frac{1}{r^n} \int_{B_1 \Delta B_2} |u(y)|\; dy. \]
    %
    As $r \to \infty$, we have $|B_1 \Delta B_2| \lesssim r^{n-1}$, so taking $r \to \infty$ gives that $u(x_1) = u(x_2)$ for any $x_1,x_2 \in \RR^d$.
\end{proof}

\emph{Any} function satisfying the mean value theorem is harmonic, as we now show.

\begin{theorem}
    Suppose $u$ is continous on $\Omega$ and satisfies the mean value property on $\Omega$. Then $u$ is twice differentiable, and harmonic in $\Omega$.
\end{theorem}
\begin{proof}
    To begin with, we may suppose that $u$ is apriori twice differentiable. To see why, for any $x$, we can find a neighborhood of $x$ such that $u$ is given by convolution with a smooth bump function in that neighborhood, which actually shows that $u$ is $C^\infty$. Now fix $x \in \Omega$, and for sufficiently small $r$, let
    %
    \[ M(r) = \fint_{|y - x| = r} u(y)\; dy. \]
    %
    Our proof will be complete if we can show that $M''(0) = \Delta u(x) / n$. But we can do this by taking a Taylor series when $r$ is small, i.e. we find that
    %
    \begin{align*}
        M(r) &= \fint_{|y - x| = r} \left[ u(x) + \left( \sum_i \partial_i u(x) \cdot y_i \right) + \left( \sum_{i,j} \partial_{i,j} u(x) \cdot y_i y_j \right) + o(|y|^2) \right]\; d\sigma(y).
    \end{align*}
    %
    By symmetry considerations, we thus find that
    % (y_i + x_i)^2 = y_i^2 + x_i^2
    \begin{align*}
        M(r) &= u(x) + \nabla u(x) \cdot x + \sum_i \partial_i^2 u(x) x_i^2 + \fint_{|y| = r} \left( \sum_i \partial_i^2 u(x) y_i^2\; d\sigma(y) \right) + o(r^2)\\
        &= C + r^2/2 \sum_i \partial_i^2 u(x) \fint_{|y| = 1} y_i^2\; d\sigma(y) + o(r^2).
    \end{align*}
    %
    Now for any $i$ and $j$, we have
    %
    \[ \fint_{|y| = 1} y_i^2 = \fint_{|y| = 1} y_j^2. \]
    %
    But this means that
    %
    \[ \fint_{|y| = 1} y_i^2 = \frac{1}{n} \fint_{|y| = 1} \sum_j y_j^2 = 1/n. \]
    %
    Thus we find that $M(r) = C + (r^2/2n) \Delta u(x) + o(r^2)$. Taking second derivatives gives the required claim.
\end{proof}

This condition makes it easy to check (as with the Cauchy integral formula for harmonic functions) that the locally uniform limit of a sequence of harmonic functions is also harmonic.

\section{Poisson Kernels}

Consider the classic Dirichlet problem on a bounded domain $\Omega \subset \RR^d$ with $C^1$ boundary. Given a continuous function $b$ defined on $\partial \Omega$, is it possible to find a harmonic function $u$ on $\Omega$ which extends to a continuous function on $\overline{\Omega}$ in such a way that $u = b$ on $\partial \Omega$? We have already seen that $u$, if it exists, must be unique.

Let us write the relation of $u$ and $b$ in operator form, i.e. writing $u = Lb$ for some operator $L$. We use the method of \emph{Green's functions} to derive an integral expression for the operator $L$. Let $\Phi$ be the fundamental solution for the Laplacian on $\RR^d$, i.e. the distribution such that $\Delta \Phi = \delta$. Applying Green's theorem yields that if $u$ is harmonic in $\Omega$, then for $x \in \Omega$,
%
\begin{align*}
    u(x) &= \int_\Omega u(y) \Delta \Phi(y - x)\; dy\\
    &= \int_\Omega \left[ u(y) \Delta \Phi(y - x)\; dy - \Phi(y - x) \Delta u (y) \right] \; dy\\
    &= \int_{\partial \Omega} \left[ u(y) \partial_\eta \Phi(y - x) - \partial_\eta u(y) \Phi(y - x) \right]\; dy.
\end{align*}
%
This almost gives an expression for $u$ given it's boundary values, expect we must know the normal derivatives $\partial_\eta u$, which is not available to us. To fix this, we find a harmonic function $\phi^x$ on $\Omega$ for each $x \in \Omega$, subject to the boundary conditions that $\phi^x(y) = \Phi(y - x)$ for $y \in \partial \Omega$. It then follows that
%
\begin{align*}
    0 &= \int_\Omega u(y) \Delta \phi^x(y) - \Delta u(y) \phi^x(y)\\
    &= \int_{\partial \Omega} u(y) \partial_\eta \phi^x(y) - \partial_\eta u(y) \phi^x(y).
\end{align*}
%
But this means that
%
\[ u(x) = \int_{\partial \Omega} u(y) \left[ \partial_\eta \Phi(y - x) - \partial_\eta \phi^x(y) \right]\; dy. \]
%
Thus we conclude that the \emph{Poisson kernel}, i.e. the kernel of the operator $L$, is given by
%
\[ K(x,y) = \partial_\eta \Phi(y - x) - \partial_\eta \phi^x(y). \]
%
In general, for a very general family of domains $\Omega$ it is possible to find a family of functions $\{ \phi^x \}$, though it is only in certain nice, symmetry domains that one can find explicit formula for these functions, and thus to have an explicit formula for the Poisson kernel $K$.

The easiest Green's function to find is for the half space
%
\[ \mathbf{H} = \{ x \in \RR^n : x_n > 0 \}. \]
%
To find the Green's function, we rely on a reflection trick. We define
%
\[ \phi^x(y) = \Phi(y - \tilde{x}), \]
%
where $\tilde{x}$ is obtained from $x$ by reflecting it across the line defining the half plane. Noting that for $y \in \partial \mathbf{H}$, $|y - \tilde{x}| = |y - x|$, we conclude that the Poisson kernel is given by
%
\begin{align*}
    K(x,y) &= \frac{1}{|S^{n-1}|} \left[ - \frac{y_n - x_n}{|y - x|^n} + \frac{y_n + x_n}{|y - \tilde{x}|^n} \right]\\
    &= \frac{2}{|S^{n-1}|} \frac{x_n}{|y - x|^n}.
\end{align*}
%
Thus we should expect that, for a function $b$ defined on $\RR^{n-1}$, we have
%
\[ Lb(x) = \int_{\partial \mathbf{H}} \frac{2x_n}{|S^{n-1}|} \frac{1}{|x - y|^n} b(y)\; dy. \]
%
This is Poisson's formula for the half plane.

Next, let us find the Green's function for the unit ball $B$ in $\RR^n$. Here we use a similar inversion trick. Given $x$ in the unit ball, we let $\tilde{x} = x / |x|^2$ be the \emph{dual point} to $x$, i.e. the point obtained by \emph{spherical inversion} about the unit sphere. For $y \in \partial B$, we have
%
\[ |y - \tilde{x}|^2 = |y|^2 + |\tilde{x}|^2 - 2 y \cdot \tilde{x} = 1 + \frac{1}{|x|^2} - \frac{2 y \cdot x}{|x|^2} = \frac{1}{|x|^2} \left( |x|^2 + 1 - 2 y \cdot x \right) = \frac{|y - x|^2}{|x|^2}. \]
%
Thus the function $\phi^x(y) = \Phi(|x| (y - \tilde{x}))$ has the right boundary conditions. Moreover, it is harmonic, for $n \geq 3$ because $\Phi$ is homogeneous, so
%
\[ \phi^x(y) = \frac{\Phi(y - \tilde{x})}{|x|^{n-2}}, \]
%
and for $n = 2$ because
%
\[ \phi^x(y) = \Phi(y - \tilde{x}) - \frac{\ln |x|}{2 \pi}, \]
%
and both choices are harmonic on $B$. Regardless, since, for $|y| = 1$, we have $|y - \tilde{x}| = |y - x| |x|^{-1}$, we conclude that the Poisson kernel for the unit ball is given by
% Phi(y - x)
% Gradient is -1/|S^{n-1}| * (y - x) / |y - x|^n
% So radial derivative is -1/|S^{n-1}| * <y, (y - x)>
\begin{align*}
    K(x,y) &= \frac{-1}{|S^{n-1}|} \left[ - \frac{1 - y \cdot x}{|y - x|^n} + \frac{1}{|x|^{n-2}} \frac{1 - y \cdot \tilde{x}}{|y - \tilde{x}|^n} \right]\\
    &= \frac{-1}{|S^{n-1}|} \frac{1}{|y - x|^n} \left[ - (1 - y \cdot x) + (|x|^2 - y \cdot x) \right]\\
    &= \frac{1}{|S^{n-1}|} \frac{1 - |x|^2}{|y - x|^n}.
\end{align*}
%
Thus we should expect that, for a function $b$ defined on $S^{n-1}$, we have
%
\[ Lb(x) = \frac{1}{|S^{n-1}|} \int_{S^{n-1}} \frac{1 - |x|^2}{|y - x|^n} b(y)\; dy. \]
%
This is Poisson's formula for the unit ball.

\section{Holomorphic Functions and the Poisson Kernel}

If $\Omega \subset \RR^2$, and $f: \RR^2 \to \CC$, viewed as a function with domain $\CC$, is holomorphic, and $f = u + i v$ for two real functions $u$ and $v$, then $u$ and $v$ are both harmonic. Conversely, if $\Omega$ is \emph{simply connected}, then for any harmonic function $u$ on $\Omega$, we can find a harmonic $v$ on $\Omega$ such that $u + i v$ is harmonic. To do this, we note that the differential form
%
\[ \frac{\partial u}{\partial x}\; dy - \frac{\partial u}{\partial y}\; dx \]
%
is exact, so that there exists a function $v$ such that
%
\[ \frac{\partial v}{\partial x} = - \frac{\partial u}{\partial y} \quad\text{and}\quad \frac{\partial v}{\partial y} = \frac{\partial u}{\partial x}. \]
%
These are precisely the Cauchy-Riemann equations, so that we see $u + iv$ is harmonic. In particular, we see that this implies harmonic functions are automatically analytic, i.e. they lie in $C^\infty(\Omega)$, and their Taylor series expansions converge locally uniformly to $u$.













\chapter{Complex-Variable Methods}

\section{Fourier Transforms of Holomorphic Functions}

For each $a > 0$, let $S_a = \{ x + iy: |y| < a \}$ denote the horizontal strip of width $2a$. The next theorem says that functions extendable to be holomorphic on the strip have exponential Fourier decay.

\begin{theorem}
    Let $f: S_a \to \CC$ be holomorphic, integrable on each horizontal line in the strip, such that $f(x + iy) \to 0$ as $|x| \to \infty$. Then if $\widehat{f}$ is the Fourier transform of the restriction of $f$ to the real line, then for each $b < a$,
    %
    \[ |\widehat{f}(\xi)| \lesssim_b e^{-2 \pi b |\xi|}. \]
\end{theorem}
\begin{proof}
    For any $b < a$, $R$, and $\xi > 0$, consider the contour $\gamma_R$ on the rectangle with corners $-R$, $R$, $-R-ib$, and $R-ib$. As $R \to \infty$, the integral along the vertical lines of the rectangle tends to zero as $R \to \infty$, so we conclude that
    %
    \begin{align*}
        \int_{-\infty}^\infty f(x)e^{-2\pi i x \xi}\; dx &= \int_{-\infty}^\infty f(x-ib)e^{- 2 \pi i (x - ib) \xi}\; dx\\
        &= e^{-2 \pi i b \xi} \int_{-\infty}^\infty f(x-ib) e^{- 2 \pi i \xi x}\; dx = e^{-2 \pi i b \xi} \widehat{f_b}(\xi)
    \end{align*}
    %
    where $f_b(x) = f(x - ib)$. But $|\widehat{f_b}(\xi)| \leq \| f_b \|_{L^\infty(\RR)} \lesssim_b 1$, which implies that
    %
    \[ |\widehat{f}(\xi)| \lesssim_b e^{-2 \pi i b \xi}. \]
    %
    A similar estimate when $\xi < 0$ completes the argument.
\end{proof}

It follows that $\widehat{f}$ has exponential decay if $f$ satisfies the hypothesis of the theorem. Thus we can always apply the inverse Fourier transform to conclude
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi. \]
%
Conversely, if $f$ is \emph{any} integrable function with $|\widehat{f}(\xi)| \lesssim e^{-2 \pi a |\xi|}$, then $\widehat{f}$ is integrable so the Fourier inversion formula holds. If we define
%
\[ f(x + iy) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{-2 \pi \xi y} e^{2 \pi i \xi x}\; d\xi, \]
%
then this gives a holomorphic extension of $f$ which is well defined on $S_a$.

Pushing this result to an extreme leads to the Paley-Wiener theorem, which gives precise conditions when a function has a compactly supported Fourier transform.

\begin{theorem}
    A function $f: \RR \to \CC$ is bounded, integrable, and continuous. Then $f$ extends to an entire function on the complex plane, such that for all $z$,
    %
    \[ |f(z)| \lesssim e^{2 \pi M |z|}, \]
    %
    if and only if $\widehat{f}$ is supported on $[-M,M]$.
\end{theorem}
\begin{proof}
    If $\widehat{f}$ is supported on $[-M,M]$, then the Fourier inversion formula comes into play, telling us that for all $x \in \RR$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi = \int_{-M}^M \widehat{f}(\xi) e^{2 \pi i \xi x}\; d\xi. \]
    %
    But then we can clearly extend $f$ to an entire function by defining
    %
    \[ f(z) = \int_{-M}^M \widehat{f}(\xi) e^{2 \pi i \xi z}\; d\xi, \]
    %
    and then $|f(z)| \leq e^{2 \pi i M |z|} \| \widehat{f} \|_{L^1[-M,M]} \lesssim e^{2 \pi i M |z|}$.

    Conversely, suppose $f$ is an entire function such that for all $z \in \CC$,
    %
    \[ |f(z)| \leq A g(x) e^{2 \pi M |y|}, \]
    %
    where $g \geq 0$ is integrable on $\RR$. We also assume that $f(x + iy) \to 0$ uniformly as $x \to -\infty$, independently of $y$. Then a contour shift down guarantees that for any $y$,
    %
    \begin{align*}
        \widehat{f}(\xi) &= \int_{-\infty}^\infty f(x) e^{-2 \pi i \xi x}\; dx\\
        &= \int_{-\infty}^\infty f(x - iy) e^{-2 \pi i \xi (x - iy)}\; dx\\
        &\leq A e^{2 \pi M y - 2 \pi \xi y} \int_{-\infty}^\infty g(x) \; dx \lesssim e^{2 \pi (M y - \xi y)}.
    \end{align*}
    %
    If $\xi > M$, then taking $y \to \infty$ shows $\widehat{f}(\xi) = 0$. A contour shift up instead gives $\widehat{f}(\xi) = 0$ if $\xi < -M$. Thus the proof is completed in this case.

    Now suppose the weaker condition
    %
    \[ |f(z)| \leq A e^{2 \pi M |y|}. \]    
    %
    For each $\varepsilon > 0$, let
    %
    \[ f_\varepsilon(z) = \frac{f(z)}{(1 - i\varepsilon z)^2}. \]
    %
    Then $f_\varepsilon$ is analytic in the lower half plane. Moreover,
    %
    \[ |f_\varepsilon(x + iy)| \lesssim_\varepsilon \frac{A e^{2\pi M |y|}}{1 + x^2}. \]
    %
    Thus we can apply the previous shifting techniques to show that $\widehat{f_\varepsilon}(\xi) = 0$ for $\xi > M$. For $x \in \RR$, we have $|f_\varepsilon(x)| \leq |f(x)|$, and since $f_\varepsilon \to f$ pointwise as $\varepsilon \to 0$, we can apply the dominated convergence theorem to imply $\widehat{f_\varepsilon}(\xi) \to \widehat{f}(\xi)$ for each $\xi$. In particular, we find $\widehat{f}(\xi) = 0$ for $\xi > M$. A similar technique with the family of functions
    %
    \[ f_\varepsilon(z) = \frac{f(z)}{(1 + i\varepsilon z)^2}, \] 
    %
    show that $\widehat{f}(\xi) = 0$ for $\xi < -M$.

    Finally, it suffices to show that the condition
    %
    \[ |f(z)| \lesssim e^{2\pi M |z|} \]
    %
    implies $|f(x + iy)| \lesssim e^{2 \pi M |y|}$. To prove this, we can apply a version of the Phragm\'{e}n-Lindel\"{o}f on the quandrant $\{ x + iy: x, y > 0 \}$. Let $g(z) = f(z) e^{-2 \pi i M y}$. Then we have
    %
    \[ |g(x)| = |f(x)| \leq \| f \|_{L^\infty(\RR)}, \]
    %
    and
    %
    \[ |g(iy)| = |f(iy)| e^{-2 \pi i M y} \leq A. \]
    %
    Since $g$ has at most exponential growth on the quadrant, we can apply the Phragm\'{e}n-Lindel\"{o}f to conclude $|g(z)| \leq \max(A, \| f \|_{L^\infty(\RR)})$ for all $z$ on the quandrant. A similar argument works for the other quadrants. Thus we conclude that for all $z \in \CC$
    %
    \[ |f(z)| \leq \max(A, \| f \|_{L^\infty(\RR)}) e^{2 \pi i M |y|}, \]
    %
    and so we can apply the previous cases to conclude that $\widehat{f}$ is supported on $[-M,M]$.
\end{proof}

\begin{remark}
    The Paley-Wiener theorem has several variants. For instance, if $f$ is continuous, integrable, and $\widehat{f}$ is integrable, and we further assume that $\widehat{f}(\xi) = 0$ for all $\xi < 0$, then for $z = x + iy$, we can define
    %
    \[ f(z) = \int_0^\infty \widehat{f}(\xi) e^{2 \pi i \xi z} = \int_0^\infty \widehat{f}(\xi) e^{- 2 \pi \xi y} e^{2 \pi i \xi x} \]
    %
    to extend $f$ to an analytic function in the upper half-plane, i.e. for $y > 0$, which is also continuous and bounded for $y \geq0$. Conversely, similar techniques to those above enable us to show that if $f$ is continuous, integrable, $\widehat{f}$ is integrable, and we can extend $f$ to an analytic function on the open upper half plane, which is continuous and bounded on the closed half plane, then contour shifting shows that $\widehat{f}(\xi) = 0$ for $\xi < 0$.
\end{remark}

\section{Classical Theorems by Contours}

We now prove some classical theorems of Fourier analysis using techniques of harmonic analysis, given that the functions we study have holomorphic extensions to tubes.

\begin{theorem}
    Let $f: S_b \to \CC$ be holomorphic. Then for any $x \in \RR$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e^{2 \pi i \xi x}\; dx, \]
    %
    where $\widehat{f}$ is the Fourier transform of $f$ restricted to the real-axis.
\end{theorem}
\begin{proof}
    As in the last theorem, the sign of $\xi$ matters. We write
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e^{-2 \pi i \xi x} = \int_0^\infty \widehat{f}(\xi) e^{- 2 \pi i \xi x} + \widehat{f}(-\xi) e^{2 \pi i \xi x}. \]
    %
    Now if $b < a$, we can apply a contour integral argument to conclude that
    %
    \begin{align*}
        \widehat{f}(\xi) &= \int_{-\infty}^\infty f(x - ib) e^{-2 \pi i \xi (x - ib)}\; dx\\
        &= \int_{-\infty}^\infty f(x + ib) e^{2 \pi i \xi (x + ib)}\; dx.
    \end{align*}
    %
    Thus by Fubini's theorem, for each $x_0 \in \RR$,
    %
    \begin{align*}
        \int_0^\infty \widehat{f}(\xi) e^{2 \pi i \xi x_0} &= \int_0^\infty \int_{-\infty}^\infty f(x - ib) e^{2 \pi i \xi [x_0 - (x - ib)]}\; dx\; d\xi\\
        &= \int_{-\infty}^\infty f(x - ib) \left( \int_0^\infty e^{2 \pi i \xi [x_0 - (x - ib)]}\; d\xi \right)\; dx\\
        &= \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{f(x - ib)}{(x - ib) - x_0}\; dx.
    \end{align*}
    %
    Similarily, another application of Fubini's theorem implies
    %
    \begin{align*}
        \int_0^\infty \widehat{f}(-\xi) e^{-2 \pi i \xi x_0}\; d\xi &= \int_0^\infty \int_{-\infty}^\infty f(x + ib) e^{-2 \pi i \xi [x_0 - (x + ib)]}\; dx\; d\xi\\
        &= \int_{-\infty}^\infty f(x + ib) \int_0^\infty e^{-2 \pi i \xi [x_0 - (x + ib)]}\; d\xi\; dx\\
        &= \frac{-1}{2 \pi i} \int_{-\infty}^\infty \frac{f(x + ib)}{[(x + ib) - x_0]}\; dx.
    \end{align*}
    %
    In particular, we conclude that
    %
    \[ \int \widehat{f}(\xi) e^{2 \pi i \xi x_0} = \frac{1}{2\pi i} \int_\gamma \frac{f(z)}{z - x_0}, \]
    %
    where $\gamma$ is the path traces over the two horizontal strips $x + ib$ and $x - ib$. Approximating this integral by rectangles, and then apply Cauchy's theorem, we find this value is equal to $f(x)$.
\end{proof}

We can also prove the Poisson summation formula.

\begin{theorem}
    Let $f: S_a \to \CC$ be holomorphic. Then
    %
    \[ \sum_{n \in \ZZ} f(n) = \sum_{n \in \ZZ} \widehat{f}(n), \]
    %
    where $\widehat{f}$ is the Fourier transform of $f$ restricted to the real line.
\end{theorem}
\begin{proof}
    The function
    %
    \[ \frac{f(z)}{e^{2 \pi i z} - 1} \]
    %
    is meromorphic, with simple poles on $\ZZ$, with reside equal to $f(n)$ at each $n \in \ZZ$. If we apply the Residue theorem to a curve $\gamma_N$ travelling around the rectangle connecting the points $N+1/2-ib$, $N+1/2+ib$, $-N-1/2+ib$, and $-N-1/2-ib$, then we conclude
    %
    \[ \sum_{|n| \leq N} f(n) = \int_{\gamma_N} \frac{f(z)}{e^{2 \pi i z} - 1}\; dz. \]
    %
    These values converge to $\sum_{n \in \ZZ} f(n)$ as $N \to \infty$. But this means that
    %
    \[ \sum_n f(n) = \int_\gamma \frac{f(z)}{e^{2 \pi i z} - 1}\; dz, \]
    %
    where $\gamma$ is the two horizontal strips at $b$ and $-b$. Now we use the expansion
    %
    \[ \frac{1}{z - 1} = \sum_{n = 1}^\infty z^{-n}, \]
    %
    for $|z| > 1$, to conclude
    %
    \begin{align*}
        \int_{-\infty}^\infty \frac{f(x - ib)}{e^{2 \pi i (x - ib)} - 1}\; dx &= \int_{-\infty}^\infty \sum_{n = 1}^\infty \frac{f(x - ib)}{e^{2 \pi n i (x - ib)}}\; dx\\
        &= \sum_{n = 1}^\infty \int_{-\infty}^\infty f(x - ib) e^{-2 \pi n i (x - ib)}\; dx = \sum_{n = 1}^\infty \widehat{f}(n),
    \end{align*}
    %
    where we have performed a contour shift at the end. Similarily, we use the expansion
    %
    \[ \frac{1}{z - 1} = - \sum_{n = 0}^\infty z^n, \]
    %
    to conclude that
    %
    \begin{align*}
        - \int_{-\infty}^\infty \frac{f(x + ib)}{e^{2 \pi i (x + ib)} - 1} &= \int_{-\infty}^\infty \sum_{n = 0}^\infty f(x + ib) e^{2 \pi i (x + ib)}\; dx\\
        &= \sum_{n = 0}^\infty \widehat{f}(-n).
    \end{align*}
    %
    Combining these two calculations completes the proof.
\end{proof}

\section{The Laplace Transform}

We now look at things from the dual perspective. Instead of looking at whether a function can be extended to a holomorphic function, we look at whether the Fourier transform can be extended to a holomorphic function. For a function $x: \RR \to \RR$, this gives rise to the \emph{Laplace transform}
%
\[ X(z) = \int_{-\infty}^\infty x(t) e^{- z t}\; dt, \]
%
also denoted by $(\mathcal{L}x)(z)$. For $\xi \in \RR$, $X(i\xi) = \widehat{x}(\xi)$ operates as the usual Fourier transform (slightly rescaled from the version in our notes). But the Laplace transform can also be extended to not-necessarily integrable functions. Given $x$, we can define $X(z)$ for any $z = x + iy$ such that
%
\[ \int e^{-xt} |f(t)|\; dt < \infty. \]
%
It is simple to see this forms a vertical tube in the complex plane, called the \emph{region of convergence} for the Laplace transform. For a particular vertical tube $I \subset \CC$, we let $\mathcal{E}(I)$ be the collection of all functions $x$ whose region of convergence for the Dirichlet transform contains $I$.

\begin{example}
    Let
    %
    \[ H(x) = \begin{cases} 0 &: x < 0, \\ 1/2 &: x = 0, \\ 1 &: x > 0. \end{cases} \]
    %
    The function $H$ is called the \emph{Heavyside Step Function}. It's region of convergence consists of the right-most half plane, i.e. all $\omega + i\xi$, where $\omega > 0$. And if $z = \omega + i\xi$, we calculate that
    %
    \[ \mathcal{L}(H)(z) = \int_0^\infty e^{- z t}\; dt = z^{-1}. \]
    %
    We note that even though the integral formula does not define the Laplace transform of $H$ in the right-most half plane, we \emph{can} analytically continue $\mathcal{L}(H)$ to a meromorphic function on the entire complex plane.
\end{example}

\begin{example}
    Similarily, an integration by parts shows that for $z = \omega + i\xi$ with $\omega > 0$, we have
    %
    \[ \mathcal{L}(tH)(z) = \int_0^\infty t e^{-zt} = \int_0^\infty \frac{e^{-zt}}{z} = z^{-2}. \]
    %
    Against, $\mathcal{L}(tH)$ extends to a meromorphic function on the entire complex plane.
\end{example}

\begin{comment}
    The Laplace transform is useful because it connects the study of the Fourier transform of a function to the study of certain complex analytic functions. For simplicity, we work with functions on the half-line, which eliminates some symmetry at the cost of a more simple theory. For a function $f: [0,\infty) \to \CC$, and $z \in \CC$, we study the integral transform
%
\[ (\mathcal{L} f)(z) = \int_{-\infty}^\infty f(t) e^{-zt}\; dt. \]
%
In some senses, the Laplace transform is a more general version of the Fourier transform. Indeed, we find
%
\[ (\mathcal{L} f)(\omega + i \xi) = \widehat{f e^{- \omega t}}(\xi). \]
%
Thus the Laplace transform of $Lf$ at a particular value $\omega$ measures a weighted frequency representation of $f$. A major advantage is that $Lf$ is defined as the integral of $f$ against a holomorphic function, and in particular, is often a holomorphic function, which enables us to use techniques of complex analysis.

We fix $f \in L^1(\RR)$, andse $f$ is supported on $[-N,\infty)$ for some large $N$. Then for any $\omega \geq 0$,
%
\[ \int_{-\infty}^\infty |f(t)| e^{-\omega t} < \infty. \]
%
Thus the integral
%
\[ \int f(t) e^{-zt}\; dt \]
%
is defined as an absolutely convergent integral for all $z = \omega + i\xi$ with $\omega \geq 0$. Thus we can define the Laplace transform $(\mathcal{L} f)(z)$ for all $z$ in the closed right half-plane. If $\gamma$ is a closed curve in the open right half-plane, and $f \in L^1(\RR)$, then Fubini's theorem implies that
%
\begin{align*}
    \int_\gamma \mathcal{L} f\; dz &= \int_0^1 (\mathcal{L} f)(\gamma(s)) \gamma'(s)\; ds\\
    &= \int_0^1 \int_0^\infty f(t) e^{- \gamma(s) t} \gamma'(s)\; dt\; ds\\
    &= \int_0^\infty f(t) \left( \int_\gamma e^{-zt}\; dz \right)\; dt = \int_0^\infty 0\; dt = 0.
\end{align*}
%
Thus Morera's theorem implies $\mathcal{L} f$ is analytic in the open right half-plane. The Dominated convergence theorem also implies $\mathcal{L} f$ is continuous in the closed half-plane. If we also assume that $f$ is compactly supported, then the Laplace $\mathcal{L} f$ is defined everywhere, and is an entire function.
\end{comment}

\begin{comment}
We often study functions supported on $[0,\infty)$, in which case it suffices to analyze the `one sided' Laplace transform
%
\[ (\mathcal{L} f)(\omega + i\xi) = \int_0^\infty f(x) e^{-2 \pi (\omega + i \xi)t}\; dt. \]
%
The reason for this is quite simple. The Laplace transform is often used to analyze certain convolution operators $Tf = f * g$. One views the function $f(t)$ as a certain signal, with amplitudes varying over a time period. Most often, $T$ is an operator which is computed `online'; we think of feeding in the signal $f(t)$ in real time, and then produce $(Tf)(t)$ at the same time. For example, the operator $Tf = f * H$, where $H$ is the heavyside step function, is defined so that
%
\[ (Tf)(t) = \int_{-\infty}^t f(s)\; ds, \]
%
so $(Tf)(t)$ can be produced given only knowledge of $f$ up to time $t$. In general, $(Tf)(t)$ depends only on $f$ up to time $t$ if and only if $g$ is supported on $[0,\infty)$. As expected, we will show $\mathcal{L}(f * g) = \mathcal{L}f \cdot \mathcal{L}g$ so in many senses it suffices to analyze the Laplace transform of a function defined on a half line.


To rigorously study the Laplace transform, we look at a nice family of functions for which the transform is particularly well behaved. For each $\alpha \in \RR$, we let $\mathcal{E}_\alpha$ be the collection of all functions $f$ supported on $[0,\infty)$ such that $f e^{- \alpha t} \in L^1(\RR^d)$. Then if $\omega \geq \alpha$, and $\xi \in \RR$, $(\mathcal{L}f)(\omega + i\xi)$ is well defined by the integral formula. Moreover, for $\omega > \alpha$, $\mathcal{L} f$ is actually an \emph{analytic} function, with
%
\[ (\mathcal{L}f)'(\omega + i \xi) = - 2\pi \cdot \mathcal{L}(tf)(\omega + i\xi). \]
%
This can be established by a simple approximation argument. The dominated convergence theorem also implies that $\mathcal{L}f$ is continuous on the closed half plane defined by $\omega \geq \alpha$.
\end{comment}

What distinguishes the Laplace transform from the Fourier transform is the ability to use techniques of complex analysis. If $x$ has region of convergence $I$, then $X$ is continuous on $I$, and analytic on $I^\circ$. We can even calculate an explicit formula for the derivative As expected from the Fourier transform of the derivative, if $y(t) = tx(t)$, and $Y$ is the Laplace transform of $y$, then $X'(z) = -Y(z)$. One can verify this quite simply by taking limits of the derivatives of the analytic integrals
%
\[ \int_{-N}^N x(t) e^{-zt}\; dt, \]
%
as $N \to \infty$. Like the Fourier transform, the Laplace transform is symmetric under modulation, translation, and polynomial multiplication:
%
\begin{itemize}
    \item If $w \in \CC$, and $x$ is a function, set $y(t) = e^{wt} x(t)$. Then if $z$ is in the region of convergence for $x$, $z - w$ is in the region of convergence for $y$, and $X(z) = Y(z-w)$.

    \item If $x$ has region of convergence $I$, then the region of convergence for $y(t) = tx(t)$ contains $I^\circ$, and $Y(z) = -X(z)$.

    \item If $x$ has region of convergence $I$, $t_0 \in \RR$, and we set $y(t) = x(t + t_0)$, then $y$ has region of convergence $I$, and $Y(z) = e^{zt_0} X(z)$.

    \item For a function $x$, define
    %
    \[ (\Delta_s x)(t) = \frac{x(t + s) - x(t)}{s}. \]
    %
    If $\omega$ is fixed, if
    %
    \[ \lim_{s \to 0} \int |(\Delta_s x)(t) - x'(t)| e^{-\omega t}\; dt = 0, \]
    %
    if $y(t) = x'(t)$, and if $z = \xi + i \omega$ for some $\xi \in \RR$, then $Y(z) = z X(z)$.

    In particular, this is true if $x$ is supported on $[-N,\infty)$ for some $N$, has a continuous derivative $x'$, and there is $\omega_0 < \omega$ such that
    %
    \[ \lim_{t \to \infty} x(t) e^{-\omega_0 t} = \lim_{t \to \infty} x'(t) e^{-\omega_0 t} = 0. \]
    %
%    It will be useful to consider functions $f$ with $f(t) = 0$ for $t < 0$, such that $f$ is continuously differentiable for $t > 0$, since such functions can be used to solve ordinary differential equations, but such that
    %
%    \[ f(0+) = \lim_{t \to 0^+} f(t) \]
    %
%    exists and is finite. Then $f'$ is defined everywhere but the origin, and an integration by parts tells us that
    %
%    \[ (\mathcal{L} f')(z) = z \cdot (\mathcal{L} f)(z) - f(0+). \]
    %
%    More generally, $(\mathcal{L} f^{(n)})(z) = z^n \cdot (\mathcal{L} f)(z)$
\end{itemize}

\begin{remark}
    It will be interesting for us to consider functions $x$ supported on $[-N,\infty)$ which have a piecewise continuous derivative $x'$ except at finitely many points $t_1, \dots, t_N$, such that the left and right-hand limits exist at each $t_i$. For each $i \in \{ 1, \dots, N \}$, we let
    %
    \[ A_i = x(t_i+) - x(t_i-) \quad\text{and}\quad B_i = x'(t_i+) - x'(t_i-). \]
    %
    If $y(t) = x'(t)$, we calculate a relation between the Laplace transforms of $X$ and $Y$ at $z = \omega + i\xi$ such that there exists $\omega_0 < \omega$ such that
    %
    \[ \lim_{t \to \infty} x(t) e^{-\omega_0 t} = \lim_{t \to \infty} x'(t) e^{-\omega_0 t} = 0. \]
    %
    We consider the function
    %
    \[ x_1(t) = x(t) - \sum_{i = 1}^N A_i H(t - t_i) - \sum_{i = 1}^N B_i (t - t_i) H(t - t_i). \] 
    %
    Then $x_1$ is continuous everywhere, and moreover, has a continuous derivative. We have
    %
    \[ x_1'(t) = x'(t) - \sum_{i = 1}^N B_i H(t - t_i). \]
    %
    Thus if $\omega > 0$, and $z = \omega + i \xi$, if $y_1(t) = x_1'(t)$, we find
    %
    \[ Y_1(z) = z X_1(z). \]
    %
    Now
    %
    \[ Y_1(z) = Y(z) - \sum_{i = 1}^N \frac{B_i e^{-i z t_i}}{iz} \]
    %
    and
    %
    \[ X_1(z) = X(z) - \sum_{i = 1}^N \frac{A_i e^{-i z t_i}}{iz} + \sum_{i = 1}^N \frac{B_i e^{-i z t_i}}{z^2}. \]
    %
    Thus, rearranging, we conclude
    %
    \[ Y(z) = z X(z) - \sum_{i = 1}^N A_i e^{-i z t_i} \]
    %
    We can carry this through recursively to higher order derivatives. For each $k$, we set $A^k_i = f^{(k)}(t_i+) - f^{(k)}(t_i-)$. Then if $y(t) = f^{(n)}(t)$, then
    %
    \[ Y(z) = z^n X(z) - \sum_{k = 0}^{n-1} \sum_{i = 1}^N z^{n-1-k} A^k_i e^{-izt_i}. \]
    %
    This is very useful when wants to solve differential equations, provided the solutions to those differential equations do not grow faster than exponentially.
\end{remark}

\begin{example}
    Suppose we wish to find a formula for the unique real-valued function $x: [0,\infty) \to \RR$ such that $x''(t) - x'(t) - 6x(t) = 5e^{3t}$ for $t \geq 0$, such that $x(0) = 6$ and $x'(0) = 1$. Such a function increases at most exponentially, since it is linear, so we may take the Laplace transform of each sides to conclude that if $X$ is the Laplace transform of $x$, then
    %
    \[ \mathcal{L}(x'')(z) = z^2 X(z) - 6z - 1 \quad\text{and}\quad \mathcal{L}(x')(z) = z X(z) - 6. \]
    %
    Thus we conclude
    %
    \[ [z^2 X(z) - 6z - 1] - [zX(z) - 6] - (6X) = \frac{5}{z - 3}. \]
    %
    Thus
    %
    \[ X(z) = \frac{(3z - 4)(2z - 5)}{(z - 3)^2(z+2)} = \frac{3.6}{z + 2} + \frac{2.4}{z - 3} + \frac{1}{(z - 3)^2}. \]
    %
    But this implies that for $t \geq 0$, $x(t) = 3.6 e^{-2t} + 2.4 e^{3t} + te^{3t}$. In particular, we note that the pole of $X$ determines the large scale behaviour of $X$, i.e. for large $t$, and for any $\varepsilon > 0$,
    %
    \[ e^{(3 - \varepsilon)t} \lesssim_\varepsilon x(t) \lesssim_\varepsilon e^{(3 + \varepsilon)t}. \]
    %
    In the next section, we generalize this situation to give asymptotics of functions whose Laplace transforms extend to meromorphic functions on the complex plane.
\end{example}

\section{Asymptotics via the Laplace Transform}

For simplicity, in this chapter we study integrable functions $x: [0,\infty) \to \RR$, whose Laplace transform is thus well defined on the closed, right half-plane. If the Fourier transform of $x$ is integrable, then we can apply the inversion formula to conclude that for each $t \in \RR$,
%
\[ x(t) = \int_{-\infty}^\infty X(i\xi) e^{i \xi t}\; d\xi. \]
%
Now suppose that $X$ can be analytically continued to a holomorphic function $X(\omega + i\xi)$ for all $\omega \geq -\varepsilon$ which is continuous at the boundary, such that, uniformly for $\omega \in [-\varepsilon,0]$,
%
\[ \lim_{|\xi| \to \infty} X(\omega + i\xi) = 0. \]
%
Then a contour shift argument implies that for each $t$,
%
\[ x(t) = \lim_{R \to \infty} \int_{-R}^R X(-\varepsilon + i\xi) e^{(-\varepsilon + i\xi) t}\; d\xi = e^{-\varepsilon t} \lim_{R \to \infty} \int_{-R}^R X(-\varepsilon + i\xi) e^{i \xi t}\; d\xi. \]

For simplicity, we study functions supported on $[0,\infty)$. The region of convergence for such functions then takes the form of a half plane. For a given $a \in \RR$, we let $\mathcal{E}_a$ be the set of functions whose region of convergence contains $\omega + i\xi$ for all $\omega > a$.

\begin{theorem}
    Suppose $x: [0,\infty) \to \RR$ is a continuous function such that some $\omega$,
    %
    \[ \int |x(t)| e^{-\omega t}\; dt < \infty. \]
    %
\end{theorem}
\begin{proof}
    Since $|X(u + iv)| \to 0$ uniformly as $v \to \infty$, we can shift the Fourier inversion formula
    %
    \[ x(t) = \lim_{R \to \infty} \frac{1}{2\pi} \int_{-R}^R X(\omega + i\xi) e^{(\omega + i\xi)t}\; d\xi \]
    %
    (where the $2\pi$ comes up from our rescaling of the Fourier transform) to conclude that
    %
    \[ x(t) = \lim_{R \to \infty} \frac{1}{2\pi} \]
    %
    \[ X(z) = \lim_{} \]
\end{proof}












\chapter{Spherical Harmonics}

One of the main advantages with doing harmonic analysis with $\RR^d$ rather than with a general Abelian group $G$ is that $\RR^d$ has a much greater family of symmetries then such a general group (which a priori only has translational symmetries). In this chapter, we exploit the \emph{rotational symmetry} of $\RR^d$ to obtain further information about the Fourier transform.

Each orthogonal matrix $R$ commutes with the Fourier transform, i.e. for any function $f$, if $R^*f(x) = f(Rx)$, then we have
%
\[ \widehat{R^* f} = R^* \widehat{f}. \]
%
It follows from this that the Fourier transform of any radial function is radial. If we let $\mathfrak{H}^0(\RR^n)$ denote the space of all square integrable radial functions, then $\mathfrak{H}^0(\RR^n)$ is an invariant subspace of the Fourier transform on $L^2(\RR^n)$ with respect to the Fourier transform. The theory of \emph{spherical harmonics} will allow us to continue this development, writing
%
\[ L^2(\RR^n) = \bigoplus_k \mathfrak{H}^k(\RR^n), \]
%
where $\mathfrak{H}^k(\RR^d)$ is an invariant subspace of the Fourier transform, and also satisfies good symmetry properties with respect to orthogonal matrices.

The simplest version of this study is on the real line, where $\mathfrak{H}^0(\RR)$ corresponds to the \emph{even} square integrable functions. The orthogonal complement of this space is precisely the \emph{odd} square integrable functions, i.e. the space $\mathfrak{H}^1(\RR)$, since one can in general decompose a function in $L^2(\RR)$ into it's even and odd part, and these functions are orthogonal to one another. There are only two elements of $O(1)$, namely, the identity, and the reflection operator $R_0x = -x$, and we find that these spaces are characterized by this operator, i.e.
%
\[ \mathfrak{H}^0(\RR) = \{ f \in L^2(\RR): Rf = f \} \quad\text{and}\quad \mathfrak{H}^1(\RR) = \{ f \in L^2(\RR): Rf = -f \}. \]
%
Thus we have found an orthogonal complement to the space $\mathfrak{H}^0(\RR)$ of radial functions, which behaves nicely with respect to rotations.

The space $\RR^2$, which we identify with $\CC$, is also tractable given the techniques we already know. Given $f \in \mathcal{S}(\RR^2)$, Fubini's theorem implies that, the function $f_r: S^1 \to \CC$ given by $f_r(x) = f(rx)$ is square integrable, and moreover, the map $r \mapsto f_r$ is continous from $(0,\infty)$ to $L^1(S^1)$. It follows that there are continuous functions $\{ a_k: (0,\infty) \to \CC \}$ such that
%
\[ f(r e^{i\theta}) = \sum_k a_k(r) e^{ki \theta}, \]
%
such that for any fixed $r > 0$, the series on the right converges in the $L^2_\theta$ norm, and moreover,
%
\[ \int_{S^1} |f(r e^{i\theta})|^2\; d\theta = \sum_k |a_k(r)|^2. \]
%
But by monotone convergence, this implies that
%
\[ \int_{\RR^2} |f(x)|^2\; dx = \int_0^\infty \int_{S^1} r |f(r e^{i\theta})|^2\; d\theta = \sum_k \int_0^\infty r |a_k(r)|^2\; dr. \]
%
In particular, if we define a sequence $\{ f_k \}$ by setting $f_k(r e^{i \theta} ) = a_k(r) e^{k i \theta}$, then we find that
%
\[ \| f \|_{L^2(\RR^2)} = \sum_k \| f_k \|_{L^2(\RR^2)}^2, \]
%
and that $f = \sum f_k$. The boundedness of this decomposition shows that this decomposition exists for any $f \in L^2(\RR)$, and that for each such function $f$, we have
%
\[ f_k(r e^{i \theta}) = a_k(r) e^{k i \theta}, \]
%
where the function $a_k$ is defined analogously to the Schwartz case. We have therefore found a decomposition
%
\[ L^2(\RR^2) = \bigoplus_k \mathfrak{H}^k(\RR^2), \]
%
where
%
\[ \mathfrak{H}^k(\RR^2) = \{ f \in L^2(\RR^2) : f(r e^{i \theta}) = a(r) e^{ki \theta}\ \text{for some function $a$} \}. \]
%
If we parameterize $SO(2)$ by defining $R_\theta(x) = e^{i \theta} x$, then $\mathfrak{H}^k$ can also be written as
%
\[ \{ f \in L^2(\RR^2) : R_\theta^* f = e^{k i \theta} f \}. \]
%
This implies that $\mathfrak{H}^k$ is preserved under the Fourier transform, i.e. since if $R_\theta^* f = e^{k i \theta} f$, then taking Fourier transforms on both sides of this equation yields that
%
\[ R_\theta^* \widehat{f} = e^{k i \theta} \widehat{f}. \]
%
Thus we have decomposed $L^2(\RR^2)$ into a family of orthogonal subspaces that behave nicely with respect to rotations.

If $f \in \mathfrak{H}^k(\RR^2)$, with $f(r e^{ i \theta}) = a(r) e^{k i \theta}$, then there exists a function $b$ such that $\widehat{f}(\rho e^{i t}) = b(\rho) e^{k i t}$, and we can determine $b$ in terms of $a$. Indeed, we have
%
\begin{align*} % f^(- i rho) = (-i)^k f^(rho)
    b(\rho) &= (-i)^k \widehat{f}(i \rho)\\
    &= (-i)^k \int_0^\infty \int_0^{2\pi} r a(r) e^{ki \theta} e^{-2 \pi i r \rho \sin(\theta)}\; d\theta\; dr\\
    &= (-i)^k \int_0^\infty \int_0^{2\pi} r a(r) e^{-ki \theta} e^{2 \pi i r \rho \sin(\theta)}\; d\theta\; dr.
\end{align*}
%
If we introduce the Bessel functions
%
\[ J_k(t) = \frac{1}{2\pi} \int_0^{2\pi} e^{i t \sin \theta} e^{-ki \theta}\; d\theta, \]
%
then we conclude that
%
\[ b(\rho) = (2 \pi) (-i)^k \int_0^\infty r a(r) J_k(2 \pi r \rho)\; dr. \]
%
A simple change of variables shows that $J_{-k}(t) = (-1)^k J_k(t)$, so we can alternatively write
%
\[ b(\rho) = (2 \pi) i^k \int_0^\infty r a(r) J_{-k}(2 \pi r \rho)\; dr. \]
%
Let us now move on to $\RR^n$, where we must replace Fourier series with more general \emph{spherical harmonics}.

We obtained an expansion on $\RR^2$ by first performing an expansion on the spheres around the origin, which reduced to the study of Fourier series, since in $\RR^2$ the sphere $S^1$ is precisely the torus. In other words, we first decomposed $L^2(S^1)$, and then used this to decompose $L^2(\RR^2)$. In higher dimensions, to decompose $L^2(S^{n-1})$, we must rely on a slightly different perspective. To begin with, let us look at the Fourier series from a different perspective. A trigonometric polynomial on $\TT$ of the form
%
\[ t \mapsto \sum_{k = -N}^N a_k e^{kit} \]
%
can be identified with a restriction to $S^1$ of the meromorphic function
%
\[ P(z) = \sum_{k = -N}^N a_k z^k. \]
%
If $P$ is real-valued on $S^1$, then $a_{-k} = \overline{a_k}$, and thus $P$ can be written as
%
\[ \text{Re} \left( a_0 + \sum_{k = 1}^N a_k e^{kit} \right). \]
%
Thus $P$ is the restriction to $S^1$ of a \emph{harmonic polynomial} on $\RR^2$. Any such polynomial can be decomposed as
%
\[ P = P_0 + \dots + P_N, \]
%
where $P_j(z) = \text{Re}(a_k z^k)$. In general, we shall call a function $P: S^{n-1} \to \RR$ obtained by restricting a homogeneous harmonic polynomial of degree $k$ on $\RR^n$ to the unit sphere $S^{n-1}$ a \emph{spherical harmonic of degree $k$}. In general, we will find that we can decompose $L^2(\RR^n)$ into spaces $\mathfrak{H}_k(\RR^n)$, where $\mathfrak{H}_k$ is spanned by functions that are products of radial functions, and spherical harmonics of degree $k$.

Let $\mathcal{P}_k(\RR^n)$ be the space of all harmonic homogeneous polynomials of degree $k$ on $\RR^n$. A simple counting argument shows this space has dimension
%
\[ \frac{(n + k - 1)!}{(n-1)!\ k!}. \]
%
We define an inner product on $\mathcal{P}_k$ by setting $\langle P, Q \rangle = P(D) \overline{Q}$. Since $P$ and $Q$ are both homogeneous of the same degree, $\langle P, Q \rangle$ is scalar valued. If $P = \sum_{|\alpha| = k} c_\alpha x^\alpha$, then
%
\[ \langle P, P \rangle = \sum_{|\alpha| = k} |c_\alpha|^2 \alpha! \]
%
and so we see the inner product is positive definite.

\begin{theorem}
    If $P$ is homogeneous of degree $k$, then there exists homogeneous harmonic polynomials $P_j$ of degree $k - 2j$ for $j \leq k/2$, such that
    %
    \[ P = P_0 + |x|^2 P_1 + \dots + |x|^{2l} P_l, \]
    %
    where $l$ is the smallest integer smaller than $2l$.
\end{theorem}
\begin{proof}
    We may assume without loss of generality that $k \geq 2$, since any polynomial of degree $< 2$ is harmonic. Define $\varphi: \mathcal{P}_k \to \mathcal{P}_{k-2}$ by setting $\varphi(P) = \Delta P$. Then $\varphi$ is onto, since otherwise we could find a nonzero polynomial $Q \in \mathcal{P}_{k-2}$ orthogonal to the range of $\varphi$ with respect to the inner product defined above. But this means that if $P(x) = |x|^2 Q(x)$, then
    %
    \[ 0 = \langle Q, \Delta P \rangle = Q(D) \overline{\Delta P} = \Delta Q(D) \overline{P} = P(D) \overline{P} = \langle P, P \rangle. \rangle \]
    %
    But this implies $P = Q = 0$.

    Let $\mathcal{A}_j$ be all harmonic polynomials in $\mathcal{P}_j$. We claim that $\mathcal{P}_j$ is the orthogonal direct sum of $\mathcal{A}_j$ and the space $\mathcal{B}_j = |x|^2 \mathcal{P}_{j-2}$. By induction, this would complete the proof. Certainly $\mathcal{A}_j$ and $\mathcal{B}_j$ are orthogonal, since if $Q$ is harmonic, then
    %
    \[ \langle |x|^2 P, Q \rangle = \Delta P(D) \overline{Q} = P(D) \overline{\Delta Q} = 0. \]
    %
    The fact that $\varphi$ is onto implies that the dimensions of $\mathcal{A}_j$ and $\mathcal{B}_j$ add to the dimensions of $\mathcal{P}_j$, completing the argument.
\end{proof}

\begin{remark}
    A consequence of this result is that the restriction of \emph{any} not-necessarily homogeneous polynomial on $\RR^n$ to $S^{n-1}$ is a linear combination of homogeneous polynomials.
\end{remark}

Let $\mathcal{H}^k$ be the space of all spherical harmonics of degree $k$. Note that the argument above shows that for $k \geq 2$,
%
\begin{align*}
    \dim \mathcal{H}^k &= \dim \mathcal{A}^k\\
    &= \dim \mathcal{P}_k - \dim \mathcal{P}_{k-2}\\
    &= {n + k - 1 \choose k} - {n + k - 3 \choose k - 2}.
\end{align*}
%
We can now calculate that $\dim \mathcal{H}^0 = 1$ and $\dim \mathcal{H}^1 = n$. In the particular case $n = 3$, we have that $\dim \mathcal{H}^k = 2k+1$ for all $k \geq 0$. The space $\mathcal{A}^k$ is sometimes called the space of \emph{solid spherical harmonics}, and $\mathcal{H}^k$ the space of \emph{surface spherical harmonics}. We observe that the result above implies that the span of $\bigcup_k \mathcal{H}^k$ contains the restriction of all polynomials to $S^{n-1}$, and therefore, by an application of Stone-Weirstrass, is dense in $C(S^{n-1})$, and therefore, dense in $L^2(S^{n-1})$. If we can show that each of the spaces $\mathcal{H}^k$ are orthogonal to one another, we therefore have an orthogonal decomposition of $L^2(S^{n-1})$.

Using the inner product we have defined on the space of polynomials, we can also prove the following interesting result.

\begin{theorem}
    The space $\mathcal{A}^k$ is spanned by polynomials of the form $(w \cdot x)^k$, where $\sum w_i^2 = 0$.
\end{theorem}
\begin{proof}
    Certainly any polynomial of the form $(w \cdot x)^k$ is harmonic if $\sum w_i^2 = 0$. Conversely, if $Q \in \mathcal{A}^k$, and suppose that for any polynomial of the form $P_w(x) = (w \cdot x)^k$, where $\sum w_i^2 = 0$, we have $\langle Q, P_w \rangle = 0$. We calculate that
    %
    \[ \langle Q, P_w \rangle = m! Q(c), \]
    %
    so we conclude that $Q$ vanishes on $Z(x_1^2 + \dots + x_n^2)$. Since the polynomial $x_1^2 + \dots + x_n^2$ is irreducible, by Hilbert's Nullstellensatz, $Q$ lies in the ideal generated by $x_1^2 + \dots + x_n^2$. But we have seen that any polynomial in this family is orthogonal to $\mathcal{H}^k$, and so we conclude that $Q = 0$.
\end{proof}

Next, we note the spaces $\mathcal{H}^k$ is orthogonal.

\begin{theorem}
    If $Y^k$ and $Y^l$ are spherical harmonics of degree $k$ and $l$, with $k \neq l$, then
    %
    \[ \int_{S^{n-1}} Y^k(x) Y^l(x)\; dx = 0. \]
\end{theorem}
\begin{proof}
    Let $u(rx) = r^k Y^k(x)$ and $v(rx) = r^l Y^l(x)$ for $|x| = 1$. Then $u$ and $v$ are homogeneous harmonic polynomials of degree $k$ and $l$ on $\RR^d$. By Green's theorem,
    %
    \begin{align*}
        0 = \int_{|x| \leq 1} u \Delta v - v \Delta u &= \int_{|x| = 1} \left( u \frac{\partial v}{\partial \eta} - v \frac{\partial u}{\partial \eta} \right)\\
        &= \int_{|x| = 1} (l - k) Y^k(x) Y^l(x).
    \end{align*}
    %
    If $l \neq k$, we obtain the required result.
\end{proof}

Alternatively, this follows from the following argument. Since $S^{n-1}$ has a Riemannian structure, it naturally has a Laplace-Beltrami operator $\Delta_{S^{n-1}} f = \nabla \cdot \nabla f$, where the divergence and gradient are taken with respect to the metric on $S^{n-1}$. If we identify $\RR^n - \{ 0 \}$ with $(0,\infty) \times S^{n-1}$, then it is a simple calculation to argue that
%
\[ \Delta f = \frac{\partial_r \left( r^n \partial_r f \right)}{r^n} + \frac{\Delta_{S^{n-1}} f}{r^2}. \]
%
where $\Delta_{S^{n-1}}$ corresponds to the spherical Laplacian. As a result of this fact, for a spherical harmonic $Y^k$ of degree $k$ on $S^{n-1}$, we have
%
\[ \Delta_{S^{n-1}} Y^k = - k (n+k-1) Y^k. \]
%
Since $\Delta$ is self-adjoint, this implies the orthogonality property of the spherical harmonics above.

\begin{comment}
\begin{lemma}
    Let $\Delta$ denote the Laplacian on $\RR^n$. Suppose we identify $\RR^n - \{ 0 \}$ with $(0,\infty) \times S^{n-1}$ diffeomorphically, using polar coordinates (this is not an isometry). Then
    %
    \[ \Delta f = \frac{\partial_r \left( r^n \partial_r f \right)}{r^n} + \frac{\Delta_{S^{n-1}} f}{r^2}, \]
    %
    where $\Delta_{S^{n-1}}$ corresponds to taking the spherical Laplacian with respect to the $S^{n-1}$ variables.
\end{lemma}
\begin{proof}
    Let $g_{\RR^n}$ be the Riemannian metric on $\RR^n$, and let $\tilde{g}_{S^{n-1}}$ denote the \emph{pullback} of the Riemannian metric $g_{S^{n-1}}$ under the projection map $\RR^n - \{ 0 \} \to S^{n-1}$. Consider a polar coordinate system $x = r \theta$, and let $(v, U)$ be a coordinate system on $S^{n-1}$. Then
    %
    \[ \frac{\partial x^i}{\partial v^j} = r \frac{\partial \theta^i}{\partial v^j} \]
    %
    and
    %
    \[ \frac{\partial x^i}{\partial r} = \theta^i. \]
    %
    Let $M_{ij} = \partial \theta^i / \partial v^j$. Then
    %
    \[ dx^i = \sum \frac{\partial x^i}{\partial v^j} dv^j + \frac{\partial x^i}{\partial r} dr = r \sum\nolimits_j M_{ij} dv^j + \theta^i dr. \]
    %
    Then the metric on $\RR^n$ is given by
    %
    \begin{align*}
        g_{\RR^n} &= \sum (dx^i)^2\\
        &= r^2 \left( \sum_{i,j_1,j_2} M_{i j_1} M_{i j_2} dv^{j_1} dv^{j_2} \right) + \left( 2r \sum\nolimits_{i,j} M_{ij} \theta^i dv^j dr \right) + \left( \sum\nolimits_i (\theta^i)^2 dr^2 \right)\\
        &= r^2 \left( \sum_{j_1,j_2} (M^TM)_{j_1 j_2} dv^{j_1} dv^{j_2} \right) + 2r \left( \sum_j (M^T \theta)_j dv^j \right) dr + dr^2\\
        &= r^2 \tilde{g}_{S^{n-1}} + dr^2,
    \end{align*}
    %
    where we conclude that $M^T \theta = 0$ because $\theta \cdot \theta = 1$, so that, by bilinearity, $M^T \theta = \nabla_v \theta \cdot \theta = 0$. But now we conclude that
    %
    \begin{align*}
        \Delta_{\RR^n} &= \frac{1}{r^n \sqrt{\text{Det}(g_{S^{n-1}})}} \Bigg( \sum_{i,j} \partial_{v^i} \left\{ r^n \sqrt{\text{Det}(g_{S^{n-1}})} (g_{S^{n-1}}^{ij} / r^2) (\partial_{v^j} f) \right\}\\
        &\quad\quad\quad\quad + \partial_r \left\{ r^n \sqrt{\text{Det}(g_{S^{n-1}})} (\partial_r f) \right\} \Bigg)\\
        &= r^{-2} \Delta_{S^{n-1}} +  r^{-n} \partial_r \{ r^n \partial_r f \}. \qedhere
    \end{align*}
\end{proof}
\end{comment}

Another useful representation of $S^n$ follows by identifying it with $S^{n-1} \times (-1,1)$, such that for $\sigma \in S^{n-1}$, $(\sigma,t)$ maps to $( \sin(\theta) \sigma, \cos(\theta)  )$. In this coordinate system, we have
%
\[ \Delta_{S^n} = \frac{1}{\sin(\theta)^{n-1}} \frac{\partial}{\partial \theta} \left( \sin(\theta)^{n-1} \frac{\partial f}{\partial \theta} \right) + \frac{1}{\sin(\theta)^2} \Delta_{S^{n-1}}. \]
%
A calculation of this is provided in Jean Gallier's notes on Spherical Harmonics.

To review, we have an orthogonal decomposition
%
\[ L^2(S^{n-1}) = \bigoplus_k \mathcal{H}^k. \]
%
Once a canonical orthonormal basis $Y^k_1, \dots, Y^k_l$ is fixed, we can then write
%
\[ f = \sum_{k = 0}^\infty \sum_j a_{kj} Y^k_j, \]
%
where $a_{kj} = \langle f, Y^k_j \rangle$. The canonical choice when $n = 2$ is
%
\[ Y^k_1(e^{i \theta}) = \frac{\cos(k \theta)}{\sqrt{\pi}} \quad\text{and}\quad Y^k_2(e^{i \theta}) = \frac{\sin(k \theta)}{\sqrt{\pi}}, \]
%
which connects the theory of spherical harmonics on $S^1$ back to the theory of Fourier series.

We can utilize the theory of surface harmonics to obtain a decomposition of $L^2(\RR^n)$ which plays nicely with respect to the rotation group. To see this, define $\mathfrak{H}_k$ to be the space of all linear combinations of functions of the form $a \cdot Y^k$, where $Y^k$ is a solid spherical harmonic of degree $k$, and $a$ is a radial function on $\RR^n$, such that $a \cdot Y^k$ is square integrable, which holds in particular if and only if
%
\[ \left( \int_0^\infty |a(t)|^2 t^{k+d-1}\; dt \right)^{1/2} < \infty, \]
%
a fact immediately verified by applying polar coordinates and homogeneity.

\begin{theorem}
    The spaces $\{ \mathfrak{H}^k \}$ are closed in $L^2(\RR^n)$, pairwise orthogonal, and give a decomposition
    %
    \[ L^2(\RR^n) = \bigoplus_k \mathfrak{H}^k. \]
\end{theorem}
\begin{proof}
    Choose a family of solid spherical harmonics $\{ Y^k_l \}$ for each $k$ which form an orthonormal basis when restricted to surface harmonics on $S^{n-1}$. Any element $f \in \mathfrak{H}^k$ can be written as
    %
    \[ f = \sum_l a_l Y^k_l, \]
    %
    for some radial functions $\{ a_l \}$, and applying orthogonality and integration in polar coordinates gives that
    %
    \begin{align*}
        \| f \|_{L^2(\RR^n)} &= \left( \sum_l \| a_l Y^k_l \|_{L^2(\RR^n)}^2 \right)^{1/2}\\
        &= \left( \sum_l \int_0^\infty |a_l(t)|^2 t^{k + d-1}\; dx \right)^{1/2}
    \end{align*}
    %
    Thus the $L^2$ norm of $f$ is an $l^2$ sum of a weighted $L^2$ norm of the radial functions $\{ a_l \}$. This immediately gives that the space $\mathfrak{H}^k$ is closed.

    It is immediate the spaces $\mathfrak{H}^k$ and $\mathfrak{H}^l$ are parwise orthogonal, since they are orthogonal when integrated on any sphere, and we can then integrate in polar coordinates. To show they decompose $L^2(\RR^n)$ completely, fix $f \in L^2(\RR^n)$and suppose $f$ is orthogonal to any element of $\mathcal{H}^k$, for any $k$. For almost every $r > 0$, the function $f_r(x) = f(rx)$ lies in $L^2(S^{n-1})$. But then we can write $f_r = \sum a_{kl}(r) Y^k_l$ for some coefficients $\{ a_{kl}(r) \}$ with the property that
    %
    \[ \| f \|_{L^2(\RR^n)} = \left( \sum_{k,l} \int_0^\infty r^{d-1} |a_{kl}(r)|^2\; dr \right)^{1/2} \]
    %
    For any radial function $b$ such that $b Y^k_l$ is square integrable, we have that
    %
    \[ \langle f, b Y^k_l \rangle = \int_0^\infty r^{d-1+k} a_{kl}(r) \overline{b(r)}\; dr. \]
    %
    This can only be possible for all $b$ if $a_{kl} = 0$, and since this holds for all $k$ and $l$, we conclude that $f$ vanishes almost everywhere on almost every sphere about the origin. This can only be possible if $f$ is equal to zero almost everywhere. Thus we conclude that $\mathfrak{H}$
\end{proof}

Using the theory of zonal harmonics introduced in the next section, we will be able to see that the spaces $\mathcal{H}^k$ and $\mathfrak{H}^k$ are \emph{minimal} invariant subspaces of the action of $SO(n)$ on $L^2(\RR^n)$. Indeed, the rotation group is transitive on the family of zonal harmonics of a fixed degree $k$, and these harmonics span $\mathcal{H}^k$, which shows $\mathcal{H}^k$ is a cyclic subspace of the action of $SO(n)$. We will also see later on in these notes that the spaces $\mathfrak{H}^k$ are invariant under the Fourier transform on $\RR^n$.

\section{Zonal Harmonics}

For each $x \in S^n$, we have a linear functional $L_x$ on $\mathcal{H}_k$ given by $L_x(f) = f(x)$. Applying the duality theory of inner product spaces, we can find a spherical harmonic $Z^k_x$ in $\mathcal{H}^k$ such that such that for any $Y^k \in \mathcal{H}_k$,
%
\[ Y^k(x) = \int_{S^n} Z^k(x,x') Y^k(x')\; dx'. \]
%
The function $Z^k_x$ is called the \emph{zonal harmonic of degree $k$ with pole $x$}.

\begin{theorem}
    Let $Z^k_x$ denote the zonal harmonic of degree $k$ with pole $x$. Then:
    %
    \begin{itemize}
        \item The function $Z^k_x$ is real-valued.

        \item For any $R \in SO(n)$,
        %
        \[ Z^k_{Rx} = (R^{-1})^* Z^k_x. \]

        \item For any orthonormal basis $\{ Y^k_1, \dots, Y^k_l \}$ of $\mathcal{H}_k$,
        %
        \[ Z^k_x(x') = \sum_j \overline{Y^k_j(x)} Y^k_j(x'). \]
        %
        We thus have
        %
        \[ Z^k_x(x) = \frac{\dim \mathcal{H}_k}{|S^n|}, \]
        %
        and moreover, this is the \emph{maximum} value of $Z^k_x$ on $S^n$.
    \end{itemize}
\end{theorem}
\begin{proof}
    We have
    %
    \[ Z^k_x = \sum \langle Z^k_x, Y^k_j \rangle Y^k_j, \]
    %
    but
    %
    \[ \langle Z^k_x, Y^k_j \rangle = \overline{Y^k_j}(x), \]
    %
    and so
    %
    \[ Z^k_x(x') = \sum \overline{Y^k_j}(x) Y^k_j(x'). \]
    %
    We can choose $\{ Y^k_1, \dots, Y^k_l \}$ to be real-valued, and from this we therefore conclude $Z^k_x$ is real valued. We also calculate that for $R \in SO(n)$ and $Y^k \in \mathcal{H}_k$, $R^* Y^k \in \mathcal{H}_k$, and thus
    %
    \[ \int_{|x| = 1} Z^k_x(R^{-1} x') Y^k(x')\; dx = \int_{|x| = 1} Z^k_x(x') Y^k(Rx')\; dx' = Y^k(R x), \]
    %
    But this means that $\langle Z^k_{Rx} - (R^{-1})^* Z^k_x, Y^k \rangle = 0$ for all $Y^k \in \mathcal{H}_k$, which can only be possible if $Z^k_{Rx} = (R^{-1})^* Z^k_x$.

    Using the results we have just proved, the quantity $Z^k_x(x)$ is independent of $x$. Moreover,
    %
    \[ Z^k_x(x) = \sum_j |Y^k_j(x)|^2. \]
    %
    Integrating the right hand side over $S^n$, we thus obtain that
    %
    \[ |S^n| Z^k_x(x) = \dim \mathcal{H}_k. \]
    %
    But
    %
    \[ Z^k_x(x') = \langle Z^k_{x'}, Z^k_x \rangle = \int Z^k_{x'}(x'') Z^k_x(x'')\; dx''. \]
    %
    Now
    %
    \[ \| Z^k_x \|_{L^2(S^n)}^2 = \sum |Y^k_j(x)|^2 = \frac{\dim \mathcal{H}_k}{|S^n|}, \]
    %
    and thus by Cauchy-Schwartz we have
    %
    \[ |Z^k_x(x')| \leq \frac{\dim \mathcal{H}_k}{|S^n|}. \qedhere \]
\end{proof}

Any function orthogonal to the family of functions $\{ Z^k_x : x \in S^n \}$ must vanish on $S^n$. It follows that the family $\{ Z^k_x \}$ spans $\mathcal{H}^k$.

We can immediately use the zonal harmonics to obtain an integral formula for the projections $P_k: L^2(S^n) \to \mathcal{H}^k$. Indeed, if $f \in L^2(S^n)$, and we can write $f = \sum_k f_k$, where $f_k \in \mathcal{H}^k$, then
%
\[ f_k(x) = \int Z^k_x(x') f(x')\; dx'. \]
%
Thus in general, we have
%
\[ P_k f(x) = \int Z^k_x(x') f(x')\; dx'. \]
%
Thus $(x,x') \mapsto Z^k_x(x')$ is the required integral kernel.

Many operators with rotational symmetry can be written in terms of zonal harmonics. For instance, let us consider the solution operator $L$ to the Dirichlet problem on the unit ball in $\RR^n$, i.e. such that if $b$ is an appropriately regular function on the boundary of the unit ball, then $Lb$ gives a harmonic function on the interior of the unit ball, which has $b$ as it's boundary values. The operator $L$ must be radially symmetric, i.e. for any rotation $R$, we must have
%
\[ R^*(Lb) = L(R^* b), \]
%
We might therefore expect to write $L$ in terms of zonal harmonics.

Indeed, if $Y^k \in \mathcal{H}^k$ is a spherical harmonic of degree $k$, then clearly for $0 < r < 1$ and $|x| = 1$ we must have
%
\[ L \{ Y^k \}(rx) = r^k Y^k(x) = r^k \langle Z^k_x, Y^k \rangle = r^k \int_{S^{n-1}} Z^k_x(x') Y^k(x')\; dx'. \]
%
In fact, if we set
%
\[ K(rx,x') = \sum_{k = 0}^\infty r^k Z^k_x(x'), \]
%
which is a well defined, smooth function on $B \times S^{n-1}$, then we conclude that for any polynomial $f$ restricted to the unit sphere,
%
\[ Lf(x) = \int_{S^{n-1}} K(x,x') b(x')\; dx'. \]
%
A density argument shows that $K$ must be the \emph{Poisson kernel} for the unit ball, which in particular, gives the identity
%
\[ \frac{1}{|S^{n-1}|} \frac{1 - |rx|^2}{|rx - x'|^n} = \sum_{k = 0}^\infty r^k Z^k_x(x'). \]
%
We notice that the spaces $\mathcal{H}^k$ are all eigenspaces of the operators $L_r$ on the unit sphere given by $L_r b(x) = Lb(rx)$. This is a property of all appropriately regular operators which are rotationally symmetric.

Let us now return to the study of the zonal harmonics. The following Lemma will be very useful in this regard.

\begin{lemma}
    Consider $\sigma_1, \tau_1, \sigma_2, \tau_2 \in S^n$. If $\sigma_1 \cdot \tau_1 = \sigma_2 \cdot \tau_2$, then there exists a rotation matrix $R \in SO(n+1)$ such that $R\sigma_1 = \sigma_2$ and $R\tau_1 = \tau_2$.
\end{lemma}

As a result of this fact, and the rotation invariants of the zonal harmonics, we conclude that $Z^k_x(x')$ is a function of $x \cdot x'$. We will later see that we can write $Z^k_x(x')$ as a \emph{polynomial of degree $k$} in $x$ and $x'$.

\begin{lemma}
    Let $P$ be a polynomial in $n$ variables such that $P \circ R = P$ for any rotation matrix $R \in SO(n)$. Then there exists constants $\{ c_j \}$ such that
    %
    \[ P(x) = \sum_j c_j |x|^{2j}. \]
\end{lemma}
\begin{proof}
    Write $P = \sum P_j$, where $P_j$ is homogeneous of degree $j$. Then each of the polynomials $\{ P_j \}$ satisfies the assumptions of the lemma. But then $P_j(x) / |x|^j$ is invariant under rotations, and is homogeneous of degree zero, which can only occur if $P_j(x) / |x|^j$ is constant. Since $|x|^j$ is not a polynomial if $j$ is odd, this yields the result above.
\end{proof}

\begin{remark}
    One consequence of this Lemma is that any constant coefficient differential operator on $\RR^n$ invariant under rotations can be written as
    %
    \[ P(\Delta), \]
    %
    a polynomial in the Laplacian $\Delta$.
\end{remark}

Thus a polynomial restricted to the sphere which is invariant under rotations is constant. If we fix a pole $x$, and consider harmonic polynomials restricted to the sphere which are invariant under rotations fixing $x$ (or equivalently, harmonic polynomials that are constant on \emph{parallels} to $x$, i.e. the intersections of $S^n$ with affine hyperplanes orthogonal to the line from the origin to $x$), then we introduce the zonal harmonics.

\begin{theorem}
    Fix $x_0 \in S^n$. Then any spherical harmonic $Y^k$ of degree $k$, which is invariant under rotations fixing $x_0$, can be written as a constant multiple of the zonal harmonic $Z^k_{x_0}$. Moreover, there exists a polynomial $G_{n,k}$ of degree $k$, such that
    %
    \[ Y^k(x) = Y^k(x_0) G_{n,k}( x \cdot \tau ). \]
\end{theorem}
\begin{proof}
    TODO: See notes by Jean Gallier, Theorem 1.17.
\end{proof}

The polynomial $G_{n,k}$ is called the \emph{Gegenbauer polynomial}, or \emph{ultraspherical polynomial}, of degree $k$. The proof in Jean Gallier's notes shows that if $k = 2m$ is even, then
%
\[ G_{n,k} = \sum_{j = 0}^m c_j t^{2j} (1 - t^2)^{m - j}, \]
%
and if $k = 2m + 1$ is odd, then
%
\[ G_{n,k} = \sum_{j = 0}^m c_j t^{2j+1} (1 - t^2)^{m - j}. \]
%
Thus in particular, $G_{n,k}(-t) = (-t)^k G_{n,k}(t)$. If $n = 2$, then $\{ G_{n,k} \}$ is precisely the family of \emph{Legendre polynomials}.


\section{The Funk-Hecke Formula}

The Funk-Hecke formula allows one to define a `zonal convolution' operator on the sphere. Given a measurable function $K: [-1,+1] \to \CC$ such that
%
\[ \int_{-1}^1 |K(t)| (1 - t^2)^{n/2 - 1}\; dt < \infty, \]
%
and a function $f$ on $S^n$, we can define a `convolution' $K * f$ by setting
%
\[ (K * f)(x) = \int_{S^n} K(x \cdot y) f(y)\; dy. \]
%
In other words, to calculate $(K * f)(x)$, we average $f$ along parallel circles to $x$, and then integrate these averages along $K$. The following result was first shown by Funk in 1916, and by Hecke in 1918.
%
\[ \int_{S^n} |K(x \cdot y)|^p = \int_{-1}^1 (1 - r^2)^{d/2 - 1} |K(t)|^p \]

\begin{theorem}
    If $K$ is as above, then there exists a sequence $\{ \lambda_k \}$ such that if $Y^k$ is a spherical harmonic of degree $k$, then
    %
    \[ K * f = \lambda_k f. \]
    %
    Thus the spaces $\mathcal{H}^k$ are eigenspaces for the zonal convolution operator.
\end{theorem}
\begin{proof}
    Since $K$ is as above, the theory of orthogonal polynomials allows us to write
    %
    \[ K = \sum \lambda_k G_k. \]
    %
    But this means that
    %
    \[ T Z^k_x = \lambda_k Z^k_x, \]
    %
    and since $\{ Z^k_x \}$ span $\mathcal{H}^k$, it follows that $K * f = \lambda_k f$ for all $f \in \mathcal{H}^k$. TODO: Go over this proof in more detail.
\end{proof}

Essentially all rotation invariant operators arise as zonal convolutions.

\begin{theorem}
    Let $T: \mathcal{D}(S^{n-1}) \to \mathcal{D}^*(S^{n-1})$ be a Schwartz operator such that for any $R \in SO(n)$,
    %
    \[ T \circ R^* = R^* \circ T. \]
    %
    Then $T$ is given by a zonal convolution operator.
\end{theorem}
\begin{proof}
    The operator $T$ is Schwartz, so we can find a Schwartz kernel $K$, such that for $f \in C^\infty(S^{n-1})$,
    %
    \[ Tf(x) = \int K(x,y) f(y)\; dy. \]
    %
    Then
    %
    \[ R^* \{ Tf \}(x) = Tf(Rx) = \int K(Rx, y) f(y)\; dy \]
    %
    and
    %
    \[ T \{ R^* f \}(x) = \int K(x,y) f(Ry)\; dy = \int K(x, R^{-1} y) f(y)\; dy. \]
    %
    This can only possible hold for all $f$ if $K(Rx,Ry) = K(x,y)$ for all $R \in SO(n)$. But this holds if and only if we can find a distribution $L$ on $[-1,+1]$ such that $K(x,y) = L(x \cdot y)$, for some distribution $L$. And this means, in particular, that $T$ is given by zonal convolution.
\end{proof}



\section{The Fourier Transform of $\mathfrak{H}^k$}

The Fourier transform of an even function on $\RR$ is an even function, and for an even function $f$, we can write
%
\[ \widehat{f}(\xi) = 2 \int_0^\infty \cos(2 \pi \xi x) f(x)\; dx. \]
%
Similarily, if $f$ is an odd function, then $\widehat{f}$ is odd, and
%
\[ \widehat{f}(\xi) = 2i \int_0^\infty \sin(2 \pi \xi x) f(x)\; dx. \]
%
Thus the Fourier transform preserves the decomposition $L^2(\RR) = \mathfrak{H}^0 \oplus \mathfrak{H}^1$.

We can obtain a similar formula in $\RR^2$, and here, the theory of Fourier series emerges. Indeed, here $SO(2)$ is isomorphic to $\TT$, since we can parameterize the rotation group by letting for each $\theta \in \RR$, the rotation $R_\theta$ denote the rotation $R_\theta(z) = e^{i \theta} z$. The space $\mathcal{H}^k$ is two dimensional, spanned by $e^{ki\theta}$ and $e^{-k i \theta}$, since these functions are restrictions of the harmonic functions $z^k$ and $\overline{z}^k$. Let us denote the span of the first function by $\mathcal{H}^k_+$, and the latter by $\mathcal{H}^k_-$, these spaces being orthogonal to one another. By multiplying these functions by radial functions, we can then see that the resulting spaces $\mathfrak{H}^k_+$ and $\mathfrak{H}^k_-$ are preserved by the Fourier transform, and moreover, compute a simple formula for their Fourier transform. Indeed, we can write
%
\[ \mathfrak{H}^k_+ = \{ f \in L^2(\RR^2): R_\theta f = e^{k i \theta} f\ \text{for all $R_\theta \in SO(2)$} \} \]
%
and
%
\[ \mathfrak{H}^k_- = \{ f \in L^2(\RR^2): R_\theta f = e^{-k i \theta} f\ \text{for all $R_\theta \in SO(2)$} \}. \]
%
But these properties immediately imply that $\mathfrak{H}^k_+$ and $\mathfrak{H}^k_-$ are preserved under the Fourier transform, since rotations commute with the Fourier transform, and so, for example, if $f \in \mathfrak{H}^k_+$,
%
\[ R_\theta \widehat{f} = \widehat{R_\theta f} = e^{k i \theta} \widehat{f}, \]
%
which means $\widehat{f} \in \mathfrak{H}^k_+$. We have a formula for this Fourier transform; indeed, if $f(r e^{i \theta}) = a(r) e^{k i \theta}$, for some $k \in \ZZ$, then we can write $\widehat{f}(\rho e^{i \theta}) = b(\rho) e^{k i \theta}$, and we have
%
\begin{align*}
    b(\rho) &= \widehat{f}( \rho e^{i 0} )\\
    &= \int_0^\infty r a(r) \int_0^{2\pi} e^{k i \theta - 2 \pi i \rho \xi \cos(\theta)}\\
    &= (-i)^k 2 \pi \int_0^\infty r a(r) J_k(2 \pi \rho r)\; dr.
\end{align*}
%
Thus we can find a formula for the Fourier transform of the elements of $\mathfrak{H}^k$.

On $\RR^n$, it is also simple to find an expression for the Fourier transform of a radial function. If $f(x) = a(|x|)$, then we calculate that, if $\widehat{f}(\xi) = b(|\xi|)$, and a simple calculation also shows that
%
\[ b(\rho) = 2 \pi \rho^{1-n/2} \int_0^\infty r^{n/2} a(r) J_{n/2 - 1}(2 \pi \rho r)\; dr. \]
%
Thus we also see the appearance of Bessel functions. We now show we can find such an expression for general spherical harmonics.

\begin{theorem}
    Suppose $f(x) = a(|x|) Y^k(x)$, where $Y^k$ is a solid spherical harmonic of degree $k$, and $a$ is a radial function chosen such that $f \in L^1(\RR^n) \cap L^2(\RR^n)$. Then $\widehat{f}(\xi) = b(|\xi|) Y^k(x)$, where
    %
    \[ b(\rho) = 2 \pi (-i)^k r^{-n/2 - k + 1} \int_0^\infty r^{n/2 + k} a(r) J_{n/2 + k - 1}(2 \pi \rho r)\; dr. \]
\end{theorem}
\begin{proof}
    TODO: See Stein and Weiss, Chapter 4, Theorem 3.10.
\end{proof}








\chapter{Orthogonal Polynomials}

There are many useful series representations of functions, in which the exponentials that occur in the Fourier expansion are replaced with families of polynomials. The study of these expansions is often called the theory of \emph{orthogonal polynomials}.

Let $\mathcal{P}$ denote the space of all real-valued polynomials in a single variable. We fix a non-negative weight function $w$, such that for any polynomial $f$, $f w$ is Lebesgue integral on $\RR$. We then define an inner product on $\mathcal{P}$ by setting
%
\[ \langle f, g \rangle = \int f(x) g(x) w(x)\; dx. \]
%
By taking the basis $\{ 1, x, x^2, \dots \}$ for $\mathcal{P}$, and applying the Gram-Schmidt process, we find an orthogonal basis $\{ \phi_n \}$ for $\mathcal{P}$, where $\deg(\phi_n) = n$ for all $n$. This type of basis for $\mathcal{P}$ is unique up to rescaling the individual elements $\phi_n$ by non-zero multiplicative factors. This is precisely the family of \emph{orthogonal polynomials} we wish to study in this chapter.

Given such a basis, $\phi_1,\dots,\phi_{n-1}$ must necessarily span the space of all polynomials of degree $n-1$, and so we conclude the useful property that $\langle f, \phi_n \rangle = 0$ if $f \in \mathcal{P}$ and $n > \deg(f)$.

We have the following recurrence formula for the polynomials $\{ \phi_n \}$.

\begin{lemma}
    For any set of orthogonal polynomials $\{ \phi_n \}$, let $\{ a_n \}$ be the $x^n$ coefficients of $\{ \phi_n \}$, and $\{ b_n \}$ the $x^{n-1}$ coefficients of the $\{ \phi_n \}$. Then if
    %
    \[ A_n = a_{n+1} / a_n, \quad B_n = A_n \left( \frac{b_{n+1}}{a_{n+1}} - \frac{b_n}{a_n} \right), \quad\text{and}\quad C_n = \frac{A_n}{A_{n-1}} \frac{\| \phi_n \|^2}{\| \phi_{n-1} \|^2}, \]
    %
    then we conclude that
    %
    \[ \phi_{n+1} = (A_n x + B_n) \phi_n - C_n \phi_{n-1}. \]
\end{lemma}
\begin{proof}
    TODO: See Notes by Frye and Efthimou, Proposition 3.5.
\end{proof}

Let us consider some examples:
%
\begin{itemize}
    \item If one chooses $w(x) = \Ind[-1,+1]$, then one obtains the Legendre polynomials.

    \item If one chooses $w(x) = \Ind[-1,+1] (1 - t^2)^{n/2 - 1}$, then one obtains the \emph{Gegenbauer polynomials} on $S^n$.
\end{itemize}



\section{The Rodrigues Formula}

For now, let us specialize our study to weight functions supported on the interval $[-1,+1]$. Consider the functions $\psi_n$, defined on $[-1,+1]$ for $n \geq 0$ by setting
%
\[ \psi_n(x) = \frac{1}{w(x)} \left( \frac{d}{dx} \right)^n [ w(x) (1 - x^2)^n ]. \]
%
What conditions imply that $\{ \psi_n \}$ are restrictions of polynomials, each of degree $n$? We have $\psi_0(x) = 1$, which is always a polynomial. We have
%
\[ \psi_1(x) = (1 - x^2) \frac{w'(x)}{w(x)} - 2x. \]
%
In order for this to be a restriction of a polynomial of degree one, we should be able to find constants $a$ and $b$ such that
%
\[ (1 - x^2) \frac{w'(x)}{w(x)} = ax + b, \]
%
which we can rewrite as
%
\[ \frac{w'(x)}{w(x)} = \frac{ax + b}{(1 - x)(1 + x)} = \frac{a + b}{2} \frac{1}{1 - x} + \frac{b - a}{2} \frac{1}{1 + x}. \]
%
We can then solve this equation as
%
\[ w(x) = C (1 + x)^\alpha (1 - x)^\beta. \]
%
The constant $C$ does not enter into the definition of the functions $\psi_n$, so we may assume without loss of generality that $C = 1$. We also require $\alpha$ and $\beta$ to be greater than $-1$, so that $w$ can actually be integrated against any polynomial. In this case, it turns out that the functions $\psi_n$ are then restrictions of degree $n$ polynomials.

\begin{theorem}
    For any $\alpha, \beta > -1$, let
    %
    \[ w(x) = (1 + x)^\alpha (1 - x)^\beta. \]
    %
    Then the functions
    %
    \[ \psi_n(x) = \frac{1}{w(x)} \left( \frac{d}{dx} \right)^n [ w(x) (1 - x^2)^n ] \]
    %
    are restrictions of polynomials of degree $n$.
\end{theorem}
\begin{proof}
    TODO: See Notes by Frye and Efthimou, Proposition 3.6.
\end{proof}

The family of functions $\{ \psi_n \}$ is then called the \emph{Jacobi polynomials}. The next result shows they are orthogonal polynomials for the weight function $w$, restricted to $[-1,+1]$.

\begin{theorem}
    Let $\{ \psi_n \}$ be a family of Jacobi polynomials associated with a weight function $w$, as above. Then for $0 \leq k < n$,
    %
    \[ \int_{-1}^1 \psi_n(x) x^k w(x) = 0. \]
\end{theorem}
\begin{proof}
    TODO: See Notes by Frye and Efthimou, Proposition 3.7.
\end{proof}

The fact that orthogonal polynomials are unique up to scalar multiples means that any family of orthogonal polynomials is a rescaled variant of the Jacobi polynomials, which results in an equation relating the two; this equation is called the \emph{Rodriguez formula}.



\newpage







\section{Legendre Polynomials}

Consider the function
%
\[ H(x,r) = \frac{1}{(1 - 2xr + r^2)^{1/2}}, \]
%
analytic on the line $r = 0$. If we consider the power series expansion around $r = 0$, we can write
%
\[ H(x,r) = \sum_{j = 0}^\infty P_j(x) r^j. \]
%
Thus we have
%
\[ P_j(x) = \left. \frac{1}{j!} \frac{\partial^j H}{\partial r^j} \right|_{r = 0}. \]
%
One can prove by induction that there exists polynomials $Q_{j,k}$ with $\deg(Q_{j,k}) \leq k$ such that
%
\[ \frac{\partial^j H}{\partial r^j} = \sum_{k = 0}^j \frac{Q_{j,k}(x,r)}{(1 - 2xr + r^2)^{1/2 + k}}, \]
%
since, assuming the formula works for some particular $j$, the product rule implies
%
\[ \frac{\partial^{j+1} H}{\partial r^j} \]
%
is also of this form. Setting $r = 0$ shows $P_j$ is a polynomial function with degree at most $j$. The family of polynomials $\{ P_j \}$ are called the \emph{Legendre polynomials}. We can explicitly calculate the first few, i.e. we have
%
\[  P_0(x) = 1 \quad P_1(x) = x \quad P_2(x) = \frac{3x^2 - 1}{2} \]
\[ P_3(x) = \frac{5x^3 - 3x}{2} \quad P_4(x) = \frac{35x^4 - 30x^2 + 3}{8}. \]
%
Historically, the Legendre polynomials were introduced by Adrien-Marie Legendre as the coefficients of the Newton potential in $\RR^3$, i.e.
%
\[ \frac{1}{|x - y|} = \sum_{l = 0}^\infty \frac{|y|^l}{|x|^{l+1}} P_l \left( \frac{x \cdot y}{|x| |y|} \right), \]
%
which is useful when integrating the potential over a continuous medium.

Let us now derive some of the many interrelated properties of the family of Legendre polynomials.

\begin{theorem}
    If $j$ is even, $P_j$ is an even polynomial, and if $j$ is odd, $P_j$ is an odd polynomial.
\end{theorem}
\begin{proof}
    Since $H(-x,-r) = H(x,r)$, we find that
    %
    \[ \sum_{j = 0}^\infty (-1)^j P_j(-x) r^j = \sum_{j = 0}^\infty P_j(x) r^j, \]
    %
    which shows $P_j(-x) = (-1)^j P_j(x)$.
\end{proof}

Since
%
\[ (1 - 2xr + r^2) \partial_r H - (x - r) H = 0, \]
%
substituting in the Legendre polynomials into this equation gives the recurrence relation
%
\[ (j+1) P_{j+1}(x) - (2j + 1) x P_j(x) + j P_{j-1}(x) = 0. \]
%
There are several other differential equations that $H$ satisfies, namely
%
\[ (1 - 2xr + r^2) \partial_r H - rH = 0 \]
%
and
%
\[ r \partial_r (rH) - (1 - rx) \partial_x H = 0. \]
%
This leads to the recurrence relations
%
\[ j P_j - x P_j' + P_{j-1}' = 0 \]
%
and
%
\[ j P_{j-1} - P_j' + x P_{j-1}' = 0 \]
%
respectively. Adding and transposing terms leads to the recurrence
%
\[ P_{j+1}' - P_{j-1}' = (2j + 1) P_j. \]
%
and
%
\[ (1 - x^2) P_j'' - 2xP_j' + j(j+1) P_j = 0. \]
%
Thus $P_j$ is a solution to a homogeneous linear differential equation. We now come to the \emph{orthogonality} of the Legendre polynomials.

\begin{theorem}
    If $j \neq k$, then
    %
    \[ \int_{-1}^1 P_j(x) P_k(x)\; dx = 0. \]
    %
    More generally, if $Q$ is \emph{any} polynomial with $\deg(Q) < j$, then
    %
    \[ \int_{-1}^1 P_j(x) Q(x)\; dx = 0. \]
\end{theorem}
\begin{proof}
    Multiplying the differential equation above gives that
    %
    \[ (1 - x^2) P_j'' P_k - 2x P_j' P_k + j(j+1) P_j P_k = 0 \]
    %
    and
    %
    \[(1 - x^2) P_j P_k'' - 2x P_j P_k' + k(k+1) P_j P_k = 0. \]
    %
    Thus an integration by parts justifies that
    %
    \begin{align*}
        (j(j+1) - k(k+1)) \int_{-1}^1 P_j P_k &= \int_{-1}^1 2x [P_j' P_k - P_j P_k'] - (1 - x^2) [P_j'' P_k - P_j P_k'']\\
        &= \int_{-1}^1 2x w - (1 - x^2) w'\\
        &= \int_{-1}^1 2x w - 2x w = 0.
    \end{align*}
    %
    Thus we conclude that $P_j$ and $P_k$ are orthogonal. Since $\{ P_j \}$ are orthogonal, they are linearly independent. But this means that $P_0,\dots,P_{j-1}$ span the family of all polynomials with degree less than $j$. And this yields the second claim, since any $Q$ as above can be written as a linear combination of $P_0,\dots,P_{j-1}$.
\end{proof}

\begin{remark}
    Note that, since these polynomials are orthogonal, and we have $P_0 = 1$ and $P_1 = x$, one can construct the family $\{ P_j \}$ by applying the Gram Schmidt process to the linearly independent set $\{ 1, x, \dots \}$.
\end{remark}

Given this property, it is natural to calculate the quantities
%
\[ C_j = \left( \int_{-1}^1 |P_j(x)|^2\; dx \right)^{1/2}, \]
%
since this is necessary to use $\{ P_j \}$ as an orthonormal basis.

\begin{theorem}
    We have $C_j = (j + 1/2)^{-1/2}$.
\end{theorem}
\begin{proof}
    TODO: See Page 51 of Jackson, Orthogonal Polynomials
\end{proof}

Let us define $p_j = (j + 1/2)^{1/2} P_j$ to be the $L^2$ normalization of $P_j$. The Weirstrass approximation theorem shows that this is an orthonormal basis for $L^2[-1,1]$. For $f \in L^2[-1,1]$, we can now form it's Legendre expansion
%
\[ f = \sum c_j P_j \]
%
which converges in $L^2[-1,1]$, where
%
\[ c_j = (j+1/2) \int_{-1}^1 f(x) P_j(x)\; dx. \]
%
are the \emph{Legendre coefficients} of the function $f$. Given this integral formula, we can now define the expansion of any $f \in L^1[-1,1]$, though we now no longer have guarantees on the convergence of this expansion.

Let us also introduce some other useful representations of the Legendre polynomials. First is Rodrigues's formula, which states that
%
\[ P_j(x) = \frac{1}{2^j} \frac{1}{j!} \frac{d^j}{dx^j} (x^2 - 1)^j. \]
%
One can prove this formula by noting that it is a polynomial of degree $j$, which satisfies the defining differential equation
%
\[ (1 - x^2) P_j'' - 2xP_j' + j(j+1) P_j = 0, \]
%
since $P_j$ is the unique polynomial which satisfies this equation up to a constant multiple (TODO: Page 58 of Jackson).

Another useful formula is the integral representation
%
\[ P_j(x) = \frac{1}{\pi} \int_0^\pi [x + (x^2 - 1)^{1/2} \cos \phi]^n\; d\phi. \]
%
This can be proved by showing this integral formula has the same recurrence relation as that which defines $\{ P_j \}$ (TODO: See page 59 of Jackson).

In particular, this tells us that the leading coefficient $A_j$ of $P_j$ satisfies the recurrence
%
\[ A_{j+1} = \frac{2j+1}{j + 1} A_j. \]
%
Thus
%
\[ A_j = \frac{1 \cdot 3 \cdot \dots \cdots (2j - 1)}{j!} = \frac{1}{2^{j-1}} \frac{(2j-1)!}{j! (j-1)!}. \]
%
We thus conclude using Stirling's formula that $A_j = 2^{j + O(\log j)}$, and so the leading coefficient grows exponentially in $j$. On the other hand, if $B_j$ denotes the constant term of $P_{2j}$ (the constant term is zero for odd index Legendre polynomials), then we find that
%
\[ (j+1) B_j + j B_{j-1} = 0, \]
%
and $B_0 = 1$. Thus we find that $B_j = (-1)^j / (j+1)$, which is rather small. In fact, overall the Legendre polynomials satisfy rather good bounds.

\begin{theorem}
    We have
    %
    \[ |P_j(x)| \lesssim \frac{1}{j^{1/2} (1 - x^2)^{1/2}}. \]
    %
    In particular, we also have $\| P_j \|_{L^\infty[-1,1]} \lesssim j^{-1/2}$.
\end{theorem}

To study the convergence of the Legendre series, it is natural to introduce the partial summation operators
%
\[ S_N f = \sum_{j = 0}^N c_j P_j. \]
%
We can write
%
\[ S_N f(x) = \int_{-1}^1 K_N(x,y) f(y)\; dy, \]
%
where
%
\[ K_N(x,y) = \sum_{j = 0}^N (j + 1/2) P_j(x) P_j(y). \]
%
In 1858, Elwin Bruno Christoffel found an expression for this operator in a more simple manner, known as \emph{Christoffel's Identity}.

\begin{theorem}
    We have
    %
    \[ K_N(x,y) = \frac{N+1}{2} \frac{P_{N+1}(x) P_N(y) - P_N(x) P_{N+1}(y)}{y - x}. \]
\end{theorem}
\begin{proof}
    TODO: See Page 55 of Jackson, Orthogonal Polynomials.
\end{proof}

Since $S_N 1 = 1$, we conclude that for all $x \in [-1,1]$,
%
\[ 1 = \int K_N(x,y)\; dy. \]
%
We thus have
%
\[ |S_N f(x) - f(x)| = \left| \frac{N+1}{2} \int_{-1}^1 \frac{f(y) - f(x)}{y - x} [ P_{N+1}(x) P_N(y) - P_N(x) P_{N+1}(y) ]\; dy \right|. \]
%
Taking in absolute values gives that
%
\[ |S_N f(x) - f(x)| \lesssim \int_{-1}^1 \frac{f(y) - f(x)}{y - x}\; dy. \]
%
In particular, if $f$ is differentiable at $x$, then $S_N f(x)$ converges to $f(x)$ as $N \to \infty$, or more generally, a left and right hand derivative at $x$.







\section{Bessel Functions}

s








\chapter{Tauberian Theorems}

In many situations in Fourier analysis, one studies a sum $\sum a_n$, to which we associate, via some nonstandard summation method, like that of Cesaro or Abel, a finite quantity $a$. One often would like conditions that ensure the sum $\sum a_n$ actually converges to this quantity in the classical sense. The first result of this kind was due to Austrian mathematician Alfred Tauber, in 1897, who showed that an Abel summable series with $a_n = o(n^{-1})$ was classically convergent. Hardy and Littlewood showed that it was actually sufficient to assume that $a_n = O(n^{-1})$, and began a series of generalizations, beginning the study of the general theory of these problems, called \emph{Tauberian Theory}. We begin with Tauber's basic result, which follows from a simple calculation.

\begin{theorem}
    If $\sum_{n = 0}^\infty a_n$ is Abel summable and $a_n = o(n^{-1})$, then $\sum a_n$ converges.
\end{theorem}
\begin{proof}
    Set
    %
    \[ f(z) = \sum_{n = 0}^\infty a_n z^n. \]
    %
    Set $S_N = \sum_{n = 0}^N a_n$. Then
    %
    \begin{align*}
        \left| S_N - f(x) \right| &= \left| \sum_{n = 1}^N a_n (1 - x^n) - \sum_{n = N+1}^\infty a_n x^n \right|\\
        &\leq \sum_{n = 1}^N n (1 - x) |a_n| + \frac{1}{N} \sum_{n = N+1}^\infty |na_n| |x|^n\\
        &\leq (1 - x) \sum_{n = 1}^N n |a_n| + \frac{1}{N (1 - x)} \sup_{n > N} |na_n|.
    \end{align*}
    %
    Thus we conclude that
    %
    \[ \left| S_N - f(1 - 1/N) \right| \leq N^{-1} \sum_{n = 1}^N n |a_n| + \sup_{n > N} |na_n|. \]
    %
    The second term on the right converges to zero as $N \to \infty$. The first also converges to zero, as an average of a sequence converging to zero. But this means that $S_N - f(1 - 1/N)$ converges to zero, and thus $S_N$ converges to the Abel mean of the sequence.
\end{proof}

\begin{remark}
    A similar identity shows that if $a_n = O(n^{-1})$, and if the function $f(x) = \sum_{n = 1}^\infty a_n x^n$ is bounded on $[0,1)$, then the partial sums $S_N$ are uniformly bounded.
\end{remark}

Hardy noticed that this a fortiori implied that a sequence which is \emph{Cesaro summable} and $o(n^{-1})$ is summable. In 1910, he published a Tauberian result for Cesaro summability assuming only the sum was $O(n^{-1})$. That same year, Landau extended the proof to a `one-sided bound'.

\begin{theorem}
    Let $\{ a_n \}$ be a sequence. If the sequence is Cesaro summable, and there exists $C > 0$ such that $a_n \geq - C / n$ for all $n > 0$, then $\sum a_n$ converges.
\end{theorem}
\begin{proof}
    We consider a proof method due to Kloosterman, published in 1940. Assume without loss of generality that the sequence is real, and is Cesaro summable to zero. We note that
    %
    \begin{align*}
        (n + m) \sigma_{n + m} &= s_1 + \dots + s_{n+m}\\
        &= n \sigma_n + m s_n + (m a_{n+1} + (m-1) a_{n+2} + \dots + a_{n+m}).
    \end{align*}
    %
    We have
    %
    \[ \frac{m(m+1)}{2} \min_{k \in (n,n+m]} a_k \leq (m a_{n+1} + (m-1) a_{n+2} + \dots + a_{n+m}) \leq \frac{m(m+1)}{2} \max_{k \in (n,n+m]} a_k, \]
    %
    and so there exists a quantity $\delta_{n,m}$ lying between $\min_{k \in (n,n+m]} a_k$ and $\max_{k \in (n,n+m]} a_k$ for which
    %
    \[ (n + m) \sigma_{n + m} = n \sigma_n + m s_n + \frac{m(m+1)}{2} \delta_{n,m}. \]
    %
    Under the assumption that $\{ a_n \}$ is Cesaro summable to zero, we have $\sigma_n \to 0$ as $n \to \infty$. We now use the identity above to extract the convergence of $\{ s_n \}$, i.e. since we have
    %
    \[ s_n = \frac{(n+m) \sigma_{n+m} - n \sigma_n}{m} - \frac{m+1}{2} \delta_{n,m}. \]
    %
    Under the assumption that $a_n \geq - C / n$, we have $\delta_{n,m} \geq - C / n$. For any $\varepsilon > 0$, if $n$ is suitably large, we also have $|\sigma_{n+m}| + |\sigma_n| \leq \varepsilon$, and so
    %
    \[ s_n \leq (2n/m + 1) \varepsilon + C \frac{m+1}{2n}. \]
    %
    Provided $m < n$, we have
    %
    \[ s_n \lesssim (n/m) \varepsilon + (m / n). \]
    % n^2 varepsilon = m^2
    Thus optimizing for $m$, i.e. by picking $m = n \varepsilon^{1/2} + O(1)$, we conclude that
    %
    \[ s_n \lesssim \varepsilon^{1/2}. \]
    %
    On the other hand, we have
    %
    \begin{align*}
        (n - m) \sigma_{n - m} &= s_1 + \dots + s_{n-m}\\
        &= n \sigma_n - (s_{n-m+1} + \dots + s_n)\\
        &= n \sigma_n - m s_n + ( (m-1) a_n + (m-2) a_{n-1} + \dots + a_{n - m + 2} ).
    \end{align*}
    %
    We can find $\delta'_{n,m}$ such that
    %
    \[ (n - m) \sigma_{n - m} = n \sigma_n - m s_n + \frac{(m-1)m}{2} \delta'_{n,m}, \]
    %
    where $\delta'_{n,m}$ lies between $\min_{k \in (n-m+1,n]} a_k$ and $\max_{k \in (n-m+1,n]} a_k$. Thus we conclude that
    %
    \[ s_n = \frac{n \sigma_n - (n-m) \sigma_{n-m}}{m} + \frac{(m-1)m}{2} \delta_{n,m}. \]
    %
    But for any $\varepsilon > 0$, if $n$ is chosen sufficiently large so that $|\sigma_n| + |\sigma_{n-m}| \leq \varepsilon$, we conclude that
    %
    \[ s_n \geq - 2(n/m) \varepsilon - C \frac{m-1}{2n}. \]
    %
    Again, picking $m = n \varepsilon^{1/2} + O(1)$, we conclude that there is a constant $C'$ such that
    %
    \[ s_n \geq -C \varepsilon^{1/2}. \]
    %
    Putting the two bounds above together, we conclude $|s_n| \lesssim \varepsilon^{1/2}$, and we can now take $\varepsilon \to 0$ to obtain the required result.
\end{proof}

Several results on the convergence of Fourier series follow from this argument:
%
\begin{itemize}
    \item If $f$ is a continuous, periodic function on the real line, and $|\widehat{f}(n)| \lesssim |n|^{-1}$, then the Fourier series of $f$ converges pointwise everywhere to $f$. Indeed, under these assumptions, the result above implies Cesaro summation implies normal summation.

    \item We obtain a new proof of Dini's Theorem: If $f$ has bounded variation, then the Fourier series of $f$ converges everywhere to $(1/2) [f(t-) + f(t+)]$.
\end{itemize}
%
We also note a slight weakening of the assumptions. Namely, the result would follow under the weaker assumption that the quantities
%
\[ w( \rho ) = \liminf_{n \to \infty} \inf_{n \leq m \leq \rho n} |s_m - s_n| \]
%
converge to zero as $\rho \searrow 0$. A sequence $\{ s_n \}$ satisfying these assumptions is called a \emph{slowly varying sequence}.

Hardy asked whether an analogous result held for Abel summation. Littlewood showed in 1911 that such a result was true. His original proof, using repeated differentiation, is quite difficult, and over the past century, many different proof techniques have been devised to demonstratet the result.

TODO: Read more of Korevaar's Book.



















