%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Calderon-Zygmund Theory}

Here, we try and describe the more modern approaches to real-variable harmonic analysis, as developed by the \emph{Calderon-Zygmund school} in the 1960s and 1970s. Almost all of the problems we consider can be phrased as showing some operator is bounded as a map between functions spaces. Given some function $f$ lying in a space $V$, we have an associated function $Tf$ lying in some space $W$. The main goal of the techniques in this part of the book attempt to understand how quantitative control on certain properties of $f$ imply quantitative control on properties of $Tf$. In particular, given some quantity $A(f)$ associated with each $f \in V$, and a quantity $B(g)$ defined for all $g \in W$, our goal is to understand whether a general bound $B(Tf) \lesssim A(f)$ is possible for all functions $f \in V$, i.e. whether these exists a universal constant $C > 0$ such that $B(Tf) \leq C \cdot A(f)$ for all $f \in V$.

A core technique we employ here is the method of \emph{decomposition}. We write $f = \sum_k f_k$, where the functions $f_k$ have particular properties, perhaps being concentrated in a particular region of space, or having a Fourier transform concentrated in a particular region. These concentration properties often simplify the analysis of the operator $T$, enabling us to obtain bounds $B(Tf_k) \lesssim A(f_k)$ for each $n$. Provided that the operator $T$, and the quantities $A$ and $B$ are `stable under addition', we can then obtain the bound $B(Tf) \leq A(f)$ by `summing' up the related quantities. The stability of $A$ and $B$ is often obtained by assuming these quantities are \emph{norms} on their respective function spaces, i.e. that there exists norms $\| \cdot \|_V$ and $\| \cdot \|_W$ such that $A(f) = \| f \|_V$ for each $f \in V$ and $B(g) = \| g \|_W$ for each $g \in W$. The stability of $T$ under addition is obtained by assuming linearity, or at least sub-linearity, in the sense that for each $f_1, f_2 \in V$,
%
\[ \| T(f_1 + f_2) \|_W \leq \| T f_1 \|_W + \| Tf_2 \|_W. \]
%
We can then use the triangle inequality to conclude that
%
\[ \| Tf \|_W \leq \sum_k \| Tf_k \|_W \lesssim \sum_k \| f_k \|_V. \]
%
Thus if $\sum_k \| f_k \|_V \lesssim \| f \|_V$, our argument is complete. This will be true, for instance, if there exists $\varepsilon > 0$ such that $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$. This can often be obtained if we employ one of a family of \emph{dyadic decomposition techniques}. For such decompositions, it is also possible to generalize our techniques not only to norms, but also to \emph{quasinorms}, i.e. maps $\| \cdot \|$ which are homogeneous and satisfy a \emph{quasi-triangle inequality} $\| v + w \| \lesssim \| v \| + \| w \|$.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasi-norm on a vector space $V$, and under the topology induced by $\| \cdot \|_V$, we can write $f = \sum_{k = 1}^\infty f_k$, where there is $\varepsilon > 0$ and $C > 0$ such that for each $n$, $\| f_k \|_V \leq C \cdot 2^{-\varepsilon k}$. Then $\| f \|_V \lesssim_\varepsilon C$.
\end{lemma}

\begin{remark}
	Thus if $T$ is sublinear and we have $\| Tf_k \|_W \lesssim \| f_k \|_V$ and $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$, we conclude $\| Tf_k \|_W \lesssim 2^{-\varepsilon k} \| f \|_V$, and then by sublinearity and the lemma applied to $\| \cdot \|_W$, we conclude
	%
	\[ \| Tf \|_W \leq \| \sum_k Tf_k \|_W \lesssim_\varepsilon \| f \|_V. \]
	%
	A slight modification of the proof below even gives this claim provided $T$ is \emph{quasi sublinear}, in the sense that for all $f_1, f_2 \in V$, $\| T(f_1 + f_2) \|_W \lesssim \| Tf_1 \|_V + \| Tf_2 \|_V$ for all $f_1, f_2 \in V$. However, such operators occur so rarely in practice that it isn't worth concentrating on them.
\end{remark}

\begin{proof}
	Pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A \cdot (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1$ and $f_2$. If $A < 2^{\varepsilon}$, we can write apply the quasitriangle inequality iteratively to conclude
    %
    \begin{align*}
        \| f \| &\leq C \cdot \sum_{k = 1}^\infty A^k \| f_k \|_V \leq C \cdot \left( \sum_{k = 1}^\infty (A 2^{-\varepsilon})^k \right) \leq C \cdot \left( \frac{1}{1 - A 2^{-\varepsilon}} \right) \lesssim_\varepsilon C.
    \end{align*}
    %
    In general, fix $N$, and write $f = f^1 + \dots + f^N$, where $f^m = \sum_{k = 0}^\infty f_{m + Nk}$. Then $\| f_{m + Nk} \|_V \leq C \cdot 2^{- N \varepsilon k}$, and if $N$ is chosen large enough that $A < 2^{N \varepsilon}$, we can apply the previous case to conclude that $\| f^m \|_V \lesssim_\varepsilon C$. Then we can apply the quasi-triangle inequality to conclude that $\| f \| \lesssim_\varepsilon C$.
\end{proof}

We can even apply the method of decomposition in the presence of suitably large polynomial decay.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasinorm on a function space $V$. Then there exists $t$ such that for all $s > t$, if $f = \sum_{k = 1}^\infty f_k$, and if $\| f_k \|_V \leq C \cdot k^{-s}$, for $s > t$, then $\| f \|_V \lesssim_s C$.
\end{lemma}
\begin{proof}
    As in the previous lemma, pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1,f_2 \in V$. We perform a decomposition of dyadic type, writing $f = \sum_{m = 0}^\infty f^m$, where
    %
    \[ f^m = \sum_{k = 2^m}^{2^{m+1} - 1} f_k. \]
    %
    By applying the divide and conquer approach, splitting up the indices $2^m \leq k \leq 2^{m+1} - 1$ via a binary tree with depth at most $O(m)$, we can ensure that
    %
    \[ \| f^m \|_V \lesssim A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} \| f_k \|_V \leq C \cdot A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} k^{-s} \lesssim C (A 2^{1-s})^m. \]
    %
    If $s > 1 + \lg(A)$, the previous lemma implies that $\| f \|_V \lesssim C$.
\end{proof}

In this part of the notes, we define the various classes of quasi-norms we will study, describe the general methods which make up the Calderon-Zygmund theory, and find applications to geometric measure theory, complex analysis, partial differential equations, and analytic number theory.





\chapter{Monotone Rearrangement Invariant Norms}

In this chapter, we discuss common families of \emph{monotone, rearrangement invariant quasinorms} that occur in harmonic analysis. The general framework is as follows. For each function $f$, we associate it's \emph{distribution function} $F: [0,\infty) \to [0,\infty]$ given by $F(t) = |\{ x : |f(x)| > t \}|$. A \emph{rearrangement invariant space} is a subspace $V$ of the collection of measurable complex-valued functions on some measure space $X$, equipped with a quasi-norm $\| \cdot \|$, satisfying the following two properties:
%
\begin{itemize}
    \item \emph{Monotonicity}: If $|f(x)| \leq |g(x)|$ for all $x \in X$, then $\| f \| \leq \| g \|$.

    \item \emph{Rearrangement-Invariance}: If $f$ and $g$ have the same distribution function, then $\| f \| = \| g \|$.
\end{itemize}
%
A monotone rearrangement-invariant norm essentially provides a way of quantifying the height and width of functions on $X$. It has no interest in the `shape' of the objects studied, because of the property of rearrangement invariance. In a particular problem, one picks the norm best emphasizing a particular family of features useful in the problem. Height and width are of course, vague properties; but roughly speaking, the canonical example of a function with height $H$ and width $W$ is a function $f = H \cdot \mathbf{I}_E$, where $|E| = W$. More general functions can be thought of as being composed from a combination of  functions with various heights and widths, and since a unique way to quantify the behaviour of these combinations is not obvious, we will obtain various different ways to quantify how various heights and widths come together.

There are two very useful classes of functions useful for testing the behaviour of translation invariant norms:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
The class of all simple functions forms a vector space, and for almost all the monotone rearrangement invariant norm we consider in this section, this vector space will form a dense subspace of the class of all functions. This means that when we want to study how an operator transforms the height and width of functions, the behaviour of the operator on simple functions often reflects the behaviour of an arbitrary function.

\section{The $L^p$ norms}

We begin by introducing the most fundamental monotone, rearrangement invariant norms. For $p \in (0,\infty)$, we define the $L^p$ norm of a measurable function $f$ on a measure space $X$ by
%
\[ \| f \|_{L^p(X)} = \left( \int_X |f(x)|^p\; dx \right)^{1/p}. \]
%
For $p = \infty$, we define
%
\[ \| f \|_{L^\infty(X)} = \min \left\{ t \geq 0: |f(x)| \leq t\ \text{almost surely} \right\}, \]
%
a quantity often called the \emph{essential} supremum. If the measure space $X$ is implicit, these quantities are also denoted by $\| f \|_p$, as we do often in this chapter. The space of functions $f$ with $\| f \|_p < \infty$ is denoted by $L^p(X)$. The most important spaces to consider here are the space $L^1(X)$, consisting of absolutely square integrable functions, $L^\infty(X)$, consisting of almost-everywhere bounded functions, and $L^2(X)$, consisting of square integrable functions. The main motivation for the introduction of the other $L^p$ spaces is that much of the quantitative theory in harmonic analysis for $p = 1$ and $p = \infty$ is rather trivial, in the sense that for most operators that occur in practice, it is simple to determine whether these operators are bounded on these spaces; obtaining $L^p$ bounds of an operator for $1 < p < \infty$ reflects a deeper understanding of the quantitative properties of an operator.

As $p$ increases, the $L^p$ norm of a particular function $f$ gives more control over the height of the function $f$, and weaker control on values where $f$ is particular small. At one extreme, $L^\infty(X)$ only has control over the height of a function, and no control over it's width. Conversely, as $p \to 0$, $L^p(X)$ has more control over the width of functions. It is therefore natural to introduce the space $L^0(X)$ as the space of measurable functions with finite measure support. But there is no natural norm on $L^0(X)$ which can classify the support of functions. After all, such a quantity couldn't be homogeneous, since the width of $f$ and $\alpha f$ are the same for each $\alpha \neq 0$.

\begin{example}
  If $f(x) = |x|^{-s}$ for $x \in \RR^d$ and $s > 0$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M r^{d-1 - ps}\; dr = \frac{M^{d - p s} - \varepsilon^{d - p s}}{d - p s}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p s$, and finite as we let $M \to \infty$ if and only if $d < p s$. Thus if $p < d/s$, $f$ is \emph{locally} in $L^p$, in the sense that $f \in L^p(B)$ for every bounded $B \in \RR^d$. The class of functions for which this condition holds is denoted $L^p_{\text{loc}}(X)$. Conversely, if $p > d/s$, then for every closed set $B$ not containing the origin, $f \in L^p(B)$. For $p = d/s$, the function $f$ fails to be $L^p(\RR^d)$, but only `by a logarithm', which manifests in the fact that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M \frac{dr}{r} = \log(M/\varepsilon). \]
  %
  We will later introduce Lorentz norms $L^{p,q}$, which one can think of as differing from the standard $L^p$ norms `by a logarithmic factor', and the $L^{p,q}$ norm of $f$ will be finite if $q$ is chosen appropriately.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of sharp singularities, and control of an $L^p$ norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $s = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| s \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| s \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| s \|_p = H$. If $s = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| s \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| s \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, $\lim_{p \to 0} \| f \|_p$ does not in general exist, even for step functions with finite measure support. Nonetheless, we can conclude that $\lim_{p \to 0} \| s \|_p^p = \sum |E_n|$.
\end{example}

As $p \to \infty$, the last example shows the width of a function is disregarded completely by the $L^p$ norm, from which it follows that $\| s \|_{L^p(X)} \to \| s \|_{L^\infty(X)}$ as $p \to \infty$. The same is true for more general functions, which we can prove using a density argument.

\begin{theorem}
    Let $p \in (0,\infty)$. If $f \in L^p(X) \cap L^\infty(X)$, then
    %
    \[ \lim_{t \to \infty} \| f \|_t = \| f \|_\infty. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $p \geq 1$. Consider the norm $\| \cdot \|$ on $L^p(X) \cap L^\infty(X)$ given by
    %
    \[ \| f \| = \| f \|_p + \| f \|_\infty. \]
    %
    Then $L^p(X) \cap L^\infty(X)$ is complete with respect to this metric. For each $t \in [p,\infty)$, define $T_t(f) = \| f \|_t$. Then the functions $\{ T_t \}$ are uniformly bounded in the norm $\| \cdot \|$, since if $p = \theta t$, then
    %
    \[ |T_t(f)| = \| f \|_t \leq \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \| f \|^\theta \| f \|^{1-\theta} = \| f \|. \]
    %
    For any $\varepsilon > 0$, we can find a step function $s$ with $\| s - f \|_p, \| s - f \|_\infty \leq \varepsilon$. This means that for all $t \in (p,\infty)$,$\| s - f \|_t \leq \varepsilon$. And so
    %
    \begin{align*}
        \Big| T_t(f) - \| f \|_\infty \Big| &\leq |T_t(f) - T_t(s)| + |T_t(s) - \| s \|_\infty| + |\| s \|_\infty - \| f \|_\infty| \leq 2\varepsilon + o(1).
    \end{align*}
    %
    Taking $\varepsilon \to 0$ gives the result.
\end{proof}

Abusing notation, we define $\| f \|_0^0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, and let $L^0(X)$ be the space of functions with finite support. We know that for any simple function $s$, $\| s \|_p^p \to \| s \|_0^0$ as $p \to 0$. If $f \in L^0(X) \cap L^p(X)$ for some $p \in (0,\infty)$, then the monotone and dominated convergence theorems implies that
%
\[ \| f \|_0^0 = \int \mathbf{I}(f(x) \neq 0) = \int \left( \lim_{t \to 0} |f(x)|^t \right)\; dx = \lim_{t \to 0} \int |f(x)|^t\; dx = \lim_{t \to 0} \| f \|_t^t. \]
%
Thus the space $L^0(X)$ lies at the opposite end of the spectrum to $L^\infty$.

The fact that $\| f \|_0^0$ is a norm taken to the `power of zero' implies that many nice norm properties of the $L^p$ spaces fail to hold for $L^0(X)$. For instance, homogeneity no longer holds; in fact, for each $\alpha \neq 0$,
%
\[ \| \alpha f \|_0^0 = \| f \|_0^0. \]
%
It does, however, satisfy the triangle inequality $\| f + g \|_0^0 \leq \| f \|_0^0 + \| g \|_0^0$, which follows from a union bound on the supports of the functions.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\RR} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $X^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p^\theta \| f^{\otimes n} \|_q^{1-\theta} \right)^{1/n} = 2^{1/n} \| f \|_p^\theta \| g \|_q^{1-\theta}. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p^\theta \| f \|_q^{1-\theta}$, a special case of \emph{H\"{o}lder's Inequality}.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. This often introduces some extraneous (though not too inefficient) constants. But if these constants are unnecessary, one can often apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$,
  %
  \[ \| f g \|_r \leq \| f \|_p \| g \|_q. \]
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary} \label{lptriangleinequality}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

If $p < 1$, then the proof of Corollary \ref{lptriangleinequality} no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
%
\[ \| f + g \|_p \geq \| f \|_p + \| g \|_p, \]
%
as proved in the next theorem.

\begin{theorem}
    If $p \geq 1$, then for any functions $f_1, \dots, f_N \geq 0$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \eqref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. However, for $p < 1$, we do have a \emph{quasi} triangle inequality.

\begin{theorem} \label{quasitriangleinequalitylp}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \qedhere \]
\end{proof}

This result is sharp, i.e. if we take a disjoint family of sets $\{ E_1, E_2, \dots \}$ with $|E_i| = 1$ for each $i$, and then set $f_i = \mathbf{I}_{E_i}$, then the inequality is sharp for each $N$.

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^q(X) \subset L^p(X)$, because H\"{o}lder's inequality implies
  %
  \[ \| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}. \]
  %
  Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \ZZ$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %

%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\ZZ/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$-granular.

  One can also often obtain analogous results when dealing with functions which are roughly constant at a scale $\varepsilon$, rather than literally constant at this scale. Basic examples of this include Bernstein's inequality; the Sobolev embeddings are also of this flavor. But this is a topic for another section.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the right hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

\begin{remark}
  This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.
\end{remark}

The last property of the $L^p$ norms we want to focus on is the principle of \emph{duality}. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $f \in L^p(X)$ and $g \in L^q(X)$, then $fg \in L^1(X)$. In particular, for each function $g \in L^q(X)$, the map
%
\[ \lambda: f \mapsto \int f(x)g(x)\; dx \]
%
is a linear functional on $L^p(X)$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}. In particular, if $1 < p < \infty$, one can show these are \emph{all} linear functionals. For $p \in \{ 1, \infty \}$, the dual space of $L^p(X)$ is more subtle. But, since in harmonic analysis we concentrate on quantitative bounds, the following theorem often suffices as a replacement.

\begin{theorem}
    If $1 \leq p < \infty$, and $f \in L^p(X)$, then
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 \leq p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$. Each $s_k$ lies in $L^p(X)$, but the monotone convergence theorem implies that $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \cdot \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    this completes the proof in this case.

    Now we take the case $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Decreasing Rearrangements}

 The measure-theoretic properties of a function's distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

In particular, when understanding intuition about monotone rearrangement invariant norms, one is allowed to focus on non-increasing, right continuous functions on $(0,\infty)$. For instance, this means that these norms do not care about the number of singularities that a function has, since all these singularities `pile up' in the decreasing rearrangement. The `mass' of these singularities, of course, is important.

\section{Weak Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
For this to be true, $F(t)$ must tend to zero `logarithmically faster' than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But a bound $F(t) \lesssim 1/t^p$ might be true even if $f \not \in L^p(\RR^d)$. This leads to the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is defined to be the smallest value $A$ such that $F(t) \leq (A/t)^p$ for all $t$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $\| f \|_{p,\infty} \leq \| f \|_p$ for any function $f$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. This can be proven quite simply from the property that if $f = f_1 + \dots + f_N$, and $\alpha_1, \dots, \alpha_N \in [0,1]$ satisfy $\alpha_1 + \dots + \alpha_N = 1$, then
%
\[ F(t) = F_1(\alpha_1 t) + \dots + F_N(\alpha_N t). \]
%
Thus if $f = g + h$, then
%
\[ F(t) \leq G(t/2) + H(t/2) \leq \frac{\| g \|_{p,\infty}^p + \| h \|_{p,\infty}^p}{t^p} \lesssim_p \left( \frac{\| g \|_{p,\infty} + \| h \|_{p,\infty}}{t} \right)^p. \]
%
Thus $\| f + g \|_{p,\infty} \lesssim \| f \|_{p,\infty} + \| g \|_{p,\infty}$. We can measure the degree to which the weak $L^p$ norm fails to be a norm by determining how much the triangle inequality fails for the sum of $N$ functions, instead of just one function.

\begin{theorem}[Stein-Weiss Inequality]
  Let $f_1, \dots, f_N$ be functions. If $p > 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}. \]
  %
  If $p = 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{1,\infty} \lesssim \log N \left[ \| f_1 \|_{1,\infty} + \dots + \| f_N \|_{1,\infty} \right]. \]
  %
  If $0 < p < 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \left( \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^{1/p} \right)^{1/p} \]
\end{theorem}
\begin{proof}
    Begin with the case $p \geq 1$. Without loss of generality, assume $\| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} = 1$. Fix $t > 0$. For each $k \in [1,N]$, define
    %
    \[ g_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \geq t/2, \\ 0 &: \text{otherwise}, \end{cases} \]
    %
    and
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty} \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Also define $j_k = f_k - g_k - h_k$. Then write $f = f_1 + \dots + f_N$, $g = g_1 + \dots + g_N$, $h = h_1 + \dots + h_N$, and $j = j_1 + \dots + j_N$. Note that $\| h \|_\infty \leq t/2$, so
    %
    \[ \{ x : |f(x)| \geq t \} \subset \{ x : |g(x)| \geq t/4 \} \cup \{ x : |j(x)| \geq t/4 \}. \]
    %
    Each $g_k$ is supported on a set of measure at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$. We conclude that $g$ is supported on a set of measure at most
    %
    \[ (2/t)^p \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \leq (2/t)^p. \]
    %
    If $p > 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
        \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int |j_k(x)|\\
        &= \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{p,\infty}^p}{s^p}\; ds\\
        &= \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| j_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1}} - 1 \right) \\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1 }} - 1 \right)\\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p}.
    \end{align*}
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ \frac{2^p}{t^p} + \frac{2^{p+1}}{p - 1} \frac{1}{t^p} \lesssim_p \frac{1}{t^p}. \]
    %
    If $p = 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded
    %
    \begin{align*}
        (4/t) \int |j(x)|\; dx &\leq (4/t) \sum_{k = 1}^N \int |j_k(x)|\\
        &= (4/t) \sum_{k = 1}^N \int_{\| f_k \|_{1,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{1,\infty}}{s}\; ds\\
        &= (4/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}).
    \end{align*}
    %
    Now the maximum of $x_1 \log(1/x_1) + \dots + x_N \log(1/x_N)$, subject to the constraint that $x_1 + \dots + x_N = 1$, is maximized by taking $x_k = 1/N$ for all $N$, which gives a maximal bound of $\log(N)$. In particular, we find that
    %
    \[ (2/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}) \leq (2 \log N)/t. \]
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ 2(1 + \log N)/t \lesssim \log N / t. \]
    %
    If $p < 1$, we may assume without loss of generality that
    %
    \[ \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^p = 1. \]
    %
    Then, we perform the same decomposition as before, with functions $\{ g_k \}$, $\{ h_k \}$, and $\{ j_k \}$, defined the same as before, except that
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty}^p \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    The function $g_k$ has support at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$, and thus $g$ has total support
    %
    \[ \sum \| f_k \|_{p,\infty}^p (2/t)^p = (2/t)^p. \]
    %
    The measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
      \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty}^p (t/2)}^{t/2} \frac{\| f_k \|_{p,\infty}^p}{s^p}\; ds\\
      &\leq \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^{p + p(1-p)}\\
      &= \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \max \| f_k \|_{p,\infty}^{p(1-p)} \lesssim_p \frac{1}{t^p},
    \end{align*}
    %
    Combining the two bounds gives that $\| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p 1$.
\end{proof}

\begin{remark}
  For $p = 1$, compare this \emph{logarithmic} failure to be a norm with the \emph{polynomial} failure to be a norm found in the norms $\| \cdot \|_p$, when $p < 1$, in Theorem \ref{quasitriangleinequalitylp}.
\end{remark}

For $p = 1$, the Stein-Weiss inequality is asymptotically tight in $N$.

\begin{example}
  Let $X = \RR$. For each $k$, let
  %
  \[ f_k(x) = \frac{1}{|x - k|}. \]
  %
  Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independantly of $k$. If $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
  %
  \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N). \]
  %
  Thus $\| f \|_{1,\infty} \gtrsim N \log N \gtrsim \log N \sum \| f_k \|_{1,\infty}$.
\end{example}

The weak $L^p$ norms provide another monotone translation invariant norm, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^s$ does not lie in any $L^p(\RR^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/s$, since
    %
    \[ \left| \{ 1/|x|^{ps} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/ps}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/ps}}. \]
\end{example}

Before we move on, we consider a form of duality for the weak $L^p$ norm, at least when $p > 1$.

\begin{theorem}
	If $p > 1$, and $X$ is $\sigma$-finite, then
	%
	\[ \| f \|_{p,\infty} \sim_p \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx \]
\end{theorem}
\begin{proof}
	Suppose $\| f \|_{p,\infty} < \infty$. If we write $f = \sum f_k$, where $f_k = \mathbf{I}_{F_k} f$, and $F_k = \{ x: 2^{k-1} < |f(x)| \leq 2^k \}$, then $|F_k| \leq \| f \|_{p,\infty}^p 2^{-kp}$. Thus
	%
	\[ \left| \int_E |f_k(x)| \right| \leq 2^k \| f \|_{p,\infty}^p 2^{-kp} = \| f \|_{p,\infty}^p 2^{k(1-p)}. \]
	%
	Fix some integer $n$. Then
	%
	\begin{align*}
		\int_E |f(x)|\; dx &\leq \sum_{k = -\infty}^{n-1} \int_E |f_k(x)|\; dx + \sum_{k = n}^\infty \int_E |f_k(x)|\; dx\\
		&\leq |E| 2^{n-1} + \| f \|_{p,\infty}^p \sum_{k = n}^\infty 2^{k(1-p)}\\
		&\lesssim_p |E| 2^n + \| f \|_{p,\infty}^p 2^{-k(1-p)}.
	\end{align*}
	%
	If we let $2^n \sim \| f \|_{p,\infty} |E|^{1/p}$, then we conclude
	%
	\[ \int_E |f(x)|\; dx \lesssim_p |E|^{1 - 1/p} \| f \|_{p,\infty}. \]
	%
	Conversely, write
	%
	\[ A = \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx/ \]

	%
	If $G_t = \{ x: |f(x)| \geq t \}$, then
	%
	\[ |G_t| \leq \frac{1}{t} \int_{G_t} |f(x)|\; dx \leq \frac{A |G_t|^{1 - 1/p}}{t}, \]
	%
	so
	%
	\[ |G_t| \leq \frac{A^p}{t}, \]
	%
	which gives $\| f \|_{p,\infty} \leq A$.
\end{proof}

For $p \leq 1$, the spaces $L^{p,\infty}(X)$ are not normable, as seen by the tightness of the Stein-Weiss inequality. Nonetheless, we still have a certain `duality' property, that is often useful in the analysis of operators on these spaces. Most useful is it's application when $p = 1$.

\begin{theorem} \label{weakdualitytheorem}
  Let $0 < p < \infty$, and let $f \in L^{p,\infty}(X)$, and let $\alpha \in (0,1)$. Then the following are equivalent:
  %
  \begin{itemize}
    \item $\| f \|_{p,\infty} \lesssim_{\alpha,p} A$.

    \item For any set $E \subset X$ with finite measure, there is $E' \subset E$ with $|E'| \geq \alpha |E|$ such that
    %
    \[ \int_{E'} |f(x)|\; dx \lesssim_{\alpha,p} A |E'|^{1 - 1/p}. \]
  \end{itemize}
\end{theorem}
\begin{proof}
  By homogeneity, assume $\| f \|_{p,\infty} \leq 1$, so that if $F$ is the distribution of $f$, $F(t) \leq 1/t^p$. If $|E| = (1-\alpha)^{-1} / t_0^p$, and we set
  %
  \[ E' = \{ x: |f(x)| \leq t_0 \}, \]
  %
  then
  %
  \[ |E'| \geq |E| - F(t_0) = \frac{(1 - \alpha)^{-1} - 1}{t_0^p} = \alpha |E|, \]
  %
  and
  %
  \[ \int_{E'} |f(x)| \leq t_0 |E'| \lesssim_\alpha |E'|^{1-1/p}. \]
  %
  Conversely, suppose Property (2) holds. For each $k$, set
  %
  \[ E_k = \{ x: 2^k \leq |f(x)| < 2^{k+1} \}. \]
  %
  Then there exists $E_k'$ with $|E_k'| \geq \alpha |E_k|$ and
  %
  \[ \int_{E_k'} |f(x)|\; dx \leq |E_k'|^{1 - 1/p} \]
  %
  On the other hand,
  %
  \[ \int_{E_k'} |f(x)|\; dx \geq 2^k |E_k'|. \]
  %
  Rearranging this equation gives $|E_k'| \leq 2^{-pk}$, and so $|E_k| \lesssim_\alpha 2^{-pk}$. But this means
  %
  \[ F(2^N) = \sum_{k = N}^\infty |E_k| \lesssim_{\alpha,p} 2^{-Np}, \]
  %
  and this implies $\| f \|_{p,\infty} \lesssim_{\alpha,p} 1$.
\end{proof}

\section{Lorentz Spaces}

Recall that we can write
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus $F(t) t^p$ is integrable with respect to the Haar measure on $\RR^+$. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\RR^+)$ for some $0 < q \leq \infty$, we obtain a different integrability condition, giving rise to a monotone, translation-invariant norm. Thus leads us to the definition of the \emph{Lorentz norms}. For each $0 < p,q < \infty$, we define the Lorentz norm
%
\[ \| f \|_{p,q} = p^{1/q} \| t F^{1/p} \|_{L^q(\RR^+)} \]
%
The \emph{Lorentz space} $L^{p,q}(X)$ as the space of functions $f$ with $\| f \|_{p,q} < \infty$. We can define the norm in terms of $f^*$ as well.

\begin{lemma}
  For any measurable $f: X \to \RR$, $\| f(t) \|_{p,q} = \| s^{1/p} f^*(s) \|_{L^q(\RR^+)}$.
\end{lemma}
\begin{proof}
  First, assume $f^*$ has non-vanishing derivative on $(0,\infty)$, and that $f$ is bounded, with finite support. An integration by parts gives
  %
  \[ \| f \|_{p,q} = p^{1/q} \left( \int_0^\infty t^{q-1} F(t)^{q/p}\; dt \right)^{1/q} = \left( \int_0^\infty t^q F(t)^{q/p - 1} (-F'(t))\; dt \right)^{1/q}. \]
  %
  If we set $s = F(t)$, then $f^*(s) = t$, and $ds = F'(t) dt$, and so
  %
  \[ \left( \int_0^\infty t^q F(t)^{q/p - 1} F'(t)\; dt \right)^{1/q} = \left( \int_0^\infty f^*(s)^q s^{q/p - 1} ds \right)^{1/q} = \| s^{1/p} f^* \|_{L^q(\RR^+)}. \]
  %
  This gives the result in this case. The general result can then be obtained by applying the monotone convergence theorem to an arbitrary $f^*$ with respect to a family of smooth functions.
\end{proof}

The definition of the Lorentz space may seem confusing, but we really only require various special cases in most applications. Aside from the weak $L^p$ norms $\| \cdot \|_{p,\infty}$ and the $L^p$ norms $\| \cdot \|_p = \| \cdot \|_{p,p}$, the $L^{p,1}$ norms and $L^{p,2}$ norms also occur, the first, because of the connection with integrability, and the second because we may apply orthogonality techniques. As $q \to 0$, the norms $\| \cdot \|_{p,q}$ give stronger control over the function $f$.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q,r} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{ds}{s} \right)^{1/q}\\
        &\leq \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{ds}{s} \right)\\
        &\leq (p/q)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \begin{align*}
      \| f \|_{p,r} &= \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r}\\
    &\leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (p/q)^{p(1/q - 1/r)} \| f \|_{p,q}. \qedhere
    \end{align*}
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogeneous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
	For each $p,q > 0$, $\| f_1 + f_2 \|_{p,q} \lesssim_{p,q} \| f_1 \|_p + \| f_2 \|_q$.
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + f_2$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/2) + F_2(t/2))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim \left( q \int_0^\infty \left[ t \left( F_1(t) + F_2(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_p \left( q \int_0^\infty t^q \left( F_1(t)^{q/p} + F_2(t)^{q/p} \right) \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_q  \left( q \int_0^\infty t^q F_1(t)^{q/p} \frac{dt}{t} \right)^{1/q} +  \left( q \int_0^\infty t^q F_2(t)^{q/p} \frac{dt}{t} \right)^{1/q}\\
    &= \| f_1 \|_{p,q} + \| f_2 \|_{p,q}. \qedhere
  \end{align*}
\end{proof}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

\begin{remark}
  It might seem that sub step functions of height $H$ and width $W$ can take on a great many different behaviours, rather than that of a step function with height $H$ and width $W$. However, from the point of view of monotone, translation invariant norms, this isn't so. This is because using the binary expansion of real numbers, for every sub-step function $f$ of height $H$ and width $W$, we can find sets $\{ E_k \}$ such that
  %
  \[ f(x) = H \sum_{k = 1}^\infty 2^{-k} \mathbf{I}_{E_k}, \]
  %
  where $|E_k| = 1$. Thus bounds on step functions that are stable under addition tend to automatically imply bounds on substep functions.
\end{remark}

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \ZZ$,
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then we set $f = \sum f_k$. Each $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. We can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_4$ are all comparable up to absolute constant depending only on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is decreasing in $k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \ZZ} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \ZZ} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \ZZ} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \ZZ} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \ZZ} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ in terms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \ZZ} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_4$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \ZZ} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \ZZ} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \ZZ} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width. This is one reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if we can write $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    In particular, this occurs if there exists a constant $C$ such that $C \leq |f(x)| \leq C \cdot 2^N$ for all $x$. On the other hand, if we vary the $p$ parameter, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

\begin{example}
    Consider the function $f(x) = |x|^{-s}$. For each $k$, let
    %
    \[ E_k = \{ x : 2^{-(k+1)/s} \leq |x| < 2^{-k/s} \} \]
    %
    and define $f_k = f \mathbf{I}_{E_k}$. Then $f_k$ is a quasi-step function with height $2^k$, and width $1/2^{dk/s}$. We conclude that if $p = d/s$, and $q < \infty$,
    %
    \[ \| f \|_{p,q} \sim_{p,q,d} \left( \sum_{k = -\infty}^\infty 2^{qk(1 - d/ps)} \right)^{1/q} = \infty. \]
    %
    Thus the function $f$ lies exclusively in $L^{p,\infty}(\RR^d)$.
\end{example}

A simple consequence of the layer cake decomposition is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q \geq 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$ and that $1/q = 1/q_1 + 1/q_2$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \ZZ} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \ZZ} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \ZZ} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \ZZ} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \ZZ} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \ZZ} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \ZZ} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \ZZ} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2}\\
        &\lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$ instead of the other bound.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^1_{\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_{L^1(X)} \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

A consequence of H\"{o}lder's inequality is a duality of the $L^{p,q}$ norms. If $1 < p < \infty$, and $1 < q < \infty$, then $L^{p,q}(X)^* = L^{p',q'}(X)$. When $q = 1$ or $q = \infty$, things are more complex, but the following theorem often suffices. When $p = 1$, things get more tricky, so we leave this case out.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q < \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \ZZ} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \ZZ} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \ZZ} \int f_k(x) g_k(x) = \sum_{k \in \ZZ} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \ZZ} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \ZZ} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \ZZ} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \ZZ} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \ZZ} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

We remark that if $1 < p < \infty$ and $1 \leq q \leq \infty$, then for each $f \in L^{p,q}$, the value
%
\[ \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\} \]
%
gives a norm on $L^{p,q}(X)$ which is comparable with the $L^{p,q}$ norm. In particular, this implies that for $p > 1$ and $q \geq 1$,
%
\[ \| f_1 + \dots + f_N \|_{p,q} \lesssim_{p,q} \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q}, \]
%
so that the triangle inequality has constants independent of $N$. We can also use a layer cake decomposition to get a version of the Stein-Weiss inequality for Lorentz norms.

\begin{theorem}
	For each $1 < q < \infty$, there is $\alpha(q) > 0$ such that for any functions $f_1, \dots, f_N$,
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lesssim (\log N)^{\alpha(q)} \left( \| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} \right). \]
\end{theorem}
\begin{proof}
	For values $A$ and $B$ in this argument, we write $A \lessapprox B$ if there exists $\alpha$ such that $A \lesssim (\log N)^\alpha B$. Given $f_1, \dots, f_N$, write $f_i = \sum_{j = -\infty}^\infty f_{ij}$, where $f_{ij}$ has width $W_{ij}$ and height $2^j$. If we assume, without loss of generality, that $\| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} = 1$, then
	%
	\[ \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty (2^j W_{ij})^q \right)^{1/q} \lesssim_q 1 \]
	%
	Thus we want to show $\| f_1 + \dots + f_N \|_{1,q} \lessapprox_q 1$. Our first goal is to upper bound the measure of the set
	%
	\[ E = \{ x: 2^{k-1} < |f_1(x) + \dots + f_N(x)| \leq 2^k  \} \]
	%
	The measure of the set $E$ is upper bounded by the measure of the set
	%
	\[ E' = \left\{ x: 2^{k-2} < \left|\sum_{j = k - \lg(N)}^k f_{1j}(x) + \dots + f_{Nj}(x) \right| \leq 2^{k+1} \right\} \]
	%
	Applying the usual Stein-Weiss inequality, we have
	%
	\[ \left\| \sum_{i = 1}^N \sum_{j = k - \lg N}^k f_{ij} \right\|_{1,\infty} \lessapprox \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim_q \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	Thus we conclude
	%
	\[ |E'| \lessapprox_q 2^{-k} \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	This implies that
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lessapprox_q \left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q}. \]
	%
	Applying Minkowski's inequality, we conclude
	%
	\begin{align*}
		\left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q} &\lesssim \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \left( \sum_{j = k - \lg N}^k W_{ij 2^j} \right)^q \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \sum_{j = k - \lg N}^k W_{ij}^q 2^{qj} \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty W_{ij}^q 2^{qj} \right)^{1/q} \lesssim 1. \qedhere
	\end{align*}
\end{proof}

%\begin{comment}
%
%\section{Normability of the Lorentz Spaces}
%
%Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.
%
%\begin{lemma}
%    For any measurable set $E$,
    %
%    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
%    and
    %
%    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
%\end{lemma}
%\begin{proof}
%    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
%    %
%    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
%    %
%    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
%\end{proof}
%
%For a function $f$ and $t > 0$, we define a family of averages
%
%\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
%For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
%\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
%We define
%
%\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
%and
%
%\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
%For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
%\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
%and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

%\begin{theorem}
%    If $p > 1$,
    %
%    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
%\end{theorem}
%\begin{proof}
%    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
%    %
%    \begin{align*}
%        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
%        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
%        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
%        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
%    \end{align*}
    %
%    For $q = \infty$, and $t > 0$, we have
    %
%    \begin{align*}
%        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
%        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
%        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
%    \end{align*}
    %
%    since $t$ was arbitrary, this gives the required bound.
%\end{proof}
%
%\end{comment}

Here is an interesting weighted inequality whose proof utilizes the layer cake decomposition. I first encountered this inequality in Heo, Nazarov, and Seeger's paper \emph{Radial Fourier Multipliers in High Dimensions}.

\begin{theorem}
  Suppose that $\{ f_n \}$ is a family of functions, fix $p_0 < p_\theta < p_1$. Then
  %
  \[ \| \sum_n f_n \|_{L^p(X)} \lesssim_{p_0,p,p_1} \left( \sum_n \max_i \left\{ 2^{n(p - p_i)} \| f_n \|_{p_i,\infty}^{p_i} \right\} \right)^{1/p} \]
  %
  In particular, if $\| f_n \|_{p_i,\infty} \leq C 2^n W_n^{1/p_i}$ for each $n$, then
  %
  \[ \| \sum_n f_n \|_{L^p(X)} \lesssim_{p_0,p,p_1} C \left( \sum_n 2^{pn} W_n \right)^{1/p}. \]
  %
  This might hold, for instance, if $f_n$ is a sub step function with height $2^n$ and width $W_n$ for each $n$.
\end{theorem}
\begin{proof}
  Define $f_{nm} = f_n \cdot \mathbf{I}(2^{n+m} \leq |f_n| < 2^{n+m+1})$. Then $f_n = \sum_m f_{nm}$. For each fixed $m$, define $\tilde{f}_m = \sum_n f_{nm}$. Since $f_{nm} \approx 2^{n+m}$, $f_m$ is defined by a sum over different dyadic scales, and so we have a pointwise bound
  %
  \[ |\sum_n f_{nm}| \sim \max \{ 2^m : f_{nm} \neq 0 \} \sim_p \left( \sum_n |f_{nm}|^p \right)^{1/p}. \]
  %
  Thus we find
  %
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p \left\| \left( \sum_n |f_{nm}|^p \right)^{1/p} \right\|_{L^p(X)} = \left( \sum_n \| f_{nm} \|_{L^p(X)}^p \right)^{1/p}. \]
  %
  Chebyshev's inequality implies that
  %
  \begin{align*}
    \| f_{nm} \|_{L^p(X)}^p &\leq 2^{(n+m)p} \cdot \min_i \{ 2^{-(n+m) p_i} \| f_n \|_{L^{p_i,\infty}(X)}^{p_i} \}\\
    &\lesssim \min_i \{ 2^{(n+m)(p - p_i)} \| f_n \|_{L^{p_i,\infty}(X)}^{p_i} \}.
  \end{align*}
  %
  But this means that if $m \geq 0$,
  %
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p 2^{-|m|(p_1/p - 1)} \left( \sum_n 2^{-n(p_1 - p)} \| f_n \|_{L^{p_1,\infty}(X)}^{p_1} \right)^{1/p} \]
  %
  and for $m \leq 0$,
  % 
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p 2^{-|m|(1 - p_0/p)} \left( \sum_n 2^{n(p - p_0)} \| f_n \|_{L^{p_0,\infty}(X)}^{p_0} \right)^{1/p} \]
  %
  Applying the triangle inequality to $\| \sum f_n \|_{L^p(X)} = \| \sum \tilde{f}_m \|_{L^p(X)}$ and summing over $m$ completes the proof.
\end{proof}

\section{Mixed Norm Spaces}

Given two measure spaces $X$ and $Y$, we can form the product measure space $X \times Y$. If we have a norm space $V$ of functions on $X$, with norm $\| \cdot \|_V$ and a norm space $W$ of functions on $Y$, with norm $\| \cdot \|_W$, we can consider a `product norm'; for each function $f$ on $X \times Y$, we can consider the function $y \mapsto \| f(\cdot,y) \|_V$, and take the norm of this function over $Y$, i.e. $\| \| f(\cdot,y) \|_V \|_W$. The most important case of this process is where we fix $0 < p,q \leq \infty$, and consider
%
\[ \| f \|_{L^p(X) L^q(Y)} = \left( \int \left( \int |f(x,y)|^q \; dy \right)^{p/q}\; dx \right)^{1/p}. \]
%
Similarly, we can define $\| f \|_{L^q(Y) L^p(X)}$. The notation is justified by the fact that the first case is the $L^p$ norm of the function $f$, viewed as a map from $X$ to $L^q(Y)$, and the latter the $L^q$ norm of $f$, viewed as a map from $Y$ to $L^p(X)$. We have a duality theory here; for each $1 \leq p,q \leq \infty$ and any $f$ with $\| f \|_{L^p(X) L^q(Y)} < \infty$, the standard $L^p$ and $L^q$ duality gives
%
\[ \| f \|_{L^p(X) L^q(Y)} = \sup \left\{ \int_{X \times Y} f(x,y) h(x,y)\; dx\;dy : \| h \|_{L^{p^*}(X) L^{q^*}(Y)} \leq 1 \right\}. \]
%
It is often important to interchange norms, and we find the biggest quantity obtained by interchanging norms is always obtained with the largest exponents on the inside, i.e. in the notation we use, the exponents are monotonically increasing from left to right.

\begin{theorem}
    If $p \geq q$, $\| f \|_{L^p(X) L^q(Y)} \leq \| f \|_{L^q(Y) L^p(X)}$.
\end{theorem}
\begin{proof}
  If $p = q$, then the Fubini-Tonelli theorem implies that
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}. \]
  %
  If $q = 1$, then this result is precisely the Minkowski inequality. But not complex interpolation justifies the result in general. More precisely, a variation of the proof of Riesz-Thorin using the duality established above gives the result.
\end{proof}

Let us consider two special cases. Firstly, bounds for the pointwise maxima of functions dominate the maximum $L^p$ norms
%
\[ \sup_n \| f_n \|_{L^p(X)} \leq \left\| \sup_n f_n \right\|_{L^p(X)}. \]
%
Another special case is the triangle inequality
%
\[ \left\| \sum_n f_n \right\|_{L^p(X)} \leq \sum_n \| f_n \|_{L^p(X)} \]
%
for $p \geq 1$.

The next result shows that if $p < q$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}$, then $|f|$ is a tensor product. Thus switching mixed norms is likely only efficient if we think the functions we are working with are close to tensor products.

\begin{theorem}
  Suppose $p > q$, $f$ is a function on $X \times Y$, and
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)} < \infty. \]
  %
  Then there exists $f_1(x)$ and $f_2(y)$ such that for any $x \in X$ and $y \in Y$, $|f(x,y)| = |f_1(x)| |f_2(y)|$.
\end{theorem}
\begin{proof}
  Expanding this equation out, we conclude
  %
  \[ \left( \int_Y \left( \int_X |f(x,y)|^p\; dx \right)^{q/p}\; dy \right)^{1/q} = \left( \int_X \left( \int_Y |f(x,y)|^q\; dy \right)^{p/q}\; dx \right)^{1/p}. \]
  %
  Setting $g(x,y) = |f(x,y)|^p$, we see that Minkowski's integral inequality is tight for $g$, i.e.
  %
  \[ \left( \int_Y \left( \int_X |g(x,y)|\; dx \right)^{q/p}\; dy \right)^{p/q} = \left( \int_X \left( \int_Y |g(x,y)|^{q/p}\; dy \right)^{p/q}\; dx \right). \]
  %
  Thus it suffices to show that to show the theorem for $p = 1$ and $q > 1$. Recall the standard proof of Minkowski's inequality, i.e. that by H\"{o}lder's inequality
  %
  \begin{align*}
    \int_Y & \left( \int_X |f(x,y)|\; dx \right)^p\; dy\\
    &= \int_X \left[ \int_Y |f(x_1,y)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p-1}\; dy \right]\; dx_1\\
    &\leq \int_X \left[ \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p} \left( \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^{(p-1)p^*}\; dy \right)^{1/p^*} \right]\; dx_1 \\
    &= \left[ \int_X \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p}\; dx_1 \right] \left[ \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^p \right]^{1/p^*}.
  \end{align*}
  %
  and rearranging gives Minkowski's inequality. If this inequality is tight, then our application of H\"{o}lder's inequality is tight for almost every $x_1 \in X$. Since $\int |f(x_2,y)|\; dx_2 \neq 0$ for all $y$ unless $f = 0$, it follows that there exists $\lambda(x_1)$ for almost every $x_1 \in X$ such that for almost every $y \in Y$,
  %
  \[ |f(x_1,y)|^p = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p^*(p-1)} = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^p. \]
  %
  Setting $f_1(x) = |\lambda(x)|^{1/p}$ and $f_2(y) = \int_X |f(x,y)|\; dx$ thus completes the proof.
\end{proof}

\section{Orlicz Spaces}

To develop the class of Orlicz spaces, we note that if $\| f \|_p \leq 1$, and we set $\Phi(t) = t^p$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
More generally, given any function $\Phi: [0,\infty) \to [0,\infty)$, we might ask if we can define a norm $\| \cdot \|_\Phi$ such that if $\| f \|_\Phi \leq 1$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
Since a norm would be homogenous, this would imply that if $\| f \|_\Phi \leq A$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
%
If we want these norms to be monotone, we might ask that if $A < B$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{B} \right)\; dx \leq \int \Phi \left( \frac{|f(x)|}{A} \right), \]
%
and the standard way to ensure this is to ask the $\Phi$ is an increasing function. To deal with the property that $\| 0 \| = 0$, we set $\Phi(0) = 0$. In order for $\| \cdot \|_\Phi$ to be a norm, the set of functions $\{ f : \| f \|_\Phi \leq 1 \}$ needs to be convex, and the standard way to obtain this is to assume that $\Phi$ is convex.

In short, we consider an increasing, convex function $\Phi$ with $\Phi(0) = 0$. We then define
%
\[ \| f \|_\Phi = \inf \left\{ A > 0 : \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1 \right\}. \]
%
This function is a norm on the space of all $f$ with $\| f \|_\Phi < \infty$. It is easy to verify that $\| f \|_\Phi = 0$ if and only if $f = 0$ almost everywhere, and that $\| \alpha f \|_\Phi = |\alpha| \| f \|_\Phi$. To justify the triangle inequality, we note that if
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right) \leq 1 \quad\text{and} \quad \int \Phi \left( \frac{|f(x)|}{B} \right) \leq 1, \]
%
then applying convexity gives
%
\begin{align*}
    \int \Phi \left( \frac{|f(x) + g(x)|}{A + B} \right) &\leq \int \Phi \left( \frac{|f(x)| + |g(x)|}{A + B} \right)\\
    &\leq \int \left( \frac{A}{A + B} \right) \Phi \left( \frac{|f(x)|}{A} \right) + \left( \frac{B}{A + B} \right) \Phi \left( \frac{|g(x)|}{B} \right) \leq 1.
\end{align*}
%
Thus we obtain the triangle inequality.

The spaces $L^p(X)$ for $p \in [1,\infty)$ are Orlicz spaces with $\Phi(t) = t^p$. The space $L^\infty(X)$ is not really an Orlicz space, but it can be considered as the Orlicz function with respect to the `convex' function
%
\[ \Phi(t) = \begin{cases} \infty & t > 1, \\ t & t \leq 1. \end{cases} \]
%
More interesting examples of Orlicz spaces include
%
\begin{itemize}
    \item $L \log L$, given by the Orlicz norm induced by $\Phi(t) = t \log(2 + t)$.
    \item $e^L$, defined with respect to $\Phi(t) = e^t - 1$.
    \item $e^{L^2}$, defined with respect to $\Phi(t) = e^{t^2} - 1$.
\end{itemize}
%
One should not think too hard about the constants in the functions defined above, which are included to make $\Phi(0) = 0$. When we are dealing with a finite measure space (often the case, since these norms often occur in probability theory), they are irrelevant.

\begin{lemma}
  If $\Phi(x) \lesssim \Psi(x)$ for all $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$. If $X$ is finite, and $\Phi(x) \lesssim \Psi(x)$ for sufficiently large $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$.
\end{lemma}
\begin{proof}
  The first proposition is easy, and we now deal with the finite case. We note that the condition implies that for each $\varepsilon > 0$, there exists $C_\varepsilon$ such that $\Phi(x) \leq C_\varepsilon \Psi(x)$ if $|x| \geq \varepsilon$. Assume that $\| f \|_{\Psi(L)} \leq 1$, so that
  %
  \[ \int \Psi(|f(x)|)\; dx \leq 1. \]
  %
  Then convexity implies that for each $A > 0$,
  %
  \[ \int \Psi \left( \frac{|f(x)|}{A} \right) \leq \frac{1}{A}. \]
  %
  Thus
  %
  \begin{align*}
    \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx &\leq \Phi(\varepsilon) |X| + C_\varepsilon \int \Psi \left( \frac{|f(x)|}{A} \right)\\
    &\lesssim \Phi(\varepsilon) |X| + \frac{C_\varepsilon}{A}.
  \end{align*}
  %
  If $\Phi(\varepsilon) \leq 2/|X|$, and $A \geq 2C_\varepsilon$, then we conclude that
  %
  \[ \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
  %
  Thus $\| f \|_{\Phi(L)} \lesssim 1$.
\end{proof}

The Orlicz spaces satisfy an interesting duality relation. Given a function $\Phi$, which we assume is \emph{superlinear}, in the sense that $\Phi(x)/x \to \infty$ as $x \to \infty$, define it's \emph{Young dual}, for each $y \in [0,\infty)$, by
%
\[ \Psi(y) = \sup \{ xy - \Phi(x) : x \in [0,\infty) \}. \]
%
Then $\Psi$ is the smallest function such that $\Phi(x) + \Psi(y) \geq xy$ for each $x,y$. This quantity is finite for each $y$ because $\Phi$ is superlinear; for each $y \geq 0$, there exists $x(y)$ such that $\Phi(x(y)) \geq xy$, and thus the maximum of $xy - \Phi(x)$ is attained for $x \leq x(y)$. In particular, since $\Phi$ is continuous, the supremum is actually attained. Conversely, for each $x_0 \in [0,\infty)$, convexity implies there exists a largest $y$ such that the line $y(x - x_0) + f(x_0) \leq f(x)$ for all $x \in [0,\infty)$. This means that $\Psi(y) = x_0y - x_0$.

We note also that $\Psi(0) = 0$, and $\Psi$ is increasing. Most importantly, the function is convex. Given any $y,z \in [0,\infty)$, and any $x \in [0,\infty)$,
%
\begin{align*}
  x (\alpha y + (1 - \alpha) z) - \Phi(x) &\leq \alpha(xy - \Phi(x)) + (1 - \alpha)(xz - \Phi(x))\\
  &\leq \alpha \Psi(y) + (1 - \alpha) \Psi(z).
\end{align*}
%
Taking infimum over all $x$ gives convexity. The function $\Psi$ is also superlinear, since for any $x \in [0,\infty)$,
%
\[ \lim_{y \to \infty} \frac{\Psi(y)}{y} \geq \lim_{y \to \infty} \frac{xy - \Phi(x)}{y} = x. \]
%
In particular, we can consider the Young dual of $\Psi$.

\begin{lemma}
  If $\Psi$ is the Young dual of $\Phi$, then $\Phi$ is the Young dual of $\Psi$.
\end{lemma}
\begin{proof}
  $\Pi$ is the smallest function such that $\Pi(x) + \Psi(y) \geq xy$. Since $\Phi(x) + \Psi(y) \geq xy$ for each $x$ and $y$, we conclude that $\Pi(x) \leq \Phi(x)$ for each $x$. For each $x$, there exists $y$ such that $\Psi(y) = yx - \Phi(x)$. But this means that $\Phi(x) = yx - \Psi(y) \leq \Pi(x)$.
\end{proof}

Given the Orlicz space $\Phi(L)$ for superlinear $\Phi$, we can consider the Orlicz space $\Psi(L)$, where $\Psi$ is the Young dual of $\Phi$. The inequality $xy \leq \Phi(x) + \Psi(y)$, then
%
\[ |f(x) g(x)| \leq \Phi(|f(x)|) + \Psi(|g(x)|), \]
%
so if $\| f \|_{\Phi(L)}, \| g \|_{\Psi(L)} \leq 1$, then
%
\[ \left| \int f(x) g(x) \right| \leq \int |f(x)| |g(x)| \leq \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \leq 2. \]
%
Thus in general, we have
%
\[ \left| \int f(x) g(x) \right| \leq 2 \| f \|_{\Phi(L)} \| g \|_{\Psi(L)}, \]
%
a form of H\"{o}lder's inequality. The duality between convex functions extends to a duality between the Orlicz spaces.

\begin{theorem}
  For any superlinear $\Phi$ with Young dual $\Psi$,
  %
  \[ \| f \|_{\Phi(L)} \sim \sup \left\{ \int fg : \| g \|_{\Psi(L)} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\| f \|_{\Phi(L)} = 1$. The version of H\"{o}lder's inequality proved above shows that
  %
  \[ \| f \|_{\Phi(L)} \lesssim 1. \]
  %
  Conversely, for each $x$, we can find $g(x)$ such that $f(x) g(x) = \Phi(|f(x)|) + \Psi(|g(x)|$. Provided $\| g \|_{\Psi(L)} < \infty$, we have
  %
  \[ \int fg = \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \geq 1 + \| g \|_{\Psi(L)}. \]
  %
  Assuming $f \in L^\infty(X)$, we may choose $g \in L^\infty(X)$. For such a choice of function, $\| g \|_{\psi(L)} < \infty$, which implies the result. Taking an approximation argument then gives the result in general.
\end{proof}

Let us now consider some examples of duality.

\begin{example}
  If $\Phi(x) = x^p$, for $p \geq 1$, and $1 = 1/p + 1/q$, then it's Young dual $\Psi$ satisfies
  % q = p/(p-1)
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - x^p = y^{1 + q/p} / p^{q/p} - y^q / p^q = y^q [p^{-q/p} - p^{-q}].
  \end{align*}
  %
  Thus the Young dual corresponds, up to a constant, to the conjugate dual in the $L^p$ spaces.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(t) = e^t - 1$, then it's dual satisfies, for large $y$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^x - 1)\\
    &= y \log y - (y - 1) \sim y \log y.
  \end{align*}
  %
  This is comparable to $y \log (y + 2)$ for large $y$. Thus $L \log L$ is dual to $e^L$.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(x) = e^{x^2} - 1$, then for $y \geq 2$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^{x^2} - 1) \sim y \log(y/2)^{1/2}.
  \end{align*}
  %
  Thus the dual of $e^{L^2}$ is the space $L (\log L)^{1/2}$.
\end{example}

There is a generalization of both the Lorentz spaces and the Orlicz spaces, known as the Lorentz-Orlicz spaces, but these come up so rarely in analysis that we do not dwell on these norms.












\chapter{Sobolev Spaces}

TODO: Treves, Chapter 31 for cool discussion of Sobolev spaces of negative index.

Previously, we discussed the rearrangement invariant spaces, which quantify properties of a function $f: X \to Y$ in terms of is `width' and `height'. Here we discuss the `regularity' of functions, i.e. how gradually they change, and the related topic (from a Fourier analytic perspective) of how fast the function `oscillates' (inversely proportional to the `wavelength' of a function. Such properties are certainly not quantified in terms of rearrangement invariant properties, since change and oscillation necessarily imply some topological features of the spaces involved. Here are some canonical, intuitive examples. To introduce them, we fix some function $\phi \in C_c^\infty(\RR)$, which we intuitively think of as having some height $H$ and width $W$:
%
\begin{itemize}
    \item If $\phi \in C_c^\infty(\RR)$, then the function $f(t) = \phi(t) e^{iNt}$ is the canonical example of a function oscillating at a frequency $N$. It has height $H$ and width $W$. However, it's derivative $f'(t) = \phi'(t) e^{iNt} + iN \phi(t) e^{iNt}$ for large $N$ has height roughly proportional to $N \cdot H$ and width roughly proportional to $W$, and as we successively differentiate, the height grows even faster in $N$. This means that the function fails to be `regular' for large $N$.

    \item Let $f(t) = N^{-s} \phi(t) e^{iNt}$, or let $f(t) = N^{-s} \phi(Nt)$. Both of these functions has height $N^{-s} H$ and width $W$, and oscillates at a frequency $N$. But unlike the last examples, the height (e.g. the $L^\infty$ norm) of the function $f^{(k)}(t)$ is uniformly bounded in $t$ provided that $k \leq s$. We therefore think of $f$ as having `$s$ degrees of regularity'.

    \item Let us consider the more complex function $f(x) = \phi(x) |x|^s \mathbf{I}_{x > 0}$. One can break this function up into a sum $\sum_{n = 0}^\infty \phi_n(x) |x|^s$, where $\phi_n(x) = \phi(2^n x) - \phi(2^{n+1} x)$. The function $f_n(x) = \phi_n(x) |x|^s$ behaves very similarily to the function $\phi_n(x) 2^{-ns}$, an example considered in the last bullet with $N = 2^n$. In particular, the function oscillates at a frequency $2^n$, and has $s$ degrees of regularity. Thus we would image $f$ itself has $s$ degrees of regularity, but is composed of many different frequency scales.
\end{itemize}
%
There are various norms that quantify height, width, frequncy scale, and regularity. The most common is the Sobolev norm, though there are various refinements, like the H\"{o}lder norms, Besov norms, Triebel-Lizorkin norms.

\section{H\"{o}lder Spaces}

H\"{o}lder Spaces are a simplified version of Sobolev spaces which account for the height, regularity, and oscillation of a function, but not the width. For $f: \RR^d \to \CC$, and an integer $k \geq 0$, we define
%
\[ \| f \|_{C^k(\RR^d)} = \max_{1 \leq i \leq k} \| D^i f \|_{L^\infty(\RR^d)}. \]
%
Note that a $C^k$ function might not necessarily lie have finite $C^k(\RR^d)$ norm if it's derivatives are unbounded. We let $C^k_{\text{loc}}$ denote the space of all $C^k$ functions. For instance, $e^x \in C^\infty_\text{loc}(\RR)$, but $e^x \not \in C^\infty(\RR)$. Each of the space $C^k(\RR^d)$, where $k$ is finite, forms a Banach space. The space $C^\infty(\RR^d)$ is a Fr\'{e}chet space.

It is a useful heuristic that only the smallest and largest derivatives really matter when measuring regularity in a space, a fact also tied up to interpolation. For instance, we have the following result in H\"{o}lder spaces.

\begin{theorem}
    For any function $f: \RR^d \to \CC$,
    %
    \[ \| f \|_{C^k(\RR^d)} \sim_{k,d} \| f \|_{L^\infty(\RR^d)} + \| D^k f \|_{L^\infty(\RR^d)}. \]
\end{theorem}
\begin{proof}
    Certainly the right hand side is upper bounded by the left hand side. On the other hand, suppose both $f$ and all it's $k$th order derivatives are bounded by $A$. We will prove by induction that for each $1 \leq i < k$, $\| D^i f \|_{L^\infty(\RR^d)} \lesssim_{i,k,d} \| f \|_{L^\infty(\RR^d)} + \| D^{i+1} f \|_{L^\infty(\RR^d)}$. To do this, we perform a Taylor expansion, writing
    %
    \[ \left| f(x+y) - f(x) - \sum_{j = 1}^i D^j f(x) (y,\dots,y) \right| \lesssim \| D^{i+1} f \|_{L^\infty(\RR^d)} \cdot |y|^{i+1}. \]
    %
    We have $|f(x+y) - f(x)| \leq 2 \| f \|_{L^\infty(\RR^d)}$. For $i = 1$, this means that
    %
    \[ |Df(x)(y)| \lesssim \| f \|_{L^\infty(\RR^d)} + \| D^2 f \|_{L^\infty(\RR^d)} |y|^2, \]
    %
    and since $y$ was arbitrary, letting $y$ range over all $|y| = 1$, we have
    %
    \[ \| Df \|_{L^\infty(\RR^d)} \lesssim \| f \|_{L^\infty(\RR^d)} + \| D^2 f \|_{L^\infty(\RR^d)}. \]
    %
    For $i \geq 2$, and for each $1 \leq j \leq i-1$, we have by induction,
    %
    \[ \| D^j f(x) (y,\dots,y) \| \lesssim_d \left( \| f \|_{L^\infty(\RR^d)} + \| D^{j+1} f \|_{L^\infty(\RR^d)} \right) |y|^j \lesssim_d \left( \| f \|_{L^\infty(\RR^d)} + \| D^i f \|_{L^\infty(\RR^d)} \right) |y|^j. \]
    %
    Carrying these sums up the Taylor series, we conclude that
    %
    Plugging these values in gives that
    %
    \[ |D^i f(x)(y,\dots,y)| \lesssim_d \| f \|_{L^\infty(\RR^d)} \left( 1 + |y|^{i-1} \right) + \| D^i f \|_{L^\infty(\RR^d)} \left( |y| + |y|^{i-1} \right) + \| D^{i+1} f \|_{L^\infty(\RR^d)} \cdot |y|^{i+1}. \]
    %
    Pick a constant $C \geq 1$ such that the left hand side is upper bounded by $C$ times the right hand side. Then
    %
    \[ |D^i f(x)(y,\dots,y)| - C \| D^i f \|_{L^\infty(\RR^d)} \left( |y| + |y|^{i-1} \right) \leq \| f \|_{L^\infty(\RR^d)} \left( 1 + |y|^{i-1} \right) + C \| D^{i+1} f \|_{L^\infty(\RR^d)} \cdot |y|^{i+1} \]
    %
    Choosing $y = 10C \cdot z$ for $|z| = 1$ gives
    %
    \[ (10C)^i \cdot D^i f(x)(z,\dots,z) - (20C)^{i-1} \| D^i f \|_{L^\infty(\RR^d)} \leq (10 C)^{i+2} \left( \| f \|_{L^\infty(\RR^d)} + \| D^{i+1} f \|_{L^\infty(\RR^d)} \right). \]
    %
    Our proof is completed when we notice that
    %
    \[ \| D^i f(x) \|_{L^\infty(\RR^d)} \sim_n \sup_{|z| = 1} |D^i f(x)(z,\dots,z)|, \]
    %
    so if we pick $C$ large enough depending solely on $d$, we conclude that
    %
    \[ \| D^i f \|_{L^\infty(\RR^d)} \lesssim_d \| f \|_{L^\infty(\RR^d)} + \| D^{i+1} f \|_{L^\infty(\RR^d)}. \]
    %
    This completes the induction.
\end{proof}

More generally, for any $0 \leq \alpha \leq 1$, we set $C^{k,\alpha}(\RR^d)$ to be the set of all $C^k$ functions such that $D^k f$ satisfies a H\"{o}lder condition of order $\alpha$, i.e.
%
\[ \| f \|_{C^{k,\alpha}(\RR^d)} = \| f \|_{L^\infty(\RR^d)} + \| D^k f \|_{L^\infty(\RR^d)} + \sup_{x \neq y} \frac{D^kf(x) - D^k f(y)}{|x - y|^\alpha}. \]
%
For $\alpha > 1$, this norm is finite if and only if $D^k f$ is constant, which is why only the case $\alpha \leq 1$ is interesting. It is simple to see that $C^k(\RR^d)$ is contained in $C^{k,\alpha}(\RR^d)$ for each such $\alpha$. We also have $C^{k,1}(\RR^d) \subset C^{k+1}(\RR^d)$, because of Taylor's formula.

\begin{example}
    To see the relation between the H\"{o}lder norm and the height, width, frequency scale, etc, consider a bump function $\phi \in C_c^\infty(\RR^d)$, and let $f(t) = A \phi(t/R) e^{Nt}$. Provided that $R \geq 1/N$, we think of this function as having height $A$, width $R$, and frequency $N$ (if $R < 1/N$, the frequency term does not have enough `space' to oscillate). Then $\| f \|_{C^{k+\alpha}(\RR^d)} \lesssim_{\phi,d,k} A N^{k+\alpha}$. Thus $R$ is not measured at all.
\end{example}

\begin{lemma}
    An element of $C^{k,1}(\RR^d)$ is precisely an element $f \in C^k(\RR^d)$ such that the distributional derivative $D^{k+1}f$ is an $L^\infty$ tensor.
\end{lemma}
\begin{proof}
    It suffices to prove the case $k = 0$. If $f \in C^{0,1}(\RR^d)$ then $f$ is precisely a bounded, uniformly Lipschitz function. Such functions are absolutely continuous with uniformly bounded derivative defined almost everywhere, and thus the distributional derivative $Df$ lies in $L^\infty$. Conversely, if $f \in L^\infty(\RR^d)$ and $f' \in L^\infty(\RR^d)$, then we have a representation formula
    %
    \[ f(x) = \int_0^x f'(y)\; dy, \]
    %
    which implies $f$ is Lipschitz.
\end{proof}






\chapter{Sobolev Spaces}

Let $\Omega$ be an open subset of $\RR^d$. A natural problem when studying smooth functions $\phi \in C_c^\infty(\Omega)$ is to obtain estimates on the partial derivatives of $\phi$. For instance, one can consider the norms
%
\[ \| \phi \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)}. \]
%
The space $C_c^\infty(\Omega)$ is not complete with respect to this norm, but it's completion is the space $C^n_b(\Omega)$ of $n$ times bounded continuously differentiable functions on $\Omega$, which still consists of regular functions. Unfortunately, such estimates are only encountered in the most trivial situations. As in the non-smooth case, one can often get much better estimates using the $L^p$ norms of the derivatives, i.e. considering the norms
%
\[ \| \phi \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq p} \| D^\alpha \phi \|_{L^p(\Omega)}^p \right)^{1/p}. \]
%
As might be expected, $C_c^\infty(\Omega)$ is not complete with respect to the $W^{n,p}(\Omega)$ norm. However, it's completion cannot be identified with a family of $n$ times differentiable functions. Instead, to obtain a satisfactory picture of the compoetion under this norm, a Banach space we will denote by $W^{n,p}(\Omega)$, we must take a distribution approach.

For each multi-index $\alpha$, if $f$ and $f_\alpha$ are locally integrable functions on $\Omega$, we say $f_\alpha$ is a weak derivative for $f$ if for any $\phi \in C_c^\infty(\Omega)$,
%
\[ \int_\Omega f_\alpha(x) \phi(x)\; dx = (-1)^{|\alpha|} \int_\Omega f(x) \phi_\alpha(x)\; dx. \]
%
In other words, this is the same as the derivative of $f$ viewed as a distribution on $\Omega$. We define $W^{n,p}$ to be the space of all functions $f \in L^p(\Omega)$ such that for each $|\alpha| \leq n$, a weak derivative $f_\alpha$ exists and is an element of $L^p(\Omega)$. We then define
%
\[ \| f \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq n} \| f_\alpha \|_{L^p(\Omega)} \right)^{1/p}. \]
%
Where this sum is treated as a maximum in the case $p = \infty$. Later on we will be able to show this space is a complete Banach space.

\begin{example}
  Let $B$ be the open unit ball in $\RR^d$, and let $u(x) = |x|^{-s}$, where $s < n-1$. For which $p$ is $u \in W^{1,p}(B)$? We calculate by an integration by parts that if $\phi \in C_c^\infty(B)$, we fix $\varepsilon > 0$ and write
  %
  \[ \int_B \phi_i(x) u(x)\; dx = \int_{|x| \leq \varepsilon} \phi_i(x) u(x) + \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x). \]
  %
  The integral on the $\varepsilon$ ball is neglible since $s < n$. Since $u$ is smooth away from the origin, it's distributional derivative agrees with it's standard derivative, which is
  %
  \[ u_i(x) = \frac{- \alpha x_i}{|x|^{s + 2}}. \]
  %
  Thus $|u_i| \lesssim 1/|x|^{s + 1}$. An integration by parts gives
  % in the $i$'th direction, and we calculate $\nabla u(x) = -\alpha x |x|^{-\alpha-2}$. Thus an integration by parts gives
  %
  \[ \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x) = \int_{|x| = \varepsilon} \phi(x) u(x) \nu_i\ dS + \int_{\varepsilon < |x| \leq 1} \frac{s \phi(x) x_i}{|x|^{s + 2}}\; dx, \]
  %
  where $\nu_i$ is the normal vector to the sphere pointing inward. Since $s < n-1$, the surface integral tends to zero as $\varepsilon \to 0$. Thus the weak derivative of $u$ is equal to the standard derivative. Consequently, $u \in W^{1,p}(B)$ if $s < n/p - 1$.
\end{example}

\begin{example}
  If $\{ r_k \}$ is a countable, dense subset of $B$, then we can define
  %
  \[ u(x) = \sum_{k = 1}^\infty \frac{|x - r_k|^{-s}}{2^k} \]
  %
  Then $u \in W^{1,p}(B)$ if $0 < \alpha < n/p - 1$, yet $u$ has a dense family of singularities, and thus does not behave like any differentiable function we would think of.
\end{example}

\begin{theorem}
  For each $k \in \mathbf{N}$ and $1 \leq p \leq \infty$, $W^{k,p}(\Omega)$ is a Banach space.
\end{theorem}
\begin{proof}
  It is easy to verify that $\| \cdot \|_{W^{k,p}}$ is a norm on $W^{k,p}(\Omega)$. Let $\{ u_n \}$ be a Cauchy sequence in $W^{k,p}(\Omega)$. In particular, this means that $\{ D^\alpha u_n \}$ is a Cauchy sequence in $L^p(\Omega)$ for each multi-index $\alpha$ with $|\alpha| \leq k$. In particular, these are functions $v_\alpha$ such that $D^\alpha u_n$ converges to $v_\alpha$ in the $L^p$ norm for each $\alpha$. Thus it suffices to prove that if $v = \lim u_n$, then $D^\alpha v = v_\alpha$ for each $\alpha$. But this follows because the H\"{o}lder inequality implies that for each fixed $\phi \in C_c^\infty(\Omega)$,
  %
  \begin{align*}
    (-1)^{|\alpha|} \int \phi_\alpha(x) v(x)\; dx &= \lim_{n \to \infty} (-1)^{|\alpha|} \phi_\alpha u_n(x)\; dx\\
    &= \lim_{n \to \infty} \int \phi(x) (D^\alpha u_n)(x)\; dx\\
    &= \int \phi(x) v_\alpha(x)\; dx.
  \end{align*}
  %
  Thus $W^{k,p}(\Omega)$ is complete.
\end{proof}

\section{Smoothing}

It is often useful to be able to approximate elements of $W^{k,p}(\Omega)$ by elements of $C^\infty(\Omega)$. This is mostly possible. If $u \in W^{k,p}(\Omega)$, and $\{ \eta_\varepsilon \}$ is a family of smooth mollifiers, then, viewing $u$ as a function on $\RR^n$ supported on $\Omega$, we can consider the convolution $u^\varepsilon = u * \eta_\varepsilon$, i.e. the function defined by setting
%
\[ u^\varepsilon(x) = \int_\Omega u(x - y) \eta_\varepsilon(y)\; dy. \]
%
This is just normal convolution, where we identify the function $u$ with the function $u \mathbf{I}_\Omega$ on $\RR^d$. Then $u^\varepsilon$ is a smooth function on $\RR^d$ supported on a $\varepsilon$ thickening of $\Omega$. However, $u^\varepsilon$ does not necessarily converge to $u$ in $W^{k,p}(\Omega)$ as $\varepsilon \to 0$, since the behaviour of the convolution can cause issues at the boundary of $\Omega$, where the distributional derivative $D^\alpha(u \mathbf{I}_\Omega)$ does not behave like a locally integrable function. This is the only problem, however.

\begin{theorem}
  If $U \Subset \Omega$, then $\lim_{\varepsilon \to 0} \| u^\varepsilon - u \|_{L^p(U)} = 0$.
\end{theorem}
\begin{proof}
  For each $\varepsilon > 0$, let $U^\varepsilon = \{ x \in \Omega: d(x,\partial \Omega) > \varepsilon \}$. If $x \in \Omega^\varepsilon$, then
  %
  \[ ((D^\alpha u) * \eta_\varepsilon)(x) = (u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon)(x), \]
  %
  since the convolution only depends on the behaviour of $D^\alpha u$ on a $\varepsilon$ ball around $x$, which is contained in the interior of $\Omega$. We can apply standard results about mollifiers to conclude that $u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon$ converges to $u_\alpha \mathbf{I}_\Omega$ in $L^p(\RR^d)$ as $\varepsilon \to 0$. Since $U \Subset \Omega$, we have $U \subset U^\varepsilon$ for small enough $\varepsilon$, and so $(D^\alpha u) * \eta_\varepsilon$ converges to $u_\alpha$ in $L^p(U)$ as $\varepsilon \to 0$. Since this is true for each $\alpha$ with $|\alpha| \leq k$, we obtain the result.
\end{proof}

If we are a little more careful, then we can fully approximate elements of $W^{k,p}(\Omega)$ by smooth functions on $U$.

\begin{theorem}
  $C^\infty_c(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
  Consider a family of open sets $\{ V_n \}$ such that $V_n \Subset \Omega$ for each $n$, and $U = \bigcup V_n$. Then we can consider a smooth partition of unity $\{ \xi_n \}$ subordinate to the cover $\{ V_n \}$. For each $u \in W^{k,p}(\Omega)$, we can write $u = \sum_n u \xi_n$. In particular, this means that for each $\varepsilon > 0$, there is $N$ such that $\| \sum_{n = N+1}^\infty u \xi_n \|_{W^{k,p}(\Omega)} \leq \varepsilon$. For each $n \in \{ 1, \dots, N \}$, we can find $\delta_n$ small enough that the $\delta_n$ thickening of $V_n$ is compactly contained in $\Omega$. If $\varepsilon_n$ is small enough, we find $(u \xi_n)^{\varepsilon_n}$ is supported on the $\delta_n$ thickening of $V_n$, and $\| (u \xi_n)^{\varepsilon_n} - u \xi_n \|_{W^{k,p}(V_n)} \leq \varepsilon / N$. But we then find
  %
  \begin{align*}
    \| u - \sum_{n = 1}^N (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq \varepsilon + \sum_{n = 1}^N \| u \xi_n - (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq 2\varepsilon.
  \end{align*}
  %
  Thus $C_c^\infty(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{proof}

Approximation by elements of $C^\infty(\overline{\Omega})$ requires some more care, and additional assumptions on the behaviour of $\partial \Omega$.












\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function. As should be expected, our main focus will be on the \emph{interpolation of operators}. There are both complex methods of interpolation, and real methods of interpolation. These methods are interchangable, \emph{most of the time}, except when dealing with the boundedness of operators at endpoints. Sometimes complex interpolation is more useful, and sometimes real interpolation works better. So it is useful to know both types of interpolation.

\section{Interpolation of Functions}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
    For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
    %
    \[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
    %
    says
    %
    \[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
    %
    which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
    The weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
    %
    \[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
    %
    where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
    If $f$ is a holomorphic function on the strip $S = \{ z : \text{Re}(z) \in [a,b] \}$ and there exists constants $A,B,\delta > 0$ such that for all $z \in S$,
    %
    \[ |f(z)| \leq Ae^{Be^{(\pi - \delta)|z|}}. \]
    %
    Then the function $M: [a,b] \to [0,\infty]$ given by
    %
    \[ M(s) = \sup_{s \in \RR} |f(s + it)| \]
    %
    is log convex on $[a,b]$.
\end{theorem}
\begin{proof}
    By a change of variables, we can assume that $a = 0$, and $b = 1$, and we need only show that if there are $A_0, A_1 > 0$ such that
    %
    \[ |f(it)| \leq A_0 \quad\text{and}\quad |f(1 + it)| \leq A_1 \quad \text{for all $t \in \RR$}, \]
    %
    then for any $s \in [a,b]$ and $t \in \RR$,
    %
    \[ |f(s + it)| \leq A_0^{1 - s} A_1^s. \]
    %
    By replacing $f(z)$ with the function $A_0^{1-z} A_1^z f(z)$, we may assume without loss of generality that $A_0 = A_1 = 1$, and we must show that $\| f \|_{L^\infty(S)} \leq 1$. If $|f(s + it)| \to 0$ as $|t| \to \infty$, then for large $N$, we can conclude that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \geq N$. But then the maximum principle entails that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \leq N$, which completes the proof in this case. In the general case, for each $\varepsilon > 0$, define
    %
    \[ u_\varepsilon(z) = \exp(- 2 \varepsilon \sin((\pi - \varepsilon) z + \varepsilon/2)). \]
    %
    Then if $z = s + it$,
    %
    \[ |u_\varepsilon(z)| = \exp(- \varepsilon [e^{(\pi - \varepsilon) t} + e^{-(\pi - \varepsilon) t}] \sin((\pi - \varepsilon) s + \varepsilon/2)), \]
    %
    So, in particular, $|u_\varepsilon(z)| \leq 1$, and there exists a constant $C$ such that if $z \in S$,
    %
    \[ |u_\varepsilon(z)| \leq e^{- C \varepsilon^2 e^{(\pi - \varepsilon) |z|}} \]
    %
    Note that if $\varepsilon < \delta$, then as $|\text{Im}(z)| \to \infty$,
    %
    \[ |f(z) u_\varepsilon(z)| \leq A e^{B e^{(\pi - \delta) |z|} - C \varepsilon^2 e^{(\pi - \varepsilon) |z|} } \to 0. \]
    %
    Applying the previous case to the function $|f(z) u_\varepsilon(z)|$, we conclude that for any $\varepsilon > 0$,
    %
    \[ |f(z)| \leq \frac{1}{|u_\varepsilon(z)|}. \]
    %
    Thus
    %
    \[ |f(z)| \leq \lim_{\varepsilon \to 0} \frac{1}{|u_\varepsilon(z)|} = 1, \]
    %
    which completes the proof.
\end{proof}

\begin{remark}
    The function $e^{-ie^{\pi i s}}$ shows that the assumption of the three lines lemma is essentially tight. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than double exponentially, and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
    Similar variants can be used to show that if $f$ is a holomorphic function on an annulus, then the supremum over circles centered around the origin is log convex in the radius of the circle (a result often referred to as the three circles lemma).
\end{remark}

\begin{example}
    Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
    %
    \[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
    %
    is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\begin{example}
    Let $f$ be a holmomorphic function on a strip $S = \{ z : \text{Re}(z) \in [a,b] \}$, such that if $z = a + it$, or $z = b + it$, for some $t \in \RR$,
    %
    \[ |f(z)| \leq C_1 (1 + |z|)^\alpha. \]
    %
    Then there exists a constant $C'$ such that for any $z \in S$,
    %
    \[ |f(z)| \leq C_2 (1 + |z|)^\alpha. \]
\end{example}
\begin{proof}
    The function
    %
    \[ g(z) = \frac{f(z)}{(1 + z)^\alpha} \]
    %
    is holomorphic on $S$, and if $z = a + it$ or $z = b + it$,
    %
    \[ |g(z)| \leq \frac{C_1 (1 + |z|)^\alpha}{|1 + z|^\alpha} \lesssim 1. \]
    %
    Thus the three lines lemma implies that $|g(z)| \lesssim 1$ for all $z \in S$, so
    %
    \[ |f(z)| \lesssim |1 + z|^\alpha \lesssim (1 + |z|)^\alpha. \qedhere \]
\end{proof}

TODO: Is Lemma 20.1 of Treves Distribution Theory an example of interpolation?

\section{Interpolation of Operators}

A major part of modern harmonic analysis is the study of operators, i.e. maps from function spaces to other function spaces. We are primarily interested in studying \emph{linear operators}, i.e. operators $T$ such that $T(f + g) = T(f) + T(g)$, and $T(\alpha f) = \alpha T(f)$, and also \emph{sublinear operators}, such that $|T(\alpha f)| = |\alpha| |T(f)|$ and $|T(f + g)| \leq |Tf| + |Tg|$. Even if we focus on linear operators, it is still of interest to study sublinear operators because one can study the \emph{uniform boundedness} of a family of operators $\{ T_k \}$ by means of the function $T^*(f)(x) = \max (T_k f)(x)$. This is the method of \emph{maximal functions}. Another important example are the $l^p$ sums
%
\[ (S^p f)(x) = \left( \sum |T_k(x)|^p \right). \]
%
These two examples are specific examples where we have a family of operators $\{ T_y \}$, indexed by a measure space $Y$, and we define an operator $S$ by taking $Sf$ to be the norm of $\{ T_y f \}$ in the variable $y$.

Here we address the most basic case of operator interpolation. As we vary $p$, the $L^p$ norms provide different ways of measuring the height and width of functions. Let us consider a simple example. Suppose that for an operator $T$, we have a bound
%
\[ \| Tf \|_{L^1(Y)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| Tf \|_{L^\infty(Y)} \leq \| f \|_{L^\infty(X)}. \]
%
The first inequality shows that the width of $Tf$ is controlled by the width of $f$, and the second inequality says the height of $Tf$ is controlled by the height of $f$. If we take a function $f \in L^p(X)$, for some $p \in (1,\infty)$, then we have some control over the height of $f$, and some control of the width. In particular, this means we might expect some control over the width and height of $Tf$, i.e. for each $p$, a bound
%
\[ \| Tf \|_{L^p(Y)} \leq \| f \|_{L^p(X)}. \]
%
This is the idea of interpolation on the $L^p(X)$ spaces.

\section{Complex Interpolation of Operators}

The first theorem we give is the Riesz-Thorin theorem, which utilizes complex interpolation to give such a result. In the next theorem, we work with a linear operator $T$ which maps simple functions $f$ on a measure space $X$ to functions on a measure space $Y$. For the purposes of applying duality, we make the mild assumption that for each simple function $g$,
%
\[ \int |(Tf)(y)| |g(y)|\; dy < \infty. \]
%
Our goal is to obtain $L^p$ bounds on the function $T$. The Hahn-Banach theorem then guarantees that $T$ has a unique extension to a map defined on all $L^p$ functions.

\begin{theorem}[Riesz-Thorin]
    Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Suppose that
    %
    \[ \| Tf \|_{L^{q_0}(Y)} \leq A_0 \| f \|_{L^{p_0}(X)} \quad \text{and} \| Tf \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_1}(X)}.  \]
    %
    Then for any $\theta \in (0,1)$, if
    %
    \[ 1/p_\theta = (1 - \theta)/p_0 + \theta/p_1 \quad\text{and}\quad 1/q_\theta = (1 - \theta)/q_0 + \theta/q_1, \]
    %
    then
    %
    \[ \| Tf \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}, \]
    %
    where $A_\theta = A_0^{1 - \theta} A_1^\theta$.
\end{theorem}
\begin{proof}
    If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $A_0 = A_1 = 1$. By duality and homogeneity, it suffices to show that for any two simple functions $f$ and $g$ such that $\| f \|_{q_\theta} = \| g \|_{q_\theta^*} = 1$,
    %
    \[ \left| \int_Y (Tf) g\; dy \right| \leq 1. \]
    %
    Our challenge is to make this inequality complex analytic so we can apply the three lines lemma. We write $f = F_0^{1 - \theta} F_1^\theta a$, where $F_0$ and $F_1$ are non-negative simple functions with $\| F_0 \|_{L^{p_0}(X)} = \| F_1 \|_{L^{p_1}(X)} = 1$, and $a$ is a simple function with $|a(x)| = 1$. Similarily, we can write $g = G_0^{1-\theta} G_1^\theta b$. We now write
    %
    \[ H(s) = \int_Y T(F_0^{1 - s} F_1^s a) G_0^{1-s} G_1^s b\; dy. \]
    %
    Since all functions involved here are simple, $H(s)$ is a linear combination of positive numbers taken to the power of $1-s$ or $s$, and is therefore obviously an entire function in $s$. Now for all $t \in \RR$, we have
    %
    \[ \| F_0^{1-it} F_1^{it} a \|_{L^{p_0}(X)} = \| F_0 \|_{L^{p_0}(X)} = 1, \]
    \[ \| G_0^{1-it} G_1^{it} b \|_{L^{q_0}(Y)} = \| G_0 \|_{L^{q_0}(X)} = 1. \]
    %
    Therefore
    %
    \begin{align*}
      |H(it)| &= \left| \int T(F_0^{1 - it} F_1^{it} a) G_0^{1-it} G_1^{it} b\; dy \right| \leq 1.
    \end{align*}
    %
    Similarily, $|H(1 + it)| \leq 1$ for all $t \in \RR$. An application of Lindel\"{o}f's theorem implies $|H(s)| \leq 1$ for all $s$. Setting $s = \theta$ completes the argument.
\end{proof}

If, for each $p,q$, we let $F(1/p,1/q)$ to be the operator norm of a linear operator $T$ viewed as a map from $L^p(X)$ to $L^q(Y)$, then the Riesz-Thorin theorem says that $F$ is a log-convex function. In particular, the set of $(1/p,1/q)$ such that $T$ is bounded as a map from $L^p(X)$ to $L^q(Y)$ forms a convex set. If this is true, we often say $T$ is of \emph{strong type} $(p,q)$.

\begin{example}
  For any two integrable functions $f,g \in L^1(\RR^d)$, we can define an integrable function $f * g \in L^1(\RR^d)$ almost everywhere by the integral formula
  %
  \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
  %
  If $f \in L^1(\RR^d)$ and $g \in L^p(\RR^d) \cap L^1(\RR^d)$, for some $p \geq 1$, then Minkowski's integral inequality implies
  %
  \begin{align*}
      \| f * g \|_p &= \left( \int |(f * g)(x)|^p\; dx \right)^{1/p} \leq \int \left( \int |f(y)g(x-y)|^p dx\; \right)^{1/p} dy\\
      &= \int |f(y)| \| g \|_{L^p(\RR^d)} = \| f \|_{L^1(\RR^d)} \| g \|_{L^p(\RR^d)}.
  \end{align*}
  %
  H\"{o}lder's inequality implies that if $f \in L^p(\RR^d)$ and $g \in L^q(\RR^d)$, where $p$ and $q$ are conjugates of one another, then
  %
  \begin{align*}
    \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}.
  \end{align*}
    %
    Thus we have the bound
    %
    \[ \| f * g \|_{L^\infty(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Now that these mostly trivial results have been proved, we can apply convolution. For each $f \in L^1(\RR^d) \cap L^p(\RR^d)$, we have a convolution operator $T: L^1(\RR^d) \to L^1(\RR^d)$ defined by $Tg = f * g$. We know that $T$ is of strong type $(1,p)$, and of type $(q,\infty)$, where $q$ is the harmonic conjugate of $p$, and $T$ has operator norm $1$ with respect to each of these types. But the Riesz Thorin theorem then implies that if $1/r = \theta + (1 - \theta)/q$, then $T$ is bounded as a map from $L^r(\RR^d)$ to $L^{p/\theta}(\RR^d)$ with operator norm one. Reparameterizing gives \emph{Young's convolution inequality}. Note that we never really used anything about $\RR^d$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. In particular, the Haar measure $\mu$ on such a group is only defined up to a scalar multiple, and if we swap $\mu$ with $\alpha \mu$, for some $\alpha > 0$, then Young's inequality for this measure implies
    %
    \[ \lambda^{1 + 1/r} \| f * g \|_r = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
    %
    which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$.
\end{example}

\begin{example}
Let $X$ be a measure space with $\sigma$ algebra $\Sigma_0$, and let $\Sigma \subset \Sigma_0$ be a $\sigma$ finite sub $\sigma$ algebra. Then $L^2(X,\Sigma)$ is a closed subspace of $L^2(X,\Sigma_0)$, and so there is an orthogonal projection operator $\EE(\cdot|\Sigma): L^2(X,\Sigma_0) \to L^2(X,\Sigma)$, which we call the \emph{conditional expectation operator}. The properties of the projection operator imply that for any $f,g \in L^2(X, \Sigma_0)$,
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g} = \int \EE(f|\Sigma) \overline{\EE(g|\Sigma)}. \]
%
If $g \in L^2(X,\Sigma)$, then
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g}. \]
%
This gives a full description of $\EE(f|\Sigma)$. In particular, if $u \in L^\infty(X,\Sigma_0)$, then for each $g \in L^2(X,\Sigma)$
%
\[ \int \EE(uf|\Sigma) \overline{g} = \int f [u\overline{g}] = \int u \EE(f|\Sigma) \overline{g}. \]
%
Since this is true for all $g \in L^2(X,\Sigma)$, we find $\EE(uf|\Sigma) = u \EE(f|\Sigma)$. Moreover, if $0 \leq f \leq g$, then $\EE(f|\Sigma) \leq \EE(g|\Sigma)$. This is easy to see because if $f \geq 0$, and $F = \{ x : \EE(f|\Sigma) < 0 \}$, then if $|F| \neq 0$,
%
\[ 0 > \int \EE(f|\Sigma) \mathbf{I}_F = \int f \mathbf{I}_F \geq 0. \]
%
Thus $|F| = 0$, and so $\EE(f|\Sigma) \geq 0$ almost everywhere.

Like all other orthogonal projection operators, conditional expectation is a contraction in the $L^2$ norm, i.e. $\| \mathbf{E}(f|\Sigma) \|_{L^2(X)} \leq \| f \|_{L^2(X)}$. We now use interpolation to show that conditional expectation is strong $(p,p)$, for all $1 \leq p \leq \infty$. It suffices to prove the operator is strong $(1,1)$ and strong $(\infty,\infty)$. So suppose $f \in L^2(X,\Sigma_0) \cap L^\infty(X,\Sigma_0)$. If $|E| < \infty$, then $\mathbf{I}_E \in L^2(X)$, so
%
\[ |\EE(f|\Sigma)| \mathbf{I}_E = |\EE(\mathbf{I}_E f | \Sigma)| \leq \EE(\mathbf{I}_E |f| | \Sigma) \leq \| f \|_\infty \mathbf{E}(\mathbf{I}_E|\Sigma) = \| f \|_\infty \mathbf{I}_E. \]
%
Since $\Sigma$ is a sigma finite sigma algebra, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_\infty \leq \| f \|_\infty$. The case $(1,1)$ can be obtained by duality, since conditional expectation is self adjoint, or directly, since if $f \in L^1(X,\Sigma_0) \cap L^2(X,\Sigma_0)$, then for any set $E \in \Sigma$ with $|E| < \infty$,
%
\[ \int |\EE(f|\Sigma)| \mathbf{I}_E \leq \int \EE(|f||\Sigma) \mathbf{I}_E = \int_E |f| \mathbf{I}_E \leq \| f \|_1. \]
%
Since $\Sigma$ is $\sigma$ finite, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_1 \leq \| f \|_1$. Thus the Riesz interpolation theorem implies that for each $1 \leq p \leq \infty$, $\| \EE(f|\Sigma) \|_p \leq \| f \|_p$.

Since $L^2(X,\Sigma_0)$ is dense in $L^p(X,\Sigma_0)$ for all $1 \leq p < \infty$, there is a unique extension of the conditional expectation operator from $L^p(X,\Sigma_0)$ to $L^p(X,\Sigma_0)$. For $p = \infty$, there are infinitely many extensions of the conditional expectation operator from $L^\infty(X,\Sigma_0)$ to $L^\infty(X,\Sigma_0)$. However, there is a \emph{unique} extension such that for each $f \in L^2(\Sigma_0)$ and $g \in L^\infty(\Sigma)$, $\EE(fg|\Sigma) = g \EE(f|\Sigma)$. This is because for any $E \in \Sigma$ with $|E| < \infty$, $\EE(f \mathbf{I}_E | \Sigma) = \mathbf{I}_E \EE(f|\Sigma)$ is uniquely defined since $f \mathbf{I}_E \in L^2(\Sigma_0)$, and taking $E \to \infty$ by $\sigma$ finiteness.

A simple consequence of the uniform boundedness of these operators on the various $L^p$ spaces is that if $\Sigma_1, \Sigma_2, \dots$ are a family of $\sigma$ algebras, and $\Sigma_\infty$ is the smallest $\sigma$ algebra containing all sets in $\bigcup_{i = 1}^\infty \Sigma_i$, then for each $1 \leq p < \infty$, and for each $f \in L^p(\Sigma_0)$, $\lim_{i \to \infty} \EE(f|\Sigma_i) = \EE(f|\Sigma_\infty)$. This is because the operators $\{ \EE(\cdot|\Sigma_i) \}$ are uniformly bounded. The limit equation holds for any simple function $f$ composed of sets in $\bigcup_{i = 1}^\infty \Sigma_i$, and a $\sigma$ algebra argument can then be used to show this family of simple functions is dense in $L^p(\Sigma_0)$.
\end{example}

It was an important observation of Elias-Stein that complex interpolation can be used not only with a single operator $T$, but with an `analytic family' of operators $\{ T_s \}$, one for each $s$, such that for each pair of simple functions $f$ and $g$, the function
%
\[ \int (T_s f)(y) g(y) \]
%
is analytic in $s$. Thus bounds on $T_{0+it}$ and $T_{1 + it}$ imply intermediary bounds on all other operators, provided that we still have at most doubly exponential growth. The next theorem gives an example application.

\begin{theorem}[Stein-Weiss Interpolation Theorem]
  Let $T$ be a linear operator, and let $w_0, w_1: X \to [0,\infty)$ and $v_0, v_1 : Y \to [0,\infty)$ be weights which are integrable on every finite-measure set. Suppose that
  %
  \[ \| Tf \|_{L^{q_0}(X,v_0)} \leq A_0 \| f \|_{L^{p_0}(X,w_0)}\quad\text{and}\quad \| Tf \|_{L^{q_1}(X,v_1)} \leq A_1 \| f \|_{L^{p_1}(X,w_0)}. \]
  %
  Then for any $\theta \in (0,1)$,
  %
  \[ \| Tf \|_{L^{q_\theta}(X,v_\theta)} \leq A_\theta \| f \|_{L^{p_\theta}(X,w_\theta)}, \]
  %
  where $w_\theta = w_0^{1-\theta} w_\theta$ and $v_\theta = v_0^{1-\theta} v_1^\theta$.
\end{theorem}
\begin{proof}
  Fix a simple function $f$ with $\| f \|_{L^{p_\theta}(X,w_\theta)}$. We begin with some simplifying assumptions. A monotone convergence argument, replacing $w_i(t)$ with
  %
  \[ w_i'(y) = \begin{cases} w_i(y) &: \varepsilon \leq w_i(t) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then taking $\varepsilon \to 0$, enables us to assume without loss of generality that $w_0$ and $w_1$ are both bounded from below and bounded from above. Truncating the support of $Tf$ enables us to assume that $Y$ has finite measure. Since $f$ has finite support, we may also assume without loss of generality that $X$ has finite support, and by applying the dominated convergence theorem we may replace the weights $v_i$ with
  %
  \[ v_i'(x) = \begin{cases} v_i(x) &: \varepsilon \leq v_i(x) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then take $\varepsilon \to 0$. Thus we can assume that the $v_i$ are bounded from above and below. Restricting to the support of $X$, we can also assume $X$ has finite measure.

  For each $s$, consider the operator $T_s$ defined by
  %
  \[ T_s f = w_0^{\frac{1-s}{q_0}} w_1^{\frac{s}{q_1}} T \left( f v_0^{- \frac{1-s}{p_0}} v_1^{-\frac{s}{p_1}} \right). \]
  %
  The fact that all functions involved are simple means that the family of operators $\{ T_s \}$ is analytic. Now for all $t \in \RR$
  %
  \[ \| T_{it} f \|_{L^{q_0}(Y)} = \| T f \|_{L^{q_0}(Y,w_0)} \leq A_0 \| f v_0^{-1/p_0} \|_{L^{p_0}(X,v_0)} = A_0 \| f \|_{L^{p_0}(X)}. \]
  %
  For similar reasons, $\| T_{1 + it} f \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_0}(X,v_0)}$. Thus the Stein variant of the Riesz-Thorin theorem implies that
  %
  \[ \| T_\theta f \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}. \]
  %
  But this, of course, is equivalent to the bound we set out to prove.
\end{proof}

\section{Real Interpolation of Operators}

Now we consider the case of real interpolation. One advantage of real interpolation is that it can be applied to sublinear as well as linear operators, and requires weaker endpoint estimates that the complex case. A disadvantage is that, usually, the operator under study cannot vary, and we lose out on obtaining explicit bounds.

A strong advantage to using real interpolation is that the criteria for showing boundedness at the endpoints can be reduced considerably. Let us give names for the boundedness we will want to understand for a particular operator $T$.
%
\begin{itemize}
  \item We say $T$ is \emph{strong type} $(p,q)$ if $\| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{weak type} $(p,q)$ if $\| Tf \|_{L^{q,\infty}(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{restricted strong type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^q(Y)} \lesssim HW^{1/p} \]
  %
  for any sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^q(Y)} \lesssim |E|^{1/p}. \]
  %
  The equivalence is proven by breaking any sub-step function $f$ with height $H$ and width $W$ into a dyadic sum $\sum_{k = 1}^\infty H \mathbf{I}_{E_k} 2^{-k}$, where $|E_k| \leq W$.

  \item We say $T$ is \emph{restricted weak type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^{q,\infty}(Y)} \lesssim HW^{1/p} \]
  %
  for all sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^{q,\infty}(Y)} \lesssim |E|^{1/p}. \]
\end{itemize}
%
An important tool for us will be to utilize duality to make our interpolation argument `bilinear'. Let us summarize this tool in a lemma. Proving the lemma is a simple application of Theorem \ref{weakdualitytheorem}.

\begin{lemma}
  Let $0 < p < \infty$ and $0 < q < \infty$. Then an operator $T$ is restricted weak-type $(p,q)$ if and only if for any finite measure sets $E \subset X$ and $F \subset Y$, there is $F' \subset Y$ with $|F'| \geq \alpha |F|$ such that
  %
  \[ \int_{F'} |T(\mathbf{I}_E)| \lesssim_\alpha |E|^{1/p} |F|^{1-1/q}. \]
\end{lemma}

Scalar interpoation leads to a simple version of real interpolation, which we employ as a subroutine to obtain a much more powerful real interpolation principle.

\begin{lemma}
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$. If $T$ is restricted weak type $(p_0,q_0)$ and $(p_1,q_1)$, then $T$ is restricted weak type $(p_\theta,q_\theta)$ for all $\theta \in (0,1)$.
\end{lemma}
\begin{proof}
  By assumption, if $E \subset X$ and $F \subset Y$, then there is $F_0, F_1 \subset Y$ with $|F_i| \geq (3/4)|F|$ such that
  %
  \[ \int_{F_i} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_i|^{1 - 1/q_i}. \]
  %
  If we let $F_\theta = F_0 \cap F_1$, then $|F_\theta| \geq |F|/2$, and for each $i$,
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_\theta|^{1 - 1/q_i}. \]
  %
  Scalar interpolation implies
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_\theta} |F_\theta|^{1 - 1/q_\theta}, \]
  %
  and thus we have shown
  %
  \[ \| T(\mathbf{I}_E) \|_{q_\theta,\infty} \lesssim |E|^{1/p_\theta}. \]
  %
  This is sufficient to show $T$ is restricted weak type $(p_\theta,q_\theta)$.
\end{proof}

\begin{theorem}[Marcinkiewicz Interpolation Theorem]
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$, and suppose $T$ is restricted weak type $(p_i,q_i)$, with constant $A_i$, for each $i$. Then, for any $\theta \in (0,1)$, if $q_\theta > 1$, then for any $0 < r < \infty$, then
  %
  \[ \| Tf \|_{L^{q_\theta,r}(Y)} \lesssim A_\theta \| f \|_{L^{p_\theta,r}(X)}, \]
  %
  with implicit constants depending on $p_0, p_1, q_0$, and $q_1$.
\end{theorem}
\begin{proof}
  By scaling $T$, and the measures on $X$ and $Y$, we may assume that $\| f \|_{L^{p_\theta,r}(X)} \leq 1$, and that $T$ is restricted type $(p_i,q_i)$ with constant $1$, so that for any step function $f$ with height $H$ and width $W$,
  %
  \[ \| Tf \|_{L^{q_i,\infty}(Y)} \leq \| f \|_{L^{p_i}(X)}. \]
  %
  By duality, using the fact that $q_\theta > 1$, it suffices to show that for any simple function $g$ with $\| g \|_{L^{q_\theta',r'}(Y)} = 1$,
  %
  \[ \int |Tf| |g| \leq 1. \]
  %
  Using the previous lemma, we can `adjust' the values $q_0,q_1$ so that we can assume $q_0,q_1 > 1$. We can perform a horizontal layer decomposition, writing
  %
  \[ f = \sum_{i = -\infty}^\infty f_i, \quad\text{and}\quad g = \sum_{i = -\infty}^\infty g_i, \]
  %
  where $f_i$ and $g_i$ are sub-step functions with width $2^i$ and heights $H_i$ and $H_i'$ respectively, and if we write $A_i = H_i 2^{i/p_\theta}$, and $B_i = H_i' 2^{i/q_\theta}$, then
  %
  \[ \| A \|_{l^r(\ZZ)}, \| B \|_{l^{r'}(\ZZ)} \lesssim 1. \]
  %
  Applying the restricted weak type inequalities, we know for each $i$ and $j$,
  %
  \[ \int |Tf_i| |g_j| \lesssim H_i H_j \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]. \]

  Applying sublinearity (noting that really, the decomposition of $f$ and $g$ is finite, since both functions are simple). Thus
  %
  \begin{align*}
    \int |Tf| |g| &\leq \sum_{i,j} \int |Tf_i| |g_j|\\
    &\lesssim \sum_{i,j} H_i H_j' \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]\\
    &\lesssim \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right].
  \end{align*}
  %
  If $i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k) = \varepsilon(i + \lambda j)$, where $\varepsilon = (1/p_k - 1/p_\theta)$. We then have
  %
  \[ \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right] \sim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor}. \]
  %
  Applying H\"{o}lder's inequality,
  %
  \begin{align*}
    \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\leq \| A \|_{l^r(\ZZ)} \left( \sum_i |B_{k - \lfloor i/\lambda \rfloor}|^{r'} \right)^{1/r'}\\
    &\lesssim \lambda^{1/r'} \| A \|_{l^r(\ZZ)} \| B \|_{l^{r'}(\ZZ)} \lesssim 1.
  \end{align*}
  %
  Thus we conclude that
  %
  \begin{align*}
    \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\lesssim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \lesssim_\varepsilon 1. \qedhere
  \end{align*}
\end{proof}

There are many variants of the real interpolation method, but the general technique almost always remains the same: incorporate duality, decompose inputs, often dyadically, bound these decompositions, and then sum up.










\chapter{Basic Integral Operator Estimates}

We now consider a very general class of operators, which can be seen as the infinite dimensional analogue of matrix multiplication, replacing summation over coordinates by integration. We fix two measure spaces $X$ and $Y$, and consider a function (or, if $X$ and $Y$ are smooth manifolds, distributions) $K: X \times Y \to \CC$, which we call a \emph{kernel}. From this kernel, if $K$ is suitably regular, we obtain an induced operator $T_K$ taking functions on $X$ to functions on $Y$, given, heuristically at least, by the integral formula
%
\[ (T_K f)(y) = \int_X K(x,y) f(x)\; dx. \]
%
Our goal is to relate properties of the kernel $K$ to the behaviour of the operator $T_K$.

\begin{example}
  Let $X = \{ 1, \dots, N \}$ and $Y = \{ 1, \dots, M \}$, each equipped with the counting measure. Then each kernel $K$ corresponds to an $M \times N$ matrix $A$, with $A_{ij} = K(j,i)$. For any $f: X \to Y$ we can define a vector $v \in \RR^N$ by setting $v_i = f(i)$, and then
  %
  \[ (T_K f)(m) = \sum_{n = 1}^N f(n) K(n,m) = \sum_{n = 1}^N A_{mn} v_n = (Av)_m. \]
  %
  Thus with respect to the standard basis, $T_K$ is just given by matrix multiplication by $A$.
\end{example}

\begin{example}
  Let $X = Y = \RR^d$, and let $K(x,y) = e^{2 \pi i x \cdot y}$, then using this function as a kernel we can obtain an integral operator
  %
  \[ (T f)(y) = \int f(x) e^{2 \pi i x \cdot y}\; dx. \]
  %
  This is just the Fourier transform in disguise. One can define $Tf$ directly by this integral (viewed as a Lebesgue integral) for any $f \in L^1(\RR^d)$, in which the integrand will be absolutely integrable. We also know that for any $f \in L^1(\RR^d)$,
  %
  \[ \| T f \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}. \]
  %
  We also know from the classical Hausdorff-Young inequality that if $1 \leq p \leq 2$, then for any $f \in L^1(\RR^d) \cap L^p(\RR^d)$,
  %
  \[ \| T f \|_{L^{p^*}(\RR^d)} \leq \| f \|_{L^p(\RR^d)}. \]
  %
  In particular, this means that there exists a unique extension of $T$ to a bounded operator from $L^p(\RR^d)$ to $L^{p^*}(\RR^d)$; note, however, that for a general element $f \in L^p(\RR^d)$, the integral formula
  %
  \[ \int f(x) e^{2 \pi i \xi \cdot x}\; dx \]
  %
  is \emph{not well-defined} in the Lebesgue sense. Thus we can only heuristically view the integral formula as defining the integral operator. There are two approaches to defining an integral operator $T$ on more general classes of functions. The method above, is to work with a dense family of more regular functions for which the integral formula makes sense, and then to prove uniform estimates in this family of inputs. Another method is to replace the kernel in the integral formula $T$ with a family of kernels converging to our original kernel, and then to prove uniform estimates in this family. For instance, one might instead study the family of truncated Fourier integrals
  %
  \[ T_R f(y) = \int_{|x| \leq R} e^{2 \pi i x \cdot y} f(x)\; dx \]
  %
  which are well defined for any $f \in L^1_{\text{loc}}(\RR^d)$, and then prove that for $1 \leq p \leq 2$,
  %
  \[ \| T_R f \|_{L^{p^*}(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \]
  %
  uniformly in $R$, which is sufficient justification to define $Tf$ as the $L^p(\RR^d)$ limit of $T_R f$ as $R \to \infty$, for $f \in L^p(\RR^d)$, since this limit can be easily justified to exist for $f \in L^1(\RR^d) \cap L^p(\RR^d)$.
\end{example}








\section{Schur's Lemma}

It is a useful heuristic that determining the boundedness of the operator $T$ mapping \emph{from} $L^1(X)$, or \emph{into} $L^\infty(Y)$ is almost always trivial. This is one motivation for introducing the intermediate $L^p$ norms, since these norms enable us to extract more features out of the kernel operator $K$. Before we discuss this, we must first reflect on the fact that without even qualitative knowledge of the kernel $K$ besides it's measurability, it is difficult to know how one might interpret the integral formula defining the operator. A natural trick to begin with is to introduce the sublinear analogue of the kernel operator, i.e. the operator $S_K$ defined by setting
%
\[ (S_K f)(y) = \int_X |K(x,y)| |f(x)|\; dx \]
%
The flexibility of the theory of non-negative Lebesgue integrals means this operator is well defined for \emph{any} measurable $f$. Moreover, if we are to interpret the integral formula for $(T_K f)(y)$ in the Lebesgue sense, it is necessary and sufficient that $(S_K f)(y) < \infty$.

\begin{theorem}
  Fix $q \geq 1$. Then
  %
  \[ \| S_K f \|_{L^q(Y)} \leq \| K \|_{L^\infty(X) L^q(Y)} \| f \|_{L^1(X)}. \]
  %
  Thus $T_K f(y)$ are well defined by a Lebesgue integral for almost every $y \in Y$, and
  %
  \[ \| T_K f \|_{L^q(Y)} \leq \| K \|_{L^\infty(X) L^q(Y)} \| f \|_{L^1(X)}. \]
\end{theorem}
\begin{proof}
  The proof is a simple consequence of Minkowski's inequality, i.e.
  %
  \begin{align*}
    \| S_K f \|_{L^q(Y)} &= \| K f \|_{L^q(Y) L^1(X)} \leq \| Kf \|_{L^1(X) L^q(Y)} \leq \| K \|_{L^\infty(X) L^q(Y)} \| f \|_{L^1(X)}. \qedhere
  \end{align*}
\end{proof}

\begin{remark}
  In many situations, this result is tight. For instance, suppose
  %
  \[ K = \sum_{i = 1}^N \sum_{j = 1}^M a_{ij} \mathbf{I}_{E_i \times F_j} \]
  %
  where $E_1,\dots,E_N$ and $F_1,\dots,F_N$ are disjoint finite measure sets. Then there exists $i \in \{ 1, \dots, N \}$ such that for each $x \in E_i$,
  %
  \[ \left( \int |K(x,y)|^q\; dy \right)^{1/q} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^\infty(X) L^q(Y)}. \]
  %
  If $f = \mathbf{I}_{E_i}$, then $\| f \|_{L^1(X)} = |E_i|$, and $T_K f = \sum_{j = 1}^M a_{ij} \mathbf{I}_{F_j}$, so
  %
  \[ \| T_K f \|_{L^q(Y)} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^\infty(X) L^q(Y)} \| f \|_{L^1(X)}. \]
  %
  Thus we conclude that for a certain `dense' family of kernels $K$, the inequality above is tight. This gives a strong heuristic that the inequality above is tight for a great many operators $K$, which trivializes the analysis of $L^1(X) \to L^q(Y)$ estimates. It is difficult to come up with a general statement of this form, because we require some regularity in the kernel to even formulate the operators under study. But by taking monotone limits we can at least justify that the norm of $S_K$ from $L^1(X)$ to $L^q(Y)$ is given by $\| K \|_{L^\infty(X) L^q(Y)}$.
\end{remark}

A dual statement trivializes the analysis of bounds from $L^p(X)$ to $L^\infty(Y)$.

\begin{theorem}
  Suppose $1 \leq p \leq \infty$. Then
  %
  \[ \| S_K f \|_{L^\infty(Y)} \leq \| K \|_{L^\infty(Y) L^{p^*}(X)} \| f \|_{L^p(X)}. \]
  %
  Thus if $\| K \|_{L^{p^*}(X) L^\infty(Y)} < \infty$, then $T_K f(y)$ is well defined for almost every $y \in Y$, and
  %
  \[ \| T_K f \|_{L^\infty(Y)} \leq \| K \|_{L^\infty(Y) L^{p^*}(X)} \| f \|_{L^p(X)}. \]
\end{theorem}
\begin{proof}
  One option to proving this bound is to take the adjoint of the kernel operator $T_K$ and rely on previous estimates, but we can work more directly. Applying H\"{o}lder's inequality, we conclude that
  %
  \[ \| S_K f \|_{L^\infty(Y)} = \| K f \|_{L^\infty(Y) L^1(X)} \leq \| K \|_{L^\infty(Y) L^{p^*}(X)} \| f \|_{L^p(X)}. \qedhere \]
\end{proof}

Though trivial, the two kernel bounds can often be applied together with an interpolation argument to give more sophisticated bounds.

\begin{theorem}[Schur's Test]
  Fix $1 \leq r \leq \infty$, and suppose that
  %
  \[ \| K \|_{L^\infty(X) L^r(Y)} \leq A \]
  %
  and
  %
  \[ \| K \|_{L^\infty(Y) L^r(X)} \leq B. \]
  %
  Then if $1 \leq p \leq q \leq \infty$ satisfy $1/p + 1/r = 1/q + 1$, then for $f \in L^p(X)$, $(T_K f)(y)$ is well defined by an absolutely convergent integral for almost every $y$, and
  %
  \[ \| T_K f \|_{L^q(Y)} \leq A^{r/q} B^{1 - r/q} \| f \|_{L^p(X)}. \]
\end{theorem}
\begin{proof}
  The previous two results imply that $S_K$ is bounded from $L^1(X)$ to $L^r(Y)$ and from $L^{r^*}(X)$ to $L^\infty(Y)$. Real interpolation (we cannot use complex interpolation since $S_K$ is sublinear) shows that $S_K$ is bounded from $L^p(X)$ to $L^q(Y)$ for the $p$ and $q$ satisfying the conditions above. This means $S_K f(x)$ is well defined for almost every $x \in X$, so the operator $T_K$ is well defined by Lebesgue integrals for $f \in L^p(X)$. Applying the Riesz-Thorin interpolation theorem to $T_K$, which satisfies the bounds
  %
  \[ \| T_K f \|_{L^r(Y)} \leq A \| f \|_{L^1(X)} \]
  %
  and
  %
  \[ \| T_K f \|_{L^\infty(Y)} \leq B \| f \|_{L^{r^*}(X)}, \]
  %
  we obtain the required result.
\end{proof}

\begin{example}
    Here is a version of Schur's Lemma that is more hands on and illustrative of the result. Let $M$ be an $m \times n$ matrix, such that the sums of the absolute values of the entries of $M$ on each row are upper bounded by $A$, and the sums of the absolute values of the entries of $M$ on each column are upper bounded by $B$. Then for $x \in \RR^n$, we have
    %
    \[ |Mx| \leq \sqrt{AB} \cdot |x|. \]
\end{example}

\begin{example}
    Young's Inequality can be justified by Schur's lemma, over any locally compact group $G$ equipped with a Haar measure. Indeed, for a fixed $g$, the kernel of the operator $Cf =  f * g$ is given by
    %
    \[ K(x,y) = g(x^{-1} y) \]
    %
    and then
    %
    \[ \| K \|_{L^\infty_x(G) L^r_y(G)} = \| g \|_{L^r(G)} \]
    %
    and
    %
    \[ \| K \|_{L^\infty_y(G) L^r_x(G)} = \| g \|_{L^r(G)} \]
    %
    so Schur's Lemma shows that for $1/p + 1/r = 1/q + 1$,
    %
    \[ \| f * g \|_{L^q(G)} = \| Cf \|_{L^q(G)} \leq \| f \|_{L^p(G)} \| g \|_{L^r(G)}. \]
\end{example}

\begin{example}
    We cannot use Schur's Lemma to bound the fractional integration operators
    %
    \[ T_1f(y) = \int \frac{f(x)}{|x - y|^{d-s}}\; dx \]
    %
    since the kernel $K_1(x,y) = 1/|x-y|^{d-s}$ does not lie in any of the spaces $L^p(X)$. On the other hand, we can use Schur's Lemma to bound the modified fractional integration operators
    %
    \[ T_2 f(y) = \int \frac{f(x)}{\langle x - y \rangle^{d-s}}\; dx, \]
    %
    where $\langle t \rangle = (1 + |t|^2)^{1/2}$ is the Japanese bracket. The kernel
    %
    \[ K_2(x,y) = 1/\langle x - y \rangle^{d-s} \]
    %
    lies in $L^\infty_x(\RR^d) L^r_y(\RR^d)$ and $L^\infty_y(\RR^d) L^r_x(\RR^d)$ provided that $r > d/(d-s)$. Thus Schur's Lemma implies that for $1/p - 1/q > s/d$,
    %
    \[ \| T_2 f \|_{L^q(\RR^d)} \lesssim_{d,s,p,q} \| f \|_{L^p(X)}. \]
    %
    We will obtain a weak-type version of Schur's test which will enable us to bound $T_1$ later in this section.
\end{example}

For $1 < p < \infty$, we do not expect Schur's test to be sharp in general. But a good heuristic is that a variant of the inequality can be made to be sharp provided that two properties hold:
%
\begin{itemize}
  \item For all $y \in Y$,
  %
  \[ \int |K(x,y)|\; dx \approx A \]
  %
  and for all $x \in X$,
  %
  \[ \int |K(x,y)|\; dy \approx B. \]
  %
  This kind of homogeneity will be present if $K(x,y) = k(x-y)$ is a convolution kernel.

  \item There is little oscillation in the kernel $K$.
\end{itemize}
%
Assuming for simplicity that $X$ and $Y$ have finite measure, from the first property we conclude that
%
\[ A |Y| \approx B |X|. \]
%
Thus if we set $f = \mathbf{I}_X$, then $Tf(y) \approx A$ for all $y \in Y$, hence
%
\[ \| Tf \|_{L^p(Y)} \approx A |Y|^{1/p} \approx A^{1 - 1/p} B^{1/p} |X|^{1/p}. \]
%
Thus we have tightness. If the second property remains true, but the first property fails, Schur's lemma still may remain sharp if we consider a weighted inequality, or alternatively, if we decompose the operator into components on which the marginal is approximately constant.

In some senses, if we are allowed to work with arbitrary weights, and if $K \geq 0$, Schur's test is always sharp. Suppose that
%
\[ \| T_K f \|_{L^p(Y)} \leq A \| f \|_{L^p(X)} \]
%
for all $f \in L^p(X)$, and this inequality is sharp for some particular function $f_0$. We may assume without loss of generality that $\| f_0 \|_{L^p(X)} = 1$ and, since $K$ is non-negative, that $f \geq 0$. Thus
%
\[ \int_Y (T_K f_0(y))^p\; dy = A^p. \]
%
An application of Lagrangian multipliers and basic calculus of variations then shows that there exists a scalar $\lambda$ such that
%
\[ T_K^*((T_K f)^{p-1})(x) = \lambda f(x)^{p-1}. \]
%
But this means that
%
\begin{align*}
  \lambda &= \int \lambda f(x)^p\; dx\\
  &= \int f(x)T_K^*((T_K f)^{p-1})(x)\; dx\\
  &= \int (T_K f)^p(x) = A^p.
\end{align*}
%
Thus if we set $w(x) = f(x)$ and $v(y) = (T_K f(y))^{p-1}$, then
%
\[ \int_X K(x,y) w(x)\; dx = v(y)^{1/(p-1)} \]
%
and
%
\[ \int_Y K(x,y) v(y)\; dy = A^p w(x)^{p-1}. \]
%
Using these estimates, a weighted variant of Schur's lemma, carried out in particular for the next example, gives the bound
%
\[ \| T_K f \|_{L^p(X)} \leq A \| f \|_{L^p(X)}, \]
%
which shows that the two weighted identities above contain as much information as the original bound.

\begin{example}
    Let us consider an example where a weighted estimate can give better results about a particular operator.  Consider the operator
    %
    \[ Tf(y) = \frac{1}{\pi} \int_0^\infty \frac{f(x)}{x + y}\; dx. \]
    %
    The kernel of this operator is
    %
    \[ K(x,y) = \frac{1}{\pi} \frac{1}{x + y}. \]
    %
    Since $K$ is monotonically decreasing in $y$, maximizers for this inequality must be monotonically decreasing, with a singularity at the origin. The worst case singularity we can have near the origin while remaining close to being in $L^2$ is a singularity of the form $x^{-1/2}$. Thus we plug in $f(x) = x^{-1/2}$ into the operator $T$. Then we calculate that
    %
    \begin{align*}
        Tf(y) &= \frac{1}{\pi} \int_0^\infty \frac{1}{x^{1/2} (x + y)}\; dx\\
        &\sim \int_0^y \frac{1}{x^{1/2} y} + \int_y^\infty \frac{1}{x^{3/2}}\; dx \sim y^{-1/2}.
    \end{align*}
    %
    Thus if we let $w(x) = x^{-1/2}$, and $v(y) = y^{-1/2}$, then we have already calculated that
    %
    \[ \int K(x,y) [w(x) / v(y)]\; dx \lesssim 1. \]
    %
    Similarily,
    %
    \[ \int K(x,y) [v(y) / w(x)]\; dy \lesssim 1. \]
    %
    Define
    %
    \[ K_t(x,y) = K(x,y) w(x)^{2t - 1} v(y)^{1-2t}. \]
    %
    Then $\{ K_t \}$ is an analytic family of kernels giving us an analytic family of operators $\{ T_t \}$, to which we can apply complex interpolation. The oscillation does not cause us a problem. For $t = 0$, we obtain that
    %
    \[ \| T_0 f \|_{L^1(\RR^+)} \lesssim \| f \|_{L^1(\RR^+)}. \]
    %
    For $t = 1$, we obtain that
    %
    \[ \| T_1 f \|_{L^\infty(\RR^+)} \lesssim \| f \|_{L^\infty(\RR^+)}. \]
    %
    For $t = 1/2$, we therefore obtain by interpolation that
    %
    \[ \| T_{1/2} f \|_{L^2(\RR^+)} \lesssim \| f \|_{L^\infty(\RR^+)}. \]
    %
    But $T_{1/2} = T$, which means we have proved the required boundedness statement.

    We can also get $L^p$ bounds for all $1 < p < \infty$ (the case $p = 1$ or $p = \infty$ is not possible). To do this, we obtain a weak type bound from $L^1(\RR^+)$ to $L^{1,\infty}(\RR^+)$ by proving that for $f \in L^1(\RR^+)$,
    %
    \[ Tf(y) \lesssim \| f \|_{L^1(\RR^+)} / y, \]
    %
    from which it follows that $\| Tf \|_{L^{1,\infty}(\RR^+)} \lesssim \| f \|_{L^1(\RR^+)}$. To prove this result, we note that for $f \geq 0$,
    %
    \[ Tf(y) = \int \frac{f(x)}{x + y} \lesssim \int_0^y \frac{f(x)}{y}\; dx + \int_y^\infty \frac{f(x)}{x}\; dx \lesssim \| f \|_{L^1(\RR^+)} / y + \| f \|_{L^1(\RR^+)} / y. \]
    %
    Real interpolation gives bounds from $L^p(\RR^+)$ to $L^p(\RR^+)$ for $1 < p \leq 2$, and then duality (and the fact $T$ is self-adjoint, apply boundedness for $2 \leq p < \infty$).
\end{example}

%    \begin{comment}
%    To prove this bound, consider an arbitrary input $f$ with $\| f \|_{L^1(\RR^+)} = 1$. Without loss of generality, we may assume $f$ is monotonically decreasing and non-negative. Consider an increasing sequence $\{ a_i : i \in \ZZ \}$, such that $2^{-i} \leq f(x) \leq 2^{1-i}$ for $x \in [a_i,a_{i+1}]$. Then
%    %
%    \[ \sum_{i = -\infty}^\infty 2^{-i} a_i \lesssim 1. \]
%    %
%    Write $f_i = 2^{-i} \mathbf{I}_{[0,a_i]}$, so that we have a pointwise bound $Tf \lesssim \sum_i Tf_i$. Now
%    %
%    \[ Tf_i(y) = 2^{-i} \int_0^{a_i} 1 / (x + y)\; dx. \]
%    %
%    Then for $y \geq a_i$, we have
%    %
%    \[ T f_i(y) \sim 2^{-i} a_i / y, \]
%    %
%    and for $y \leq a_i$, we have
%    %
%    \[ Tf_i(y) \sim 2^{-i}(1 + \log(a_i / y)) \lesssim 2^{-i} a_i / y. \]
%    %
%    Thus we can sum up, and conclude that
%    %
%    \[ Tf(y) \lesssim \sum_i 2^{-i} a_i / y \lesssim 1 / y. \]
%    %
%    Thus $\| Tf \|$
%
%    Now fix $k$, and let us try and control the set
%    %
%    \[ \{ y \in \RR^+: Tf_i(y) \geq 2^{-k} \}. \]
%    %
%    \[ 1 + \log(x) \leq x \]
%
%
%    We may assume without loss of generality that $f$ is monotonic. Now if $Tf(100) \geq 1$, then
%    %
%    \[ \int f(y) / (100 + y) \geq 1 \]
%
 %   If $\| f \|_{L^1(\RR^+)} = 1$, and $x \geq 1$, then
    %
  %  \[ \int f(y) / (x + y) \geq 1 \]
%
 %   If $f(x) = H \mathbf{I}(x \leq 1/H)$, then $Tf(y) \sim 1/y$ for $y \geq 1/H$, and for $y \sim H/2^k$, $Tf(x) \sim k H$.
%
 %   for $1/2H \leq y \leq 1/H$, $Tf(y) \sim H$, and for $0 < y < 1/2H$, $Tf(x) \sim H \log(1/H)$.
%
  %  and for $y \leq 1/H$, $Tf(y) \sim H \log(1/H) - \log(y)$.
    %
    %
 %   \[ Tf(x) = \int_0^y \frac{H}{y}\; dx + \int_y^{1/H} H [\log(1/H) - \log(y)] \frac{H}{x}\; dx \]
 %   \end{comment}

As another example of the trivial nature of the boundedness of kernel operators from $L^1(X)$, let us consider a version of Schur's Lemma that characterizes the boundedness from the $L^1(X)$ norm to a suitable family of Lorentz spaces, and from those Lorentz spaces to $L^\infty(Y)$.

\begin{theorem}
    Fix $1 < q \leq \infty$ and $1 \leq s \leq \infty$. Then
    %
    \[ \| S_K f \|_{L^{q,s}(Y)} \lesssim_{q,s} \| K \|_{L^\infty(Y) L^{q,s}(X)} \| f \|_{L^1(X)}, \]
    %
    which means $T_K f$ is well-defined as a Lebesgue integral for $f \in L^1(X)$, and satisfies equivalent bounds. If $0 < p \leq \infty$, and $1 \leq s \leq \infty$, then
    %
    \[ \| S_K f \|_{L^\infty(Y)} \lesssim_{p,s} \| K \|_{L^\infty(X) L^{p^*,s^*}(Y)} \| f \|_{L^{p,s}(X)}. \]
    %
    Thus $T_K f$ is well defined as a Lebesgue integral for $f \in L^{p,s}(X)$, and satisfies equivalent bounds. In particular, if $1 < r < \infty$, and
    %
    \[ \| K \|_{L^\infty(Y) L^{r,\infty}(X)} \leq A, \]
    %
    and
    %
    \[ \| K \|_{L^\infty(X) L^{r,\infty}(Y)} \leq B, \]
    %
    for some $1 < r < \infty$, then for $1 < p < q < \infty$ with $1/p + 1/r = 1/q + 1$, and any $0 < s \leq \infty$,
    %
    \[ \| S_K f \|_{L^{q,s}(X)} \lesssim_{p,q,r,s} A^{r/q} B^{1 - r/q} \| f \|_{L^{p,s}(Y)}. \]
\end{theorem}
\begin{proof}
    The space $L^{q,s}(Y)$ is a norm space for $q > 1$, so we can employ Minkowski's inequality to conclude that
    %
    \[ \| S_K f \|_{L^{q,s}(Y)} = \| S_K f \|_{L^{q,s}(Y) L^1(X)} \lesssim \| S_K f \|_{L^1(X) L^{q,s}(Y)}. \]
    %
    And then we conclude
    %
    \[ \| S_K f \|_{L^1(X) L^{q,s}(Y)} \leq \| K \|_{L^\infty(X) L^{q,s}(Y)} \| f \|_{L^1(X)} \]
    %
    which proves the first claim. To obtain the second claim, we apply H\"{o}lder's inequality in the $L^{p,q}$ norms, which shows that
    %
    \[ \| S_K f \|_{L^\infty(Y)} = \| K f \|_{L^\infty(Y) L^1(X)} \lesssim_{p,s} \| K \|_{L^\infty(Y) L^{p^*,s^*}(X)} \| f \|_{L^{p,s}(X)}. \qedhere \]
\end{proof}

\begin{remark}
    Establishing bounds from $L^1(X)$ to $L^{1,\infty}(Y)$ can be much more subtle than indicated by the other results here, e.g. for the Hardy-Littlewood Maximal function or for the Hilbert transform.
\end{remark}

\begin{example}
    For $s > 0$, and $f \in L^1(\RR^d) \cap L^\infty(\RR^d)$, we can define
    %
    \[ Tf(x) = \int \frac{f(y)}{|y-x|^{d-s}}\; dy, \]
    %
    because $z \mapsto 1/|z|^{d-s}$ is integrable for $|z| \leq 1$, and bounded for $|z| \geq 1$. Applying the result above, since $1/|z|^{d-s}$ lies in $L^r(\RR^d)$ for $r = d/(d-s)$, we conclude that for $1 < p < q < \infty$ with $s = d(1/p - 1/q)$,
    %
    \[ \| Tf \|_{L^q(\RR^d)} \lesssim_{d,s,p,q} \| f \|_{L^p(\RR^d)}. \]
    %
    This is the \emph{Hardy-Littlewood-Sobolev} inequality.
\end{example}

If $T$ has kernel $K: X \times Y \to \CC$ which is \emph{square integrable}, then we find via H\"{o}lder's inequality that
%
\begin{align*}
    \| T f \|_{L^2(Y)}^2 &= \int_Y \left| \int_X K(x,y) f(x)\; dx \right|^2\; dy\\
    &\leq \int_Y \| K \|_{L^2_x}^2 \| f \|_{L^2_x}^2\; dy\\
    &= \| K \|_{L^2_x L^2_y}^2 \| f \|_{L^2_x}^2.
\end{align*}
%
Thus $\| T \|_{L^2 \to L^2} \leq \| K \|_{L^2(X \times Y)}$. The quantity $\| K \|_{L^2(X \times Y)}$ is the \emph{Hilbert-Schmidt}, or \emph{Frobenius} norm of the operator $T$. If this inequality is tight at all steps for some input $f$, then tightness for H\"{o}lder's inequality implies that there exists $a(y)$ for almost every $y$ such that $K(x,y) = a(y) \overline{f(x)}$, so that
%
\[ Tg(y) = a(y) \langle g, f \rangle \]
%
is a rank one operator. Heuristically, this means that employing the Hilbert-Schmidt / Frobenius norm will only yield good results when $T$ is a low rank operator. One of the main importances of the family of Hilbert-Schmidt integral operators is that they are \emph{compact}, since 




\section{Change of Variables}

TODO

On the other hand, it is not necessarily possible to change all variables in $\RR^n \times \RR^m$ without affecting the mapping properties of the operator. For instance, if $T$ is the circular means operator from $\RR^d$ to $\RR^d$, then $T$ has kernel $K(x,y) = \delta(1 - |x - y|)$. If we change variables simultaneously, for instance, letting $x = z + w$ and $y = w$, then we obtain the kernel $K'(z,w) = K(z + w, w) = \delta(1 - |z|)$ is independent of $w$, which has completely different mapping properties, in particular, the output of the kernel does not actually depend on the input.








\section{Localization In Space}

Localization is a fundamental technique in anlaysis, since it enables us to isolate certain parts of a function or operator. If we understand these localized parts, one can then often recover results about the original result using a partition of unity. By doing this, we can isolate different features of a function to be controlled.

Many of the techniques of harmonic analysis are only possible once localized. In other words, rather than proving estimates of the form
%
\[ \| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}, \]
%
we only prove estimates of the form
%
\[ \| T_{\phi_1, \phi_2} f \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)} \]
%
where $\phi_1$ and $\phi_2$ are supported on finite measure subsets of $X$ and $Y$, and $T_{\phi_1, \phi_2} f = \phi_1 T(\phi_2 f)$. Because of the localized nature of the problem, the difficulty of the bound increases as $q$ becomes larger, and as $p$ becomes smaller. If $T$ has a kernel $K \in L^\infty(\text{supp}(\phi_1) \times \text{supp}(\phi_2))$, then $T_{\phi_1, \phi_2}$ maps $L^1(\RR^d)$ to $L^\infty(\RR^d)$, which makes the study of the qualitative behaviour of $T_{\phi_1, \phi_2}$ with respect to the convex norms trivial. Working quantitatively, we should therefore expect studying localized estimates to depend on quantitative measures of the singular nature of $K$, e.g. most crudely, the $L^\infty$ norm. Because of the sensitivity to the singular nature of $K$, choosing $\phi_1$ and $\phi_2$ to be non-singular often makes the problem more amenable to analysis, e.g. if $X$ and $Y$ are smooth manifolds, it is often useful to assume $\phi_1 \in C_c^\infty(Y)$ and $\phi_2 \in C_c^\infty(X)$.

Intuitively, the smaller we make the kernel, the more well behaved the resulting operator will be. If $K$ is a non-negative kernel, then it is certainly true that the $L^p$ to $L^q$ boundedness of an operator $T$ with kernel $K$ implies the boundedness of an operator $T_\Omega$ with kernel $K \mathbf{I}_\Omega$ for any $\Omega \subset X \times Y$, since we will then have a pointwise bound $|T_\Omega(f)| \leq T(|f|)$. But if $K$ is not necessarily non-negative, then this is not necessarily true anymore, since $T$ may only be bounded because of more subtle cancellation properties.

\begin{example}
    Set $K(x,y) = e^{-2 \pi i x \cdot y}$, and let $\Omega \subset \RR^d \times \RR^d$ be the set of all pairs $(x,y)$ such that $\text{Re}(e^{- 2 \pi i x \cdot y}) \geq 0$. Then the operator $T$ with kernel $K$ is unitary, and thus bounded from $L^2(\RR^d)$ to $L^2(\RR^d)$. The operator $T_\Omega$ with kernel $K \mathbf{I}_\Omega$, on the other hand, is not bounded from $L^2(\RR^d)$ to $L^2(\RR^d)$, since, if $f = \mathbf{I}(|x| \leq R)$, then we will have $|T_\Omega f(y)| \gtrsim_d R^d$ for all $y \in \RR^d$, so that $T_\Omega f \not \in L^2(\RR^d)$.
\end{example}

There are several cases where we can perform an arbitrary truncation. If $p = 1$, or $q = \infty$, then the operator norm of $T$ with kernel $K$ depends solely on mixed $L^p$ norms of the kernel $K$, and thus behave well under truncation. Another case is if $\Omega = E \times F$, for then
%
\[ \| T_\Omega f \|_{L^q(Y)} = \| \mathbf{I}_E T(\mathbf{I}_F f) \|_{L^q(Y)} \leq \| T(\mathbf{I}_F f) \|_{L^q(Y)} \leq \| \mathbf{I}_F f \|_{L^p(X)} \leq \| f \|_{L^p(X)}. \]
%
Thus $\| T_\Omega \|_{L^p \to L^q} \leq \| T \|_{L^p \to L^q}$. Similarily, if $X = \RR^n$, $Y = \RR^m$, $\Omega_1 \subset \RR^n$ and $\Omega_2 \subset \RR^m$ are precompact open sets, $L_1: \RR^n \to \RR^n$ and $L_2: \RR^m \to \RR^m$ are invertible linear maps, and $\phi: \RR^n \times \RR^m \to \CC$ is a bump function adapted to $L_1(\Omega_1) \times L_2(\Omega_2)$, then
%
\[ \| T_{K \phi} \|_{L^p \to L^q} \lesssim_{\Omega_1,\Omega_2} \| T_K \|_{L^p \to L^q}. \]
%
The trick here is to replace $\phi$ with a tensor product using a density argument / Fourier series which reduces our study to block diagonal type truncations.

More generally, if we have a family of disjoint sets $\{ E_n \}$ and $\{ F_n \}$, then we can truncate to the \emph{block diagonal} region $\Omega = \bigcup (E_n \times F_n) = \bigcup \Omega_n$. The norm of such an operator can be calculated exactly from the behaviour on each subregion, as the next lemma shows.

\begin{lemma}
    Consider a family of Banach spaces $\{ X_n \}$ and $\{ Y_n \}$, and a family of bounded operators $T_n: X_n \to Y_n$. Then for $p \leq q$,
    %
    \[ \sup_{x_n \in X_n} \frac{\| T_n(x_n) \|_{l^q_n}}{\| x_n \|_{l^p_n}} = \sup_n \| T_n \|. \]
    %
    and if $p > q$, then
    %
    \[ \sup_{x_n \in X_n} \frac{\| T_n(x_n) \|_{l^q_n}}{\| x_n \|_{l^p_n}} = \| T_n \|_{l^r_n}, \]
    %
    where $1/p + 1/r = 1/q$.
\end{lemma}
\begin{proof}
    We calculate that for $p \leq q$,
    %
    \[ \| T_n(x_n) \|_{l^q_n} \leq \| T_n(x_n) \|_{l^p_n} \leq \| T_n \|_{l^\infty_n} \| x_n \|_{l^p_n}. \]
    %
    The converse bound for the supremum is simple. For $p > q$, H\"{o}lder's inequality implies that
    %
    \[ \| T_n(x_n) \|_{l^q_n} \leq \| \| T_n \| \| x_n \| \|_{l^q_n} \leq \| T_n \|_{l^r_n} \| x_n \|_{l^p_n}. \]
    %
    Conversely, if we pick $x_n$ with $\| x_n \| = 1$ for each $n$ such that $\| T_n(x_n) \| \geq (1 - \varepsilon) \| T_n \|$, and if we pick $a_n = \| T_n \|^{r/q - 1} = \| T_n \|^{r/p}$, then
    %
    \[ \| T_n(a_n x_n) \|_{l^q_n} \geq (1 - \varepsilon) \| \| T_n \|^{r/q} \|_{l^q_n} \geq (1 - \varepsilon) \| T_n \|_{l^r_n}^{r/q}, \]
    %
    whereas
    %
    \[ \| a_n x_n \|_{l^p_n} = \| \| T_n \|^{r/p} \|_{l^p_n} = \| T_n \|_{l^r_n}^{r/p}. \]
    %
    Thus
    %
    \[ \frac{\| T_n(a_n x_n) \|_{l^q_n}}{\| a_n x_n \|_{l^p_n}} \geq (1 - \varepsilon) \| T_n \|_{l^r_n}^{r/q - r/p} = (1 - \varepsilon) \| T_n \|_{l^r_n}. \]
    %
    Taking $\varepsilon \to 0$ gives the lower bound.
\end{proof}

A similar result holds for restriction to \emph{almost} block diagonal operators, i.e. operators of the form
%
\[ T = \sum_{(n,m) \in G} T_{nm} \]
%
where $T_{nm}: X_n \to Y_m$, and $G$ is a graph on the index set such that each node has degree at most $O(1)$. One can then break the graph into $O(1)$ many block diagonal operators $T_1, \dots, T_K$, from which we obtain that e.g. for $p \leq q$,
%
\[ \| T_{nm} x_n \|_{l^q_n} \lesssim \sup \| T_{nm} \|_{l^\infty_{nm}} \| x_n \|_{l^p_n}. \]
%
and for $p < q$,
%
\[ \| T_{nm} x_n \|_{l^q_n} \lesssim \| T_{nm} \|_{l^r_{nm}} \| x_n \|_{l^p_n}. \]
%
On the other hand, we certainly have 
%
\[ \frac{\sup_x \| T_{nm} x_n \|_{l^q_n}}{\| x_n \|_{l^p_n}} \geq \| T_{nm} \|_{l^\infty_{nm}}. \]
%
TODO: Do we have a $l^r$ lower bound as well, or not?

\section{The Christ-Kiselev Lemma}

We can also truncate to `upper triangular' diagonals rather than just block diagonals, provided that $q > p$. For $q = p$, we `lose a logarithm'.

\begin{theorem}[Christ-Kiselev]
    Consider an operator $T$ mapping functions on $X$ to functions on $Y$, consider subsets $\{ E_n \}$ of $X$ and subsets $\{ F_n \}$ of $Y$, and let
    %
    \[ \Omega = \bigcup_{n \leq m} E_n \times F_m. \]
    %
    Then if $1 \leq p < q \leq \infty$,
    %
    \[ \| T_\Omega \|_{L^p \to L^q} \lesssim_{p,q} \| T \|_{L^p \to L^q}. \]
    %
    If $1 \leq p \leq \infty$, and $n$ ranges over $\{ 1, \dots, N \}$, then
    %
    \[ \| T_\Omega \|_{L^p \to L^p} \lesssim \log(N) \cdot \| T \|_{L^p \to L^p}. \]
\end{theorem}
\begin{proof}
    Let us first address the case where $q > p$. We assume the index set is finite, i.e. $1 \leq n \leq N$ for some large $N > 0$, and prove the result by induction, though our constant will be independant of $N$ and thus give us results for infinite index sets by taking limits. Fix a large constant $A_{p,q}$. Then the base case $N = 1$ is automatically satisfied if $A_{p,q}$ is large enough. Without loss of generality, assume $\| T \|_{L^p \to L^q} = 1$, and consider $f \in L^p(X)$ with $\| f \|_{L^p(X)} = 1$. Our proof is complete if we can show $\| T_\Omega f \|_{L^q(Y)} \leq A_{p,q}$. The idea here is to divide and conquer in an intelligent way. We can find an index $0 \leq n_0 \leq N$ such that
    %
    \[ \| f \mathbf{I}_{E_{\leq n_0}} \|_{L^p(X)}^p \leq 1/2 < \| f \mathbf{I}_{E_{\leq n_0 + 1}} \|_{L^p(X)}^p. \]
    %
    Write $f_0 = f \mathbf{I}_{E_{\leq n_0}}$, $f_1 = f \mathbf{I}_{E_{n_0 + 1}}$, and $f_2 = f \mathbf{I}_{E_{\geq n_0 + 2}}$. Then $\| f_0 \|_{L^p(X)}, \| f_2 \|_{L^p(X)} \leq 1/2^{1/p}$. Applying induction, we have
    %
    \[ \| \mathbf{I}_{F_{\leq n_0}} T_\Omega f_0 \|_{L^q(Y)} \leq A_{p,q} 2^{-1/p} \]
    %
    and
    %
    \[ \| T_\Omega f_2 \|_{L^q(Y)} \leq A_{p,q} 2^{-1/p}. \]
    %
    On the other hand, the other restrictions are block diagonals, which gives
    %
    \[ \| \mathbf{I}_{F_{\geq n_0 + 1}} T_\Omega f_0 \|_{L^q(Y)} \leq 2^{-1/p}, \]
    %
    and
    %
    \[ \| T_\Omega f_1 \|_{L^q(Y)} \leq \| f_1 \|_{L^p(X)} \leq \| f \|_{L^p(X)} \leq 1. \]
    %
    The triangle inequality implies for $q > p$ that if $A_{p,q}$ is chosen large enough, depending on $p$ and $q$,
    %
    \[ \| \mathbf{I}_{F_{\leq n_0}} T_\Omega f \|_{L^q(Y)} \leq (1 + A_{p,q}) 2^{-1/p} \leq 2^{(1/2)(1/p - 1/q)} A_{p,q} 2^{-1/p}, \]
    %
    \[ \| \mathbf{I}_{F_{n_0 + 1}} T_\Omega f \|_{L^q(Y)} \leq 1 + 2^{1-1/p} \leq 3, \]
    %
    and
    %
    \[ \| \mathbf{I}_{F_{\geq n_0 + 2}} T_\Omega f \|_{L^q(Y)} \leq 1 + (1 + A_{p,q}) 2^{-1/p} \leq 2^{(1/2)(1/p - 1/q)} A_{p,q} 2^{-1/p}. \]
    %
    Putting these three estimates together, using the disjoint support, gives, again if $A_{p,q}$ is suitably large, depending on $p$ and $q$, that
    %
    \begin{align*}
        \| T_\Omega f \|_{L^q(Y)} &\leq ( 2 (2^{(1/2)(1/p - 1/q)})^q A_{p,q}^q 2^{-q/p} + 3^q )^{1/q}\\
        &\leq ( 2^{-(1/2)(q/p - 1)} A_{p,q}^q + 3^q )^{1/q} \leq A_{p,q}.
    \end{align*}
    %
    This completes the proof in the case $q > p$.

    Now consider the case $q = p$, and continue an induction on $N$, assuming without loss of generality that $\| T \|_{L^p \to L^q} = 1$. Write $A_p(N)$ for the optimal constant such that
    %
    \[ \| T_\Omega \|_{L^p \to L^p} \leq A_p(N). \]
    %
    over all upper diagonal block operators of size $\leq N$. Consider $f$ with $\| f \|_{L^p(X)} = 1$, and break $f = f_0 + f_1$, where $f_0 = f \mathbf{I}_{E_{\leq n_0}}$ and $f_1 = f \mathbf{I}_{E_{> n_0}}$, where $n_0, N - n_0 \leq N/2$. Let $\| f_0 \|_{L^p(X)} = r$ and $\| f_1 \|_{L^p(X)} = s$, so $r^p + s^p = 1$. Applying induction, we have
    %
    \[ \| \mathbf{I}_{F_{\leq n_0}} T_\Omega f_0 \|_{L^p(Y)} \leq A_p(N/2) r \]
    %
    and
    %
    \[ \| T_\Omega f_1 \|_{L^p(Y)} \leq A_p(N/2) s. \]
    %
    We also have
    %
    \[ \| \mathbf{I}_{F_{\geq n_0}} T_\Omega f_0 \|_{L^p(Y)} \leq 1. \]
    %
    Putting this together yields
    %
    \begin{align*}
        \| T_\Omega f \|_{L^p(Y)} &\leq ( A_p(N/2)^p r^p + (1 + A_p(N/2) s)^p  )^{1/p}\\
        &\leq ( A_p(N/2)^p (r^p + s^p) + O_p(A_p(N/2)^{p-1} s^{p-1}) )^{1/p}\\
        &= ( A_p(N/2)^p + O_p(A_p(N/2)^{p-1} s^{p-1}) )^{1/p}\\
        &\leq ( A_p(N/2)^p + O_p(A_p(N/2)^{p-1}) )^{1/p}\\
        &\leq A_p(N/2) + O_p(1).
    \end{align*}
    %
    Thus we find $A_p(N) \leq A_p(N/2) + O_p(1)$, and this implies that $A_p(N) \lesssim_p \log(N)$, completing the proof.
\end{proof}

The decomposition is arbitrary, which implies (via linearization) a variant by maximal functions.

\begin{theorem}[Christ-Kiselev]
    Consider $E_1 \subset E_2 \subset \dots \subset X$, let $T: L^p(X) \to L^q(Y)$, and consider the maximal operator
    %
    \[ Mf = \sup_n | T(\mathbf{I}_{E_n} f) |. \]
    %
    For $1 \leq p < q \leq \infty$,
    %
    \[ \| M \|_{L^p \to L^q} \lesssim_{p,q} \| T \|_{L^p \to L^q} \]
    %
    and for $1 \leq p \leq \infty$, and $E_1 \subset E_2 \subset \dots \subset E_N \subset X$ are given,
    %
    \[ \| M \|_{L^p \to L^p} \lesssim \log(N) \| T \|_{L^p \to L^p}. \]
\end{theorem}
\begin{proof}
    By monotone convergence, we may assume without loss of generality that the index set is finite. For $f \in L^p(X)$, and $y \in Y$, let $n(y)$ be an index such that $Mf(y) = T(\mathbf{I}_{E_{n(y)}} f)(y)$. Let $X_n = E_n - E_{n-1}$, and let $Y_n = \{ y \in Y: n(y) = n \}$. Then for each $y \in Y$, if $\Omega = \bigcup_{n \leq m} X_n \times Y_m$,
    %
    \[ Mf(y) = T(\mathbf{I}_{E_{n(y)}} f)(y) = T_\Omega f(y). \]
    %
    We can then apply the Christ-Kiselev Lemma above, since $\Omega$ is upper triangular.
\end{proof}

We can apply this result to study the \emph{maximal Fourier transform}
%
\[ \mathcal{F}^* f(\xi) = \sup_I \int_I f(x) e^{-2 \pi i \xi \cdot x}\; dx = \sup_I \widehat{f \mathbf{I}_I}, \]
%
where $I$ ranges over all compact intervals.

\begin{theorem}[Menshov-Paley-Zygmund]
    For $1 \leq p < 2$,
    %
    \[ \| \mathcal{F}^* f \|_{L^{p^*}(\RR)} \lesssim_p \| f \|_{L^p(\RR^)}. \]
\end{theorem}
\begin{proof}
    Applying the triangle inequality, we may assume one endpoint of each interval in the supremum lies at the origin. By symmetry, we may assume that this is the left hand endpoint. A convergence argument allows us to assume that the other endpoint is a positive rational number, and we may restrict ourselves by monotone convergence to a finite subset $\{ q_1 < q_2 < \dots < q_N \}$. But then the result follows by the Christ-Kiselev Maximal Function Lemma above, and the Hausdorff-Young inequality.
\end{proof}

A qualitative consequence is that if $f \in L^p(\RR)$ for some $1 \leq p < 2$, then
%
\[ \widehat{f}(\xi) = \lim_{a,b \to \infty} \int_{-a}^b f(x) e^{-2 \pi i \xi \cdot x}\; dx, \]
%
for almost every $\xi \in \RR$.

\begin{remark}
    The result is also true for $p = 2$, but is a \emph{much harder theorem}, due to Carleson.
\end{remark}

The Christ-Kiselev Lemma and its `vector valued estimates' becomes very useful in the study of nonlinear dispersive partal differential equations.








\chapter{Maximal Averages}

This chapter is an introduction to the behaviour of basic averaging operators. A classical example, given a function $f \in L^1_{\text{loc}}(\RR)$, are the averaging operators
%
\[ A_\delta f(x) = \frac{1}{2\delta} \int_{x-\delta}^{x+\delta} f(y)\; dy. \]
%
If $f \in C(\RR)$, then for each $x \in \RR$, $\lim_{\delta \to 0} A_\delta f(x) = f(x)$. This fact is fundamentally connected to differentiation under the integral sign; if we define the function
%
\[ F(x) = \int_0^x f(y)\; dy \]
%
then for each $x \in \RR$,
%
\[ F'(x) = \lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = \lim_{h \to 0} \frac{1}{h} \int_x^{x+h} f(y)\; dy = f(x). \]
%
Our main goal will be study whether pointwise convergence of the averages $A_\delta f$ hold in higher dimensions, for a more general family of functions that are not necessarily continuous, and for a more general family of averaging operators, thus testing the extent to which the `fundamental theorem of calculus' holds.

The classical family of averaging operators on $\RR^d$ are defined for $\delta > 0$, $f \in L^1_{\text{loc}}(\RR^d)$, and $x \in \RR^d$ by setting
%
\[ A_\delta f(x) = \fint_{B(x,\delta)} f(y)\; dy, \]
%
where $B(x,\delta)$ is the ball of radius $\delta$ centred at $x$. A simple application of Schur's lemma shows that $\| A_\delta f \|_{L^p(\RR^d)} \leq \| f \|_{L^p(\RR^d)}$ for all $1 \leq p \leq \infty$, uniformly in $p$. This uniform bound in $\delta$ is strong enough, together with the density of compactly supported continuous functions is enough to conclude that for any $f \in L^p(\RR^d)$, for $1 \leq p < \infty$, $A_\delta f$ converges to $f$ in $L^p$ norm. This implies that for any $f \in L^p(\RR^d)$, there exists a sequence $\delta_i$ converging to zero such that $A_{\delta_i} f$ converges to $f$ pointwise almost everywhere. In this chapter, we would like to show $A_\delta f$ converges to $f$ pointwise almost everywhere \emph{without taking a subsequence of values $\delta_i$}. To do this, we introduce the fundamental tool of \emph{maximal functions}.

\section{The Method of Maximal Functions}

Hardy and Littlewood introduced a powerful technique to study such pointwise convergence problems, known as the \emph{method of maximal functions}. For each $f \in L^1_{\text{loc}}(X)$, we define a sublinear operator $M$ by setting
%
\[ Mf = \sup_{\delta > 0} A_\delta |f|. \]
%
The next theorem indicates why obtaining bounds on the operator $M$ gives pointwise convergence results.

\begin{theorem}
  Let $V$ be a quasinorm space, let $0 < q < \infty$, and consider a family of bounded operators $\{ T_t: V \to L^{q,\infty}(X) \}$. Then we can define the pointwise maximal operator
  %
  \[ T_* f(x) = \sup_t |T_t f(x)|. \]
  %
  Suppose that for every $f \in L^p(X)$,
  %
  \[ \| T_* f \|_{L^{q,\infty}(X)} \lesssim \| f \|_V. \]
  %
  Then for any bounded operator $S: V \to L^{q,\infty}(X)$, the set
  %
  \[ \{ f \in V : \lim_{t \to \infty} T_t f(y) = Sf(y)\; \text{for a.e $y$} \} \]
  %
  is closed in $V$.
\end{theorem}
\begin{proof}
  Fix $\{ u_n \}$ in $V$ converging to $u \in V$, and suppose for each $n$,
  %
  \[ \lim_{t \to \infty} (T_t u_n)(x) = Su_n(x) \]
  %
  holds for almost every $x \in X$. For each $\lambda > 0$, we find
  %
  \begin{align*}
    |\{ x \in X: &\limsup_{t \to \infty} |T_t u(x) - Su(x)| > \lambda \}|\\
    &\leq |\{ x \in X: \limsup_t |T_t(u - u_n)(x) - S(u - u_n)(x)| > \lambda \}|\\
    &\leq |\{ x \in X : |T_*(u - u_n)(x)| > \lambda/2 \}| + | \{ x: |S(u - u_n)(x)| > \lambda/2 \} |\\
    &\lesssim_{p,q} \frac{\| u - u_n \|_V^q}{\lambda^q} + \frac{\| u - u_n \|_V^p}{\lambda^p}.
  \end{align*}
  %
  as $n \to \infty$, this quantity tends to zero. Thus for all $\lambda > 0$,
  %
  \[ |\{ x: \limsup_{t \to \infty} |T_t u(x) - Su(x)| > \lambda \}| = 0 \]
  %
  Taking $\lambda \to 0$ gives that $\limsup_t |T_t u(x) - Su(x)| = 0$ for almost every $x \in X$. But this means precisely that $T_tu(x) \to Su(x)$ for almost every $x \in X$.
\end{proof}

Since we know $A_\delta f$ converges to $f$ pointwise for any $f \in C(\RR)^d$, we see from the result above that taking $T_t = A_\delta$ and $S$ the identity map gives almost everywhere convergence if we can obtain bounds for the maximal operator $M$ of the form
%
\[ \left\| \sup_{\delta > 0} A_\delta f \right\|_{L^{q,\infty}(\RR^d)} \lesssim \| f \|_V \]
%
for an appropriate norm $\| \cdot \|_V$ and $0 < q < \infty$ in which $C(\RR^d)$ is dense. We have already obtained a bound
%
\[ \sup_{\delta > 0} \| A_\delta f \|_{L^{q,\infty}(\RR^d)} \leq \sup_{\delta > 0} \| A_\delta f \|_{L^q(\RR^d)} \leq \| f \|_{L^q(\RR^d)} \]
%
but moving the supremum inside the $L^q$ norm is nontrivial. One way to think about the difference between the two bounds is that the latter uniformly controls the height and width of the functions $A_\delta f$, whereas the former inequality not only controls the height and width of functions, but also shows that the main contributions to the height and widths of the functions $A_\delta f$ are supported on common regions of space.

\section{Covering Methods}

The bound $\| Mf \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}$ follows from a direct calculation. This it is trivial to control the height of the function $Mf$ in terms of the heigt of the function $f$. The difficult part is obtaining control of the width of $Mf$ in terms of the width of $f$. Control on width can only be obtained up to a certain degree, because for any locally integrable $f \neq 0$, $\text{supp}(Mf) = \RR^d$, so the width of $f$ `explodes'. A slightly more technical calculation shows that we cannot even have a bound of the form
%
\[ \| Mf \|_{L^1(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}. \]
%
In fact, $Mf$ is not integrable for any nonzero $f \in L^1(\RR^d)$.

\begin{lemma}
    If $f \in L^1(\RR^d)$ is nonzero, then $Mf$ is not integrable. Moreover, there exists $f \in L^1(\RR^d)$ such that $Mf \not \in L^1_{\text{loc}}(\RR^d)$.
\end{lemma}
\begin{proof}
    Fix a nonzero $f \in L^1(\RR^d)$. By rescaling, we may assume without loss of generality that $\| f \|_{L^1(\RR^d)} = 2$. Then, for suitably large $R \geq 1$,
    %
    \[ \int_{B_R(0)} |f(x)|\; dx \geq 1. \]
    %
    For each $x \in \mathbf{R}^d$, $B_R(0) \subset B_{|x|+R}(x)$ and so
    %
    \[ Mf(x) \geq \fint_{B_{|x|+R}(x)} |f(y)|\; dy \gtrsim \frac{1}{(|x| + R)^d} \gtrsim \frac{1}{|x|^d} \]
    %
    But this means that
    %
    \[ \int_{\RR^d} |Mf(x)| \gtrsim \int_{\RR^d} \frac{1}{|x|^d} = \infty. \]
    %
    Thus $Mf \not \in L^1(\RR^d)$.

    To find $f$ such that $Mf \not \in L^1_{\text{loc}}(\RR^d)$ take
    %
    \[ f(x) = \frac{1}{|x| (\log |x|)^2}. \]
    %
    Then for $x \geq 0$,
    %
    \begin{align*}
        \frac{1}{2h} \int_{x-h}^{x+h} \frac{dy}{|y| \log |y|^2} &= \frac{1}{2h} \left( \frac{1}{\log(x-h)} - \frac{1}{\log(x+h)} \right)\\
        &= \frac{1}{2x \log x} + O \left( \frac{h}{\log x} \right)
    \end{align*}
    %
    implies that
    %
    \[ Mf(x) \geq \frac{1}{2x \log x}. \]
    %
    Thus $Mf$ isn't integrable near the origin.
\end{proof}

The last lemma shows that if $f \in L^1(\RR^d)$, then we have a pointwise bound $|Mf(x)| \gtrsim_f \langle x \rangle^{-d}$. Note, however, that $|x|^{-d}$ is only \emph{barely} nonintegrable. We will also show that $Mf$ is barely nonintegrable by obtaining a bound
%
\[ \| Mf \|_{L^{1,\infty}(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}. \]
%
Interpolation thus shows that $\| Mf \|_{L^p(\RR^d)} \lesssim_{d,p} \| f \|_{L^p(\RR^d)}$ for all $1 < p \leq \infty$.

The standard real-variable technique of obtaining the $L^1(\RR^d) \to L^{1,\infty}(\RR^d)$ bound of the maximal function is geometric, applying a covering argument. To obtain the weak-type bound, we must show that the set
%
\[ E_\lambda = \{ x \in \RR^d : |Mf(x)| > \lambda \} \]
%
is small. If $|Mf(x)| > \lambda$, there is a ball $B$ around $x$ such that
%
\[ \int_B |f(y)|\; dy > \lambda |B|. \]
%
Clearly $B \subset E_\lambda$. If we could find a large family of \emph{disjoint balls} $B_1,\dots,B_N$ such that this inequality held, such that $\sum |B_i| \gtrsim_d |E_\lambda|$, then we would conclude that
%
\[ \| f \|_{L^1(\RR^d)} \geq \sum_{i = 1}^N \int_{B_i} |f(y)|\; dy > \lambda \sum_{i = 1}^N |B_i| \gtrsim_d \lambda |E_\lambda| \]
%
which would show $|E_\lambda| \lesssim_d \| f \|_{L^1(\RR^d)} / \lambda$, i.e. that $\| Mf \|_{L^{1,\infty}(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}$. This intuition is true, and the process through which we obtain the family of disjoint balls $B_1,\dots,B_N$ is through the \emph{Vitali covering lemma}.

This particular technique has been shown to generalize to a wide variety of situations in which an averaging operator is involved. All that is really required for the basic theory is a basic `covering type argument' that holds in a great many situations. To prove the Vitali Covering Lemma in this greater level of generality, we fix a locally compact space $X$ equipped with a nonzero Radon measure. For each $x \in X$ and $\delta > 0$, we fix an open, precompact set $B(x,\delta)$, which we assume to be monotonically increasing in $\delta$. We then assume the following property holds:
%
\begin{itemize}
    \item There is $c > 0$ such that for any $x \in X$ and $\delta > 0$, if
    %
    \[ B^*(x,\delta) = \bigcup \{ B(x',\delta): B(x,\delta) \cap B(x',\delta) \neq \emptyset \}, \]
    %
    then $|B^*(x,\delta)| \leq c |B(x,\delta)|$.
\end{itemize}
%
If $X$ is a metric space, and $B(x,\delta)$ is the ball of radius $\delta$, then we have $B^*(x,\delta) \subset B(x,3\delta)$. If the radon measure satisfies a \emph{doubling condition}
%
\[ |B(x,3\delta)| \leq c |B(x,\delta)|, \]
%
then the assumption will hold for the same $c$. For instance, the Lebesgue measure $X = \RR^d$ satisfies the doubling condition
%
\[ |B(x,3\delta)| \leq 3^d |B(x,\delta)|. \]
%
So in this case we can set $c = 3^d$.

\begin{lemma}[Vitali Covering Lemma]
    If $B_1, \dots, B_N$ is a finite collection of balls in $X$, then there is a disjoint subcollection $B_{i_1}, \dots, B_{i_M}$ such that
    %
    \[ \bigcup_i B_i \subset \bigcup_j B_{i_j}^*. \]
    %
    Thus given the property above, we have
    %
    \[ \left| \bigcup_{i = 1}^N B_i \right| \leq c \sum_{j = 1}^M |B_{i_j}|. \]
\end{lemma}
\begin{proof}
  Consider the following greedy selection procedure. Let $B_{i_1}$ be the ball in our collection of maximal radius. Given that we have selected $B_{i_1},\dots,B_{i_k}$, let $B_{i_{k+1}}$ be the ball of largest radius not intersecting previous balls selected if possible. Continue doing this until we cannot select any further balls. If $B_j$ is any ball not chosen by this procedure, it must intersect a ball with radius at least as big as $B_j$ itself. But this means that
  %
  \[ \bigcup_{i = 1}^N B_i \subset \bigcup_{j = 1}^M B^*_{i_j}. \]
  %
  Thus
  %
  \[ \left| \bigcup_{i = 1}^N B_i \right| \leq \sum_{j = 1}^M |B^*_{i_j}| \leq c \sum_{j = 1}^M |B_{i_j}|. \qedhere \]
\end{proof}

Let us now prove the bonuds for the maximal average using the Vitali covering lemma. The following technical assumptions are not always required, but make certain parts of the argument cleaner, and hold in most applications:
%
\begin{itemize}
  \item For any $x \in X$,
  %
  \[ \bigcap_{\delta > 0} \overline{B}(x,\delta) = \{ x \} \quad\text{and}\quad \bigcup_{\delta > 0} B(x,\delta) = X \]

  \item For any open set $U \subset X$ and $\delta > 0$, the function
  %
  \[ x \mapsto |B(x,\delta) \cap U| \]
  %
  is a continuous function of $x$.
\end{itemize}
%
These are fairly easily verifiable in most particular instance, but in some situations they can be worked around to obtain similar results that we will obtain here. It follows from these technical assumptions that $|B(x,\delta)| > 0$ for each $x \in X$ and $\delta > 0$, and moreover, for each $\delta > 0$, and $f \in L^1_{\text{loc}}(X)$, the averaged function $A_\delta f$ given by setting
%
\[ A_\delta f(x) = \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} f(y)\; dy, \]
%
is measurable.

\begin{lemma}
  If $f \in L_1^{\text{loc}}(X)$, then $A_\delta f$ is a measurable function.
\end{lemma}
\begin{proof}
  If $f = a_1 \mathbf{I}_{U_1} + \dots + a_N \mathbf{I}_{U_N}$ is a simple function, where $U_1,\dots,U_N$ are open sets, then
  %
  \[ A_\delta f(x) = a_1 \frac{|B(x,\delta) \cap U_1|}{|B(x,\delta)|} + \dots + a_N \frac{|B(x,\delta) \cap U_N|}{|B(x,\delta)|} \]
  %
  is a continuous function by our technical assumptions. Next, if $f \geq 0$ is a step function, then there exists a monotonically decreasing family of simple functions $\{ f_n \}$ such that $f_n \to f$ pointwise, then the monotone convergence theorem implies that $A_\delta f_n \to A_\delta f$ pointwise, so $A_\delta f$ is measurable. Finally, decomposing any measurable function into the difference of non-negative measurable functions and then considering pointwise limits of step functions completes the proof.
\end{proof}

It also follows from our technical assumptions that for any $x \in X$, and any open neighborhood $U$ of $x$, there exists $\delta_0$ such that for $\delta \leq \delta_0$, $\overline{B(x,\delta)} \subset U$. It follows that for any $f \in C(X)$ and $x \in X$,
%
\[ \lim_{\delta \to 0} A_\delta f(x) = f(x). \]
%
If $Mf = \sup_{\delta > 0} A_\delta f$, then we will show
%
\[ \| Mf \|_{L^{1,\infty}(X)} \lesssim_c \| f \|_{L^1(X)}. \]
%
In particular, we have seen that this implies that for any $f \in L^1(X)$,
%
\[ \lim_{\delta \to 0} A_\delta f(x) = f(x) \]
%
for almost every $x \in X$. Since this result is a local result, this pointwise convergence also holds for any $f \in L^1_{\text{loc}}(X)$. In particular, it also holds for any $f \in L^p(X)$ for $1 \leq p \leq \infty$.

\begin{theorem}
  For any $f \in L^1(X)$,
  %
  \[ \| Mf \|_{L^{1,\infty}(X)} \leq c \cdot \| f \|_{L^1(X)}. \]
\end{theorem}
\begin{proof}
  Set
  %
  \[ E_\lambda = \{ x \in X: Mf(x) > \lambda \}. \]
  %
  Since we are working with a Radon measure, and $E_\lambda$ is open, we have
  %
  \[ |E_\lambda| = \sup_{K \subset E_\lambda} |K|, \]
  %
  where $K$ is compact, and thus has finite measure. Fix any such compact subset $K$. Then $K$ is covered by finitely many balls $B_1,\dots,B_N$ such that on each ball $B_i$,
  %
  \[ \int_{B_i} |f(y)|\; dy > \lambda |B_i|. \]
  %
  Using the Vitali lemma, extract a disjoint subfamily $B_{i_1},\dots, B_{i_M}$ with
  %
  \[ \left| \sum_{j = 1}^M B_{i_j} \right| \leq c \sum_{j = 1}^M |B_{i_j}|. \]
  %
  Then
  %
  \[ \| f \|_{L^1(X)} > \lambda \sum_{j = 1}^M |B_{j_i}| \geq \frac{\lambda}{c} \left| \bigcup_{j = 1}^M B_{j_i} \right| \geq \frac{\lambda |K|}{c}. \]
  %
  Rearranging gives
  %
  \[ |K| \leq \frac{c \| f \|_{L^1(X)}}{\lambda}. \]
  %
  Since $K$ was arbitrary, inner regularity gives
  %
  \[ |E_\lambda| \leq \frac{c \| f \|_{L^1(X)}}{\lambda}. \]
  %
  Since $\lambda$ was arbitrary, the proof is complete.
\end{proof}

\begin{remark}
    A similar covering argument can be used to show that the \emph{uncentered} Hardy-Littlewood maximal function
    %
    \[ M'f(x) = \sup_{x \in B} \frac{1}{|B|} \int_B |f(y)|\; dy \]
    %
    where $B$ ranges over all balls, also satisfies a bound
    %
    \[ \| M' f \|_{L^{1,\infty}(X)} \leq c \| f \|_{L^1(X)}. \]
    %
    Given the weak assumption above, the uncentered and centered maximal functions can actually behave quite differently. We have the pointwise inequality $Mf \leq M'f$, but in general $M'f$ can be significantly bigger than $Mf$. However, we have $M'f \lesssim Mf$ under the following slightly stronger assumption on the family of balls we are working with: that there exists two constants $c_1,c_2 > 0$ such that the following two properties hold:
    %
    \begin{itemize}
        \item (The Engulfing Condition) If $B(x,\delta) \cap B(x',\delta) \neq \emptyset$, then $B(x',\delta) \subset B(x,c_1 \delta)$.
        \item (The Doubling Condition) $|B(x,c_1 \delta)| \leq c_2 |B(x,\delta)|$.
    \end{itemize}
    %
    If $B = B(x',\delta)$ contains $x$, then $B$ is contained in $B(x,c_1 \delta)$, and conversely, $B(x,\delta)$ is contained in $B(x',c_1 \delta)$. Thus
    %
    \[ |B| = |B(x',\delta)| \geq c_2^{-1} B(x', c_1 \delta) \geq c_2^{-1} |B(x,\delta)| \geq c_2^{-2} |B(x,c_1 \delta)|. \]
    %
    Thus
    %
    \[ \frac{1}{|B|} \int_B |f(y)|\; dy \leq \frac{c_2^2}{|B(x,c_1 \delta)|} \int_{B(x,c_1 \delta)} |f(y)|\; dy \leq c_2^2 Mf(x). \]
    %
    Taking suprema gives $M'f(x) \leq c_2^2 Mf(x)$. Thus under these stronger conditions, we have a pointwie bound $Mf \approx M'f$ with implicit constants independent of $f$. The engulfing and doubling conditions arise in more sophisticated techniques in this theory, e.g. when we analyze Calderon-Zygmund decompositions that come up in the real-variable analysis of singular integrals.
\end{remark}

With the result proved, we obtain the Lebesgue differentiation theorem: If $f \in L^{1,\text{loc}}(\RR^d)$, then for almost every $x_0 \in \RR^d$,
%
\[ f(x_0) = \lim_{\delta \to 0} \int_{|x - x_0| \leq \delta} f(x)\; dx. \]
%
For $d = 1$, we can directly connect this to the fundamental theorem of calculus; if $f \in L^{1,\text{loc}}(\RR^d)$, then the function
%
\[ g(x) = \int_0^x f(y)\; dy \]
%
is locally Lipschitz, and conversely we can find such $f$ for any $g$ by the Radon-Nikodym theorem. The Lebesgue differentiation theorem then says precisely that if $g$ is locally Lipschitz, then $g$ is differentiable almost everywhere, and that
%
\[ g(x) = g(0) + \int_0^x g'(x)\; dx. \]
%
This result is called the \emph{Rademacher differentiation theorem}. We develop similar ideas, and in higher dimensions, in the next chapter.

Under various other assumptions, one can obtain different covering lemmas that improve upon constants in the Vitali covering lemma. For instance, one can exploit the ordering of the real line to show that for any family of intervals $\{ I_\alpha \}$ covering a compact set $K$, there is a subcover $I_1,\dots, I_N$ such that any point in $\RR$ is contained in at most two of the intervals. A modification of the argument above shows this gives the slightly better bound
%
\[ \| Mf \|_{L^{1,\infty}(\RR)} \leq 2 \| f \|_{L^1(\RR)}, \]
%
rather than the bound
%
\[ \| Mf \|_{L^{1,\infty}(\RR)} \leq 3 \| f \|_{L^1(\RR)}. \]
%
One can also modify the proof to involve an infinite cover rather than a finite cover, a result called the \emph{Wiener Covering Lemma}, which requires a slightly more technical algorithm.

\begin{lemma}
    Let $X$ be a space satisfying the engulfing and doubling property, and also the following additional property:
    %
    \begin{itemize}
        \item For all $\varepsilon > 0$, there exists $\delta > 0$ such that if $x \in X$ and $r \leq \delta$, $|B(x,r)| \leq \varepsilon$.
    \end{itemize}
    %
    Let $\mathcal{B}$ be a family of balls covering a set $E$, such that
    %
    \[ \sup \{ r_i : B(x_i,r_i) \in \mathcal{B} \} < \infty. \]
    %
    Then there exists a subfamily $\mathcal{B}' \subset \mathcal{B}$ of disjoint balls such that
    %
    \[ |E| \lesssim \bigcup_{B \in \mathcal{B}'} B^*. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ C_1 = \sup \{ r_i : B(x_i,r_i) \in \mathcal{B} \}. \]
    %
    As in the Vitali covering lemma, we greedily construct a disjoint family of balls. We start by picking a ball $B_0$ with diameter at least $C/2$ in the set. Given that we have chosen $\{ B_1,\dots, B_N \}$, we set
    %
    \[ C_N = \sup \{ r : B(x,r) \in \mathcal{B}\ \text{and}\ B(x,r) \cap B_i = \emptyset\ \text{for all $1 \leq i \leq N$} \}. \]
    %
    If the right hand side is nonempty, we can choose a ball $B_{N+1} = B(x_{N+1}, r_{N+1})$ with $r_{N+1} \geq C_N/2$ which is disjoint from $B_1,\dots,B_N$, and we continue the algorithm. Otherwise, the algorithm terminates. In either case, we let $\mathcal{B}'$ be the set of balls chosen. If
    %
    \[ \sum_{B \in \mathcal{B}'} |B| = \infty, \]
    %
    then both sides of the inequality are infinity and there is nothing to be proven. Otherwise, we have $\sum_{B \in \mathcal{B}'} |B| < \infty$, and so $|B_i| \to 0$ as $i \to \infty$, so that $r_i \to 0$. We claim that
    %
    \[ E \subset \bigcup_i B(x_i, 2c r_i). \]
    %
    If $B = B(x,r) \in \mathcal{B}$, then there therefore must exist $i$ such that $r > 2 r_i$. Let $i_0$ be the first such integer for which this is true. We must have $i_0 > 0$ since $B_0$ is chosen so that this inequality is false for all $B \in \mathcal{B}$. Thus for $0 \leq i < i_0$ we must have $r \leq 2 r_i$. It must be true that $B \cap B_i \neq \emptyset$ for some $0 \leq i < i_0$ since otherwise we would have
    %
    \[ r \leq C_N \leq 2 r_{i_0}. \]
    %
    Thus the engulfing property implies that $B \subset B(x_i, 2c r_i)$. Thus we find
    %
    \[ |E| \leq \sum_i |B(x_i, 2c r_i)| \lesssim \sum_i |B(x_i, r_i)|. \qedhere \]
\end{proof}

Under these assumptions, if we study the sets
%
\[ E_\alpha = \{ x \in X : Mf(x) > \alpha \}, \]
%
associated with the maximal average of some $f \in L^1(X)$, then for each $x \in E_\alpha$, one may find a ball $B = B(x,r)$ such that
%
\[ \int_{B} |f(x)|\; dx \geq \alpha |B|. \]
%
Since we also have
%
\[ \int_B |f(x)|\; dx \leq \| f \|_{L^1(X)}, \]
%
we have $|B| \leq \| f \|_{L^1(X)} / \alpha$. Our assumption thus implies that if $\alpha$ is suitably large, then $r$ is bounded from above. Thus we may apply the Wiener covering lemma to find a disjoint subcover $\{ B_i \}$ of these balls with
%
\[ |E_\alpha| \lesssim \sum |B_i| \lesssim \frac{\| f \|_{L^1(X)}}{\alpha}. \]
%
Thus we can still obtain estimates on these sets without having to study compact subsets of $E_\alpha$.

Finally, we consider a covering lemma which allows one to consider much more general families of measures than the ones satisfying the doubling and engulfing type properties considered above. We shall restrict ourselves to normal Euclidean balls in $\RR^d$.

\begin{lemma} (Besicovitch Covering Lemma)
    Let $A$ be a bounded subset of $\RR^d$, and let $\mathcal{B}$ be a family of closed balls with centres in $A$. Then there is a subcollection of balls $\mathcal{B}' \subset \mathcal{B}$ which covers $A$, and with the property that each point in $\RR^d$ is contained in at most $O_d(1)$ of the balls in $\mathcal{B}'$. Moreover, we can find $O(d)$ subfamilies $\mathcal{B}_1,\dots, \mathcal{B}_N \subset \mathcal{B}$, each disjoint from one another, and each individually containing pairwise disjoint balls.
\end{lemma}
\begin{proof}
    TODO: See Matilla, Theorem 2.7.
\end{proof}

The Besicovitch Covering Lemma gives a Vitali like covering argument for arbitrary Radon measures on $\RR^d$.

\begin{theorem}
    Let $\mu$ be a Radon measure on $\RR^d$. if $A \subset \RR^d$, and $\mathcal{B}$ is a family of closed balls such that each point in $A$ is the centre of arbirarily small balls of $\mathcal{B}$, then we can find a disjoint family of balls $\mathcal{B}'$ such that
    %
    \[ \mu \left( A - \bigcup_{B' \in \mathcal{B}'} B' \right) = 0. \]
\end{theorem}
\begin{proof}
    For simplicity, assume first that $A$ is bounded (the general proof is given in Matilla, Theorem 2.8). Applying outer regularity, for any $\varepsilon > 0$, we can find an open set $U$ containing $A$ such that
    %
    \[ \mu(U) \leq (1 + \varepsilon) \mu(A). \]
    %
    Then consider the family
    %
    \[ \mathcal{B}' = \{ B \in \mathcal{B}: B \subset U \}. \]
    %
    The assumption implies $\mathcal{B}'$ still covers $A$, so we can choose $N_d = O_d(1)$ families of balls $\mathcal{B}'_1,\dots,\mathcal{B}'_N \subset \mathcal{B}'$ as in Besicovitch's covering theorem. But this means that
    %
    \[ \mu(A) \leq \sum_{i = 1}^N \sum_{B \in \mathcal{B}'_i} \mu(B) \leq.  \]
    %
    There there exists some $i_0$ such that
    %
    \[ \frac{\mu(A)}{N} \leq \sum_{B \in \mathcal{B}'_{i_0}} \mu(B). \]
    %
    Moreover, we can find a family subcolllection of balls $B_1,\dots,B_K$ from $\mathcal{B}'_{i_0}$ such that
    %
    \[ \frac{\mu(A)}{N} \leq 2 ( \mu(B_1) + \dots + \mu(B_K) ). \]
    %
    Let $A' = A - B_1 - \dots - B_K$. Then
    %
    \[ \mu(A') \leq \mu( U - B_1 - \dots - B_K ) = \mu(U) - \mu(B_1) - \dots - \mu(B_K) \leq (1 + \varepsilon) \mu(A) - (1/2N_d) \mu(A). \]
    %
    Choosing $\varepsilon = 1/4N_d$ gives $\mu(A') \leq (1 - 1/4N_d) \mu(A)$. Thus we may repeat this process infinitely to obtain a disjoint family of balls which give the required condition.
\end{proof}

We obtain a maximal average theorem for general Radon measures using this covering argument.

\begin{theorem}
    Let $\mu$ be a Radon measure on $\RR^d$, and define
    %
    \[ M_\mu f(x) = \sup_{r > 0} \frac{1}{\mu(B(x,r))} \int_{B(x,r)} |f|\; d\mu. \]
    %
    Then
    %
    \[ \| M_\mu f \|_{L^{1,\infty}(\mu)} \lesssim \| f \|_{L^1(\mu)}. \]
\end{theorem}
\begin{proof}
    Fix $f \in L^1(\mu)$, and let
    %
    \[ E_\alpha = \{ x : M_\mu(f) > \alpha \}. \]
    %
    For each $x \in E_\alpha$, we can find a ball $B$ such that
    %
    \[ \int_B |f|\; d\mu \geq \alpha |B|. \]
    %
    Apply the Besicovitch Covering Lemma, finding a finite subcollection of these balls $\mathcal{B}$ covering $E_\alpha$, and covering any other point in $\RR^d$ at most $O_d(1)$ times. Thus
    %
    \[ \mu(E_\alpha) \leq \sum_i \mu(B_i) \leq \alpha^{-1} \sum_i \int_{B_i} |f|\; d\mu \lesssim \frac{\| f \|_{L^1(\mu)}}{\alpha}. \]
\end{proof}

Interpolating between the trivial $L^\infty \to L^\infty$ bound, we obtain that $\| M_\mu f \|_{L^p(\mu)} \lesssim \| f \|_{L^p(\mu)}$ for all $1 < p \leq \infty$. Moreover, if for a finite Radon measure $\nu$, we set
%
\[ M_\mu \nu(x) = \sup_{r > 0} \frac{\nu(B(x,r))}{\mu(B(x,r))}, \]
%
then the same argument above implies that $\| M_\mu \nu \|_{L^{1,\infty}(\mu)} \lesssim \nu(\RR^d)$.

\begin{corollary}
    If $f \in L^1(\mu)$, then
    %
    \[ \lim_{r \to 0} \frac{1}{\mu(B(x,r))} \int_{B(x,r)} f(y) d\mu(y) = f(x) \]
    %
    for $\mu$ almost every $x \in \RR^d$.
\end{corollary}
\begin{proof}
    If $f \in C_c(\RR^d)$, then it is simple to see that
    %
    \[ \lim_{r \to 0} \frac{1}{\mu(B(x,r))} \int_{B(x,r)} f(y)\; d\mu(y) = f(x) \]
    %
    for all $x \in \RR^d$. But $C_c(\RR^d)$ is dense in $L^1(\mu)$, i.e. by the Riesz representation theorem, so a density argument using the maximal function implies the corollary.
\end{proof}





\section{Dyadic Methods}

There are many different techniques for showing the boundedness of the maximal operator. Let us consider some \emph{dyadic methods} for proving the inequality. Recall that the set of dyadic cubes is
%
\[ \{ Q_{n,k} : n \in \ZZ, k \in 2^n \ZZ^d \} \]
%
where $Q_{n,k}$ is the cube $[k_1, k_1 + 2^n] \times \dots \times [k_d, k_d + 2^n]$. We note that dyadic cubes nest within one another much more easily than balls do (cubes are either nested or disjoint). In particular, if $Q_1,\dots,Q_N$ is any collection of dyadic cubes, there exists an almost disjoint subcollection $Q_{i_1}, \dots, Q_{i_k}$ with $Q_{i_1} \cup \dots \cup Q_{i_k} = Q_1 \cup \dots \cup Q_N$. In particular, this operates as a Vitali-type covering lemma with a constant independant of $d$, so if we define the \emph{dyadic} Hardy-Littlewood maximal operator
%
\[ M_\Delta f(x) = \sup_{x \in Q} \frac{1}{|Q|} \int_Q |f(y)|\; dy \]
%
then we easily obtain the bound $\| M_\Delta f \|_{L^{1,\infty}(\RR^d)} \leq \| f \|_{L^1(\RR^d)}$, with no implicit constant depending on $d$. The bound $\| M_\Delta f \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}$ is easy, so interpolation gives $\| M_\Delta f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for all $1 < p \leq \infty$, with a constant now \emph{independent of dimension}.

Two families of sets $\{ B(x,\delta) : x \in \RR^d, \delta > 0 \}$ and $\{ B'(x,\delta) : x \in \RR^d, \delta > 0 \}$ are \emph{equivalent} if there exists $c_1$, $c_2$ such that
%
\[ B'(x, c_1 \delta) \subset B(x,\delta) \subset B(x,c_2 \delta). \]
%
It follows that the resultant maximal averages from the two sets pointwise differ from one another by a universal constant. This allows us to obtain bounds for maximal averages over cubes centred at a point, and ellipses with bounded eccentricity, etc. If for $2^k \leq \delta \leq 2^{k+1}$, we set $B(x,\delta)$ to be a dyadic cube with sidelength $1/2^k$, then the family $\{ B(x,\delta) \}$ is \emph{not} equivalent to the usual family of cubes, but below we show that bounds on the two maximal operators are still equivalent.

If $Q$ is a dyadic cube, then it is contained in a ball $B$ with $|Q| \lesssim_d B$. It follows that for any function $f$ and $x \in \RR^d$,
%
\[ M_\Delta f(x) \lesssim_d Mf(x). \]
%
Thus bounds on $M$ automatically give bounds on $M_\Delta$. The opposite pointwise inequality is unfortunately, \emph{not true}. For instance, if $f$ is the indicator function on $[0,1]$. Then $M_\Delta f$ is supported on $[0,1]$, but $Mf$ is positive on the entirety of $\RR$. To reduce the study of $M$ to the study of $M_\Delta$, we must instead rely on the \emph{$1/3$ translation trick} of Michael Christ.

\begin{lemma}
  Let $I \subset [0,1]$ be an interval. Then there exists an interval $J$, which is either a dyadic interval, or a dyadic interval shifted by $1/3$, such that $I \subset J$ and $|J| \lesssim |I|$.
\end{lemma}
\begin{proof}
  Let $I = [a,b]$. Perform a binary expansion of $a$ and $b$, writing
  %
  \[ a = 0.a_1a_2 \dots \quad\text{and}\quad b = b_1 b_2 \dots. \]
  %
  Let $n$ be the first value where $a_n \neq b_n$. Then $a_n = 0$ and $b_n = 1$. Then $[a,b]$ is contained in the dyadic interval
  %
  \[ Q_1 = \left[ 0.a_1 \dots a_{n-1}, 0.a_1\dots a_{n-1} + 1/2^{n-1} \right] \]
  %
  which has length $1/2^{n-1}$. Find $0 \leq i < \infty$ such that
  %
  \[ a = 0.a_1 \dots a_{n-1} 0 1^i 0 \dots \]
  %
  and $0 \leq j < \infty$ such that
  %
  \[ b = 0.a_1 \dots a_{n-1} 1 0^j 1. \]
  %
  If no such $j$ exists, then $b = 0.a_1 \dots a_{n-1} 1$, and so $[a,b]$ is contained in the rational interval
  %
  \[ Q_2 = \left[ 0.a_1 \dots a_{n-1} 0 1^i, 0.a_1 \dots a_{n-1} 0 1^i + 1/2^{n+i} \right] \]
  %
  and $b - a \geq 1/2^{n+i+1}$, so $|Q_2| \leq 2(b - a)$. Now if $i \leq 5$ or $j \leq 5$, then $b - a \geq 1/2^{n+5}$, so $|Q_1| \leq 2^5(b-a)$. On the other hand, if $i \geq 5$ and $j \geq 5$, we find $b - a \geq 1/2^{n+\min(i,j)}$. Then we can find a dyadic interval $Q_3$ and $2 \leq r \leq 5$ such that
  %
  \[ 1/3 + Q_3 = \left[ 0.a_1 \dots a_{n-1} 0 1^{\min(i,j)-r} 1 0 1 0 \dots, 0.a_1 \dots a_{n-1} 0 1^{i-r} 1 0 1 0 \dots + 1/2^{n+\min(i,j)-r}  \right] \]
  %
  and so $1/3 + Q_3$ contains $[a,b]$ and $|Q_3| = 1/2^{n+\min(i,j)-r} \leq 2^5 (b - a)$.
\end{proof}

It follows that for each $x \in \RR^d$, and any function $f$,
%
\[ Mf(x) \lesssim_d (M_\Delta f)(x) + (M_\Delta \text{Trans}_{1/3} f)(x). \]
%
Since the $L^p$ norms are translation invariant, this implies that the dyadic maximal operator and the maximal operator satisfy equivalent bounds, with operator norms differing by a constant depending on $n$. Since we independently obtained bounds on $M_\Delta$, this section provides an alternate proof to the boundedness of $M$.

There is an alternate way to view the operator $M_\Delta$. For each integer $n$, we let $\mathcal{B}(n)$ denote the family of all sidelength $1/2^n$ dyadic cubes. Thus $\mathcal{B}(n)$ gives a decomposition of $\RR^d$ into an almost disjoint union of cubes. If we define the conditional expectation operators
%
\[ E_n f(x) = \sum_{Q \in \mathcal{B}(n)} \left( \frac{1}{|Q|} \fint_Q f \right) \cdot \mathbf{I}_Q \]
%
then $M_\Delta f = \sup_{n \in \ZZ} E_n f$. In particular, it is easy to see from the bounds on $M_\Delta$ that for any $f \in L^1_{\text{loc}}(\RR^d)$, $\lim_{n \to \infty} E_n f(x) = f(x)$ holds for almost every $x \in \RR^d$. It is simple to conclude from this result a very useful technique, known as the \emph{Calder\'{o}n-Zygmund decomposition}.

\begin{theorem}
  Given $f \in L^1(\RR^d)$ and $\lambda > 0$, we can write $f = g + b$, where $\| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda$, and there is an almost disjoint family of dyadic cubes $\{ Q_i \}$ such that $g$ is supported on $\bigcup_i Q_i$,
  %
  \[ \sum_i |Q_i| \leq \frac{\| f \|_{L^1(\RR^d)}}{\lambda}, \]
  %
  and for each $i$,
  %
  \[ \int_{Q_i} f(y)\; dy = 0. \]
  %
  We also have $\| g \|_{L^1(\RR^d)}, \| b \|_{L^1(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}$.
\end{theorem}
\begin{proof}
  Write $E = \{ x: M_\Delta f(x) > \lambda \}$. By the dyadic Hardy-Littlewood maximal inequality,
  %
  \[ |E| \leq \frac{\| f \|_{L^1(\RR^d)}}{\lambda}. \]
  %
  Because $f$ is integrable, $E \neq \mathbf{R}^d$. Thus we can write $E$ as the almost disjoint union of dyadic cubes $\{ Q_i \}$, such that for each $i$,
  %
  \[ \int_{Q_i} |f(x)|\; dx > \lambda |Q_i|, \]
  %
  and also, if $R_i$ is the parent cube of $Q_i$,
  %
  \[ \int_{R_i} |f(x)|\; dx \leq \lambda |R_i|. \]
  %
  This can be done by a greedy strategy, taking the union of dyadic cubes of largest sidelength contained in $E$. This means
  %
  \[ \int_{Q_i} |f(x)|\; dx \leq \int_{R_i} |f(x)|\; dx \leq \lambda |R_i| \leq 2^d \lambda |Q_i|. \]
  %
  Define
  %
  \[ g(x) = \begin{cases} f(x) &: x \not \in E, \\ \frac{1}{|Q_i|} \int_{Q_i} f(x)\; dx &: x \in Q_i\ \text{for some $i$}. \end{cases} \]
  %
  For almost every $x \in E^c$, $|f(x)| \leq \lambda$, since $E_n f(x) \leq \lambda$ for each $n$, and $E_n f(x) \to f(x)$ as $n \to \infty$ for almost every $x$. Conversely, if $x \in Q_i$ for some $i$, then
  %
  \[ \left| \frac{1}{|Q_i|} \int_{Q_i} f(x)\; dx \right| \leq \frac{1}{|Q_i|} \int_{Q_i} |f(x)|\; dx \leq 2^d \lambda. \]
  %
  Thus $\| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda$. If we define $b = f - g$, then $b$ is supported on $\bigcup Q_i = E$, and for each $i$,
  %
  \[ \int_{Q_i} b(x)\; dx = \int_{Q_i} \left( f(x) - \frac{1}{|Q_i|} \int_{Q_i} f(y)\; dy \right)\; dx = 0. \qedhere \]
\end{proof}

The Calderon-Zygmund theorem will be very useful to us in the sequel, especially when we analyze the theory of singular integrals.

\section{Linearization of Maximal Operators}

It is often a very useful technique to study a maximal operator by reducing it's analysis to studying a family of linear operators. The technique is very general, and applies to virtually all the maximal functions, so we give the general discussion here. Fix a family of linear operators $\{ T_t \}$, and consider the associated maximal operator $Mf = \sup_t |T_t f|$. By monotone convergence, we can obtain $L^p \to L^q$ operator norm bounds on the maximal operator $M$ if we can prove uniform $L^p \to L^q$ operator norm bounds on the maximal operators $Mf = \sup_{t \in T} |T_t f|$, where $T = \{ t_1, \dots, t_N \}$ is a finite subset of indices. For such an operator, and each $y \in Y$, there exists $t(y) \in T$ such that $Mf(y) = T_{t(y)} f(y)$. Thus we can divide $Y$ into $N$ disjoint sets $Y_1 \cup \dots \cup Y_N$, such that
%
\[ Mf = \sum_{i = 1}^N \mathbf{I}_{Y_i} T_i f. \]
%
To bound the \emph{sublinear} operator $M$, it therefore suffices to obtain uniform bounds on the behaviours of the family of \emph{linear operators} of the form
%
\[ \sum_{i = 1}^N \mathbf{I}_{Y_i} T_i. \]
%
This is the method of linearization. TODO: Are there any measurability issues here?

\section{$TT^*$ Arguments}

The method of $TT^*$ arguments enables us to obtain bounds on a linear operator $T$ by exploiting cancellation when the operator is composed with it's adjoint. The main calculation from which the method follows is that if $H$ is a Hilbert space, and $X$ is a Banach space, and $T: H \to X$ is a bounded operator, then
%
\[ \| T T^* \|_{X^* \to X} = \| T \|_{H \to X}^2, \]
%
because certainly $\| T^* \|_{X^* \to H} = \| T \|_{H \to X}$. For any $f \in X^*$,
%
\[ \| T^* f \|_H^2 = \langle T^* f, T^* f \rangle = \langle TT^* f, f \rangle \leq \| TT^* \|_{X^* \to X} \| f \|_{X^*}^2, \]
%
so $\| T \|^2 \leq \| TT^* \|$, and conversely,
%
\[ \| TT^* \| \leq \| T \| \| T^* \| = \| T \|^2. \]
%
Thus we study the boundedness of an operator $T$ via the boundedness of the associated operator $TT^*$.

By linearity, to obtain bounds on the Hardy-Littlewood-Maximal operator it suffices to obtain uniform bounds on the behaviour of the linear operators of the form
%
\[ T_r f(y) = A_{r(y)} f(y), \]
%
where $r(y) \in \{ r_1, \dots, r_N \} \subset (0,\infty)$ are radii. Now
%
\[ T^*_r g(x) = \int_{|x - y| \leq r(y)} \frac{g(y)}{|B(y,r(y))|}\; dy \]
%
Thus
%
\begin{align*}
    T_r T_r^* g(y) &= A_{r(y)} T^* g(y)\\
    &= \frac{1}{V_d^2} \int_{|x - y| \leq r(y)} \int_{|x - z| \leq r(z)} r(y)^{-d} r(z)^{-d} g(z)\; dx\; dz.
\end{align*}
%
On the integrand, we must have $|z - y| \leq r(y) + r(z)$, and $x$ is constrained to lie in a ball of radius $\min(r(y), r(z))$. Thus
%
\[ |T_rT_r^* g(y)| \leq \frac{1}{V_d} \int_{|y - z| \leq r(y) + r(z)} \frac{g(z)}{\max(r(y), r(z))^d}\; dz. \]
%
We can split this integral into two parts, depending on whether $r(y) \geq r(z)$ or $r(y) \leq r(z)$, which yields
%
\begin{align*}
    |T_rT_r^* g(y)| &\leq \frac{1}{V_d} \int_{|y - z| \leq 2r(y)} \frac{g(z)}{r(y)^d}\; dy + \int_{|y - z| \leq 2r(z)} \frac{g(z)}{r(z)^d}\; dy\\
    &\leq 2^d( T_{2r} g(y) + T^*_{2r} g(y) ).
\end{align*}
%
Thus if $C_N = \sup_r \| T_r \|_{L^2 \to L^2}$, where the supremum is over functions taking over at most $N$ values, then we conclude that
%
\[ \| T_r T_r^* g(y) \|_{L^2} \leq 2^d( \| T_{2r} g \|_{L^2} + \| T^*_{2r} g \|_{L^2} ) \leq 2^{d+1} C_N, \]
%
so that for any $r$, we find that $\| T_r \|_{L^2 \to L^2}^2 = \| T_r T_r^* \|_{L^2 \to L^2}^{1/2} \leq 2^{d+1} C_N$. Thus $C_N^2 \leq 2^{d+1} C_N$, and since $C_N < \infty$ (we have a trivial bound $C_N \lesssim N$ because the operator norm of the averages is uniformly bounded), this gives $C_N \leq 2^{d+1}$, which shows $\| Mf \|_{L^2(\RR^d)} \leq 2^{d+1} \| f \|_{L^2(\RR^d)}$.

\section{Lebesgue Density Theorem}

If $E$ is a measurable subset of $\mathbf{R}^d$, and $x \in \mathbf{R}^d$, we say $x$ is a point of \emph{Lebesgue density} of $E$, or has \emph{full metric density} if
%
\[ \lim_{\delta \to 0} \frac{|B(x,\delta) \cap E|}{|B(x,\delta)|} = 1 \]
%
This means that for any $\varepsilon > 0$, the inequality $|B(x,\delta) \cap E| \geq (1 - \varepsilon) |B(x,\delta)|$ holds for suitably small $\delta$, so $E$ asymptotically contains as large a fraction of the local points around $x$ as is possible. Since $\chi_E \in L^1_{\text{loc}}(\mathbf{R}^d)$, we can apply the Lebesgue differentiation theorem to immediately obtain an interesting result.

\begin{theorem}[Lebesgue Density Theorem]
    If $E$ is a measurable subset, then almost every point in $E$ is a point of Lebesgue density, and almost every point not in $E$ is not a point of Lebesgue density.
\end{theorem}

The fact that a point is a point of Lebesgue density implies the existence of large sets of rigid patterns in $E$. A simple corollary is that any set of positive Lebesgue measure contains arbitrarily long arithmetic progressions.

\begin{theorem}
  Let $E \subset \RR^d$ be a set of nonzero Lebesgue measure. Then for any non-zero $a_1,\dots,a_N \in \RR$ there exists $x \in E$ and $c \in \RR$ such that
  %
  \[ a_1 x + c,\dots, a_N x + c \in E. \]
\end{theorem}
\begin{proof}
  Without loss of generality, by translation we may assume $0$ is a point of Lebesgue density of $E$. We then claim that we can set $c = 0$. It is simple to see that if $t_0$ is a point of Lebesgue density for a set $E$ and a set $F$, then it is also a point of Lebesgue density for $E \cap F$. In particular $0$ is a point of Lebesgue density for $E \cap a_1^{-1} E \cap \dots \cap a_N^{-1} E$, which means the set is nonempty. If $y \in E \cap a^{-1} E \cap \dots \cap a_N^{-1} E$, then $y,a_1y, \dots, a_N y \in E$.
\end{proof}

If $f$ is locally integrable, the \emph{Lebesgue set} of $f$ consists of all points $x \in \mathbf{R}^d$ such that $f(x)$ is finite and
%
\[ \lim_{\delta \to 0} \frac{1}{|B_\delta|} \int_{B(x,\delta)} |f(y) - f(x)|\ dy = 0. \]
%
If $f$ is continuous at $x$, it is obvious that $x$ is in the Lebesgue set of $f$, and if $x$ is in the Lebesgue set of $f$, then $A_\delta f(x) \to f(x)$ as $\delta \to 0$.

\begin{theorem}
    If $f \in L^1_{\text{loc}}(\mathbf{R}^d)$, almost every point is in the Lebesgue set of $f$.
\end{theorem}
\begin{proof}
    For each rational number $p$, the function $|f - p|$ is measurable, so that there is a set $E_p$ of measure zero such that for $x \in E_p^c$,
    %
    \[ \lim_{\delta \to 0} \fint_{B(x,\delta)} |f(y) - p|\ dy \to |f(x) - p|. \]
    %
    Taking unions, we conclude that $E = \bigcup E_p$ is a set of measure zero. Suppose $x \in E^c$, and $f(x)$ is finite. For any $\varepsilon > 0$, there is a rational $p$ such that $|f(x) - p| < \varepsilon$, and we know the equation above holds, so
    %
    \begin{align*}
        \lim_{\delta \to 0} \fint_{B(x,\delta)} |f(y) - f(x)|\ dy \leq \limsup_{\delta \to 0} \fint_{B(x,\delta)} \left( |f(y) - p| + |p - f(x)| \right)\ dy \leq 2\varepsilon.
    \end{align*}
    %
    We then let $\varepsilon \to 0$. Since $f(x)$ is finite for almost all $x$, this completes the proof.
\end{proof}

It is interesting to note that for any $f \in L^1_{\text{loc}}(\RR^d)$, there is $g \in L^1_{\text{loc}}(\RR^d)$ such that $f = g$ almost everywhere, and the Lebesgue set of $g$ is maximal. One choice is to define
%
\[ g(x) = \limsup_{\delta \to 0} \fint_{B(x,\delta)} f(y)\; dy. \]
%
Often the Lebesgue set of $f$ is defined to be the Lebesgue set of $g$, when one wants to think of the Lebesgue set as a distributional invariant of $f$ rather than depending solely on the pointwise behaviour.

\section{Ergodic Averages}

Ergodic theory studies the behaviour of measure preserving dynamical systems. By this, we mean, for a probability space $X$, a bimeasurable bijection $T: X \to X$ such that $|T^{-1}(E)| = |E|$ for all $E \subset X$. A classic example, for $\TT = \RR / \ZZ$, is the shift map $T: \TT \to \TT$ given by $T(x) = x + \alpha$. The map $T$ induces a linear operator $T$, such that $Tf(x) = f(Tx)$. That $T$ is measure preserving implies that $T$ is an isometry of $L^p(X)$ for any $p$. We begin with a result of Von Neumann.

\begin{theorem}[Von-Neumann Ergodic Theorem]
    Let $T: H \to H$ be a unitary operator. Then for any $f \in H$, the averages
    %
    \[ A_N f = \frac{f + \dots + T^{N-1} f}{N} \]
    %
    converge as $N \to \infty$ in $H$.
\end{theorem}
\begin{proof}
    If $Tf = f$, then it is clear that $A_N f \to f$ as $N \to \infty$. Conversely, if $f = Tg - g$ for some $g \in H$, then the averages telescope, and we obtain that $A_N f = N^{-1}(T^Ng - g)$, which converges to zero since $T$ is unitary. But these two cases turn out to be orthogonal complements of one another, i.e. we can write $H$ as the orthogonal sum of the closures of the two subspaces
    %
    \[ H_1 = \{ f \in H: Tf = f \} \quad\text{and}\quad H_2 = \{ f \in H: f = Tg - g\ \text{for some $g \in H$} \}. \]
    %
    These spaces are clearly orthogonal; if $Tf_1 = f_1$ and $f_2 = Tg - g$, then
    %
    \[ \langle f_1, g \rangle = \langle Tf_1, Tg \rangle = \langle f_1, Tg \rangle \]
    %
    and thus
    %
    \[ \langle f_1, f_2 \rangle = \langle f_1, Tg \rangle - \langle f_1, g \rangle = 0. \]
    %
    To show these spaces are orthogonal complements, let $f$ be orthogonal to the closure of $H_2$. Then $\langle f, Tf - f \rangle = 0$. But this means that
    %
    \[ \langle f, Tf \rangle = \langle f, f \rangle = \langle Tf, Tf \rangle, \]
    %
    and so $\langle Tf, Tf - f \rangle = 0$. But this means that $\langle Tf - f, Tf - f \rangle = 0$, so $Tf = f$.
\end{proof}

Now we move onto the mean ergodic theorem.

\begin{theorem}
    Suppose $T: X \to X$ is measure preserving and $1 \leq p < \infty$. Then if $f \in L^p(X)$, then $\{ A_N f \}$ converges in $L^p(X)$.
\end{theorem}
\begin{proof}
    The operators $\{ A_N \}$ are uniformly bounded on $L^p(X)$. Thus it suffices to verify the theorem for a dense subclass of functions $f$. So suppose $f \in L^\infty(X)$. The functions $\{ A_N f \}$ converge in $L^2(X)$ and thus converge in $L^p(X)$ for any $1 \leq p < \infty$ by H\"{o}lder's inequality. The functions are also \emph{bounded} in $L^\infty(X)$, so interpolation gives convergence in $L^p(X)$ for any $1 \leq p < \infty$.
\end{proof}

The functions $A_N f$ do not necessarily converge in $L^\infty(X)$ if $f \in L^\infty(X)$. But they do converge \emph{almost everywhere}, as we will prove using our theory of maximal functions we have developed. For functions $f$ on $X$, define
%
\[ Mf(x) = \sup_{N \geq 1} \left| \frac{1}{N} \sum_{n = 0}^{N-1} T^n f(x) \right|. \]
%
We trivially have $\| Mf \|_{L^\infty(X)} \leq \| f \|_{L^\infty(X)}$, and we will now justify that $\| Mf \|_{L^{1,\infty(X)}} \lesssim \| f \|_{L^1(X)}$. The space $X$ has no metric properties, so it seems surprising that we can use our previous theory of maximal functions here. But the idea is to \emph{lift} our transform to a space where we \emph{do} have such properties, thus obtaining a \emph{transference principle} reducing the study of general measure preserving systems to particular ones.

%For $f : \ZZ \to \CC$, define
%
%\[ Mf(n) = \sup_{N > 0} \sum_{m = 1}^N |f(n + m)|. \]
%
%This is a setting to which the general theory applies, with integers being balls (and with a singleton set being the ball of radius $\delta$ for any $0 < \delta < 1$). Thus we obtain that $\| Mf \|_{L^{1,\infty}(\ZZ)} \leq 2 \| f \|_{L^1(\ZZ)}$ and $\| Mf \|_{L^p(\ZZ)} \lesssim_p \| f \|_{L^p(\ZZ)}$ for $1 < p \leq \infty$. A consequence of this inequality is a pointwise convergence result in ergodic theory. We recall that a \emph{measure preserving system} is a probability space $X$ together with a measure preserving transformation $T: X \to X$.

\begin{theorem}
    Let $T: X \to X$ be a measure preserving system. Then for $f \in L^1(X)$,
    %
    \[ \| Mf \|_{L^{1,\infty}(X)} \lesssim \| f \|_{L^1(X)}. \]
\end{theorem}
\begin{proof}
    We have $M = \lim_{K \to \infty} M_K$, where
    %
    \[ M_K f(x) = \sup_{1 \leq N < K} \frac{1}{N} \sum_{n = 1}^N T^n f(x). \]
    %
    For any $K > 0$, define $F: X \times [2K] \to \CC$ by setting
    %
    \[ F(x,n) = T^nf(x). \]
    %
    The space $[K]$ is a space to which we can apply the Hardy-Littlewood theory of maximal functions we have developed, \emph{uniformly in $K$}, if we equip it with the uniform measure, which is doubling with respect to the standard metric on $[K]$. Thus we obtain that for each $x \in X$,
    %
    \[ \left\| \sup_{1 < N \leq K} N^{-1} \sum_{n = 1}^N F(x,n+k) \right\|_{l^{1,\infty}_k[K]} \lesssim \| F(x,k) \|_{l^1_k[2K]}. \]
    %
    Apply the $L^{1,\infty}_x$ norm to the left hand side of the equation, and the $L^1$ norm to the right hand side. Since $T$ is measure preserving, $\| F(x,k) \|_{L^1_x(X) l^1_k[2K]} = \| f \|_{L^1(X)}$. Thus
    %
    \[ \left\| \sup_{1 < N \leq K} \frac{1}{N} \sum_{n = 1}^N F(x,n+k) \right\|_{L^{1,\infty}(X \times [K])} \lesssim \| f \|_{L^1(X)}. \]
    %
    To work with the left hand side, notice the identity
    %
    \[ \sup_{1 \leq N < K} \frac{1}{N} \sum_{n = 1}^N T^{n+k} f(x) = \sup_{1 \leq N < K} \frac{1}{N} \sum_{n = 1}^N T^n (T^k f)(x). \]
    %
    Thus the left hand side is equal to $\| \left\| M_K f \right\|_{L^{1,\infty}(X)} \lesssim \| f \|_{L^1(X)}$. Taking $K \to \infty$ yields the required inequality.
\end{proof}

\begin{corollary}[The Pointwise Ergodic Theorem]
    Let $T: X \to X$ be a measure preserving system. If $f \in L^1(X)$, then $A_N f(x)$ converges for almost every $x \in X$.
\end{corollary}
\begin{proof}
    Our maximal function bounds thus imply that the result holds for a dense subclass of $L^1(X)$. The result is obvious for a function $f \in L^2(X)$ with $Tf = f$. The theorem is also true for $f = g - Tg$, where $g \in L^\infty(X)$. But the sums of such functions are dense in $L^2(X)$ by the orthogonal decomposition we just proved, and thus dense in $L^1(X)$.
\end{proof}

\section{Approximations to the Identity}

We now switch to the study of how we can approximate functions by convolutions of concentrated functions around the origin. In this section we define the various classes of such functions which give convergence results, to various degrees of strength. We say a family of integrable functions $\{ K_\alpha : \alpha > 0 \}$ in $\RR^d$ is a \emph{good kernel} if it is bounded in the $L^1$ norm, for every $\alpha > 0$,
%
\[ \int K_\alpha(x)\ dx = 1 \]
%
and if for every $\delta > 0$,
%
\[ \lim_{\alpha \to 0} \int_{|x| \geq \delta} |K_\alpha(x)|\ dx \to 0. \]
%
It requires only basic analysis to verify good kernel convergence.

\begin{theorem}
    If $\{ K_\alpha \}$ is a good kernel, then for any absolutely integrable function $f$, $\lim_{\alpha \to 0} f * K_\alpha = f$ in $L^1(\RR^d)$, and for any continuity point $x$ of $f$, $\lim_{\alpha \to 0} (f * K_\alpha)(x) = f(x)$.
\end{theorem}
\begin{proof}
    Note that
    %
    \begin{align*}
        \| (f * K_\alpha) - f \|_1 &= \int |(f * K_\alpha)(x) - f(x)|\ dx\\
        &= \int \left| \int K_\alpha(y) [f(x - y) - f(x)]\ dy \right|\ dx\\
        &\leq \int |K_\alpha(y)| \| T_y f - f \|_1\ dy
    \end{align*}
    %
    where $(T_y f)(x) = f(x - y)$. We know that $\| T_y f - f \|_1 \to 0$ as $y \to 0$. Thus, for each $\varepsilon$, we can pick $\delta$ such that if $|y| < \delta$, $\| T_y f - f \|_1 \leq \varepsilon$, and if we pick $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon$, and then
    %
    \[ \| (f * K_\alpha) - f \|_1 \leq \varepsilon \int_{|y| < \delta} |K_\alpha(y)|\ dy + 2 \| f \|_1 \int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon[\| K_\alpha \|_1 + 2 \| f \|_1] \]
    %
    Since $\| K_\alpha \|_1$ is universally bounded over $\alpha$, we can let $\varepsilon \to 0$ to obtain convergence. If $x$ is a fixed point of continuity, and for a given $\varepsilon > 0$, we pick $\delta > 0$ with $|f(y) - f(x)| \leq \varepsilon$ for $|y - x| < \delta$, then
    %
    \begin{align*}
        |(f * K_\alpha)(x) - f(x)| &= \left| \int_{-\infty}^\infty f(y) K_\alpha(x - y)\ dy - f(x) \right|\\
        &= \left| \int_{-\infty}^\infty [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &= \left| \int_{-\delta}^\delta [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &\ \ \ \ \ + \left| \int_{|y| \geq \delta} [f(y) - f(x)] K_\alpha(x - y)\ dy \right|\\
        &\leq \varepsilon \| K_\alpha \|_1 + [\| f \|_1 + f(x)] \int_{|y| \geq \delta} |K_\alpha(y)|\ dy
    \end{align*}
    %
    If $\| K_\alpha \|_1 \leq M$ for all $\alpha$, and we choose $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)| \leq \varepsilon$, then we conclude the value about is bounded by $\varepsilon [M + \| f \|_1 + f(x)]$, and we can then let $\varepsilon \to 0$.
\end{proof}

To obtain almost sure pointwise convergence of $f * K_\alpha$ to $f$, we must place stronger conditions on our family. We say a family $K_\delta \in L^1(\mathbf{R}^d)$, is an \emph{approximation to the identity} if $\int K_\delta = 1$, and
%
\[ |K_\delta(x)| \lesssim \frac{\delta}{|x|^{d+1}}\ \ \ \ |K_\delta(x)| \lesssim \frac{1}{\delta^d} \]
%
where the constant bound is independent of $x$ and $\delta$. These assumptions are stronger than being a good kernel, because if $K_\delta$ is an approximation to the identity, then
%
\[ \int_{|x| \geq \varepsilon} |K_\delta(x)| \leq \int_\varepsilon^\infty \int_{S^{d-1}} \frac{C \delta}{r}\ d\sigma dr = C \delta |S^{n-1}| \int_\varepsilon^\infty \frac{dr}{r} \leq \frac{C \delta |S^{n-1}|}{\varepsilon} \]
%
which converges to zero as $\delta \to 0$. Combined with
%
\[ \int_{|x| < \varepsilon} |K_\delta(x)| \leq C \int_0^\varepsilon \int_{S^{d-1}} \frac{r^{d-1}}{\delta^d} d\sigma dr = \frac{C \varepsilon^d |S^{n-1}|}{d \delta^d} \]
%
This calculation also implies
%
\begin{align*}
    \| K_\delta \|_1 &\leq C |S^{n-1}| \left[ \frac{\delta}{\varepsilon} + \frac{\varepsilon^d}{\delta^d} \right]
\end{align*}
%
Setting $\varepsilon = \delta$ optimizes this value, and gives a bound
%
\[ \| K_\delta \|_1 \leq 2C |S^{n-1}| \]
%
So an approximation to the identity is a stronger version of a good kernel.

\begin{example}
    If $\varphi$ is a bounded function in $\mathbf{R}^d$ supported on the closed ball of radius one with $\int \varphi(x)\ dx = 1$, then $K_\delta(x) = \delta^{-d} \varphi(\delta^{-1}x)$ is an approximation to the identity, because by a change of variables, we calculate
    %
    \[ \int_{\mathbf{R}^d} \frac{\varphi(\delta^{-1}x)}{\delta^d} = \int_{\mathbf{R}^d} \varphi(x) = 1 \]
    %
    Because $\varphi$ is bounded, we find
    %
    \[ |K_\delta(x)| \leq \frac{\| \varphi \|_\infty}{\delta^d} \]
    %
    Now $K_\delta$ is supported on a disk of radius $\delta$, this bound also shows
    %
    \[ |K_\delta(x)| \leq \frac{\delta \| \varphi \|_\infty}{|x|^{d+1}} \]
    %
    and so $K_\delta$ is an approximation to the identity. If $\varphi$ is an arbitrary integrable function, then $K_\delta$ will only be a good kernel.
\end{example}

\begin{example}
    The Poisson kernel in the upper half plane is given by
    %
    \[ P_y(x) = \frac{1}{\pi} \frac{y}{x^2 + y^2} \]
    %
    where $x \in \mathbf{R}$, and $y > 0$. It is easy to see that
    %
    \[ P_y(x) = y^{-1} P_1(xy^{-1}) \]
    %
    And
    %
    \[ \int \frac{1}{1 + x^2} = \arctan(\infty) - \arctan(-\infty) = \pi \]
    %
    We easily obtain the bounds
    %
    \[ |P_y(x)| \leq \frac{\| P_1 \|_\infty}{y}\ \ \ \ \ |P_y(x)| \leq \frac{y}{\pi |x|^2} \]
    %
    so the Poisson kernel is an approximation to the identity.
\end{example}

\begin{example}
    The heat kernel in $\mathbf{R}^d$ is defined by
    %
    \[ H_t(x) = \frac{e^{-|x|^2/4t}}{(4 \pi t)^{d/2}} \]
    %
    where $\delta = t^{1/2} > 0$. Then $H_t(x) = \delta^{-d} H_1(x\delta^{-1})$, and
    %
    \[ \int e^{-|x|^2/4} = \frac{1}{2^d} \int e^{-|x|^2} = \frac{|S^{n-1}|}{2^d} \int_0^\infty r^{d-1} e^{-r^2} dr \]
    %
%    By induction, we can prove that if $d$ is odd, then the antiderivative of $r^de^{-r^2}$ is equal to $P_d(r)e^{-r^2}$, where the coefficients of $P_d$ are nonzero only when the coefficient index is even. This follows because the chain rule gives
    %
%    \[ \int re^{-r^2} = -e^{-r^2}/2 \]
    %
%    and an integration by parts gives
    %
%    \[ \int r^{d+2}e^{-r^2} = r^2P_d(r)e^{-r^2} - 2 \int rP_d(r)e^{-r^2} \]
    %
%    Thus
    %
%    \[ \int r^3e^{-r^2} = (-r^2/2)e^{-r^2} + \int re^{-r^2} = (-1/2)(r^2 + 1) e^{-r^2} \]
%    \[ \int r^5e^{-r^2} = -(1/2) r^2(r^2 + 1)e^{-r^2} + \int r(r^2 + 1) e^{-r^2} = (-1/2)[r^4 + 2r^2 + 2] \]
%    \[ \int r^7e^{-r^2} = -(1/2) r^2[r^4 + 2r^2 + 2]e^{-r^2} + \int (r^5 + 2r^3 + 2r) e^{-r^2} = (-1/2) [r^6 + 3r^4 + 6r^2 + ] e^{-r^2} \]
\end{example}

\begin{example}
    The Poisson kernel for the disk is
    %
    \[ \frac{P_r(x)}{2 \pi} = \begin{cases} \frac{1}{2\pi} \frac{1 - r^2}{1 - 2r \cos x + r^2} &: |x| \leq \pi \\ 0 &: |x| > \pi \end{cases} \]
    %
    where $0 < r < 1$, and $\delta = 1-r$.
\end{example}

\begin{example}
    The F\'{e}jer kernel is
    %
    \[ \frac{F_N(x)}{2 \pi} = \begin{cases} \frac{1}{2 \pi N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)} \end{cases} \]
    %
    where $\delta = 1/N$.
\end{example}

As $\delta \to 0$, we may think of the $K_\delta$ as `tending to the unit mass' Dirac delta function $\delta$ at the origin. $\delta$ may be given a precise meaning, either in the theory of Lebesgue-Stieltjes measures or as a `generalized function', but we don't need it to discuss the actual convergence results of the functions $K_\delta$.

\begin{theorem}
    If $\{ K_\delta \}$ is an approximation to the identity, and $f$ is integrable on $L^1(\mathbf{R}^d)$, then $(f * K_\delta)(x) \to f(x)$ for every $x$ in the Lebesgue set of $f$, and $f * K_\delta$ converges to $f$ in the $L^1$ norm.
\end{theorem}
\begin{proof}
    We rely on the fact that if $x$ is in the Lebesgue set, then the function
    %
    \[ A(r) = \frac{1}{r^d} \int_{|y| \leq r} |f(x-y) - f(x)|\ dy \]
    %
    is a bounded continuous function of $r > 0$, converging to $0$ as $r \to 0$. This means that if $\Delta(y) = |f(x-y) - f(x)| |K_\delta(y)|$, then
    %
    \[ \int \Delta(y)\ dy = \int_{|y| \leq \delta} \Delta(y) + \sum_{k = 0}^\infty \int_{2^k \delta \leq |y| \leq 2^{k+1} \delta} \Delta(y) \]
    %
    The first term is easily upper bounded by $CA(\delta)$, and the $k$'th term of the sum by $C'2^{-k}A(2^{k+1}\delta) \leq C''2^{-k}$ for constants $C',C''$ that do not depend on $\delta$. Letting $\delta \to 0$ gives us the convergence result.
\end{proof}

\section{$H^p$ Spaces}

We briefly describe how the Hardy-Littlewood maximal principle can be used to develop the theory of Hardy spaces. Recall that if $f: \DD \to \CC$ is a harmonic function on the interior of the unit disk, and we define $f_r: \TT \to \CC$ by setting $f_r(t) = f(r e^{2 \pi it})$, then for the \emph{Poisson kernel}
%
\[ P_t(x) = \frac{1 - t^2}{1 + t^2 - 2t \cos(2 \pi x)} = \text{Re} \left( \frac{e^{2 \pi i x} + t}{e^{2 \pi i x} - t} \right), \]
%
we have for $0 \leq s < r < 1$, $f_s = f_r * P_{s/r}$. Applying Young's inequality with the fact $\{ P_t \}$ is positive and with unit mass, we thus conclude that $s \mapsto \| f_s \|_{L^p(\TT)}$ is a monotone increasing function of $s$. We define $H^p(\DD)$ to be the space of all \emph{holomorphic} (and thus harmonic) functions for which the norm
%
\[ \| f \|_{H^p(\DD)} = \lim_{t \to 1} \| f_t \|_{L^p(\TT)}. \]
%
We have seen that the Poisson kernel is an approximation to the identity, so that we have a pointwise estimate $|f * P_t| \lesssim Mf$.

\begin{theorem}
    If $f \in H^p(\DD)$, then for $1 < p \leq \infty$, the function
    %
    \[ f_1 = \lim_{t \to 1} f_t \]
    %
    exists pointwise almost everywhere, and lies in $L^p(\TT)$. If $1 < p < \infty$, then $\{ f_t \}$ also converges to $f_1$ in $L^p$ norm.
\end{theorem}
\begin{proof}
    Fix $0 < t < 1$. For $g \in L^{p^*}(\TT)$, we verify that
    %
    \[ \langle f_r, g * P_t \rangle = \langle f_r * P_t, g \rangle = \langle f_{rt}, g \rangle = \langle f_t * K_r, g \rangle. \]
    %
    As $r \to 1$, $f_t * K_r$ converges to $f_t$ in the $L^p$ norm, so we conclude that there exists a quantity $A_t$ such that as $r \to 1$,
    %
    \[ \langle f_r, g * P_t \rangle \to A_t. \]
    %
    We have $|A_t| \lesssim \| f \|_{H^p(\DD)} \| g \|_{L^{p^*}(\TT)}$, uniformly in $t$. As $t \to 1$, $g * P_t$ converges to $g$ in the $L^{p^*}(\TT)$ norm, and thus because $\{ f_r \}$ is bounded in $L^p(\TT)$, uniformly in $r$, we conclude that $\langle f_r, g * P_t \rangle$ converges to $\langle f_r, g \rangle$ uniformly in $r$. But this is enough to justify the convergence of $\langle f_r, g \rangle$. Thus we have justified that there exists $f_1 \in L^p(\TT)$ such that $f_r \to f_1$ weakly in $L^p(\TT)$. But this means that
    %
    \[ \langle f_t, g \rangle = \lim_{r \to 1} \langle f_t * P_r, g \rangle = \lim_{r \to 1} \langle f_r, g * P_t \rangle = \langle f_1, g * P_t \rangle = \langle f_1 * P_t, g \rangle. \]
    %
    Thus $f_t = f_1 * P_t$. From our results on approximations to the identity proved in this chapter, the remaining results are now immediate.
\end{proof}

\section{The Strong Maximal Function}

TODO

\section{The Tangential Poisson Maximal Function}

TODO

\chapter{Differentiability of Measurable Functions}

A simple consequence of the results above maximal functions is a kind of fundamental theorem of calculus. If $f \in L^1(\RR)$, then we can define $F \in C(\RR)$ by setting
%
\[ F(t) = \int_{-\infty}^t f(s)\; ds. \]
%
It follows from the maximal functions bounds we've established that $F$ is differentiable almost everywhere, and $F'(t) = f(t)$ for almost every $t$. Thus the fundamental theorem of calculus holds in this setting, i.e.
%
\[ F(t) = \int_{-\infty}^t F'(s)\; ds. \]
%
Let us now consider \emph{what} conditions we can assume on a measurable function $f$ such that $f$ is differentiable almost everywhere, such that $f' \in L^1(\RR)$, and such that
%
\[ f(t) = \int_{-\infty}^t f'(s)\; ds \]
%
holds for almost every $t \in \RR$. Clearly this is equivalent to finding which functions are expressed as the indefinite integral of an integrable function.

We shall find that if $f$ has {\it bounded variation}, then most of these problems are answered. If $f$ is a complex valued function on $[a,b]$, and $P$ is a partition, we can consider it's variation on a partition $P = a \leq t_0 < \dots < t_n \leq b$ to be
%
\[ V(f,P) = \sum_{k = 1}^n |f(t_k) - f(t_{k-1})| \]
%
we say $f$ has \emph{bounded variation} if there is a constant $M$ such that for any partition $P$, $V(f,P) \leq M$. This implies that, since the net $P \mapsto V(f,P)$ is increasing, the net converges to a value $V(f) = V(f,a,b)$, the \emph{total variation} of $f$ on $[a,b]$.

The problem of the variation of a function is very connected to the problem of the {\it rectifiability of curves}. If $x: [a,b] \to \mathbf{R}^d$ parameterizes a continuous curve in the plane, then, for a given partition $P = a \leq t_0 \leq \dots \leq t_n$, we can consider an approximate length
%
\[ L_P(x) = \sum_{k = 1}^n |x(t_i) - x(t_{i-1})| \]
%
If $x$ has a reasonable notion of length, then the straight lines between $x(t_{i-1})$ and $x(t_i)$ should be shorter than the length of $x$ between $t_{i-1}$ and $t_i$. It therefore makes sense to define the \emph{length} of $x$ as
%
\[ L(x) = \sup L_P(x) \]
%
The triangle inequality implies that the map $P \mapsto L_P(x)$ is an increasing net, so $L$ is also the limit of the meshes as they become finer and finer. If $L(x) < \infty$, we say $x$ is a \emph{rectifiable curve}. One problem is to determine what analytic conditions one must place on $x$ in order to guarantee regularity, and what further conditions guarantee that, if $x_i$ is differentiable almost everywhere,
%
\[ L(x) = \int_a^b \sqrt{x_1'(t)^2 + \dots + x_n'(t)^2}\ dt \]
%
Considering rectifiable curves leads directly to the notion of a function with bounded variation.

\begin{theorem}
    A curve $x$ is rectifiable iff each $x_i$ has bounded variation.
\end{theorem}
\begin{proof}
    We can find a universal constants $A,B > 0$ such that for any $x,y \in \mathbf{R}^d$,
    %
    \[ A \sum |x_i - y_i| \leq |x-y| \leq B \sum |x_i - y_i| \]
    %
    This means that if $P$ is a partition of $[a,b]$, then
    %
    \[ A \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \leq \sum |x(t_i) - x(t_{i-1})| \leq B \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \]
    %
    So $A \sum V(x_i,P) \leq L_P(x) \leq B \sum V(x_i,P)$ gives the required result.
\end{proof}

\begin{example}
    If $f$ is a real-valued, monotonic, increasing function on $[a,b]$, then $f$ has bounded variation, and one can verify that $V(f) = f(b) - f(a)$.
\end{example}

\begin{example}
    If $f$ is differentiable at every point, and $f'$ is bounded, then $f$ has bounded variation. The mean value theorem implies that if $|f'| \leq M$, then for all $x,y \in [a,b]$,
    %
    \[ |f(x) - f(y)| \leq M |x-y| \]
    %
    This implies that $V(f,P) \leq M(b-a)$ for all partitions $P$.
\end{example}

\begin{example}
    Consider the functions $f$ defined on $[0,1]$ with
    %
    \[ f(x) = \begin{cases} x^a \sin(x^{-b}) &: 0 < x \leq 1 \\ 0 &: x = 0 \end{cases} \]
    %
    Then $f$ has bounded variation on $[0,1]$ if and only if $a > b$. The function oscillates from increasing to decreasing on numbers of the form $x = (n \pi)^{-1/b}$, so the total variation is described as
    %
    \begin{align*}
      V(f) &= 1 + \sum_{n = 1}^\infty (n \pi)^{-a/b} + ((n+1) \pi)^{-a/b}
    \end{align*}
    %
    This sum is finite precisely when $a/b > 1$. Thus functions of bounded variation cannot oscillate too widely, too often.
\end{example}

The next result is a decomposition theorem for bounded variation functions into bounded increasing and decreasing functions. We define the \emph{positive variation} of a real valued function $f$ on $[a,b]$ to be
%
\[ P(f,a,b) = \sup_P \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \]
%
The \emph{negative variation} is
%
\[ N(f,a,b) = \sup_P \sum_{f(t_i) \leq f(t_{i-1})} -[f(t_i) - f(t_{i-1})] \]
%
Note that for each partition $P$, the sums of the two values above add up to the variation with respect to the partition.

\begin{lemma}
    If $f$ is real-valued and has bounded variation on $[a,b]$, then for all $a \leq x \leq b$,
    %
    \[ f(x) - f(a) = P(f,a,x) - N(f,a,x) \]
    %
    \[ V(f) = P(f,a,b) + N(f,a,b) \]
\end{lemma}
\begin{proof}
    Given $\varepsilon$, there exists a partition $a = t_0 < \dots < t_n = x$ such that
    %
    \[ \left| P(f,a,x) - \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    \[ \left| N(f,a,x) + \sum_{f(t_i) \leq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    %
    It follows that
    %
    \[ |f(x) - f(a) - [P(f,a,x) - N(f,a,x)]| < 2 \varepsilon \]
    %
    and we can then take $\varepsilon \to 0$. The second identity follows the same way.
\end{proof}

A real function $f$ on $[a,b]$ has bounded variation if and only if $f$ is the difference of two increasing bounded functions, because if $f$ has bounded variation, then
%
\[ f(x) = [f(a) + P(f,a,x)] - N(f,a,x) \]
%
is the difference of two bounded increasing functions. On the other hand, the difference of two bounded increasing functions is clearly of bounded variation. A complex function has bounded variation if and only if it is the linear combination of four increasing functions in each direction.

\begin{theorem}
    If $f$ is a continuous function of bounded variation, then
    %
    \[ x \mapsto V(f,a,x) \ \ \ \ \ x \mapsto V(x,b) \]
    %
    are continuous functions.
\end{theorem}
\begin{proof}
    $V(f,a,x)$ is an increasing functin of $x$, so for continuity on the left it suffices to prove that for each $x$ and $\varepsilon$, there is $x_1 < x$ such that $V(f,a,x_1) \geq V(f,a,x) - \varepsilon$. If we consider a partition
    %
    \[ P = \{ a = t_0 <  \dots < t_n = x \} \]
    %
    where $|V(f,P) - V(f,a,x)| \leq \varepsilon$, then by continuity of $f$ at $x$, there is $t_{n-1} < x_1 < x$ with $|f(x) - f(x_1)| < \varepsilon$, and then if we modify $P$ to obtain $Q$ by swapping $t_n$ with $x_1$, we find
    %
    \begin{align*}
        V(f,a,x_1) \geq V(f,Q) &= V(f,P) - |f(x) - f(t_{n-1})| + |f(x_1) - f(t_{n-1})|\\
        &\geq V(f,P) - \varepsilon \geq V(f,a,x) - \varepsilon
    \end{align*}
    %
    A similar argument gives continuity on the right, and the continuity as the left bound of the interval changes.
\end{proof}

To obtain the differentiation theorem for functions of bounded variation, we require a lemma of F. Riesz.

\begin{lemma}[Rising Sun lemma]
    If $f$ is real-valued and continuous on $\mathbf{R}$, and $E$ is the set of points $x$ where there exists $h > 0$ such that $f(x+h) > f(x)$, then, provided $E$ is non-empty, it must be open, and can be written as a union of disjoint intervals $(a_n,b_n)$, where $f(b_n) = f(a_n)$. If $f$ is continuous on $[a,b]$, then $E$ is still an open subset of $[a,b]$, and can be written as the disjoint union of countably many intervals, with $f(b_n) = f(a_n)$ except if $a_n = a$, where we can only conclude $f(a_n) \leq f(b_n)$.
\end{lemma}
\begin{proof}
  The openness is clear, and the fact that $E$ can be broken into disjoint intervals follows because of the characterization of open sets in $\mathbf{R}$. If
  %
  \[ E = \bigcup (a_n,b_n) \]
  %
  Then $f(a_n + h) \leq f(a_n)$ and $f(b_n + h) \leq f(b_i)$, implying in particular that $f(b_n) \leq f(a_n)$, If $f(b_n) < f(a_n)$, then choose $f(b_n) < c < f(a_n)$. The intermediate value theorem implies there is $x$ with $f(x) = c$, and we may choose the largest $x \in [a_n,b_n]$ for which this is true. Then since $x \in (a_n,b_n)$, there is $y \in (x,b_i)$ with $f(x) < f(y)$, and by the intermediate value theorem, since $f(b_n) < f(x) < f(y)$, there must be $x' \in (y,b_n)$ with $f(x') = c$, contradicting that $x$ was chosen maximally. The proof for closed intervals operates on the same principles.
\end{proof}

\begin{theorem}
    If $f$ is increasing and continuous on $[a,b]$, then $f$ is differentiable almost everywhere. That is,
    %
    \[ f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} \]
    %
    exists for almost every $x \in [a,b]$, $f'$ is measurable, and
    %
    \[ \int_a^b f'(x) \leq f(b) - f(a) \]
    %
    In particular, if $f$ is bounded on $\mathbf{R}$, then $f'$ is integrable on $\mathbf{R}$.
\end{theorem}
\begin{proof}the theorem in the
    It suffices to assume that $f$ is increasing, and we shall start by proving case assuming $f$ is continuous. We define
    %
    \[ \Delta_h f (x) = \frac{f(x+h) - f(x)}{h} \]
    %
    and the four {\it Dini derivatives}
    %
    \[ D_+ f(x) = \liminf_{h \downarrow 0} \Delta_h f(x)\ \ \ \ \ D^+ f(x) = \limsup_{h \downarrow 0} \Delta_h f(x) \]
    \[ D_- f(x) = \liminf_{h \uparrow 0} \Delta_h f(x)\ \ \ \ \ D^- f(x) = \limsup_{h \uparrow 0} \Delta_h f(x) \]
    %
    Clearly, $D_+ f \leq D^+ f$ and $D_- f \leq D^- f$, It suffices to show $D^+ f(x) < \infty$ for almost every $x$, and $D^+ f(x) \leq D_- f(x)$ for almost every $x$, because if we consider the function $g(x) = -g(-x)$, then we obtain $D^- f(x) \leq D_+ f(x)$ for almost every $x$, so
    %
    \[ D^+ f (x) \leq D_- f(x) \leq D^- f(x) \leq D_+ f(x) \leq D^+ f(x) < \infty \]
    %
    for almost every $x$, implying all values are equal, and that the derivative exists at $x$.

    For a fixed $\gamma > 0$, consider $E_\gamma = \{ x: D^+ f (x) > \gamma \}$. Since each $\Delta_h f$ is continuous, the supremum of the $\Delta_h f$ over any index set is lower semicontinuous, and since
    %
    \[ D^+ f(x) = \lim_{h \to 0} \sup_{0 \leq s \leq h} \Delta_h f (x + s) \]
    %
    can be expressed as the countable limit of these lower semicontinuous functions, $D^+ f$ is measurable, hence $E_\gamma$ is measurable. Now consider the shifted function $g(x) = f(x) - \gamma x$. If $\bigcup (a_i,b_i)$ is the set obtainable from $g$ from the rising sun lemma, then $E_\gamma \subset \bigcup (a_i, b_i)$, for if $D^+ f(x) > \gamma$, then there is $h > 0$ arbitrarily small with $\Delta_h f(x) > \gamma$, hence $f(x + h) - f(x) > \gamma h$, hence $g(x+h) > g(x)$. We know that $g(a_k) \leq g(b_k)$, so $f(b_k) - f(a_k) \geq \gamma(b_k - a_k)$, so
    %
    \[ |E_\gamma| \leq \sum (b_k - a_k) \leq \frac{1}{\gamma} \sum f(b_k) - f(a_k) \leq \frac{f(b) - f(a)}{\gamma} \]
    %
    Thus $|E_\gamma| \to 0$ as $\gamma \downarrow 0$, implying $D^+ f(x) = \infty$ only on a set of measure zero.

    Now for two real numbers $r < R$, we will now show
    %
    \[ E = \{ a \leq x \leq b : D^+ f(x) > R\ \ \ D_-f(x) < r \} \]
    %
    is a set of measure zero. Letting $r$ and $R$ range over all rational numbers establishes that $D^+ f(x) \leq D_-f(x)$ almost surely. We assume $|E| > 0$ and derive a contradiction. By regularity, we may consider an open subset $U$ in $[a,b]$ containing $E$ such that $|U| < |E| (R/r)$. We can write $U$ as the union of disjoint intervals $I_n$. For a fixed $I_N$, apply the rising sun lemma to the function $rx - f(-x)$ on the interval $-I_N$, yielding a union of intervals $(a_n,b_n)$. If we now apply the rising sun lemma to the function $f(x) - Rx$ on $(a_n, b_n)$, we get intervals $(a_{nm}, b_{nm})$, whose union we denote $U_N$. Then
    %
    \[ R(b_{nm} - a_{nm}) \leq f(b_{nm}) - f(a_{nm})\ \ \ \ \ f(b_n) - f(a_n) \leq r(b_n - a_n) \]
    %
    then, because $f$ is increasing,
    %
    \begin{align*}
      |U_N| &= \sum_{nm} (b_{nm} - a_{nm}) \leq \frac{1}{R} \sum_{nm} (f(b_{nm}) - f(a_{nm}))\\
      &\leq \frac{1}{R} \sum f(b_n) - f(a_n) \leq \frac{r}{R} \sum_n (b_n - a_n) \leq \frac{r}{R} |I_N|
    \end{align*}
    %
    Now $E \cap I_N$ is contained in $U_N$, because if $x \in E \cap I_N$, then $D^+ f(x) > R$ and $D_- f(x) < r$, so we can sum in $N$ to conclude that
    %
    \[ |E| \leq \sum \frac{r}{R} |I_N| = \frac{r}{R} |U_N| < |E| \]
    %
    a contradiction proving the claim.
\end{proof}

\begin{corollary}
  If $f$ is increasing and continuous, then $f'$ is measurable, non-negative, and
  %
  \[ \int_a^b f'(x)\; dx \leq f(b) - f(a) \]
\end{corollary}
\begin{proof}
  The fact the $f'$ is measurable and non-negative results from the fact that the functions $g_n(x) = \Delta_{1/n} f(x)$ are non-negative and continuous, and $g_n \to f'$ almost surely. We know
  %
  \begin{align*}
    \int_a^b f'(x) &\leq \liminf_{n \to \infty} \int_a^b g_n(x) = \liminf_{n \to \infty} n \int_a^b [f(x + 1/n) - f(x)]\\
    &= \liminf_{n \to \infty} n \left[ \int_b^{b+1/n} f(x) - \int_a^{a + 1/n} f(x) \right] = f(b) - f(a)
  \end{align*}
  %
  where the last equality follows because $f$ is continuous.
\end{proof}

Even for increasing continuous functions, the inequality in the theorem above need not be an equality, as the next example shows, so we need something stronger to obtain our differentiation theorem.

\begin{example}
  The Cantor-Lebesgue function is a continuous increasing function $f$ from $[0,1]$ to itself, with $f(0) = 0$, and $f(1) = 1$, but with $f'(x) = 0$ almost everywhere. This means
  %
  \[ \int_0^1 f'(x) = 0 < 1 = f(1) - f(0) \]
  %
  so we cannot obtain equality in general. To construct $f$, consider the Cantor set $C = \bigcap C_k$, where $C_k$ is the disjoint union of $2^k$ closed intervals. Set $f_0 = 0$, and $f_1(0) = 0$, $f_1(x) = 1/2$ on $[1/3,2/3]$, $f_1(1) = 1$, and $f$ linear between $[0,1/3]$ and $[2/3,1]$. Similarily, set $f_2(0) = 0$, $f_2(x) = 1/4$ on $[1/9, 2/9]$, $f_2(x) = 1/2$ on $[1/3,2/3]$, $f_2(x) = 3/4$ on $[7/9,8/9]$, and $f_2(1) = 1$. The functions $f_i$ are increasing and cauchy in the uniform norm, so they converge to a continuous function $f$ called the \emph{Cantor function}. $f$ is constant on each interval in the complement of the cantor set, so $f'(x) = 0$ almost everywhere.
\end{example}

To obtain equality in the integral formula, we require additional conditions on our increasing functions, provided by absolute continuity.

\section{Absolute Continuity}

A function $f: [a,b] \to \mathbf{R}$ is \emph{absolutely continuous} if for every $\varepsilon > 0$, there is $\delta > 0$ such that whenever $(a_1, b_1), \dots, (a_n,b_n)$ are disjoint intervals with $\sum (b_i - a_i) < \delta$, $\sum |f(b_i) - f(a_i)| < \varepsilon$. Thus the function should be `essentially constant' over every set of zero measure. It is easy to see from this that absolutely continuous functions must be uniformly continuous, and have bounded variation. Thus $f$ has a decomposition into the difference of two continuous increasing functions, and one can see quite easily that these functions are also absolutely continuous. Most promising to us, if $f$ is a function defined by $f(x) = \int_a^x g(t)\ dt$, where $g \in L^1[a,b]$, then $f$ is absolutely continuous. This shows that absolute continuity is necessary in order to hope for the integral formula
%
\[ \int_a^b f'(x)\ dx = f(b) - f(a) \]
%
The Cantor function is {\it not} absolutely continuous, since it is constant except on the Cantor set, and we can cover the Cantor set by intervals with total length $(2/3)^n$ for each $n$. Thus it is impossible for the Cantor function to satisfy the fundamental theorem of calculus.

\begin{theorem}
  If $g \in L^1(\mathbf{R})$, and
  %
  \[ f(x) = \int_a^x g(t)\; dt \]
  %
  then $f$ is absolutely continuous.
\end{theorem}
\begin{proof}
  Fix $\varepsilon > 0$. We claim that there is $\delta$ such that if $|E| < \delta$, then $\int_E |g| < \varepsilon$. Otherwise there are sets $E_n$ with $|E_{n+1}| \leq |E_n|/3$ and with $\int_{E_n} |g| \geq \varepsilon$. Thus if we define the sets $E_m' = E_m - \bigcup_{n > m} E_n$ then the $E_m'$ and we have $|E_m| \sim |E_m|'$. Since $g$ is integrable, we must have $\sum \int_{E_n'} |g| < \infty$, so we conclude that as $N \to \infty$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| \to 0 \]
  %
  Yet for any $N$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| = \int_{E_N} |g| \geq \varepsilon \]
  %
  which is an impossibility. Thus such a $\delta$ exists for every $\varepsilon$, and so if we have disjoint intervals $(a_n,b_n)$ with $\sum (b_n - a_n) < \delta$, then
  %
  \[ \sum |f(b_n) - f(a_n)| = \sum \left| \int_{a_n}^{b_n} g(t) \right| \leq \sum \int_{a_n}^{b_n} |g| = \int_{\bigcup (a_n,b_n)} |g| < \varepsilon \]
  %
  which shows the function is absolutely continuous.
\end{proof}

To prove the differentiation theorem, we require a covering estimate not unlike that used to prove the Lebesgue differentiation theorem. We say a collection of balls is a \emph{Vitali covering} of a set $E$ if for every $x \in E$ and every $\eta > 0$, there is a ball $B$ in the cover containing $x$ with radius smaller than $\eta$. Thus every point is covered by an arbitrary small ball.

\begin{lemma}
    If $E$ is a set of finite measure, and $\{ B_\alpha \}$ is a Vitali covering of $E$, then there eixsts a disjoint family of cubes $\{ B_\beta \}$ in the covering such that
    %
    \[ \left| E - \bigcup_\beta B_\beta \right| = 0. \]
\end{lemma}
\begin{proof}
  Fix $\delta > 0$. We claim we can find a disjoint family of cubes $B_1, \dots, B_N$ in the Vitali cover such that
  %
  \[ \left| E - \bigcup_{i = 1}^N B_i \right| \leq \delta. \]
  %
  By inner regularity, pick a compact set $K \subset E$ with $|K| \geq |E| - \delta/2$. Then $K$ is covered by finitely many balls of radius less than $\eta$ in the covering $\{ B_\alpha \}$, and the elementary Vitali covering lemma gives a disjoint subcollection of balls $B_1, \dots, B_{n_0}$ with
  %
  \[ |K| \leq \left| \bigcup B_\alpha \right| \leq 3^d \sum |B_k| \]
  %
  so $\sum |B_k| \geq 3^{-d} |K|$. If $\sum |B_k| \geq |K| - \delta/2$, we're done. Otherwise, define $E_1 = K - \bigcup \overline{B_k}$. Then
  %
  \[ |E_1| \geq |K| - \sum |\overline{B_k}| = |K| - \sum |B_k| > \delta/2 \]
  %
  If we pick a compact set $K_1 \subset E_1$ with $|K_1| \geq \delta/2$, then if we remove all sets in the Vitali covering which intersect $B_1, \dots, B_{n_0}$, then we still obtain a Vitali covering for $K_1$, and we can repeat the argument above to find a disjoint collection of open sets $B_1^1, \dots, B_{n_1}^1$ with $\sum |B_k^1| \geq 3^{-d} |K_1|$. Then $\sum |B_k| + \sum |B^1_k| \geq 2 (3^{-d} \delta)$. If $\sum |B_k| + \sum |B^1_k| < |K| - \delta/2$, we repeat the same process, finding a disjoint family for $K_2 \subset E_2$, where $\smash{E_2 = K_1 - \bigcup \overline{B^1_k}}$. If this process repeats itself $k$ times, then we obtain a family of open sets with total measure greater than or equal to $k (3^{-d} \delta)$. But then if we eventually have $k \geq (|E| - \delta) 3^d/ \delta$, then we obtain the required bound.

  We now construct our final cover inductively. Given $E$, we can find finitely many balls $B_{11},\dots,B_{1 n_1}$ such that
  %
  \[ \left| E - \bigcup_{i = 1}^{n_1} B_i \right| \leq 1/2. \]
  %
  Set $E_1 = E - \bigcup_{i = 1}^{n_1} B_i$. If we remove all balls from the Vitali cover that intersect the balls $B_1,\dots,B_{n_1}$, we still have a Vitali cover of $E_1$. Inductively, we can then find a disjoint family of balls $B_{k1},\dots,B_{kn_k}$ which are disjoint from all previously selected balls such that
  %
  \[ \left| E - \bigcup_{k = 1}^{k_0} \bigcup_{i = 1}^{n_k} B_{ki} \right| \leq 1/2^{k_0}. \]
  %
  Taking $k_0 \to \infty$ gives an infinite family of disjoint balls which cover $E$ up to a set of zero Lebesgue measure.
\end{proof}

\begin{theorem}
    If $f: [a,b] \to \mathbf{R}$ is absolutely continuous, then $f'$ exists almost everywhere, and if $f'(x) = 0$ almost surely, then $f$ is constant.
\end{theorem}
\begin{proof}
    It suffices to prove that $f(a) = f(b)$, since we can then apply the theorem on any subinterval. Let $E = \{ x \in (a,b): f'(x) = 0 \}$. Then $|E| = b - a$. Fix $\varepsilon > 0$. Since for each $x \in E$, we have
    %
    \[ \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = 0 \]
    %
    This implies that the family of intervals $(x,y)$ such that the inequality $|f(y) - f(x)| \leq \varepsilon (y-x)$ holds forms a Vitali covering of $E$, and we may therefore select a family of disjoint intervals $I_i = (x_i,y_i)$ with
    %
    \[ \sum |I_i| \geq |E| - \delta = (b - a) - \delta \]
    %
    But $|f(y_i) - f(x_i)| \leq \varepsilon (y_i - x_i)$, so we conclude
    %
    \[ \sum |f(y_i) - f(x_i)| \leq \varepsilon (b - a) \]
    %
    The complement of $I_i$ is a union of intervals $J_i = (x_i',y_i')$ of total length $\leq \delta$. Applying the absolute continuity of $f$, we conclude
    %
    \[ \sum |f(y_i') - f(x_i')| \leq \varepsilon \]
    %
    so applying the triangle inequality,
    %
    \[ |f(b) - f(a)| \leq \sum |f(y_i') - f(x_i')| + \sum |f(y_i) - f(x_i)| \leq \varepsilon(b - a + 1) \]
    %
    We can then let $\varepsilon \to 0$ to obtain equality.
\end{proof}

\begin{theorem}
    Suppose $f$ is absolutely continuous on $[a,b]$. Then $f'$ exists almost every and is integrable, and
    %
    \[ f(b) - f(a) = \int_a^b f'(y)\ dy \]
    %
    so the fundamental theorem of calculus holds everywhere. Conversely, if $f \in L^1[a,b]$, then there is an absolutely continuous function $g$ with $g' = f$ almost everywhere.
\end{theorem}
\begin{proof}
    Since $f$ is absolutely continuous, we can write $f$ as the difference of two continuous increasing functions on $[a,b]$, and this easily implies $f$ is differentiable almost everywhere and is integrable on $[a,b]$. If $g(x) = \int_a^x f'(x)$, then $g$ is absolutely continuous, hence $g - f$ is also absolutely continuous. But we know that $(g - f)' = g' - f' = 0$ almost everywhere, so the last theorem implies that $g$ differs from $f$ by a constant. Since $g(a) = 0$, $g(x) = f(x) - f(a)$. The converse was proved exactly in our understanding of differentiating integrals.
\end{proof}

We now dwell slightly longer on the properties of absolutely continuous functions, which enables us to generalize other properties of integrals found in the calculus. We begin by noting that it is easy to verify that if $f$ and $g$ are absolutely continuous functions, then $fg$ is also absolutely continuous. We know $f'$, $g'$, and $(fg)'$ exist almost everywhere. But when all three exist simultaneously, the product rule gives $(fg)' = f'g + fg'$. The absolute continuity implies that
%
\[ \int_a^b f'g + fg' = \int_a^b (fg)' = f(b)g(b) - f(a)g(a) \]
%
Thus one can integrate a pair of absolutely continuous functions by parts. Next, we shall show that monotone absolutely continuous functions are precisely those we can use to change variables. One important thing to note is that even if $f$ is a continuous function, and $g$ is measurable, $g \circ f$ need not be measurable. The easy reason to see this is that the inverse image of every open set in $g$ is measurable, so in order to guarantee $g \circ f$ is measurable we need the inverse image of every measurable set under $f$ be measurable.

\begin{example}
  Consider the function $f(x) = \int_0^x \chi_E(x)\; dx$, where $E$ is a thick Cantor set. Then $f$ is absolutely continuous, strictly increasing on $[0,1]$, and maps $E$ to a set of measure zero. This is because $E = \lim E_n$, where $E_n$ is a family of intervals with $|E_n| \downarrow |E|$. Then $f(E_n)$ has total length $|E_n - E|$, so as $n \to \infty$, we see $\lim f(E_n) = f(E)$ has measure zero.  This means that $f(X)$ is measurable for any subset $X$ of $E$, and in particular, if $X$ is non-measurable, then $f^{-1}(f(X))$ cannot be measurable, even though $f(X)$ is measurable. Note that $f$ is strictly increasing even though it's derivatives vanish on a set of positive measure.
\end{example}

The next lemmas will show that even though $g \circ f$ may not be Lebesgue measurable when $f$ is absolutely continuous and $g$ is Lebesgue measurable, this does not really bother us too much when changing variables.

\begin{lemma}
  If $f$ is absolutely continuous, then it maps sets of measure zero to sets of measure zero.
\end{lemma}
\begin{proof}
  Let $E$ be a set of measure zero. Then for each $\delta > 0$, $E$ is coverable by a family of open intervals with total length $\delta$. But if $\delta$ is taken small enough, this means that $f(E)$ is coverable by a family of open intervals with total length bounded by $\varepsilon$, for any $\varepsilon$.
\end{proof}

This property of absolutely continuous functions is independant of the properties of the Euclidean domain as it's domain, and is used in the generalization of absolute continuity to more general domains, or even to measures. If $f$ is absolutely continuous, then the image of every interval is an interval, and since $f(\bigcup K_n) = \bigcup f(K_n)$, this implies that the image of a $F_\sigma$ set is measurable. But since every measurable set of $\mathbf{R}$ differs from a $F_\sigma$ set by a set of measure zero, the image of every Lebesgue measurable set is Lebesgue measurable. The reverse is almost true.

\begin{lemma}
  If $f$ is absolutely continuous, and $E$ measurable, then the set
  %
  \[ f^{-1}(E) \cap \{ x : f'(x) > 0 \} \]
  %
  is measurable.
\end{lemma}
\begin{proof}
  If $E$ is an open set, then
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  It suffices to prove this when $E$ is an interval, and then this is just the theorem of differentiation for absolutely continuous functions. But then applying the dominated convergence theorem shows that this equation remains true if $E$ is an $G_\delta$ set. Furthermore, this means the theorem is true if $E$ is a closed set, and so by applying the monotone convergence theorem, the theorem is true if $E$ is an $F_\sigma$ set. But if $E$ is an arbitrary measurable set, then for every $\varepsilon$ there are $F_\sigma$ and $G_\delta$ sets $K \subset E \subset U$ with $|U - K| = 0$. But
  %
  \[ \alpha|f^{-1}(U - K) \cap \{ f' \geq \alpha \}| \leq \int_{f^{-1}(U-K)} f'(x)\; dx = |U - K| = 0 \]
  %
  Thus $f^{-1}(U-K) \cap \{ f' \geq \alpha \}$ is a set of measure zero, and so in particular by completeness, every set contained in this set is measurable, in particular $f^{-1}(U - E) \cap \{ f' \geq \alpha \}$ is measurable. But now this means
  %
  \[ \{ f' \geq \alpha \} - f^{-1}(U-E) \cap \{ f' \geq \alpha \} = f^{-1}(E) \cap \{ f' \geq \alpha \} \]
  %
  is measurable. Taking $\alpha \downarrow 0$ completes the proof.
\end{proof}

Because of this, even though $g \circ f$ is not necessarily measurable, $(g \circ f) f'$ is always measurable if $f$ is absolutely continuous. Thus the expression $\int (g \circ f) f'$ makes sense, and thus we can always interpret the change of variables formula.

\begin{theorem}
  If $f$ is absolutely continuous, and $g$ is integrable, then
  %
  \[ \int g(f(x)) f'(x)\; dx = \int g(y)\; dy \]
\end{theorem}
\begin{proof}
  Using the notation in the last proof, if $E$ is measurable, then
  %
  \[ |K| = \int_{f^{-1}(K)} f'(x)\; dx \leq \int_{f^{-1}(E)} f'(x)\; dx \leq \int_{f^{-1}(U)} f'(x)\; dx = |U| \]
  %
  and $|U| = |K| = |E|$, so that for any measurable set $E$,
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  This imples the theorem we need to prove is true whenever $g$ is the characteristic function of any measurable set. But then by linearity, it is true for any simple function. By monotone convergence, it is then true for any non-negative function, and then by partitioning $g$ into the sum of simple functions, we obtain the theorem in general.
\end{proof}





\section{Differentiability of Jump Functions}

We now consider the differentiability of not necessarily continuous monotonic functions. Set $f$ to be an increasing function on $[a,b]$, which we may assume to be bounded.  Then the left and right limits of $f$ exist at every point, which we will denote by $f(x-)$ and $f(x+)$. Of course, we have $f(x-) \leq f(x) \leq f(x+)$. If there is a discontinuity, this means we are forced to have a `jump discontinuity' where $f$ skips an interval. This implies that $f$ can only have countably many such discontinuities, because a family of disjoint intervals on $\mathbf{R}$ is at most countable. Now define the jump function $\Delta f(x) = f(x^+) - f(x-)$, with $\theta(x) \in [0,1]$ defined such that $f(x_n) = f(x_n-) + \theta(x) \Delta f(x)$. If we define the functions
%
\[ j_y(x) = \begin{cases} 0 & : x < y \\ \theta(y) & : x = y \\ 1 & x > y \end{cases} \]
%
then we can define the \emph{jump function} associated with $f$ by
%
\[ J(x) = \sum_x \Delta f(x) j_n(x) \]
%
Since $f$ is bounded on $[a,b]$, we make the final observation that
%
\[ \sum_{x \in [a,b]} \Delta f(x) \leq f(b) - f(a) < \infty \]
%
so the series defining $J$ converges absolutely and uniformly.

\begin{lemma}
    If $f$ is increasing and bounded on $[a,b]$, then $J$ is discontinuous precisely at the values $x$ with $\Delta f(x) \neq 0$ with $\Delta J(x) = \Delta f(x)$. The function $f - J$ is continuous and increasing.
\end{lemma}
\begin{proof}
    If $x$ is a continuity point of $f$, then $j_y$ is continuous at $x$, and hence, because $\sum_y \Delta f(y) j_y(x) \to J(x)$ uniformly, so we conclude that $J$ is continuous at $x$. On the other hand, for each $y$, $j_y(y-) = 0$ and $j_y(y+) = 1$, and if we label the points of discontinuity of $f$ by $x_1, x_2, \dots$, then
    %
    \[ J(x) = \sum_{i = 1}^k \Delta f(x_i) j_{x_i} + \sum_{i = k+1}^\infty \Delta f(x_i) j_{x_i} \]
    %
    The right hand partial sums are continuous at $x_k$, whereas the left hand sum has a jump discontinuity of the same order as $f$ at $x_k$, we conclude $J$ also has this discontinuity. But this means that
    %
    \[ (f - J)(x_k+) - (f - J)(x_k-) = 0 \]
    %
    so $f - J$ is continuous at every point. $f - J$ is increasing because of the inequality
    %
    \[ J(y) - J(x) \leq \sum_{x < x_n \leq y} \alpha_n \leq f(y) - f(x) \]
    %
    which follows because $J$ is just the sum of jump discontinuities, and the right hand side because $f$ can decrease and increase outside of the jump discontinuities.
\end{proof}

Since $f - J$ is continuous and increasing, it is differentiable almost everywhere. It therefore remains to analyze the differentiability of the jump function $J$.

\begin{theorem}
    $J'$ exists and vanishes almost everywhere.
\end{theorem}
\begin{proof}
    Fix $\varepsilon > 0$, and consider
    %
    \[ E = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J(x + h) - J(x)}{h} > \varepsilon \right\} \]
    %
    Then $E$ is measurable, because we can take the $\limsup$ over rational numbers because $J$ is increasing. We want to show it has measure zero. Suppose $\delta = |E|$. Consider $\eta > 0$ to be chosen later, and find $n$ such that $\sum_{k = n}^\infty \alpha_k < \eta$. Write
    %
    \[ J_0(x) = \sum_{n > N} \alpha_n j_n \]
    %
    Then $J_0(b) - J_0(a) < \eta$. Now $E$ differs from the set
    %
    \[ E' = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J_0(x + h) - J_0(x)}{h} > \varepsilon \right\} \]
    %
    by finitely many points. Using inner regularity, find a compact set $K \subset E'$ with $|K| \geq \delta/2$. For each $x \in K$, we can find intervals $(\alpha_x, \beta_x)$ upon which $J_0(\beta_x) - J_0(\alpha_x) \geq \varepsilon |\beta_x - \alpha_x|$. But applying the elementary Vitali covering lemma, we can find a disjoint family of such intervals with $\sum (\beta_{x_i} - \alpha_{x_i}) \geq |K|/3 \geq \delta/6$. But now we find
    %
    \[ J_0(b) - J_0(a) \geq \sum J_0(\beta_{x_i}) - J_0(\alpha_{x_i}) \geq \varepsilon \delta/6 \]
    %
    This means $\delta \leq 6 \eta/\varepsilon$, and by letting $\eta \to 0$, we can conclude $\delta = 0$.
\end{proof}

This concludes our argument that {\it every} function of bounded variation has a derivative almost everywhere, because every such function can be uniquely written (up to a shift in the range of the functions) as the sum of a continuous function and a jump function. If $f$ is a function with bounded variation, then the function
%
\[ F(x) = \int_0^x f'(x) \]
%
is absolutely continuous, and $f - F$ is a continuous function with derivative zero almost everywhere. The fact that this decomposition is unique up to a shift as well (which can easily be seen in the case of an increasing function, from which the general case follows) leads us to refer to this as the \emph{Lebesgue decomposition} of a function of bounded variation on the real line.

\section{Rectifiable Curves}

We now consider the validity of the length formula
%
\[ L = \int_a^b (x'(t)^2 + y'(t)^2)^{1/2}\ dt \]
%
where $L$ is the length of the curve parameterized by $(x,y)$ on $[a,b]$. We cannot always expect this formula to hold, because if $x$ and $y$ are both the Cantor devil staircase function, then the formula above gives a length of zero, whereas we know the curve traces a line between $0$ and $1$, hence has length at least $\sqrt{2}$.

\begin{theorem}
    If a curve is parameterized by absolutely continuous functions $x$ and $y$ on $[a,b]$, then the curve is rectifiable, and has length
    %
    \[ \int_a^b (x'(t) + y'(t))^{1/2}\ dt \]
\end{theorem}
\begin{proof}
  This proof can be reworded as saying if $f$ is complex-valued and absolutely continuous, then it's total variation can be expressed as
  %
  \[ V(f,a,b) = \int_a^b |f'(t)|\; dt \]
  %
  If $P = \{ a \leq t_1 < \dots < t_n \leq b \}$ is a partition, then
  %
  \[ \sum |f(t_{n+1}) - f(t_n)| = \sum \left| \int_{t_n}^{t_{n+1}} f'(t)\; dt \right| \leq \sum \int_{t_n}^{t_{n+1}} |f'(t)|\; dt \leq \int_a^b |f'(t)|\; dt \]
  %
  so $V(f,a,b) \leq \int_a^b |f'(t)|\; dt$. To prove the converse inequality, fix $\varepsilon > 0$, and find a step function $g$ with $f' = g + h$, with $\| h \|_1 \leq \varepsilon$. If $G(x) = \int_a^x g(t)\; dt$ and $H(x) = \int_a^x h(t)\; dt$, then $F = G + H$, and $V(f,a,b) \geq V(G,a,b) - V(H,a,b) \geq V(G,a,b) - \varepsilon$, and if we partition $[a,b]$ into $a = t_0 < \dots < t_N$, where $G$ is constant on each $(t_n, t_{n+1})$, then
  %
  \begin{align*}
    V(G,a,b) &\geq \sum |G(t_n) - G(t_{n-1})| = \sum \left| \int_{t_{n-1}}^{t_n} g(t)\; dt \right|\\
    &= \sum \int_{t_{n-1}}^{t_n} |g(t)|\; dt = \int_a^b |g(t)|\; dt \geq \| f' \|_1 - \varepsilon
  \end{align*}
  %
  Letting $\varepsilon \to 0$ now gives the result.
\end{proof}

It is interesting to note that any rectifiable curve has a special {\it parameterization by arclength}, i.e. a parameterization $(x(t), y(t))$ such that if $L$ is the length function associated to the parameterization, then $L(A,B) = B - A$. This is obtainable by inverting the length function.

\begin{theorem}
  If $z = (x,y)$ is a parameterization of a rectifiable curve by arclength, then $x$ and $y$ are absolutely continuous, and $|z'| = 1$ almost everywhere.
\end{theorem}
\begin{proof}
  For any $s < t$,
  %
  \[ t - s = L(s,t) = V(f,s,t) \geq |z(t) - z(u)| \]
  %
  so it follows immediately that $|z|$ is an absolutely continuous function, and $|z'| \leq 1$ almost surely. But now we know that
  %
  \[ \int_a^b |z'(t)| = b - a \]
  %
  and this equality can now only hold if $|z'(t)| = 1$ almost surely.
\end{proof}

\section{Bounded Variation in Higher Dimensions}

Since the higher dimensional Euclidean domains do not have an ordering, it is impossible to define their length by partitioning their domain, and the meaning of a jump discontinuity is no longer clear. However, there are properties equivalent to having bounded variation which are more extendable to higher dimensions.

\begin{theorem}
  The following properties of $f: \mathbf{R} \to \mathbf{R}$ are equivalent, for some fixed finite constant $A$.
  %
  \begin{itemize}
    \item $f$ can be modified on a set of measure zero so that it has bounded variation not exceeding $A$.
    \item $\int |f(x+h) - f(x)| \leq A|h|$ for all $h \in \mathbf{R}$.
    \item For any $C^1$ function $\varphi$ with compact support, $\left| \int f(x) \varphi'(x) \right| \leq A \| \varphi \|_\infty$.
  \end{itemize}
\end{theorem}
\begin{proof}
  If $V(f) = A$, where $A < \infty$, then we can write $f = f^+ - f^-$, where $f^+$ and $f^-$ are both increasing functions, and with $V(f) = V(f^+) + V(f^-)$. It then follows that $|f(x+h) - f(x)| \leq (f^+(x+h) - f^+(x)) + |f^-(x+h) - f^-(x)|$, so it suffices to prove the second property by assuming $f$ is increasing. But then by the monotone convergence theorem, assuming $h > 0$ without loss of generality,
  %
  \[ \int |f(x+h) - f(x)| = \lim_{y \to \infty} \int_{-y}^y f(x+h) - f(x) = \lim_{y \to \infty} \int_y^{y+h} f(x) - \int_{-y-h}^{-y} f(x) \]
  %
  The first term of the limit converges to $hV(f)$, and the second to zero, completing the first part of the theorem. Now assuming the second point, we prove the third point. Then using the second point, we find
  %
  \begin{align*}
    \left|\int f(x) \varphi'(x) \right| &= \left| \lim_{h \to 0} \int f(x) \frac{\varphi(x+h) - \varphi(x)}{h} \right|\\
    &= \left| \lim_{h \to 0} \int \frac{f(x-h) - f(x)}{h} \varphi(x) \right| \leq A \| \varphi \|_\infty
  \end{align*}
  %
  Finally, we consider the third point being true. The set of all partitions with rational points is countable. Suppose that for each rational $P = \{ t_0 < \dots < t_N \}$ there is a set $E_P$ of measure zero for each rational partition $P$ such that
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) \leq A \]
  %
  Then the union of $E_P$ over all rational $P$ has measure zero. We can modify $f$ on $E_P$ by setting $f(x) = \liminf_{y \to 0} f(x+y)$, and then $V(f,P) \leq A$ for all rational partitions $P$. If $Q$ is now any partition, we can find a rational partition $P$ with $V(f,P) \geq V(f,Q) - \varepsilon$, and so $V(f,P) \leq A - \varepsilon$. Taking $\varepsilon \to 0$ completes the argument. Thus if $f$ cannot be modified to have finite variation $A$, there exists a rational partition $P$ such that for any set $E$ of measure zero,
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) > A \]
  %
  Thus for any $\varepsilon$, there exists $E_n^+, E_n^- \subset [t_{n-1},t_n]$ of positive measure such that
  %
  \[ \sum_{n = 1}^N \inf_{x \in E_n^+} f(x) - \sup_{x \in E_n^-} f(x) > A \]
  %
  If we consider the polygonal function $\phi$ which
\end{proof}

\section{Minkowski Content}

Given a set $K \in \mathbf{R}^n$, we let $K^\delta$ denote the open set consisting of points $x$ with $d(x,K) < \delta$. The $m$ dimensional \emph{Minkowski content} of $K$ is defined to be
%
\[ \lim_{\delta \to 0} \frac{1}{\alpha(n-m)} \frac{|K^\delta|}{\delta^m} \]
%
where $\alpha(d)$ is the volume of the unit ball in $d$ dimensions. When this limit exists, we denote it by $M^m(K)$. In this section, we mainly discuss the one dimensional Minkowski content in two dimensions, i.e. the values of
%
\[ \lim_{\delta \to 0} \frac{|K^\delta|}{2 \delta^m} \]
%
and it's relation the length of curves. Since we now only care about the one dimensional Minkowski content, we let $M(K)$ denote the one dimension Minkowski content.

\begin{lemma}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a curve, and $\Delta$ is the distance between the endpoints of the curve, then $|\Gamma^\delta| \geq 2 \delta \Delta$.
\end{lemma}
\begin{proof}
  By rotating, we may assume that both endpoints of the curve lie on the $x$ axis, so $z(a) = (A,0)$, $z(b) = (B,0)$ with $A < B$, so $\Delta = B - A$. If $\Delta = 0$, the theorem is obvious. Otherwise, for each point $x \in [A,B]$ there is $t(x)$ such that if $z_1(t(x)) = x$, and so $\Gamma^\delta$ contains $x \times [z_2(t(x)) - \delta, z_2(t(x)) + \delta]$, which has length $2 \delta$. Thus by Fubini's theorem,
  %
  \[ |\Gamma^\delta| = \int_{-\infty}^\infty \int_{-\infty}^\infty \chi_{\Gamma^\delta}(x,y)\; dx \;dy \geq \int_A^B 2 \delta = 2 \delta \Delta \]
  %
  so the theorem is proved.
\end{proof}

\begin{theorem}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a quasi-simple curve (simple except at finitely many points), then the Minkowski content of $\Gamma$ exists if and only if $\Gamma$ is rectifiable, and in this case $M^1(\Gamma)$ is the length of the curve $L$.
\end{theorem}
\begin{proof}
  To prove the theorem, we consider the upper and lower Minkowski contents
  %
  \[ M^*(\Gamma) = \limsup_{\delta\to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta}\ \ \ \ M_*(\Gamma) = \liminf_{\delta \to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta} \]
  %
  First, we prove that $M^*(\Gamma) \leq L$. Consider a partition $P$ of $[a,b]$, and let $L_P$ be the length of the polygonal approximation to the curve. By refining the partition, we may assume that $\Gamma$ is simple, with the repeated points at the boundaries of the intervals. For each interval $I_n$ in the partition, we select a closed subinterval $J_n = [t_n,u_n]$ such that $\Gamma$ is simple on $\bigcup J_n$, and
  %
  \[ \sum |z(u_n) - z(t_n)| \geq L_P - \varepsilon \]
  %
  Since the intervals $J_n$ are disjoint, for suitably small $\delta$ the sets $J_n^\delta$ are disjoint. Applying the previous lemma, we conclude that
  %
  \[ |\Gamma^\delta| \geq \sum |J_n^\delta| \geq 2 \delta \sum |z(u_n) - z(t_n)| = 2 \delta (L_p - \varepsilon) \]
  %
  First, by letting $\varepsilon \to 0$ and then $\delta \to 0$, we conclude that $M_*(\Gamma) \geq \lim_P L_P$. In particular, this shows that if $\Gamma$ has Minkowski content one, then the curve is rectifiable. Conversely, we consider the functions
  %
  \[ F_n(s) = \sup_{0 < |h| < 1/n} \left| \frac{z(s+h) - z(s)}{h} - z'(s) \right| \]
  %
  Because $z$ is continuous, this supremum can be considered over a countable, dense subset, and so each $F_n$ is measurable. Since $F_n(s) \to 0$ for almost every $s$, we can apply Egorov's theorem to show that this limit is uniform except on a singular set $E$ with $|E| < \varepsilon$, so that for some large $N$, for $s \not \in E$ and $|h| < 1/N$, $|z(s+h) - z(s) - hz'(s)| < \varepsilon h$. We now split the interval $[a,b]$ into consecutive intervals $I_1, \dots, I_{M+1}$, with each interval but $I_{M+1}$ having length $1/N$. We let $\Gamma_n$ denote the section of the curve travelled along the interval $I_n$. Thus $|\Gamma^\delta| \leq \sum |\Gamma_n^\delta|$. If an interval $I_n$ contains an element of $E^c$, we say $I_n$ is a `good' interval. Then we can pick an element $x_n \in I_n$ for which for any $x \in I_n$,
  %
  \[ |z(x) - z(x_n) - (x - x_n) z'(x_n)| < \varepsilon |x - x_n| < \varepsilon / N \]
  %
  Thus $\Gamma_n$ is covered by a $\varepsilon / N$ thickening of a length $1/N$ line $J_n$ in $\mathbf{R}^2$ through $z(x_n)$ with slope $z'(x_n)$. Thus if $\varepsilon \leq 1$, we conclude
  %
  \begin{align*}
    |\Gamma_n^\delta| &\leq J_n^{\varepsilon/N + \delta} \leq (1/N + 2\varepsilon/N + 2 \delta)(2\varepsilon/N + 2\delta)\\
    \leq 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2)
  \end{align*}
  %
  Since $M \leq NL$, if we take the sum of $|\Gamma_n^\delta|$ over all `good' intervals we obtain an upper bound of
  %
  \[ NL \left( 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2) \right) = 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N) \]
  %
  On the other hand, if $I_n$ is contained within $E$, or if $n = M+1$, we say $I_n$ is a bad interval. Since $E$ has total measure bounded by $\varepsilon$, there can be at most $\varepsilon N + 1$ bad intervals. On these intervals we use the crude estimate $|z(t) - z(u)| \leq |t-u|$ (true because $z$ is an arclength parameterization) to show $\Gamma_n$ is contained in a rectangle with sidelengths $1/N$, so we obtain that $|\Gamma_n^\delta| \leq (1/N + 2\delta)^2 = O(1/N^2 + \delta^2)$. Thus the sum of $|\Gamma_n^\delta|$ over the `bad intervals' is bounded by
  %
  \[ O(\varepsilon/N + 1/N^2 + \varepsilon N \delta^2 + \delta^2) \]
  %
  In particular, the sum of the two bounds gives
  %
  \[ |\Gamma^\delta| \leq 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N + 1/N^2) \]
  %
  Or
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \varepsilon/N + 1/N^2) \]
  %
  If we choose $N \geq 1/\delta$, we get that
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \delta \varepsilon) = L + O(\varepsilon + \delta N) \]
  %
  Letting $\delta \downarrow 0$, we conclude that $M^*(\Gamma) \leq L + O(\varepsilon)$, and we can then let $\varepsilon \downarrow 0$ to conclude $M^*(\Gamma) \leq L$. This completes the proof that if $\Gamma$ is rectifiable, then $\Gamma$ has one dimensional Minkowski content, and $M(\Gamma) = L$.
\end{proof}

If $\Gamma$ is rectifiable, it is parameterizable by a Lipschitz map (the arclength parameterization). If we instead consider a curve parameterizable by a map $z$ which is Lipschitz of order $\alpha$, which may no longer be absolutely continuous, but still has a decay very similar to the Minkowski dimension decay.

\begin{theorem}
  If $z$ is a planar curve which is Lipschitz of order $\alpha > 1/2$, then it's trace $\Gamma$ satisfies $|\Gamma^\delta| = O(\delta^{2-1/\alpha})$.
\end{theorem}
\begin{proof}
  Since $|z(t) - z(s)| \leq |t - s|^\alpha$, we can cover $z$ by $O(N)$ radius $1/N^\alpha$ balls, so $|\Gamma| \lesssim N^{1-2\alpha}$, and so $|\Gamma^\delta| \lesssim N (1/N^\alpha + \delta)^2$. Setting $N = \delta^{-1/\alpha} + O(1)$ gives $|\Gamma^\delta| \lesssim \delta^{2-\alpha - 1/\alpha}$.
\end{proof}

\section{The Isoperimetric Inequality}

We now use our Minkowski content techniques to prove the isoperimetric inequality, which asks us to find the region in the plane with largest area whose boundary has a bounded length $L$. We suppose $\Omega$ is a bounded region of the plane, whose boundary $\partial \Omega$ is a rectifiable curve with length $L$. In particular, we shall find the region with the largest area whose boundary has a fixed length are balls. A key inequality used in the proof is the Brun Minkowski inequality, which lowers bounds the measure of $A+B$ in terms of $A$ and $B$. If we hope for an estimate $|A+B|^\alpha \gtrsim |A|^\alpha + |B|^\alpha$, then taking $B = \alpha A$, where $A$ is convex and, for which $A + \alpha A = (1 + \alpha)A$, we find $(1 + \alpha)^{d\alpha} \gtrsim (1 + \alpha^{d\alpha})$. Thus $\alpha \geq 1/d$.

\begin{lemma}
  If $A$, $B$, and $A+B$ are measurable, $|A + B|^{1/d} \geq |A|^{1/d} + |B|^{1/d}$.
\end{lemma}
\begin{proof}
  Suppose first that $A$ and $B$ are rectangles with side lengths $x_n$ and $y_n$. Then the Minkowski inequality becomes
  %
  \[ \left( \prod (x_n + y_n) \right)^{1/d} \geq \left( \prod x_n \right)^{1/d} + \left( \prod y_n \right)^{1/d} \]
  %
  Replacing $x_n$ with $\lambda_n x_n$ and $y_n$ with $\lambda_n y_n$, we find that we may assume $x_n + y_n = 1$, and so we must prove that for any $x_n \leq 1$,
  %
  \[ \left( \prod x_n \right)^{1/d} + \left( \prod (1 - x_n) \right)^{1/d} \leq 1 \]
  %
  But this inequality is an immediate consequence of the arithmetic geometric mean inequality. Thus the case is proved. Next, we suppose $A$ and $B$ are unions of disjoint closed rectangles, and we prove the inequality by induction on the number of rectangles. Without loss of generality, by symmetry in $A$ and $B$, we may assume that $A$ has at least two rectangles $R_1$ and $R_2$. Since the inequality is translation invariant separately in $A$ and $B$, and $R_1$ and $R_2$ is disjoint, hence separated by a coordinate axis, we may assume there exists an index $j$ such that every element $x$ of $R_1$ has $x_1 < 0$ and every element $x$ of $R_2$ has $x_1 > 0$. Let $A^+ = A \cap \{ x_j \leq 0 \}$ and $A^- = A \cap \{ x_j \geq 0\}$. Next, we translate $B$ such that if $B^{\pm}$ are defined similarily, then
  %
  \[ \frac{|B^{\pm}|}{|B|} = \frac{|A^{\pm}|}{|A|} \]
  %
  Note that $A+B$ contains the union of $A^+ + B^+$ and $A^- + B^-$, and this union is disjoint. Thus by induction,
  %
  \begin{align*}
    |A+B| &\geq |A^+ + B^+| + |A^- + B^-|\\
    &\geq (|A^+|^{1/d} + |B^+|^{1/d})^d + (|A^-|^{1/d} + |B^-|^{1/d})^d\\
    &= |A^+| \left( 1 + \left( \frac{|B|^+}{|A|^+} \right)^{1/d} \right)^d + |A^-| \left( 1 + \left( \frac{|B|^-}{|A|^-} \right) \right)^d\\
    &= (|A|^{1/d} + |B|^{1/d})^d
  \end{align*}
  %
  Thus the proof is completed for unions of rectangles. The proof then passes to open sets by approximating open sets by closed rectangles contained within. Then we can pass to where $A$ and $B$ are compact sets, since then $A+B$ is compact, and so if we consider the open thickenings $A^\varepsilon$, $B^\varepsilon$, and $(A+B)^\varepsilon$, then
  %
  \[ |A| = \lim |A^\varepsilon|\ \ \ |B| = \lim |B^\varepsilon|\ \ \ |A + B| = \lim |(A + B)^\varepsilon| \]
  %
  and $(A+B)^\varepsilon \subset A^\varepsilon + B^\varepsilon \subset (A + B)^{2\varepsilon}$. Finally, we can use inner regularity to obtain the theorem in full.
\end{proof}

\begin{theorem}
  For any region $\Omega$, $4 \pi |\Omega| \leq L^2$.
\end{theorem}
\begin{proof}
  For $\delta > 0$, consider
  %
  \[ \Omega_+(\delta) = \{ x: d(x,\Omega) < \delta \}\ \ \ \ \Omega_-(\delta) = \{ x : d(x,\Omega^c) \geq \delta \} \]
  %
  Then we have a disjoint union $\Omega_+(\delta) = \Omega_-(\delta) + \Gamma^\delta$, where $\Gamma$ is the boundary curve of $\Omega$. Furthermore, $\Omega_+(\delta)$ contains $\Omega + B_\delta$, and $\Omega$ contains $\Omega_-(\delta) + B_\delta$. Applying the Brun Minkowski inequality, we conclude
  %
  \[ |\Omega_+(\delta)| \geq (|\Omega|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega| + 2 \pi^{1/2} \delta |\Omega|^{1/2} \]
  \[ |\Omega| \geq (|\Omega_-(\delta)|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega_-(\delta)| + 2 \pi^{1/2} \delta |\Omega_-(\delta)|^{1/2} \]
  %
  But
  %
  \[ |\Gamma^\delta| = |\Omega_+(\delta)| - |\Omega_-(\delta)| \geq 2 \pi^{1/2} \delta \left( |\Omega|^{1/2} + |\Omega_-(\delta)|^{1/2} \right) \]
  %
  Dividing by $2\delta$ and letting $\delta \to 0$, we conclude $L \geq 2 \pi^{1/2} |\Omega|^{1/2}$. This is precisely the inequality we need.
\end{proof}

Using some Fourier analysis, we can prove that the only smooth curves which make this inequality tight are circles. Indeed, if a closed $C^1$ curve $\Gamma = \{ z(t): a \leq t \leq b \}$ is given, then Green's theorem implies the area of its interior is given by
%
\[ \frac{1}{2} \left| \int_\Gamma x\; dy - y\; dx \right| = \frac{1}{2} \left| \int_a^b x(t) y'(t) - y(t) x'(t) \right| \]
%
We then take a Fourier series in $x$ and $y$.

\begin{theorem}
  The only curves $\Gamma$ with rectifiable boundary such that $A = \pi (L/2)^2$ are circles.
\end{theorem}
\begin{proof}
By normalizing, we may assume $z$ is an arcline parameterization, and $\Gamma$ has length $2\pi$, so $z:[0,2\pi] \to \mathbf{R}^2$, and $z$ is absolutely continuous. If $x(t) \sim \sum a_n e^{nit}$ and $y(t) \sim \sum b_n e^{int}$, then $x'(t) \sim \sum i n a_n e^{n i t}$ and $y(t) \sim \sum i n b_n e^{nit}$. Parseval's equality implies
%
\[ \int_0^{2\pi} x(t) y'(t) - y(t) x'(t) = 2 \pi i \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \]
%
Thus the area of the curve is precisely
%
\[ \pi \left| \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \right| \leq \pi \sum 2n|b_na_n| \leq \pi \sum |n|(|a_n|^2 + |b_n|^2) \]
%
On the other hand, the length constraint implies that, since $|z'(t)| = 1$,
%
\[ 1 = \frac{1}{2\pi} \int_0^{2\pi} x'(t)^2 + y'(t)^2 = \sum |n|^2(|a_n|^2 + |b_n|^2) \]
%
If $A = \pi$, then
%
\[ \sum |n| (|a_n|^2 + |b_n|^2) \geq 1 = \sum |n|^2 (|a_n|^2 + |b_n|^2) \]
%
This means we cannot have $|n| < |n|^2$ whenever $a_n$ or $b_n$ is nonzero. Thus the Fourier support of $x$ and $y$ is precisely $\{ -1, 0, 1 \}$. Since $x$ is real valued, $a_1 = \overline{a_{-1}} = a$, $b_1 = \overline{b_{-1}}$. We thus have $2(|a_1|^2 + |b_1|^2) = 1$, and since we must have $a$ a scalar multiple of $b$ so the Cauchy Schwarz inequality application becomes an equality, we must have $|a_1| = |b_1| = 1/2$. If $a_1 = e^{i\alpha}/2$ and $b_1 = e^{i\beta}/2$, the fact that $1 = 2|a_1\overline{b_1} - \overline{a_1}b_1|$ implies $|\sin(\alpha - \beta)| = 1$, hence $\alpha - \beta = k \pi /2$, where $k$ is an odd integer. Thus $x(s) = \cos(\alpha + s)$, and $y(s) = \cos(\beta + s)$, which parameterizes a circle.
\end{proof}

\section{Differentiability of Measures}

Using the Besicovitch covering theorem, we can obtain some differentiability properties of Radon measure on $\RR^d$. For two such measures $\mu$ and $\nu$ on $\RR^d$, define
%
\[ \overline{\frac{d\mu}{d \nu}}(x) = \limsup_{r \to 0} \frac{\nu(B(x,r))}{\mu(B(x,r))} \]
%
and
%
\[ \underline{\frac{d\mu}{d\nu}}(x) = \liminf_{r \to 0} \frac{\nu(B(x,r))}{\mu(B(x,r))}. \]
%
The derivative is defined when both quantities agree with one another, i.e. precisely when the limit
%
\[ \frac{d\mu}{d \nu}(x) = \lim_{r \to 0} \frac{\nu(B(x,r))}{\mu(B(x,r))} \]
%
exists.

\begin{theorem}
    Let $\mu$ and $\nu$ be Radon measures on $\RR^d$. Then the derivative $d\mu / d\nu$ exists for $\nu$ almost every $x \in \RR^d$, and for any Borel set $E \subset \RR^d$,
    %
    \[ \int_E \frac{d\mu}{d\nu}(x) d\nu(x) \leq \mu(B), \]
    %
    with equality if $\mu$ is absolutely continuous with respect to $\nu$. Moreover, if
    %
    \[ \underline{\frac{d\mu}{d\nu}}(x) < \infty \]
    %
    for $\mu$ almost every $x \in \RR^d$, then $\mu$ is absolutely continuous with respect to $\nu$.
\end{theorem}
\begin{proof}
    TODO: See covering lemma argument in 2.13 of Matilla.
\end{proof}




\chapter{Singular Integral Operators}

Let us now consider some kernel operators
%
\[ Tf(y) = \int K(x,y) f(x)\; dx \]
%
where $K(x,y)$ is singular for $x = y$. The prototypical example is the Hilbert transform on $\RR$, i.e.
%
\[ Hf(y) = \int \frac{f(x-y)}{y}\; dy. \]
%
One cannot even interpret the right hand side in the Lebesgue sense because the function $1/y$ is not Lebesgue integrable. We can proceed  

\section{The Calderon-Zygmund Decomposition}

The main trick of the Calderon-Zygmund decomposition, to exploit the local cancellation properties of the singular kernel $K$, is to decompose a general function into a bounded term (the `good' term), and a family of terms which are locally oscillating (the `bad' terms). The resulting decomposition is called the Calderon-Zygmund decomposition. The trick here is to exploit the compatibility of measure and metric that has already been exploited, e.g. in proving Hardy-Littlewood maximal bounds. We begin with a version of the decomposition obtained by dyadic methods.

\begin{theorem}
    Let $f \in L^1(\RR^d)$ and set $\lambda > 0$. Then there exists a set $\mathcal{Q}$ of disjoint, dyadic cubes, and a decomposition
    %
    \[ f = g + \sum_{Q \in \mathcal{Q}} b_Q, \]
    %
    such that
    %
    \[ \| g \|_{L^1(\RR^d)} \leq \| f \|_{L^1(\RR^d)}  \quad\text{and}\quad   \| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda, \]
    %
    and for $Q \in \mathcal{Q}$, $\text{supp}(b_Q) \subset Q$, $\int b_Q = 0$, and $\| b_Q \|_{L^1(\RR^d)} \lesssim_d \lambda |Q|$. We have
    %
    \[ \bigcup \mathcal{Q} = \{ x : M_\Delta f(x) > \lambda \}, \]
    %
    where $M_\Delta$ is the maximal averaging operator over dyadc cubes. From the weak $L^1$ bound for this operator we thus obtain that
    %
    \[ \sum_{Q \in \mathcal{Q}} |Q| \leq \frac{\| f \|_{L^1(\RR^d)}}{\lambda}. \]
\end{theorem}
\begin{proof}
    Set $c = 2^d$. Call a dyadic cube $Q$ \emph{bad} if $\fint_Q |f(x)|\; dx > \lambda$. Since $f \in L^1(\RR^d)$, any cube with sidelength exceeding $\| f \|_{L^1(\RR^d)} / \lambda$ is good. Thus every bad cube is contained in a \emph{maximal} bad cube, and the union of these bad cubes is precisely $\{ x : M_\Delta f(x) > \lambda \}$. Let $\mathcal{Q}$ be the set of all maximal bad cubes. Define
    %
    \[ g(x) = \sum_{Q \in \mathcal{Q}} \mathbf{I}(x \in Q) \fint_Q f(y)\; dy + \mathbf{I}(M_\Delta f(y) \leq \lambda) f(y). \]
    %
    By the Lebesgue density theorem, $|f| \leq M_\Delta f$ almost everywhere. Thus $|f(y)| \leq \lambda$ for almost every $y$ with $M_\Delta f(y) \leq \lambda$. Conversely, if $Q$ is a maximal bad cube, then the parent cube $Q'$ of $Q$ is good, which means that
    %
    \[ \fint_Q |f(y)|\; dy \leq 2^d \fint_{Q'} |f(y)|\; dy \leq 2^d \lambda. \]
    %
    Thus we conclude that $\| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda$. It is also easy to see that $\| g \|_{L^1(\RR^d)} \leq \| f \|_{L^1(\RR^d)}$. On the other hand, if we set
    %
    \[ b_Q(x) = \mathbf{I}(x \in Q) [f(x) - \fint_Q f(y)\; dy], \]
    %
    then $\int b_Q = 0$, $\text{supp}(b_Q) \subset Q$, and $\int |b_Q(x)| \leq 2 \int_Q |f(x)|\; dx \leq 2^{d+1} \lambda$.
\end{proof}

\begin{remark}
    On a general measure space $X$, for $f \in L^1(X)$ one can write $f = f \mathbf{I}_{x \leq \lambda} + f \mathbf{I}_{x > \lambda} = g + b$. We have
    %
    \[ \| g \|_{L^1(X)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| g \|_{L^\infty(X)} \leq \lambda. \]
    %
    And for the bad function,
    %
    \[ \| b \|_{L^1(X)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad |\text{supp}(b)| \leq \| f \|_{L^1(X)} / \lambda. \]
    %
    Thus the Calderon-Zygmund decomposition obtains a similar version of this result, but accounting for additional metric structure.
\end{remark}

\begin{remark}
    For each point $x \in \RR^d$ contained in a bad cube, let $T_x$ be the integer $n$ such that the maximal bad cube containing $x$ has sidelength $2^{-l}$. Otherwise, let $T_x = \infty$. Then in the language of conditional expectations, $g = \EE[f | T_x]$. Thus one can view the Calderon-Zygmund decomposition as a kind of non-probabilistic \emph{stopping time} result.
\end{remark}

The key idea in the proof above was to first decompose the open set $\Omega = \{ x : M_\Delta f(x) > \lambda \}$ into disjoint dyadic cubes, which gives another very useful geometric result, the \emph{Whitney decomposition}.

\begin{theorem}
    Let $\Omega \subset \RR^d$ be an open set. For any $K \geq 1$, there exists a decomposition $\Omega$ into a disjoint union of dyadic cubes $\mathcal{Q}$, where for any $Q \in \mathcal{Q}$, $\text{diam}(Q) \sim K d(Q, \Omega^c)$.
\end{theorem}
\begin{proof}
    Let $\mathcal{Q}'$ denote the dyadic cubes $Q$ contained in $\Omega$ such that
    %
    \[ K \text{diam}(Q) \leq d(Q, \Omega^c ) \leq 4K \text{diam}(Q).  \]
    %
    These cubes cover $\Omega$. Indeed, for each $x \in \Omega$, one can find a dyadic cube $Q$ with diameter between $d(x,\Omega^c)/4K$ and $d(x,\Omega^c)/2K$ containing $x$. Then
    %
    \begin{align*}
        d(Q,\Omega^c) &\geq d(x,\Omega^c) - \text{diam}(Q)\\
        &\geq (1 - 1/4K) \cdot d(x,\Omega^c)\\
        &\geq (2K - 1/2) \cdot \text{diam}(Q)\\
        &\geq K \text{diam}(Q).
    \end{align*}
    %
    Conversely,
    %
    \[ d(Q,\Omega^c) \leq d(x,\Omega^c) \leq 4K \text{diam}(Q). \]
    %
    But now we can take a maximal subfamily $\mathcal{Q}$ of $\mathcal{Q}'$.
\end{proof}

\begin{remark}
    Consider the decomposition $\mathcal{Q}$ in the last theorem. If $Q_1,Q_2$ are two nearby cubes in the decomposition, and
    %
    \[ d(Q_1,Q_2) \leq \delta ( \text{diam}(Q_1) + \text{diam}(Q_2)) \]
    %
    for some $\delta > 0$, then
    %
    \begin{align*}
        | d(Q_1,\Omega^c) - d(Q_2,\Omega^c) | &\leq d(Q_1,Q_2) + \text{diam}(Q_1) + \text{diam}(Q_2)\\
        &\leq (1 + \delta) (\text{diam}(Q_1) + \text{diam}(Q_2)).
    \end{align*}
    %
    Thus
    %
    \begin{align*}
        \text{diam}(Q_2) \leq \frac{d(Q_2,\Omega^c)}{K} &\leq \frac{d(Q_1,\Omega^c)}{K} + \frac{1 + \delta}{K} \text{diam}(Q_1) + \frac{1 + \delta}{K} \text{diam}(Q_2).
    \end{align*}
    %
    Rearranging, we find that for $\delta \leq K/2 - 1$,
    %
    \[ \frac{\text{diam}(Q_2)}{2} \leq \frac{d(Q_1,\Omega^c)}{K} + (1 + \delta) \text{diam}(Q_1) \leq (5 + \delta) \text{diam}(Q_1), \]
    %
    and so
    %
    \[ \text{diam}(Q_2) \leq (5 + \delta) \cdot \text{diam}(Q_1). \]
    %
    By symmetry, we automatically obtain the two sided inequality
    %
    \[ (5 + \delta)^{-1} \cdot \text{diam}(Q_1) \leq \text{diam}(Q_2) \leq (5 + \delta) \cdot \text{diam}(Q_1). \]
    %
    Thus balls which are close together also have comparable diameter.
\end{remark}

Given the Whitney decomposition, how does Calderon-Zygmund follow? Set $\Omega = \{ x : M_\Delta f(y) > \lambda \}$, and let $\mathcal{Q}$ denote the Whitney decomposition. If $Q \in \mathcal{Q}$, then $d(Q,\Omega^c) \lesssim \text{diam}(Q)$. Thus we can find a point $x$ with $d(x,Q) \lesssim \text{diam}(Q)$ and with $M_\Delta f(x) \leq \lambda$. Thus for a universal constant $C > 0$, $x \in C \cdot Q$, and so
%
\[ \fint_Q |f(y)|\; dy \leq C^d \fint_{CQ} |f(y)|\; dy \leq C^d \lambda. \]
%
Writing $b_Q(x) = \mathbf{I}(x \in Q) \cdot [f(x) - (\fint_Q f(y)\; dy)]$ and $g = f - \sum b_Q$, we obtain an analogous decomposition to the one obtained before.

Certainly one cannot prove an exact analogy of the Whitney decomposition for \emph{balls}, i.e. one cannot cover a general open set by disjoint open balls with radius comparable to their distance to the boundary of the open set. Nonetheless, we can obtain such a decomposition with the \emph{bounded intersection property}, i.e. such that no point is contained in too many of the balls in the particular cover.

\begin{theorem}
    Let $\Omega \subset \RR^d$ be an open set. For any $K \geq 1$, $\Omega$ is the union of a family of balls $\mathcal{B}$, where for each ball $B \in \mathcal{B}$, the radius $r_B$ of this ball is comparable to $K d(Q, \Omega^c)$, and each point in $\Omega$ is contained in $O_d(1)$ balls.
\end{theorem}
\begin{proof}
    Applying the last remark, without loss of generality assume $K \geq 2$, and pick $\delta = 1$. Consider the cubes $\mathcal{Q}$ in the decomposition above, and let $\mathcal{B}$ be a family of balls obtained by covering each cube $Q$ in $\mathcal{Q}$ by a ball $B$ with $\text{diam}(B) = \text{diam}(Q)$. If a point $x$ is contained in a family of balls $B_1,\dots,B_k$ corresponding to dyadic cubes $Q_1,\dots,Q_k$, then $d(Q_i,Q_j) \leq \text{diam}(Q_i) + \text{diam}(Q_j)$. Thus we find that for any $Q_i$ and $Q_j$
    %
    \[ \text{diam}(Q_i) \leq 50 \cdot \text{diam}(Q_j). \]
    %
    Thus there is a common quantity integer $n$ such that for all $i$, $2^n \leq \text{diam}(Q_i) \leq 50^2 \cdot 2^n$. The number of dyadic lattice points whose vertices have coordinates which can be written as a fraction with denominator $2^n$, and which lie a distance at most $50^2 \cdot 2^n$ from $x$ is $O_d(1)$, which shows $k \lesssim_d 1$, and thus we obtain the required bounded intersection property.
\end{proof}

This decomposition using balls is the one most generalizable to more general situations where one is working in a space without quite as regular a tiling as the family of cubes. To obtain this generalization, we assume the slightly stronger assumptions we made in our analysis of the Hardy-Littlewood maximal function, i.e. we assume we are working on a locally compact topological space $X$ equipped with a locally finite Radon measure such that the technical assumptions made there, and the slightly stronger \emph{engulfing} and \emph{doubling} conditions mentioned, hold true. To generalize the Whitney decompositon, we fix two additional constants $c^*$ and $c^{**}$ with $1 < c^* < c^{**}$ which will depend only on $c_1$ and $c_2$, and for a ball $B = B(x,\delta)$, we let $B^* = B(x, c^* \delta)$ and $B^{**} = B(x, c^{**} \delta)$.

\begin{theorem}
    Let $\Omega \subset X$ be an open set. Then there is a collection of pairwise disjoint balls $\mathcal{B}$, such that
    %
    \[ \bigcup_{B \in \mathcal{B}} B^* = \Omega, \quad\text{and}\quad B^{**} \cap \Omega^c \neq \emptyset\ \text{for any $B \in \mathcal{B}$}. \]
    %
    It is simple to construct from these balls a disjoint family of sets $Q_B$ for each $B \in \mathcal{B}$ such that $B \subset Q_B \subset B^*$, and $\bigcup Q_B = \Omega$, which can be taken as a substitute for cubes in the original Whitney covering lemma.
\end{theorem}

\begin{remark}
    As with the Euclidean case above, the balls $\{ B^* : B \in \mathcal{B} \}$, though not disjoint, have the bounded intersection property. This follows from a similar argument to that of the above argument. First we show intersecting balls have comparable radii. Suppose $B_1, B_2 \in \mathcal{B}$ and $B_1 \cap B_2 \neq \emptyset$, where $B_i = B(x_i,r_i)$, and $r_1 \leq r_2$. Then
    %
    \[ B_1^{**} = B(x_1, c^{**} r_1) \subset B(x_2, c_2 c^{**} r_1). \]
    %
    Since $B_2^* = B(x_2, c^* r_2)$ is disjoint from $\Omega^c$, whereas $B_1^{**}$ is not disjoint from $\Omega^c$ it follows that $c^* r_2 \leq c_2 c^{**} r_1$, so that $r_2 \lesssim r_1$, and by symmetry, $r_1 \sim r_2$. Now if $B_1^*, \dots, B_N^*$ are balls whose intersection contains a point $x_0$, where $B_i = B(x_i,r_i)$. Then the balls all have comparable radii, i.e. if $r = \max(r_1,\dots,r_N)$ then $r \sim r_i$. Set $B = B(x_0,r)$. The doubling / engulfing property implies that $|B_i| \sim |B|$ for all $i$. But also $B_i \subset B(x_0,c_1 r)$ for all $i$, and since the $\{ B_i \}$ are disjoint, we find that
    %
    \[ N |B| \lesssim |B_1| + \dots + |B_N| \leq |B(z,c_1 r)| \lesssim |B|. \]
    %
    Thus we find $N \lesssim 1$, i.e. so we have the bounded intersection property.
\end{remark}

\begin{proof}
    TODO: See Big Stein.
\end{proof}

A consequence is a generalized Calderon-Zygmund decomposition.

\begin{theorem}
    Let $f \in L^1(X)$, and $\alpha > 0$, where
    %
    \[ \alpha > \frac{\| f \|_{L^1(X)}}{|X|}. \]
    %
    Then we can write $f = g + b$, where $b$ has a decomposition as $\sum b_k$ associated with a family of balls $\{ B_k \}$ such that:
    %
    \begin{itemize}
        \item $\| g \|_{L^\infty(X)} \lesssim \alpha$.

        \item The functions $\{ b_k \}$ have disjoint support, $b_k$ is supported on $B_k$, $\| b_k \|_{L^1(X)} \lesssim \alpha |B_k|$, and
        %
        \[ \int b_k(x)\; dx = 0. \]
        
        \item $\sum |B_k| \lesssim \alpha^{-1} \| f \|_{L^1(X)}$.

        \item We can find disjoint sets $\{ Q_k \}$ such that $Q_k \subset B_k$, $b_k$ is supported on $Q_k$
    \end{itemize}
\end{theorem}
\begin{proof}
    TODO: See Big Stein.
\end{proof}

\section{Calderon-Zygmund Kernels}

Let $X$ be some measure space, equipped with balls satisfying the assumptions under which the Calderon-Zygmund decomposition holds (in particular, the engulfing and doubling property). We will now use this theory of Calderon-Zygmund decompositions to study some singular integrals formally written
%
\[ Tf(x) = \int_X K(x,x') f(x')\; dx', \]
%
where $K$ is a kernel which, in some sense, only has singularities on the diagonal. We make the apriori assumptions that $T$ is bounded from $L^q(X)$ to itself, for some $q > 1$. More precisely, we assume the following properties:
%
\begin{itemize}
    \item (Integrability Conditions): The kernel $K$ is a measurable function away from the diagonal,  and for each $f \in L^q(X)$ with compact support, for almost every $x \not \in \text{supp}(f)$, we have
    %
    \[ Tf(x) = \int K(x,x') f(x')\; dx, \]
    %
    where the right hand side is absolutely integrable in $x'$ and thus can be interpreted in a Lebesgue sense.

    \item (Cancellation Condition): There exists a constants $A > 0$ and $c > 1$ such that for any $\delta > 0$, any $y \in X$ and any $y' \in B(y,\delta)$,
    %
    \[ \int_{B(y,c \delta)^c} |K(x,y) - K(x,y')| \leq A. \]
\end{itemize}
%
On $\RR^d$, this class contains the algebra of \emph{Calderon-Zygmund operators}, i.e. those operators given by convolution by a tempered distribution $k$, measurable away from the origin and satisfying:
%
\begin{itemize}
    \item $|k(x)| \leq A |x|^{-d}$.
    \item There exists $A > 0$ such that for all $y \neq 0$,
    %
    \[ \int_{|x| > 2 |y|} |k(x) - k(x-y)|\; dx \leq A. \]
    \item For any $0 < r_1 < r_2 < \infty$,
    %
    \[ \int_{r_1 < |x| < r_2} k(x)\; dx = 0. \]
\end{itemize}
%
We can then define an operator $T$, first for say, $C_c^\infty(\RR^d)$ functions, by a \emph{principal value}, i.e.
%
\[ Tf(x) = \lim_{r \to 0} \int_{|y| > r} k(y) f(x-y)\; dy. \]
%
This is well defined because of the cancellation conditions present in $k$, i.e. because
%
\[ \int_{|y| > r} k(y) f(x-y)\; dy = \int_{|y| > r} k(y) [f(x-y) - f(x)] \]
%
and the integrand of the right hand side is $O(|y|^{1-d})$ as $y \to 0$. The second condition is implied if we have $|\nabla k(x)| \lesssim A/|x|^{d+1}$, and if this condition holds, we say $k$ is a \emph{strong Calderon-Zygmund kernel}. These operators are automatically bounded on $L^2(\RR^d)$, because their Fourier transforms are bounded.

\begin{lemma}
    Let $k$ be a Calderon-Zygmund kernel. Then $\| \widehat{k} \|_{L^\infty(\RR^d)} \lesssim A$.
\end{lemma}
\begin{proof}
    For any $0 < r < s$, we will show that
    %
    \[ m_{r,s}(\xi) = \int_{r < |x| < s} k(x) e^{-2 \pi i \xi \cdot x}\; dx. \]
    %
    is uniformly bounded in $L^\infty$, from which the result will follow. Let $a = \max(r,|\xi|^{-1})$, and let $b = \min(s,|\xi|^{-1})$. We have
    %
    \begin{align*}
        \left| \int_{r < |x| < b} k(x) e^{-2 \pi i \xi \cdot x} \right| &= \left| \int_{r < |x| < |\xi|^{-1}} k(x) [e^{-2 \pi i \xi \cdot x} - 1] \right|\\
        &\leq \int_{r < |x| < b} |\xi| |x| k(x)\; dx\\
        &\leq A |\xi| \int_{0 < |x| < |\xi|^{-1}} |x|^{1-d}\\
        &\lesssim A |\xi| |\xi|^{-1} \lesssim A.
    \end{align*}
    %
    For large $|x|$, we utilize the fact that the exponential is oscillating sufficiently rapidly, and we must somehow use the smoothness of $k$. If we had a strong derivative condition we could integrate by parts, but we cannot do this in general with the weaker conditions assumed. Instead, we use a trick, using the fact that the exponential is $\xi/2 |\xi|^2$ periodic to write
    %
    \begin{align*}
        \int_{a < |x| \leq s} k(x) e^{-2 \pi i \xi \cdot x}\; dx &= - \int_{a < |x| \leq s} k(x) e^{-2 \pi i \xi \cdot (x + \xi / 2 |\xi|^2}\; dx\\
        &= - \int_{a < |x - \xi / 2 |\xi|^2| \leq s} k(x - \xi / 2 |\xi|^2) e^{-2 \pi i \xi \cdot x}.
    \end{align*}
    %
    The region $\{ x : a < |x - \xi / 2 |\xi|^2 | \leq s \}$ does not differ from the set $\{ x : a < |x| \leq s \}$ by very much. Indeed, if the first condition holds, then $|x| \geq |\xi|^{-1} / 2$, and so if a point is in the first set but not the second, then
    %
    \[ |\xi|^{-1} / 2 \leq |x| \leq |\xi|^{-1}. \]
    %
    On this set, $|k(x - \xi / 2 |\xi|^2)| \leq A |\xi|^{-d}$, so together with this bound the total integral of $k(x - \xi / 2 |\xi|^2)$ over this region is at most $O(A)$. Similarily, if a point is in the second set but not the first, then
    %
    \[ |x - \xi / 2 |\xi|^2| \geq |\xi|^{-1}/2, \]
    %
    and a similar analysis gives the integral of $k(x - \xi / 2|\xi|^2)$ is at most $O(A)$. Thus we conclude that
    %
    \begin{align*}
        2& \left| \int_{a < |x| \leq s} k(x) e^{-2 \pi i \xi \cdot x}\; dx \right|\\
        &\quad\quad \leq \left| \int_{a < |x| \leq s} (k(x) - k(x - \xi / 2 |\xi|^2)) e^{-2 \pi i \xi \cdot x} \right| + O(A).
    \end{align*}
    %
    But now the triangle inequality implies that
    %
    \[ \left| \int_{a < |x| \leq s} (k(x) - k(x - \xi / 2 |\xi|^2)) e^{-2 \pi i \xi \cdot x} \right| \lesssim A, \]
    %
    which completes the proof.
\end{proof}

The main result we will prove is condition; given an operator $T$ bounded in $L^q(\RR^d)$, and with a kernel $K$ satisfying the conditions above, we will show that $T$ is bounded on $L^p(\RR^d)$ for $1 < p < \infty$. Interpolation shows it suffices to show an $L^1(\RR^d) \to L^{1,\infty}(\RR^d)$ bound.

\begin{theorem}
    The operator $T$ satisfies an estimate of the form
    %
    \[ \| Tf \|_{L^{1,\infty}(X)} \lesssim \| f \|_{L^1(X)} \]
    %
    for $f \in L^1(X) \cap L^q(X)$, so that $T$ extends uniquely to an operator from $L^1(X)$ to $L^{1,\infty}(X)$, and by interpolation, from $L^p(X)$ to $L^p(X)$ for all $1 < p \leq q$.
\end{theorem}
\begin{proof}
    Our goal is to bound the measure of the set
    %
    \[ \{ x : |Tf(x)| > \alpha \}. \]
    %
    It suffices to obtain the bound (by a density argument) for $f \in L^1(X) \cap L^q(X)$. Perform a Calderon-Zygmund decomposition at the scale $\alpha$, writing $f = g + \sum b_k$, associated with a family of balls $\{ B_k \}$. It suffices to obtain a bound on the measure of the sets
    %
    \[ \{ x : |Tg(x)| > \alpha/2 \} \quad\text{and}\quad \{ x : |Tb(x)| > \alpha/2 \}. \]
    %
    First, we argue that $g \in L^q(X)$, and more precisely, $\| g \|_{L^q(X)} \lesssim \alpha^{1-1/q} \| f \|_{L^1(X)}$. On $A = (\bigcup B_k)^c$, the function $g$ arees with $f$, so we have $\| g \|_{L^\infty(A)} \lesssim \alpha \| f \|_{L^1(X)}$ and $\| g \|_{L^1(A)} \lesssim \| f \|_{L^1(A)}$, which we can interpolate to conclude that $\| g \|_{L^q(A)} \lesssim \alpha^{1-1/q} \| f \|_{L^1(X)}$. On the other hand, $|A^c| \lesssim \alpha^{-1} \| f \|_{L^1(X)}$, so combined with the bound $\| g \|_{L^\infty(A^c)} \lesssim \alpha \| f \|_{L^1(X)}$ we can again interpolate to yield $\| g \|_{L^q(A^c)} \lesssim \alpha^{1-1/q} \| f \|_{L^1(X)}$, and combining this with the previous bound completes the claim.

    Thus we have $\| Tg \|_{L^q(X)} \lesssim \alpha^{1-1/q} \| f \|_{L^1(X)}$, which conveniently yields via Chebyshev's inequality that the measure of the set
    %
    \[ \{ x : |Tg(x)| > \alpha / 2 \} \]
    %
    has measure at most $O(\alpha^{-1} \| f \|_{L^1(X)})$, which is precisely the bound we need.

    Thus it remains to analyze the set $\{ x : |Tb(x)| > \alpha / 2 \}$. Each of the functions $b_k$ differs from $f$ on it's support $Q_k$ by the average value of $f$ on $Q_k$, and so these functions all lie in $L^q(X)$. If $x_0$ denotes the center of the ball $B_k$, then
    %
    \begin{align*}
        \int_{(B_k^*)^c} |Tb_k(x)|\; dx &= \int_{(B_k^*)^c} \left| \int K(x,x') b_k(x')\; dx' \right|\; dx\\
        &= \int_{(B_k^*)^c} \left| \int [K(x,x') - K(x,x_0)] b_k(x')\; dx' \right|\; dx\\
        &\leq \int_{(B_k^*)^c} \int |K(x,x') - K(x,x_0)| |b_k(x')|\; dx'\; dx\\
        &\leq \left( \sup_{x' \in B_k} \int_{(B_k^*)^c} |K(x,x') - K(x,x_0)|\; dx'\; dx \right) \| b_k \|_{L^1(X)}\\
        &\lesssim A \alpha |B_k|.
    \end{align*}
    %
    In particular, this means that
    %
    \[ \| Tb \|_{(\bigcup_k B_k^*)^c} \lesssim \sum_k A \alpha |B_k| \lesssim A \| f \|_{L^1(X)}. \]
    %
    On the other hand, $\sum |B_k^*| \lesssim \alpha^{-1} \| f \|_{L^1(X)}$, so we conclude that by Chebyshev,
    %
    \[ \{ x : |Tb(x)| > \alpha / 2 \} \lesssim \alpha^{-1} A \| f \|_{L^1(X)} + \sum |B_k^*| \lesssim \alpha^{-1} \| f \|_{L^1(X)}. \]
    %
    This concludes the proof.
\end{proof}

How much such a kernel arise? First off, if $k$ is a tempered distribution which is homogeneous of degree $-d$, smooth away from the origin, and satisfies
%
\[ \int_{|x| = 1} k(x)\; dx = 0, \]
%
then $k$ is a Calderon-Zygmund kernel. In fact, if $m$ is homogeneous of degree zero, and smooth away from the origin, then it's Fourier transform will satisfy this condition automatically (TODO: Prove integral on sphere is zero), which connects the theory immediately to the theory of Fourier multipliers. More generally, if $m$ is smooth away from the origin, and satisfies $|\partial^\alpha m(\xi)| \lesssim_\alpha |\xi|^{-|\alpha|}$ for all $\alpha > 0$, then (TODO: Add this) we will see in the section on Fourier multipliers that $|\partial^\alpha k(x)| \lesssim_\alpha |x|^{-n-|\alpha|}$, which shows $k$ satisfies all the required estimates to be a Calderon-Zygmund kernel (TODO: Integral on sphere is zero). More generally, if $|\partial^\alpha m(\xi)| \lesssim_\alpha |\xi|^{-\alpha}$ for $|\alpha| \leq \lceil n/2 \rceil$, then $k$ might not have the required derivative bounds, but will satisfy the required cancellation condition
%
\[ \int_{|x| \geq 2 |y|} | k(x-y) - k(x)|\; dx \leq A, \]
%
which is enough to apply the theory. Such multipliers are called \emph{Marcinkiewicz}.




\chapter{Fourier Multiplier Operators}

Our aim in this chapter is to study the boundedness of \emph{Fourier multiplier operators}. Given a function $m: \RR^d \to \CC$, known as a \emph{symbol}, we want to associate a multiplier operator $T$, sometimes denoted $m(D)$, which when applied to a function $f: \RR^d \to \CC$ should be formally given by the equation
%
\[ Tf(x) = \int_{\RR^d} m(\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi. \]
%
In maximum generality, for any tempered distribution $m$ on $\RR^d$ we can define $T$ as a continuous operator from $\mathcal{S}(\RR^d)$ to itself. But often times we will consider much more regular symbols $m$, i.e. those which are locally integrable functions, and our goal will be to obtain stronger continuity statements for the associated multiplier operators. If $K$ is the tempered distribution which is the Fourier transform of $m$, then $Tf = K * f$. Thus Fourier multiplier operators are precisely the same as the class of convolution operators formed by tempered distributions. In any case, the map $m \mapsto m(D)$ gives an injective \emph{algebra homomorphism} from the family of all tempered distributions to the family of continuous operators on $\mathcal{S}(\RR^d)$ (another injective homomorphism is obtained by considering the multiplier operators $m \mapsto m(X)$, where $m(X)$ is the multiplier operator $m(X) f = m \cdot f$, the familty of \emph{spatial} multiplier operators, which have a much simpler theory). The main goal, of course, is to determine what properties of the symbol or it's Fourier transform imply boundedness properties of the operator $T$.

\begin{remark}
  In engineering these operators are known as \emph{filters}, and occur in a variety of contexts. Due to the presence of error the regularity of these operators are of utmost importance. The function $m$ is known as the \emph{system-transfer function}, \emph{optical-transfer function}, or \emph{frequency response}, depending on the context, and the function $K$ is known as the \emph{point-spread function}.
\end{remark}

\begin{example}
  Over $\RR$, consider a rough cutoff $\mathbf{I}_{[-1,1]}$. Then we calculate explicitly that
  %
  \[ K(x) = \int_{-1}^1 e^{2 \pi i \xi \cdot x} = \frac{\sin(2 \pi x)}{\pi x}. \]
  %
  Thus convolution by $K$ acts by cutting off higher frequency parts of the function. In engineering this operator is called a \emph{low pass filter}.
\end{example}

\begin{example}
  Over $\RR$, we consider the Fourier multiplier
  %
  \[ m(\xi) = - i \cdot \text{sgn}(\xi). \]
  %
  Then $m(D)$ is the Hilbert transform.
\end{example}

\begin{example}
  In $\RR^d$, we consider the Fourier multiplier
  %
  \[ m_R(\xi) = \mathbf{I}(|\xi| \leq R). \]
  %
  The operator $m_R(D)$ is known as the \emph{ball multiplier operator}. More generally, given any compact set $S$ we can consider the Fourier multiplier $\mathbf{I}_S(D)$. In the engineering literature these multipliers are called \emph{ideal low pass filters}.
\end{example}

\begin{example}
  In this chapter, it is natural to renormalize the differentiation operators $D^\alpha: \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ so that for $f \in \mathcal{S}(\RR^d)$,
  %
  \[ \widehat{D^\alpha f} = \xi^\alpha \widehat{f}. \]
  %
  In particular, this implies that if $m(\xi) = \xi_i^\alpha$, then $m(D) = D^\alpha$. More generally, if $m(\xi) = \sum_{|\alpha| \leq k} c_\alpha \xi^\alpha$, then
  %
  \[ m(D) = \sum_{|\alpha| \leq k} c_\alpha D^\alpha. \]
  %
  Thus the family of Fourier multiplier operators contains all constant coefficient differential operators.
\end{example}

Fourier multiplier operators have proved essential to our study of classical Fourier analysis. In particular, we have used Fourier multiplier operators to prove a great many results; the convolution operator by the Poisson kernel is a Fourier multiplier given by the symbol $e^{-|x|}$, and the heat kernel is a Fourier multiplier with symbol $e^{- \pi |x|^2}$. This is no coincidence. It is a general heuristic that any well-behaved translation invariant operator is given by convolution with an appropriate function.

We have already seen in our study of distributions that any translation invariant continuous linear operator $T: C_c^\infty(\RR^d) \to C^\infty_{\text{loc}}(\RR^d)$ is given by convolution with a distribution. If the distribution is tempered, we can take the Fourier transform to conclude that the operator is a Fourier multiplier operator. In fact, if $1 \leq p,q \leq \infty$ and a translation invariant operator $T$ satisfies a bound of the form
%
\[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for any $f \in \mathcal{S}(\RR^d)$, then $T$ is a Fourier multiplier operator. To prove this, we apply the theory of Sobolev embeddings.

%\begin{lemma}
%  Suppose $1 \leq p,q \leq \infty$. If $f \in L^p(\RR^d)$ has a strong derivative $D^\alpha f$ in $L^p(\RR^d)$ for all $|\alpha| \leq d+1$, then $f \in C(\RR^d)$, and
    %
%    \[ \| f \|_{L^\infty(\RR^d)} \lesssim_{d,p} \sum_{|\alpha| \leq d + 1} \| D^\alpha f \|_{L^p(\RR^d)}. \]
%\end{lemma}
%\begin{proof}
%    Let us first suppose $p = 1$. Then
    %
%    \begin{align*}
%      |\widehat{f}(x)| &\lesssim \frac{\sum_{|\alpha| \leq d+1} |x^\alpha \widehat{f}(x)|}{(1 + |x|)^{d+1}}.
%    \end{align*}
    %
%    Since $1/(1 + |x|)^{d+1} \in L^1(\RR^d)$, we can integrate both sides of the equation to conclude that
    %
%    \[ \| \widehat{f} \|_{L^1(\RR^d)} \lesssim \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}. \]
    %
%    It follows by the Fourier inversion formula that $f \in C(\RR^d)$, and moreover,
    %
%    \[ \| f \|_{L^\infty(\RR^d)} \leq \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}, \]
    %
%    which completes the proof for $p = 1$.

%    For $p > 1$, any compactly supported bump function $\phi$, and any multi-index $\alpha$ with $|\alpha| \leq d+1$,
    %
%    \[ \| D^\alpha(\phi f) \|_{L^1(\RR^d)} \leq \sum_{\beta \leq \alpha} \| D^\beta \phi \cdot D^{\alpha - \beta} f \|_{L^1(\RR^d)} \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
%    It follows from the previous case that $\phi f \in C(\RR)$, and
    %
%    \[ \| \phi f \|_{L^\infty(\RR^d)} \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
%    These bounds hold uniformly over translates of $\phi$, and taking advantage of this shows that $f \in C(\RR)$, and that
    %
%    \[ \| f \|_{L^\infty(\RR^d)} \lesssim \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \qedhere \]
%\end{proof}
%\end{comment}

\begin{theorem}
  Suppose $1 \leq p,q \leq \infty$, and $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear map commuting with translations and satisfies
  %
  \[ \| Tf \|_{L^q(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $T$ is a Fourier multiplier operator.
\end{theorem}
\begin{proof}
  For any $f \in \mathcal{S}(\RR^d)$, $Tf \in W^{q,n}(\RR^d)$ for any $n > 0$. To see this, we note that for any $h > 0$ and $k \in \{ 1, \dots, d \}$, and
  %
  \[ (\Delta_h f)(x) = \frac{f(x + he_k) - f(x)}{h}. \]
  %
  Then $\Delta_h(T f) = T(\Delta_h f)$ because $T$ is translation invariant. Since $f$ is a Schwartz function, $\Delta_h f$ converges to $D^k f$ in $L^p(\RR^d)$. Thus by continuity of $f$, $Tf$ has a strong derivative $T(D^k f)$ in $L^q(\RR^d)$. Induction shows $Tf$ has strong derivatives of all orders. The last lemma shows that $Tf \in C(\RR^d)$, and
  %
  \begin{align*}
    \| Tf \|_{L^\infty(\RR^d)} &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(Tf) \|_{L^q(\RR^d)}\\
    &= \sum_{|\alpha| \leq n+1} \| T(D^\alpha f) \|_{L^q(\RR^d)}\\
    &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha f \|_{L^q(\RR^d)}.
  \end{align*}
  %
  The map $f \mapsto Tf(0)$ is thus a continuous operator on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$. Translation invariance shows that $Tf = \Lambda * f$, and setting $m = \widehat{\Lambda}$ completes the proof.
\end{proof}

\begin{remark}
    It follows from this argument that if $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear operator commuting with translations satisfying a bound
    %
    \[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}, \]
    %
    then for any $f \in \mathcal{S}(\RR^d)$, $Tf \in C^\infty_{\text{loc}}(\RR^d)$ and is slowly increasing, as is all of it's derivatives.
\end{remark}







\section{Frequency Localization}

One use of Fourier multipliers is to localize the support of the Fourier tranform of a function to a portion of space. Given a compactly supported function $m$ supported on some set $S$, and any function $f$, $\widehat{m(D) f} = m \widehat{f}$ is supported on $S$. Frequency localization has the additional feature that $m(D) f$ is smooth (analytic even), since it's Fourier transform is compactly supported. One major advantage of localizing in frequency is that it enables us to control the behaviour of the derivatives of a function; if $m$ is a cutoff function supported $\xi_0$, then $\widehat{m(D) f}$ is supported near $\xi_0$, and so we might expect that $\partial_\alpha (m(D) f) \approx \xi_0^\alpha f$. This makes frequency localization useful especially useful in problems involving derivatives. The uncertainty principle also gives another heuristic application of this principle; if $m$ is supported on a cube centred at the origin with sidelengths $R_1,\dots,R_d$, then the function $m(D) f$ will be roughly speaking, locally constant on `dual rectangles' with sidelength $1/R_1, \dots, 1/R_d$. More generally, if we instead choose $m$ supported on a cube centered at $\xi_0$ with sidelengths $R_1,\dots,R_n$, then $f$ acts roughly like a constant multiple of $e^{2 \pi i \xi \cdot x}$ on dual rectangles. This trick comes up all over the place since the behaviour of certain operators can be exploited more clearly once inputs or outputs have been localized in frequency.

Let us consider some examples. If we consider the Fourier multiplier $\mathbf{I}_{[-R,R]}$ in $\RR^1$, then this multiplier corresponds to the kernel
%
\[ K(x) = \int_{-R}^R e^{2 \pi i \xi x} = \frac{\sin(2 \pi R x)}{\pi x} = 2R \cdot \text{sinc}(2 \pi R x), \]
%
i.e. a sinc function. If $f$ is supported on an interval $I$, then it follows from a simple estimate that
%
\[ |(K * f)(x)| \lesssim \frac{\| f \|_{L^1(\RR)}}{d(x,I)}. \]
%
Thus we see that we can localize in frequency while remaining somewhat localized in space, but with some additional fuzziness that decays away from this interval at a rate of $1/x$. Unfortunately,this is often not enough to obtain useful estimates, e.g. the fuzziness does not even lie in $L^1(\RR)$. In $\RR^d$, if we write $K = K_1 \otimes \dots \times K_d$ be the kernel associated with the rectangle multiplier, then we have a similar $1/x$ decay estimate (though we do get up to $1/x^d$ decay in directions not close to being parallel with any axis, an error that still remains non integrable).

We can do better if we use a smooth cutoff function, i.e. we choose a smooth non-negative function $m$ compactly supported on a cube $I$ of sidelength $L$ which equals one on the interior third of $I$, and satisfies
%
\[ \| D^\alpha m \|_{L^\infty(\RR^d)} \lesssim_\alpha L^{-|\alpha|} \]
%
for all multi-indices $\alpha$, and then consider the Fourier multiplier $m(D)$. Then $m(D)$ corresponds to the convolution kernel
%
\[ K(x) = \int e^{2 \pi i \xi \cdot x} m(\xi)\; d\xi. \]
%
Integrating by parts gives that for all $n > 0$, $|K(x)| \lesssim_n L^{d-n} |x|^{-n}$, which decreases away from the origin much faster than for a rough cutoff. This implies that we have the decay estimates
%
\[ |(K * f)(x)| \lesssim_n \frac{L^{d-n} \| f \|_{L^1(\RR^d)}}{d(x,J)^n}. \]
%
for $f$ supported on a cube $J$, and all $n > 0$. Thus the majority of the mass of $K * f$ is concentrated in an $O(1/L)$-thickening of the interval $J$, so spatial localization is preserved provided the sidelengths of $J$ are $\Omega(1/L)$. This means the `fuzziness' outside of the interval $J$ here is fast decaying in a quantitative manner, which is often enough that it can be safely ignored. Thus frequency localization in this setting also preserves spatial localization as long as we respect the uncertainty principle, i.e. we do not care about localization in space to an accuracy finer than $\Omega(1/L)$.









\section{$L^p$ Regularity}

We now wish to study conditions on $m$ which guarantee bounds of the form
%
\[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
%
for all $f \in \mathcal{S}(\RR^d)$. This question was of course prominant throughout the study of Harmonic analysis, but the explicit problem of studying general multipliers was pushed forwards by analysts like H\"{o}rmander in the 1960s.

\begin{example}
    Let $k_s(x) = |x|^{-s}$, for $0 < s < d$ be the \emph{Riesz kernel}. Then $k_s \in L^{r,\infty}(\RR^d)$ for $r = d/s$, so the weak-type variant of Young's inequality implies that
    %
    \[ \| k_s * f \|_{L^q(\RR^d)} \lesssim_{p,q} \| f \|_{L^p(\RR^d)} \]
    %
    provided $1/p - 1/q = 1 - s/d$. Analysing the scaling properties of each side of this equation shows these are the only exponents for which this inequality holds. Now it turns out that $\widehat{k_s} = C_{d,s} k_{d-s}$ for some constants $C_{d,s}$, and so it follows that $k_s \in M^{p,q}(\RR^d)$ when $1/p - 1/q = s/d$.
\end{example}

In general, a characterization of the tempered distributions which give bounded convolution operators is unknown except in a few very particular situations. For each $1 \leq p \leq q \leq \infty$, we let $\| m \|_{M^{p,q}(\RR^d)}$ denote the operator norm of $m(D)$ from $\mathcal{S}(\RR^d)$ to $\mathcal{S}(\RR^d)^*$, via the $L^p(\RR^d)$ norm in the input, and via the $L^q(\RR^d)$ norm in the output, i.e. it is the smallest quantity $\| m \|_{M^{p,q}(\RR^d)}$ such that
%
\[ \| m(D) f \|_{L^q(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)} \| f \|_{L^p(\RR^d)} \]
%
for all $f \in \mathcal{S}(\RR^d)$. If $1 \leq p < \infty$, then the Hahn-Banach density theorem shows every element of $M^{p,q}(\RR^d)$ extends uniquely to an operator from $L^p(\RR^d)$ to $L^q(\RR^d)$ with the same operator norm. If $p = \infty$, then every such operator extends to a map from $L^\infty(\RR^d)$ to $L^q(\RR^d)$ with the same operator norm, but this extension need not be unique. We let $M^{p,q}(\RR^d)$ be the set of tempered distributions for which the bound is finite. For simplicity, we also let $M^p(\RR^d)$ denote $M^{p,p}(\RR^d)$. All of these spaces are Banach spaces. By symmetries of the Fourier transform, it is easy to check that translations, modulations, and dilations all preserve the space $M^{p,q}(\RR^d)$, though dilations need not preserve the $M^{p,q}$ norm unless $p = q$. Thus we have a family of Banach Algebras $M^p(\RR^d)$. On these spaces, translation, dilation, conjugation, and modulation are all isometries, so this space is highly symmetric.

Littlewood's principle tells us that the only interesting Fourier multipliers in $M^{p,q}(\RR^d)$ occur with `the larger exponent on the left'.

\begin{theorem}
  Fix $1 \leq q < p \leq \infty$, and suppose $m$ is a tempered distribution on $\RR^d$ satisfying a uniform bound
  %
  \[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $m = 0$. In other words, $M^{p,q}(\RR^d) = 0$ for $q < p$.
\end{theorem}
\begin{proof}
  Suppose $m \neq 0$ and $q < p$. Then there is $f_0 \in \mathcal{S}(\RR^d)$ with $m(D) f_0 \neq 0$. Thus $m(D) f_0$ lies in $L^q(\RR^d)$. Fix a large integer $N$ and pick $x_1,\dots,x_N \in \RR^d$ separated far enough apart that
  %
  \[ \left\| \sum_{n = 1}^N \text{Trans}_{x_n} f_0 \right\|_{L^p(\RR^d)} \gtrsim N^{1/p} \| f_0 \|_{L^p(\RR^d)} \]
  %
  and
  %
  \[ \left\| \sum_{n = 1}^N \text{Trans}_{x_n} m(D) f_0 \right\|_{L^q(\RR^d)} \sim N^{1/q} \| m(D) f_0 \|_{L^q(\RR^d)} \lesssim N^{1/q} \| f_0 \|_{L^p(\RR^d)}. \]
  %
  Translation invariance of convolution shows $N^{1/q} \lesssim N^{1/p}$, which is impossible for suitably large $N$. Thus $m = 0$.
\end{proof}

\begin{example}
    We claim that $M^{2,2}(\RR^d) = L^\infty(\RR^d)$, in the sense that the two spaces consist of the same family of distributions, and the norms on both spaces are equal, i.e. $\| m \|_{M^{2,2}(\RR^d)} = \| m \|_{L^\infty(\RR^d)}$. To see this, suppose either $m \in M^{2,2}(\RR^d)$ or $m \in L^\infty(\RR^d)$, and let
  %
  \[ \Phi(x) = e^{- \pi |x|^2} \]
  %
  be the Gaussian distribution. Then $\Phi$ is a Schwartz function, and satisfies
  %
  \[ \widehat{m(D) \Phi} = \Phi \cdot m. \]
  %
  Since $\Phi \in L^2(\RR^d)$, $\Phi \cdot m \in L^2(\RR^d)$. But since $1/\Phi \in L^\infty_{\text{loc}}(\RR^d)$, this implies that $m \in L^1_{\text{loc}}(\RR^d)$.

  Now we know $m$ is locally integrable, we can obtain the general result by Parseval's inequality, since a bound of the form
  %
  \[ \| m(D) f \|_{L^2(\RR^d)} \leq C \| f \|_{L^2(\RR^d)} \]
  %
  holds for all $f \in \mathcal{S}(\RR^d)$ if and only if
  %
  \[ \| m \cdot g \|_{L^2(\RR^d)} \leq C \| g \|_{L^2(\RR^d)} \]
  %
  for all $g \in \mathcal{S}(\RR^d)$. The former bound is equivalent to $\| m \|_{M^{2,2}(\RR^d)} \leq C$, and the second bound is equivalent to $\| m \|_{L^\infty(\RR^d)} \leq C$ by H\"{o}lder's inequality.
\end{example}

For any tempered distribution $m$ and $f,g \in \mathcal{S}(\RR^d)$, the fact that the Fourier transform is self adjoint implies that
%
\begin{align*}
  \langle m(D) f, g \rangle &= \langle m \cdot \widehat{f}, \widehat{g} \rangle\\
  &= \langle \widehat{f}, \overline{m} \cdot \widehat{g} \rangle\\
  &= \langle f, \overline{m}(D) g \rangle.
\end{align*}
%
Thus we have an adjoint relation $m(D)^* = \overline{m}(D)$, which gives a natural duality theory for Fourier multiplier operators. In particular, this means that if $R$ is the reflection operator $[Ru](x) = u(-x)$, then
%
\[ m(D) f = [(R \circ m^*(D) \circ R) f^*]^*. \]
%
In particular, for any $0 < p \leq \infty$, $\| m(D) f \|_{L^p(\RR^d)} = \| m(D)^* Rf^* \|_{L^p(\RR^d)}$.

\begin{theorem}
  For any $1 \leq p \leq q < \infty$ and any tempered distribution $m$,
  %
  \[ \| m \|_{M^{p,q}(\RR^d)} = \| m \|_{M^{q^*,p^*}(\RR^d)}. \]
\end{theorem}
\begin{proof}
    It will suffice to prove by duality that
    %
    \[ \| m \|_{M^{q^*,p^*}(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)}. \]
    %
    Assume without loss of generality that $\| m \|_{M^{p,q}(\RR^d)} < \infty$. Given $f \in \mathcal{S}(\RR^d)$, we know $m(D) f \in C^\infty_{\text{loc}}(\RR^d) \cap L^q(\RR^d)$. If $p \neq \infty$, then
    %
    \[ \| m(D) f \|_{L^{p^*}(\RR^d)} = \sup \left\{ \int m(D)f(x) g(x)\; dx : g \in \mathcal{S}(\RR^d), \| g \|_{L^p(\RR^d)} < \infty \right\}. \]
    %
    Given any such $g \in \mathcal{S}(\RR^d)$, we have by H\"{o}lder's inequality,
    %
    \begin{align*}
        \int m(D)f(x) g(x)\; dx &= \int f(x) m^*(D) g(x)\; dx\\
        &\leq \| f \|_{L^{q^*}(\RR^d)} \| m^*(D) g \|_{L^q(\RR^d)}\\
        &\leq \| m \|_{M^{p,q}(\RR^d)} \| f \|_{L^{q^*}(\RR^d)}.
    \end{align*}
    %
    Thus we conclude that
    %
    \[ \| m(D) f \|_{L^{p^*}(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)} \| f \|_{L^{q^*}(\RR^d)} \]
    %
    and thus $\| m \|_{M^{q^*,p^*}(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)}$. On the other hand, if $p = \infty$, then $q = \infty$ (or else the inequality is trivial). If $\| m \|_{M^{\infty,\infty}(\RR^d)} < \infty$, then it follows that for any $f \in \mathcal{S}(\RR^d)$, $m(D) f \in C^\infty(\RR^d)$. It therefore follows by smoothness that
    %
    \[ |m(D) f(0)| \leq \| m(D) f \|_{L^\infty(\RR^d)} \leq \| m \|_{M^{\infty,\infty}(\RR^d)} \| f \|_{L^\infty(\RR^d)}. \]
    %
    A consequence of this is that for all $f \in \mathcal{S}(\RR^d)$,
    %
    \[ \left| \int \widehat{m}(x) f(x)\; dx \right| \leq \| m \|_{M^{\infty,\infty}(\RR^d)} \| f \|_{L^\infty(\RR^d)}. \]
    %
    This means $\widehat{m}$ is a distribution of order zero, and is therefore equal to some Radon measure $\mu$. Moreover, the bound actually implies that $\mu$ is a finite Borel measure, with total variation at most $\| m \|_{M^{\infty,\infty}(\RR^d)}$. But then Young's inequality implies that
    %
    \[ \| \widehat{m} * f \|_{L^1(\RR^d)} \leq \| \widehat{m} \|_{M(\RR^d)} \| f \|_{L^1(\RR^d)} \leq \| m \|_{M^{\infty,\infty}(\RR^d)} \| f \|_{L^1(\RR^d)}. \]
    %
    Thus $\| m \|_{M^{1,1}(\RR^d)} \leq \| m \|_{M^{\infty,\infty}(\RR^d)}$, which completes the proof of duality.
\end{proof}

We also have a rescaling law which follows from the standard rescaling properties of the Fourier transform, i.e. for any matrix $A \in \text{GL}(d)$,
%
\[ \| m \circ A \|_{M^{p,q}(\RR^d)} = |\det(A)|^{-|1/p - 1/q|} \| m \|_{M^{p,q}(\RR^d)}. \]
%
In particular, the quantities $\| m \|_{M^p(\RR^d)}$ are invariant under scaling.

In particular, if $1 \leq p \leq \infty$ and $m \in M^p(\RR^d)$, then also $m \in M^{p^*}(\RR^d)$ and so Riesz-interpolation implies $m \in M^{2}(\RR^d)$. Thus if we are studying $L^p$ to $L^p$ boundedness for any $1 \leq p \leq \infty$, we may restrict our attention to Fourier multipliers with a bounded symbol. More generally, this interpolation approach shows that $M^p(\RR^d)$ is a larger space of multipliers the closer $p$ is to two. Thus $M^2(\RR^d) = L^\infty(\RR^d)$ is the largest family, and $M^1(\RR^d) = M^\infty(\RR^d)$ is the smallest family of multipliers bounded on some $M^p(\RR^d)$. It turns out we can also completely characterize this space of multipliers, it is the space of Fourier transforms of finite Radon measures.

\begin{example}
    The only remaining space which we can completely characterize are the spaces $M^{1,q}(\RR^d)$ (and thus $M^{q^*,\infty}$), where $1 \leq q \leq \infty$. For $q > 1$, we have
    %
    \[ M^{1,q}(\RR^d) = \widehat{L^q(\RR^d)} \]
    %
    and $M^{1,1}(\RR^d) = \widehat{M(\RR^d)}$, the set of all finite Borel measures. Moreover, in the case $q > 1$ we have
    %
    \[ \| m \|_{M^{1,q}(\RR^d)} = \| \widehat{m} \|_{L^q(\RR^d)} \]
    %
    and for $q = 1$,
    %
    \[ \| m \|_{M^{1,1}(\RR^d)} = \| \widehat{m} \|_{M(\RR^d)}. \]
    %
    Given such an $m \in M^{1,q}(\RR^d)$, if $K = \widehat{m}$, and $\{ \phi_\varepsilon \}$ is a family of standard mollifiers, then
    %
    \[ \| K * \phi_\varepsilon \|_{L^q(\RR^d)} = \| m(D)(\phi_\varepsilon) \|_{L^q(\RR^d)} \lesssim \| \phi_\varepsilon \|_{L^1(\RR^d)} = 1. \]
    %
    Applying the Banach-Alaoglu theorem, the family $\{ K * \phi_\varepsilon \}$ has a weak $*$ convergent subsequence in $L^q(\RR^d)^{**}$. Thus there is $\lambda \in L^q(\RR^d)^{**}$ and $\varepsilon_i \to 0$ such that $K * \phi_{\varepsilon_i} \to \lambda$. But this means that $K * \phi_{\varepsilon_i}$ converges to $\lambda$ distributionally. It also converges to $K$ distributionally, so $K = \lambda \in (L^q(\RR^d))^{**}$. If $q > 1$, then $(L^q(\RR^d))^{**} = L^q(\RR^d)$, with the same norm, and $(L^1(\RR^d))^{**} = M(\RR^d)$.
\end{example}

Another case where the multiplier problem is trivial is for $m \in L^\infty(\RR^d)$ with $\widehat{m} \geq 0$. This is related to the fact that the study of kernels which are non-negative and homogeneously distributed is also trivial, though the fact that we are working over a space with infinite measure complicates the analysis somewhat. To argue more precisely, by Lemma \ref{positivel1linfinitylemma}, $\| m \|_{L^\infty(\RR^d)} = \| \widehat{m} \|_{L^1(\RR^d)}$, and so for $1 \leq p \leq \infty$,
%
\[ \| \widehat{m} \|_{L^1(\RR^d)} = \| m \|_{M^2} \leq \| m \|_{M^p} \leq \| m \|_{M^1} = \| \widehat{m} \|_{L^1(\RR^d)}, \]
%
so $\| m \|_{M^p} = \| \widehat{m} \|_{L^1(\RR^d)}$ for all $p \in [1,\infty]$.

We have a version of Young's inequality for multipliers. A scaling analysis shows that we can only have an inequality
%
\[ \| m_1 * m_2 \|_{M^{p,q}(\RR^d)} \leq \| m_1 \|_{L^{r_1}(\RR^d)} \| m_2 \|_{L^{r_2}(\RR^d)} \]
%
if $1 + (1/p - 1/q) = 1/r_1 + 1/r_2$.

\begin{lemma}
    If $m_1 \in L^{r_1}(\RR^d)$ and $m_2 \in L^{r_2}(\RR^d)$, then
    %
    \[ \| m_1 * m_2 \|_{M^{p,q}(\RR^d)} \leq \| m_1 \|_{L^{r_1}(\RR^d)} \| m_2 \|_{L^{r_2}(\RR^d)} \]
    %
    for $1 \leq p,q \leq \infty$, and $1 \leq r_1,r_2 \leq 2$, and $1 + |1/p - 1/q| = 1/r_1 + 1/r_2$.
\end{lemma}
\begin{proof}
    We apply complex interpolation. Young's inequality implies $m_1 * m_2 \in L^r$ for $r = 1/|1/p - 1/q|$. In particular, if $p = q = 2$, then $m_1 * m_2 \in L^\infty(\RR^d)$, which means
    %
    \[ \| m_1 * m_2 \|_{M^2(\RR^d)} = \| m_1 * m_2 \|_{L^\infty(\RR^d)} \leq \| m_1 \|_{L^{r_1}(\RR^d)} \| m_2 \|_{L^{r_2}(\RR^d)}. \]

    If $p = q = 2$,


    If $p = 1$, then $2 - 1/q = 1/r_1 + 1/r_2$ and $1 \leq r_1,r_2 \leq 2$. We may then apply H\"{o}lder's inequality and the Hausdorff Young inequality to conclude that
    %
    \begin{align*}
        \| m_1 * m_2 \|_{M^{1,q}(\RR^d)} &= \| \widehat{m_1 * m_2} \|_{L^q(\RR^d)}\\
        &= \| \widehat{m_1} \widehat{m_2} \|_{L^q(\RR^d)}\\
        &\leq \| \widehat{m_1} \|_{L^{r_1^*}(\RR^d)} \| \widehat{m_2} \|_{L^{r_2^*}(\RR^d)}\\
        &\leq \| m_1 \|_{L^{r_1}} \| m_2 \|_{L^{r_2}(\RR^d)}.
    \end{align*}
    %
    Next, for $p = q = 2$, we have $1/r_1 + 1/r_2 = 1$, and so we can again apply Hausdorff Young to conclude that
    % 1/r_1 + 1/r_2 = 1
    \begin{align*}
        \| m_1 * m_2 \|_{M^2(\RR^d)} &= \| m_1 * m_2 \|_{L^\infty(\RR^d)}\\
        &\leq \| m_1 \|_{L^{r_1}(\RR^d)} \| m_2 \|_{L^{r_2}(\RR^d)}.
    \end{align*}
    %
    % p = q = 2, no limitations, p = q = 1, 
    %
    For the remaining cases, given an arbitrary $f \in \mathcal{S}(\RR^d)$, and $m_1, m_2 \in C_c^\infty(\RR^d)$, the quantity
    %
    \[ \| (m_1 * m_2) f \|_{L^p(\RR^d)} = \left( \left| \int (m_1 * m_2)(\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi \right|^p\; dx  \right)^{1/p} \]
    %
    is holomorphic in $p$, and so we can apply complex interpolation to prove that
    %
    \[ \| (m_1 * m_2) f \|_{L^q(\RR^d)} \leq \| m_1 \|_{L^{r_1}(\RR^d)} \| m_2 \|_{L^{r_2}(\RR^d)} \| f \|_{L^p(\RR^d)}. \qedhere \]
\end{proof}

Essentially for any other family of multipliers, it is still incredibly difficult to determine conditions when, especially when $d > 1$. For instance, it still remains a major open question in harmonic analysis, for $d > 2$, to determine the values of $p \in [1,\infty]$ and $\delta > 0$ for which the multiplier
%
\[ m^\delta(\xi) = (1 - |\xi|^2)^\delta_+ = \max((1 - |\xi|^2)^\delta,0) \]
%
lies in $M^p(\RR^d)$, a problem known as the \emph{Bochner-Riesz conjecture}.

The difficulty which causes $m^\delta$ to be unbounded is that it is singular on the boundary of the unit sphere, which is a large, curved set, upon which $m^\delta$ has $\delta$ degrees of regularity in the direction tangential to the sphere. Intuition suggests that a smooth Fourier multiplier would have a rapidly decaying Fourier transform, which would therefore be well posed as a convolution operator. One basic instance of this phenomenon occurs if $m \in \mathcal{S}(\RR^d)$. Then $\widehat{m} \in \mathcal{S}(\RR^d)$, hence integrable, and by Young's convolution inequality, it follows that for any $p \leq q$, $\| m \|_{M^{p,q}(\RR^d)} \lesssim 1$, and the induced map from $\mathcal{S}(\RR^d)$ to $M^{p,q}(\RR^d)$ is continuous. Another example is the following calculation: if $\Omega \subset \RR^d$ is bounded and open, $C$ is a fixed constant, and $L: \RR^d \to \RR^d$ is an invertible linear map, then we say $\phi$ is a \emph{bump function adapted to $L(\Omega)$} if $\phi$ is smooth and supported in $L(\Omega)$, and $|D^k (\phi \circ L)(x)| \leq C$ for all $x \in \Omega$. If $m$ is a bump function adapated to $L(\Omega)$, then it follows that $\| m \|_{M^{p,q}(\RR^d)} \lesssim_{C,\Omega} 1$.

It is important to note that it is mainly qualitative information that is of interest here. This is because $\| m \circ A \|_{M^p(\RR^d)} = \| m \|_{M^p(\RR^d)}$ for any multiplier $m$ and invertible linear transformation $A$. Thus despite the fact that a singularity can become quantitatively more singular as we focus in on it by introducing an appropriate transformation $A$, the $M^p(\RR^d)$ norm stays the same.

\begin{example}
    Consider the sawtooth function $m(\xi) = \text{sgn}(\xi) \max(1 - |\xi|, 0)$. For each $R > 0$, consider $m_R(\xi) = \text{sgn}(\xi) \max(1 - |\xi/R|, 0)$. Then $m_R$ converges pointwise almost everywhere to $m_\infty(\xi) = \text{sgn}(\xi)$, and actually $m_R(D)$ converges to $m_\infty(D)$ distributinally. Here $m_\infty(D)$ is just the Hilbert transform. Now $\| m_R \|_{M^p(\RR^d)} = \| m \|_{M^p(\RR^d)}$ for all $p \in [1,\infty]$, so we might expect that $\| m \|_{M^p(\RR^d)} = \| m_\infty \|_{M^p(\RR^d)}$. Certainly the distributional limiting process implies that
    %
    \[ \| m_\infty \|_{M^p(\RR^d)} \leq \| m \|_{M^p(\RR^d)}. \]
    %
    Conversely, $m(\xi) = a(\xi) m_\infty(\xi)$, where $a(\xi) = \max(1 - |\xi|,0)$ is a tent function. Now $\widehat{a}(x) = \text{sinc}(x)^2$ is non-negative, so in particular, this means that for any $p$, $\| a \|_{M^p(\RR^d)} = \| a \|_{L^\infty(\RR^d)} = 1$. But this means that
    %
    \[ \| m \|_{M^p(\RR^d)} \leq \| a \|_{M^p(\RR^d)} \| m_\infty \|_{M^p(\RR^d)} \leq \| m_\infty \|_{M^p(\RR^d)}, \]
    %
    which completes the proof.
\end{example}

If the multiplier $m$ is only singular on a small set, we can likely still obtain some interesting estimates. For instance, the Hilbert transform, corresponding to the Fourier multiplier $m(\xi) = i \text{sgn}(\xi)$, is singular at $\xi = 0$, but still satisfies the bounds
%
\[ \| Hf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)} \]
%
for all $f \in L^p(\RR^d)$ and $1 < p < \infty$. One can see this from the Calderon-Zygmund theory of singular integrals, or via the H\"{o}rmander-Mikhlin theory we will develop shortly. It follows from translation symmetry that for $1 < p < \infty$ and any (possibly unbounded interval) $I$,
%
\[ \| \mathbf{I}_{I} \|_{M^p(\RR^d)}, \| \mathbf{I}_{I} \|_{M^p(\RR^d)} \lesssim_p 1. \]
%
Now suppose $m \in L^\infty(\RR^d)$ has \emph{bounded variation}, which means the quantity
%
\[ V(m) = \sup_{\xi_1 < \dots < \xi_N} \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)|. \]
%
is finite. Then $m$ has countably many discontinuities, and the variation upper bound prevents $m$ from being too nonsmooth. In this case, we can obtain an operator norm bound.

\begin{theorem}
  For any symbol $m$ on $\RR$, and any $1 < p < \infty$,
  %
  \[ \| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m). \]
\end{theorem}
\begin{proof}
  For each $n$, pick $\xi_1,\dots,\xi_{N_n}$ such that
  %
  \[ \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)| \geq V(m) - 1/n. \]
  %
  If we define
  %
  \[ m_n = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N_n-1} m(\xi_i) \mathbf{I}_{(\xi_i,\xi_{i+1})} + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)} \]
  %
  Then $\| m - m_n \|_{L^1(\RR)} \leq 1/n$. But this means that $m_n(D)$ converges to $m(D)$ weakly as operators on $\mathcal{S}(\RR)$, and so
  %
  \[ \| m \|_{M^p(\RR)} \leq \limsup_{n \to \infty} \| m_n \|_{M^p(\RR)}. \]
  %
  Now we can rewrite
  %
  \[ m_n(\xi) = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N-1} [m(\xi_i) - m(\xi_{i+1})] \mathbf{I}_{(\xi_1,\xi_i)}(\xi) + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)}. \]
  %
  Since the multiplier operators corresponding to indicator functions of intervals are uniformly bounded in $M^p(\RR)$ for $1 < p < \infty$, we conclude that
  %
  \[ \| m_n \|_{M^p(\RR)} \lesssim_p |m(\xi_1)| + \sum_{i = 1}^{N-1} |m(\xi_i) - m(\xi_{i+1})| + |m(\xi_N)| \leq \| m \|_{L^\infty(\RR)} + V(m). \]
  %
  Taking $n \to \infty$ gives $\| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m)$.
\end{proof}

The theorem of H\"{o}rmander-Mikhlin is a more sophisticated instance of the smoothness-regularity phenomenon, giving $L^p$ to $L^p$ bounds to Fourier multipliers which decay smoothly away from the origin. There are several formulations of the phenomenon, of greater and greater generality. Without loss of generality, we will assume that $m \in L^\infty(\RR^d)$, since otherwise $m$ cannot lie in any of the spaces $M^p$. Let us state them in increasing order of generality, the former being most easily seen as relating to the smoothness of the multipliers:
%
\begin{itemize}
    \item The multiplier $m$ lies in $C^\infty_{\text{loc}}(\RR^d - \{ 0 \})$, and satisfies
    %
    \begin{equation} \label{hormandermikhlindecayestimate}
        |D^\beta_\xi m(\xi)| \lesssim_\beta |\xi|^{-\beta}
    \end{equation}
    %
    for all multi-indices $\beta$. In particular, this is true if $m$ is smooth away from the origin, and homogeneous of degree zero.

    \item For some integer $N$ with $N > d/2$, $m$ has weak derivatives up to order $N$ which are functions, and satisfy \eqref{hormandermikhlindecayestimate} for all $\beta$ with $|\beta| \leq N$.

    \item For some integer $N > d/2$, $m$ has weak derivatives in $L^2_{\text{loc}}(\RR^d)$ up to order $N$, and satisfies an $L^2$ average estimate
    %
    \[ \sup_{R > 0} \left( \fint_{|\xi| \leq 2R} |\xi|^{2\beta} |D^\beta_\xi m(\xi)|^2\; d\xi \right)^{1/2} \lesssim 1. \]

    \item For some non-zero, smooth radial test function $\varphi$, compactly supported away from the origin,
    %
    \begin{equation}
        \sup_{R > 0} \| \varphi\; \text{Dil}_R m \|_{L^2_\alpha} < \infty
    \end{equation}
    %
    for some $\alpha > d/2$ (not necessarily an integer).

    \item For some $\varphi$ as above, and for some $\varepsilon > 0$,
    %
    \[ \sup_{R > 0} \int |\mathcal{F}( \varphi \text{Dil}_R m)(x)| (1 + |x|)^{\varepsilon}\; dx < \infty.  \]
\end{itemize}
%
If the second last point holds, the $\varepsilon$ in the last point can be chosen to be any number smaller than $\alpha - d/2$. This result is closely related to the theory of singular integrals. In particular, under the first two assumptions, the multiplier has a convolution kernel which is a Calderon-Zygmund kernel.

\begin{theorem}
    Consider $m \in L^\infty(\RR^d)$ and suppose there exists $\varepsilon > 0$ and $\varphi$ as above with
    %
    \[ \sup_{R > 0} \int |\mathcal{F}( \varphi \text{Dil}_R m)(x)| (1 + |x|)^{\varepsilon}\; dx < \infty.  \]
    %
    Then for any $1 < p < \infty$ and $f \in \mathcal{S}(\RR^d)$,
      %
    \[ \| m(D) f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}. \]
    %
    Moreover, we have a bound $\| m(D) f \|_{L^{1,\infty}(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$, which, together with the fact that $m \in M^2(\RR^d)$ because it is bounded, implies the bounds above by Riesz-Thorin and duality.
\end{theorem}
\begin{proof}
  If the assumptions hold for some $\varepsilon$, it is simple to argue they hold for \emph{any} such $\varphi$. In particular, if we take a non-negative $\varphi$ such that for any $\xi \neq 0$,
  %
  \[ \sum_{n = -\infty}^\infty \varphi(2^n \xi) = 1. \]
  %
  Write $m_n(\xi) = \varphi(\xi) m(2^n \xi)$, and $K_n = \widehat{m_n}$. Then our assumption implies that
  %
  \[ \int K_n(x) (1 + |x|)^\varepsilon\; dx \lesssim 1, \]
  %
  In particular, this means that
  %
  \[ \int_{|x| \geq R} |K_n(x)|\; dx \leq (1 + R)^{-\varepsilon}. \]
  %
  uniformly in $n$. Similarily, Bernstein's inequality implies that
  %
  \[ \| \nabla K_n \|_{L^1(\RR^d)} \lesssim \| K_n \|_{L^1(\RR^d)} \lesssim 1. \]
  %
  This implies that for all $y \in \RR^d$, uniformly in $n$,
  %
  \[ \int |K_n(x + y) - K_n(x)|\; dx \lesssim |y|. \]
  %
  For any $f \in \mathcal{S}(\RR^d)$, we have
  %
  \[ m(D) f = \sum_{n = -\infty}^\infty (\text{Dil}_{2^n} m_n)(D), \]
  %
  where the sum converges absolutely in $L^p(\RR^d)$. Since $\widehat{\text{Dil}_{2^n} m_n} = 2^{nd} \text{Dil}_{1/2^n} K_n$, it follows that
  %
  \[ K * f = \sum_{n = -\infty}^\infty 2^{nd} \cdot (\text{Dil}_{1/2^n} K_n) * f. \]
  %
  The cancellation bound we obtained for the functions $K_n$ indicate the singular-integral nature of the kernels $K_n$, i.e. they satisfy a cancellation criterion, and the singularitity is quantitatively concentrated near the origin. Indeed, the cancellation bound allows us to use the standard Calderon-Zygmund singular integral results to obtain a uniform bound
  %
  \[ \| K_n * f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
  %
  in $n$. However, these bounds cannot be summed in $n$ as $n \to \infty$ to yield an $L^p$ bound on $K * f$, since the $L^p$ operator norm of $\text{Dil}_{1/2^n} K_n$ is the same as the $L^p$ operator norm of $K_n$. To get a better bound, we must utilize the fact that the functions decay away from the origin more strongly. We will still use the Calderon Zygmund decomposition to understand this. So fix an integrable function $b$ supported on a cube $Q$ of some sidelength $R$, with $\int b(x)\; dx = 0$. Since convolution commutes with translation, we may assume without loss of generality for the calculation of $L^p$ norms that $Q$ is centred at the origin. Let $Q^*$ denote the cube with the same centre and twice the width. Then
  %
  \begin{align*}
    \int_{(Q^*)^c} 2^{nd} |(\text{Dil}_{1/2^n} K_n) * b| &\leq 2^{nd} \int_{(Q^*)^c} \left| \int_Q K_n(2^n(x - y)) b(y)\; dy \right|\; dx\\
    &\leq 2^{nd} \int_{(Q^*)^c} \left| \int_Q K_n(2^n(x-y)) b(y)\; dy \right|\; dx\\
    &= 2^{nd} \int_{(Q^*)^c} \left| \int_Q [K_n(2^n(x-y)) - K_n(2^n x)] b(y)\; dy \right|\; dx\\
    &\leq 2^{nd} \int_Q \int_{(Q^*)^c} |b(y)| |K_n(2^n(x-y)) - K_n(2^n x)|\; dx\; dy\\
    &= \int_Q \int_{(Q^*)^c} |b(y)| |K_n(x - 2^n y) - K_n(x)|\; dx\; dy\\
    &\lesssim 2^n \int_Q |y| |b(y)|\; dx \lesssim 2^n R \cdot \| b \|_{L^1(\RR^d)}.
  \end{align*}
  %
  This is a standard Calderon-Zygmund type calculation, as in the singular integral theory, and gives good bounds for $R \leq 1/2^n$. For $R \geq 1/2^n$, we apply the decay estimate to get a more optimal bound, writing
  %
  \begin{align*}
    \int_{(Q^*)^c} 2^{nd} |(\text{Dil}_{1/2^n} K_n) * b| &\leq 2^{nd} \int_{(Q^*)^c} \int_Q |K_n(2^n(x - y))| |b(y)|\; dy\; dx\\
        &\leq 2^{nd} \int_{|z| \geq R} \int_Q |K_n(2^n z)| |b(y)|\; dy\; dz\\
        &\leq (1 + R/2^n)^{-\varepsilon} \| b \|_{L^1(\RR^d)}
  \end{align*}
  %
  This is a good for $R \geq 2^n$. In particular, we now have good bounds for any value of $R$, which we can sum up to conclude that
  %
  \[ \int_{(Q^*)^c} |K * b| \lesssim \| b \|_{L^1(\RR^d)}. \]
  %
  Now given a general $f \in \mathcal{S}(\RR^d)$, we apply a Calderon-Zygmund decomposition, fixing $\alpha > 0$, and writing
  %
  \[ f = g + \sum_{k = 1}^\infty b_k \]
  %
  where $\| g \|_{L^1(\RR^d)} + \sum_{k = 1}^\infty \| b_k \|_{L^1(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$, $\| g \|_{L^\infty(\RR^d)} \lesssim \alpha$, and there exists a family of disjoint cubes $\{ Q_k \}$ such that $b_k$ is supported on $Q_k$, $\int b_k = 0$, and $\sum_{k = 1}^\infty |Q_k| \lesssim \alpha^{-1} \| f \|_{L^1(\RR^d)}$. If $\Omega = \bigcup_{k = 1}^\infty Q_k$, then
  %
  \[ \int_{\Omega^c} |K * (\sum_{k = 1}^\infty b_k)| \lesssim \sum_{k = 1}^\infty \| b_k \|_{L^1(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}. \]
  %
  Thus
  %
  \[ |\{ x \in \Omega^c : |K * (\sum_{k = 1}^\infty b_k)| \geq \alpha/2 \}| \lesssim \| f \|_{L^1(\RR^d)} / \alpha, \]
  %
  and since $|\Omega| \leq \| f \|_{L^1(\RR^d)} / \alpha$,
  %
  \[ |\{ x \in \RR^d : |K * (\sum_{k = 1}^\infty b_k)| \geq \alpha/2 \}| \lesssim \| f \|_{L^1(\RR^d)} / \alpha. \]
  %
  Since $\alpha$ was arbitrary, we conclude that $\| K * (\sum b_k) \|_{L^{1,\infty}(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$. Next, we use the fact that $K$ is bounded on $L^2$ (since $m$ is bounded) to conclude that
  %
  \[ \| K * g \|_{L^2(\RR^d)} \lesssim \| g \|_{L^2(\RR^d)} \lesssim \alpha^{1/2} \| g \|_{L^1(\RR^d)}^{1/2} \]
  %
  and so
  %
  \[ |\{ x \in \RR^d: |(K * g)(x)| \geq \alpha / 2 \}| \lesssim \| K * g \|_{L^2(\RR^d)}^2 \alpha^{-2} \lesssim \| g \|_{L^1(\RR^d)} \alpha^{-1}. \]
  %
  But now we know $\| K * g \|_{L^{1,\infty}(\RR^d)} \lesssim \| g \|_{L^1(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$. We sum and get $\| K * f \|_{L^{1,\infty}(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$.
\end{proof}

\begin{remark}
    A fastidious reader may complain that the Calderon-Zygmund decomposition of a Schwartz function yields a family of functions that are only integrable, and not necessarily even continuous. To remedy this situation, we replace the kernel operator $K$ we are originally studying with the more regularized kernels $K^{\leq N} = \sum_{|n| \leq N} 2^{nd} \cdot \text{Dil}_{1/2^n} K_n$. The operators $K^{\leq N}$ are then Schwartz convolution kernels, and, independently of this proof, are thus easily seen to lie in $M^p(\RR^d)$ for all $1 \leq p \leq \infty$, and thus extend to be well defined on the components of Calderon-Zygmund decompositions of functions. The important part of this proof is that it shows that the operators $K^{\leq N}$ are \emph{uniformly} when they induce convolution operators from $L^1(\RR^d)$ to $L^{1,\infty}(\RR^d)$, and thus imply the resultant bounds for the limiting convolution kernel $K$.
\end{remark}

Here is a basic application of the result, a kind of \emph{Schauder estimate} for the fractional Laplacian.

\begin{theorem}
    Suppose $(- \Delta)^{k/2} u \in L^p(\RR^d)$ for some $1 < p < \infty$. Then $\partial^\alpha u \in L^p$ for any multi-index $\alpha$ with $|\alpha| = k$.
\end{theorem}
\begin{proof}
    The Fourier multiplier operator whose symbol $m(\xi)$ is a constant multiple of $\xi^\alpha / |\xi|^k$ maps $(-\Delta)^{k/2} u$ to $\partial^\alpha u$. Moreover, $m$ is homogeneous of degree zero, and $C^\infty$ away from the origin, and thus satisfies bounds of the form
    %
    \[ |\partial^\beta m(\xi)| \lesssim |\xi|^{-\beta} \]
    %
    for all $\beta > 0$. But this means that the multiplier operator $m(D)$ is bounded from $L^p(\RR^d)$ to $L^p(\RR^d)$ for all $1 < p < \infty$, and thus we have
    %
    \[ \| \partial^\alpha u \|_{L^p(\RR^d)} \lesssim \| (-\Delta)^{k/2} u \|_{L^p(\RR^d)}. \qedhere \]
\end{proof}

Since convolution can be seen as a way of smoothing out some of the irregularities of a function, one might ask whether the convolution of a multiplier in $M^{p,q}(\RR^d)$ with a function lies in $M^{p,q}(\RR^d)$. One can obtain such a result, provided the function is integrable.

\begin{theorem}
    If $u \in L^1(\RR^d)$, then $\| m * u \|_{M^{p,q}(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)} \| u \|_{L^1(\RR^d)}$.
\end{theorem}
\begin{proof}
    Let $K = \widehat{m}$. If $v = \widehat{u}$, then
    %
    \begin{align*}
        (m * u)(D) f(x) &= \int K(x-y) v(x-y) f(y)\; dy\\
        &= \int u(\xi) \int K(x-y) f(y) e^{2 \pi i (x - y) \cdot \xi}\; dy\; d\xi\\
        &= \int u(\xi) \cdot (\text{Mod}_\xi K * f)(x)\; d\xi\\
        &= \int u(\xi) (\text{Trans}_\xi m)(D) f(x)\; d\xi.
    \end{align*}
    %
    Since $\| \text{Trans}_\xi m \|_{M^{p,q}(\RR^d)} = \| m \|_{M^{p,q}(\RR^d)}$, the result follows.
\end{proof}

One might ask whether multipliers operators need at least \emph{some} regularity to get a bound at all. Provided that $1 \leq p \leq q \leq 2$, one at least needs some kind of integrability condition.

\begin{theorem}
    If $m \in M^{p,q}(\RR^d)$, and $1 \leq p \leq q \leq 2$, $M^{p,q}(\RR^d) \subset L^q(\RR^d)^*$.
\end{theorem}
\begin{proof}
    TODO
\end{proof}

On the other hand, if $q > 2$, then $M^{p,q}(\RR^d)$ contains distributions of positive order. We will show an explicit examples for large $d \geq 4$, and non constructive examples otherwise.

\begin{example}
    Recall that the surface measure $\sigma$ on the sphere in $\RR^d$ satisfies
    %
    \[ |\widehat{\sigma}(\xi)| \lesssim_d |\xi|^{- \frac{d-1}{2}}. \]
    %
    Consider the multiplier corresponding to the distribution $\Lambda = \partial \sigma / \partial r$, which is not a distribution of order zero. On the other hand, $|\widehat{\Lambda}(\xi)| \lesssim_d |\xi|^{-\frac{d-3}{2}}$. Provided $d \geq 4$, this implies that $\| \widehat{\Lambda} \|_{L^q(\RR^d)} < \infty$ for $(d-3)/2 q > d$, i.e. for $q > 2d/(d-3) = 2 + 6/(d-3)$, and thus $\| \Lambda \|_{M^{1,q}(\RR^d)} < \infty$ for this range. For each $\varepsilon > 0$, if we take $d$ appropriately large, apply duality, and iterpolate, for each $\varepsilon > 0$, we obtain a distribution $\Lambda$ of positive order, which lies in $M^{p,q}(\RR^d)$ for all $(p,q)$ with $p < 2 - \varepsilon$ and $q > 2 + \varepsilon$.
\end{example}

\begin{example}
    Our other, non constructive examples apply Baire category arguments. Fix $\eta \in C_c^\infty(\RR^d)$, and for any $\lambda > 0$, let $m_\lambda(\xi) = \eta(\xi) e^{2 \pi i \lambda |\xi|^2}$. We claim that if $K_\lambda = \widehat{m_\lambda}$, $\| K_\lambda \|_{L^\infty(\RR^d)} \lesssim \lambda^{-d/2}$. This follows from a simple oscillatory integral argument. Also $K_\lambda$ will be essentially supported on a ball of radius $O(\lambda)$ at the origin, so one can show from this that $\| K_\lambda \|_{L^1(\RR^d)} \lesssim \lambda^{d/2}$. Thus $\| m_\lambda \|_{M^{1,\infty}} \lesssim \lambda^{-d/2}$ and $\| m_\lambda \|_{M^{1,1}} = \| m_\lambda \|_{M^{\infty,\infty}} \lesssim \lambda^{d/2}$. Interpolating gives for $q > 2$ and $q \geq p$, a bound of the form $\| m_\lambda \|_{M^{p,q}(\RR^d)} \lesssim \lambda^{-\varepsilon}$ for some $\varepsilon > 0$. If $M^{p,q}(\RR^d)$ solely contained distributions of order zero, if $\chi \in C_c^\infty(\RR^d)$ is a bump function equal to one in a neighborhood of the support of $\eta$, then the operator $m \mapsto \chi m$ would be a bounded operator from $M^{p,q}(\RR^d)$ to $M(\RR^d)$ by the closed graph theorem. But this would imply that
    %
    \[ \| \eta \|_{L^1(\RR^d)} = \| \chi m_\lambda \|_{M(\RR^d)} \lesssim \| m_\lambda \|_{M^{1,q}(\RR^d)} \lesssim \lambda^{-\varepsilon}, \]
    %
    which certainly cannot be true. Thus $M^{p,q}(\RR^d)$ contains distributions of positive order for $q > 2$ and $p < 2$.
\end{example}

De Leeuw's theorem shows slices of continuous $d+1$ dimensional multipliers are bounded by the original mutiplier, so that we might view multipliers in higher dimensions as more complicated than lower dimensional multipliers.

\begin{theorem}
  Let $m \in C(\RR^{d+1})$. Fix $\xi_0 \in \RR$, and define $m_0 \in C(\RR^d)$ by setting
  %
  \[ m_0(\xi) = m(\xi,\xi_0). \]
  %
  Then for any $1 \leq p \leq \infty$, $\| m_0 \|_{M^p(\RR^d)} \leq \| m \|_{M^p(\RR^{d+1})}$.
\end{theorem}

\begin{proof}
  Without loss of generality, assume $\xi_0 = 0$. For $\lambda > 0$ set
  %
  \[ L(\xi_1,\dots,\xi_{d+1}) = (\xi_1,\dots,\xi_d,\xi_{d+1}/\lambda). \]
  %
  Then
  %
  \[ \| m \circ L_\lambda \|_{M^p(\RR^{d+1})} = \| m \|_{M^p(\RR^{d+1})}. \]
  %
  Take $\lambda \to \infty$. Since $m$ is continuous, $m \circ L_\lambda$ converges to $m \circ L_\infty$ pointwise, where $L_\infty(\xi_1,\dots,\xi_{d+1}) = (\xi_1,\dots,\xi_d,0)$. On the other hand,
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} = \| m_0 \|_{M^p(\RR^d)}. \]
  %
  Indeed, this follows from the simple fact that $(m \circ L_\infty)(D) = m_0(D) \otimes 1$, and $m_0(D) \otimes 1$ has the same operator norm as $m_0(D)$. Thus it suffices to show that
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} \leq \limsup_{\lambda \to \infty} \| m \circ L_\lambda \|_{M^p(\RR^d)}. \]
  %
  But this follows from a simple weak convergence argument; for any $f,g \in \mathcal{S}(\RR^{d+1})$, the dominated convergence theorem implies that
  %
  \[ \lim_{\lambda \to \infty} |\langle (m \circ L_\lambda)(D) f, g \rangle| = \langle (m \circ L_\infty)(D) f, g \rangle. \qedhere \]
\end{proof}

\begin{example}
    If the cone multiplier
    %
    \[ m_\lambda(\xi,\eta) = \left( 1 - \frac{|\xi|^2}{|\eta|^2} \right)^\lambda_+ \]
    %
    lies in $M^p(\RR^{d+1})$, then the corresponding Bochner-Riesz multiplier
    %
    \[ m_\lambda(\xi) = \left( 1 - |\xi|^2 \right)^\lambda_+ \]
    %
    lies in $M^p(\RR^d)$.
\end{example}

If $m$ is no longer continuous, this theorem only holds for \emph{almost all} slices of the function.

\begin{theorem}
    Fix $m \in M^p(\RR^{d+1})$, and for each $\lambda$, let $m_\lambda(\xi) = m(\xi,\lambda)$ be defined on $\RR^d$. Then for almost every $\lambda \in \RR$, $\| m_\lambda \|_{M^p(\RR^d)} \leq \| m \|_{M^p(\RR^{d+1})}$.
\end{theorem}
\begin{proof}
    By duality and the multiplication formula for the Fourier transform,
    %
    \[ \left| \int m(\xi) \widehat{f}(\xi) \widehat{g}(\xi)\; d\xi \right| \leq \| m \|_{M^p(\RR^{d+1})} \| f \|_{L^p(\RR^{d+1})} \| g \|_{L^q(\RR^{d+1})}, \]
    %
    where $q$ is the dual of $p$. If $f = f_1 \otimes f_2$ and $g = g_1 \otimes g_2$ then
    %
    \[ \left| \int m_\lambda(\xi) \widehat{f_1}(\xi) \widehat{f_2}(\lambda) \widehat{g_1}(\xi) \widehat{g_2}(\lambda)\; d\xi\; d\lambda \right| \leq \| m \|_{M^p(\RR^d)} \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Write the left hand side as
    %
    \[ \left| \int J(\lambda) \widehat{f_2}(\lambda) \widehat{g_2}(\lambda)\; d\lambda \right|, \]
    %
    where
    %
    \[ J(\lambda) = \int m_\lambda(\xi) \widehat{f_1}(\xi) \widehat{f_2}(\xi)\; d\xi. \]
    %
    The inequality above this implies that
    %
    \[ \| J \|_{L^\infty(\RR)} \leq \| J \|_{M^p(\RR)} \leq \| m \|_{M^p(\RR^{d+1})} \| f_1 \|_{L^p(\RR^d)} \| g_1 \|_{L^p(\RR^d)}. \]
    %
    But this implies precisely that for almost every $\lambda \in \RR$,
    %
    \[ |J(\lambda)| \leq \| f_1 \|_{L^p(\RR^d)} \| g_1 \|_{L^p(\RR^d)}, \]
    %
    which completes the proof (modulo a separability argument).
\end{proof}

\section{Transference}

One can view the last result of the last section as a \emph{transference theorem}, showing that the study of the boundedness of multipliers becomes harder in higher dimensions (since a higher dimensional result implies a corresponding lower dimensional result for the slices). Our goal now is to analyze a similar correspondence between the theory of multipliers on $\RR^d$ and the theory of multipliers on $\TT^d$.

Let us briefly describe the analogous properties of multipliers on $\TT^d$ that we have proved for $\RR^d$. There exists a theory of Schwartz and tempered sequences $\{ a_m : m \in \ZZ^d \}$ analogous to that of Schwartz functions and tempered distributions on $\TT^d$ and $\RR^d$, such that the Fourier transform induces an isomorphism between Schwartz functions on $\TT^d$ and Schwartz sequences on $\ZZ^d$, and tempered distributions on $\TT^d$ with tempered sequences on $\ZZ^d$. One can take the convolution in both spaces. If $T: C^\infty(\TT^d) \to C^\infty(\TT^d)$ is any continuous operator commuting with translations, then there exists a distribution $\Lambda$ on $\TT^d$ such that $Tf = \Lambda * f$ for any $f \in C^\infty(\TT^d)$. Applying the Fourier transform, for any such operator there is also a tempered sequence $\{ a_m : m \in \ZZ^d \}$ such that
%
\[ \widehat{Tf}(n) = a_n \widehat{f}(n), \]
%
so we have a theory of Fourier multipliers on $\TT^d$. For any $1 \leq p,q \leq \infty$, we let $M^{p,q}(\ZZ^d)$ denote the family of all tempered sequences $\{ a_m \}$ such that the induced Fourier multiplier operator $T$ is bounded from the $L^p(\TT^d)$ norm to the $L^q(\TT^d)$ norm on smooth functions, with the associated operator norm giving the space a topology. Similarily, we define $M^p(\ZZ^d) = M^{p,q}(\ZZ^d)$. We have $M^{p,q}(\ZZ^d) = M^{q^*,p^*}(\ZZ^d)$ for all $1 \leq p,q \leq \infty$. As for multipliers on $\RR^n$, we have $M^2(\ZZ^d) = l^\infty(\ZZ^d)$, and $M^{1,q}(\ZZ^d) = M^{q^*,\infty}(\ZZ^d) = \widehat{L^q(\TT^d)}$ for $q > 1$, and $M^{1,1}(\ZZ^d) = M^{\infty,\infty}(\ZZ^d) = \widehat{M(\TT^d)}$.

Our goal is to relate the boundedness of multipliers on $\TT^d$ to the boundedness of associated multipliers on $\RR^d$, and vice versa. To begin with, we show that bounded multipliers on $\RR^d$ induce bounded multipliers on $\TT^d$.

\begin{theorem}
    Suppose $m \in M^p(\RR^d)$, and every point in $\RR^d$ is a Lebesgue point of $m$. Then for all $R > 0$, the sequence $a_R(n) = m(n/R)$ lies in $M^p(\ZZ^d)$, and $\| a_R \|_{M^p(\ZZ^d)} \leq \| m \|_{M^p(\RR^d)}$.
\end{theorem}

\begin{remark}
    Every function can be altered on a set of measure zero in order to satisfy the assumptions of this theorem, as the theory of the Hardy-Littlewood maximal function indicates.
\end{remark}

\begin{proof}
    Without loss of generality, by rescaling we may assume that $R = 1$. The case $p = 1$ and $p = \infty$ follows from Poisson sumation and the characterizations of $M^1(\RR^d)$ and $M^1(\ZZ^d)$. Thus we may assume $1 < p < \infty$. 

    Here the proof follows from a general identity, that for any pair of trigonometric periodic polynomials $f$ and $g$, if $\Phi_\delta(x) = e^{- \pi \delta |x|^2}$, if $T$ is a Fourier multiplier on $\RR^d$ with symbol $m(\xi)$, and $S$ is a Fourier multiplier on $\ZZ^d$ with symbol $m(n)$, then for any $\alpha,\beta > 0$ with $\alpha + \beta = 1$,
    %
    \[ \lim_{\delta \to 0} \delta^{d/2} \int_{\RR^d} T \{ f \Phi_{\alpha \delta} \} \cdot \overline{ g \Phi_{\beta \delta} } = \int_{\TT^d} Sf \cdot \overline{g}\; dx.  \]
    %
    To obtain the identity, it suffices to assume by linearity that $f(x) = e^{2 \pi i n_1 \cdot x}$ and $g(x) = e^{2 \pi i n_2 \cdot x}$ for two integers $n_1$ and $n_2$. If $n_1 = n_2 = n$, we therefore have to prove that the left hand side is equal to $m(n)$, and if $n_1 \neq n_2$, we have to prove the left hand side is equal to zero. By the multiplication formula, the left hand side is
    %
    \[ \lim_{\delta \to 0} \delta^{d/2} (\delta \alpha)^{-d/2} (\delta \beta)^{-d/2} \int_{\RR^d} m(\xi) \cdot \Phi_{1/\alpha \delta}(\xi - n_1) \Phi_{1/\beta \delta}(\xi - n_2) = \lim_{\delta \to 0} (\alpha \beta \delta)^{-d/2} \int_{\RR^d} m(\xi) \Phi_{1/\alpha \delta}(\xi - n_1) \Phi_{1/\beta \delta}(\xi - n_2). \]
    %
    If $n_1 = n_2 = n$, then
    %
    \[ \Phi_{1/\alpha \delta}(\xi - n_1) \Phi_{1/\beta \delta}(\xi - n_2) = (\alpha \beta \delta)^{-n/2} \Phi_{1/\alpha \beta \delta}(\xi - n), \]
    %
    is an approximation to the identity as $\delta \to 0$, yielding the result. On the other hand, if $n_1 \neq n_2$, then the two Gaussian functions are primarily supported on disjoint sets, which yields the result in this case as well.

    Returning to the general proof, we note that it suffices to prove by density and duality that for any trigonometric polynomials $f$ and $g$, 
    %
    \[ \left| \int Sf(x) \overline{g(x)}\; dx \right| \leq \| m \|_{M^p(\RR^d)} \| f \|_{L^p(\RR^d)} \| g \|_{L^{p^*}(\RR^d)}. \]
    %
    But the identity above gives that
    %
    \begin{align*}
        \left| \int Sf(x) \overline{g(x)}\; dx \right| &\leq \lim_{\delta \to 0} \delta^{d/2} \left| \int \int_{\RR^d} T \{ f \Phi_{\alpha \delta} \} \cdot \overline{ g \Phi_{\beta \delta}} \right|\\
        &\leq \lim_{\delta \to 0} \delta^{d/2} \| m \|_{M^p(\RR^d)} \| f \Phi_{\alpha \delta} \|_{L^p(\RR^d)} \| g \Phi_{\beta \delta} \|_{L^{p^*}(\RR^d)}\\
        &= \| m \|_{M^p(\RR^d)} \| f \|_{L^p(\TT^d)} \| g \|_{L^{p^*}(\TT^d)}. \qedhere
    \end{align*}
\end{proof}

It is clearly not true that if $\{ m(n) : n \in \ZZ^d \}$ gives an element of $M^p(\ZZ^d)$, then $m$ is in $M^p(\TT^d)$, since $m$ can be poorly behaved away from the integers. But if $\{ m(n/R) : n \in \ZZ^d \}$ is uniformly in $M^p(\ZZ^d)$, we can prove that $m$ is in $M^p(\TT^d)$ given weak continuity assumptions.

\begin{theorem}
    Suppose $m$ is Riemann integrable, $1 \leq p \leq \infty$, and we define $a_R(n) = m(n/R)$. Then
    %
    \[ \| m \|_{M^p(\RR^d)} \leq \sup_{R > 0} \| a_R \|_{M^p(\ZZ^d)}. \]
\end{theorem}
\begin{proof}
    Fix $f,g \in C_c^\infty(\RR^d)$. Then for suitably large $R$, $\text{Dil}_{1/R} f$ and $\text{Dil}_{1/R} g$ are supported in $[-1/2,1/2]^d$. Define the periodic functions
    %
    \[ \tilde{f}_R(x) = \sum_{n \in \ZZ^d} \text{Dil}_{1/R} f(x - n) \quad\text{and}\quad \tilde{g}_R(x) = \sum_{n \in \ZZ^d} \text{Dil}_{1/R} g(x - n). \]
    %
    Then
    %
    \begin{align*}
        \int m(D) f(x) \overline{g}(x) &= \int m(\xi) \widehat{f}(\xi) \overline{\widehat{g}(\xi)}\\
        &= \lim_{R \to \infty} R^{-d} \sum_{n \in \ZZ^d} b(n/R) \widehat{f}(n/R) \overline{\widehat{g}(n/R)}\\
        &= \lim_{R \to \infty} R^d \sum_{n \in \ZZ^d} b(n/R) \widehat{\tilde{f}_R}(n) \widehat{\tilde{g}_R(n)}\\
        &\leq \lim_{R \to \infty} R^d \| a_R \|_{M^p(\ZZ^d)} \| \tilde{f}_R \|_{L^p(\TT^d)} \| \tilde{g}_R \|_{L^{p^*}(\TT^d)}\\
        &\leq \lim_{R \to \infty} \| a_R \|_{M^p(\ZZ^d)} \| f \|_{L^p(\RR^d)} \| g \|_{L^{p^*}(\RR^d)}.
    \end{align*}
\end{proof}

\begin{example}
    The Hilbert transform $H$ is a Fourier multiplier with symbol $i \text{sgn}(\xi)$. Since it is homogeneous, Riemann integrable, and every point is a Lebesgue point, the theory of boundedness from $L^p(\RR^d)$ to $L^p(\RR^d)$ is equivalent to the boundedness of the periodic version of the Hilbert transform from $L^p(\TT^d)$ to $L^p(\TT^d)$.
\end{example}

Similarily, we see that the convergence in $L^p(\TT^d)$ of various Fourier series (Dirichlet sums, spherical summation, square summation, and so on) are equivalent to the associated problems of the convergence of the Fourier transform in $L^p(\RR^d)$.

Many problems in harmonic analysis deal not only with the boundedness of Fourier multipliers, but also the boundedness of a maximal function associated with a family of multipliers (e.g. the almost everywhere convergence of Fourier series is connected with the properties of the maximal function $Mf = \sup_{R > 0} S_R f$, where $S_R$ is the partial summation operator. Let us proof a transference result for maximal functions associated with dilations of multiplier operators.

\begin{theorem}
    Fix a bounded, Riemann integrable function $m$ on $\RR^d$ such that every $\xi \in \RR^d$ is a Lebesgue point of $m$. Define the maximal functions $Mf = \sup_{R > 0} m(D/R) f$ on $\RR^d$, and the maximal function $Nf = \sup_{R > 0} T_R f$, where $T_R$ is the Fourier multiplier operator on $\TT^d$ associated with the sequence $a_R(n) = m(n/R)$. Then $M$ is bounded from the $L^p(\RR^d)$ norm to itself if and only if $N$ is bounded from the $L^p(\RR^d)$ norm to itself.
\end{theorem}
\begin{proof}
    It suffices to show that a uniform family of estimates of the form
    %
    \[ \| \sum_{i = 1}^K c_i m(D/R_i) f \|_{L^p(\RR^d)} \lesssim \sum |c_i| \]
    %
    uniform in $K$ and $R_1, \dots, R_K$, is equivalent to a uniform family of estimates of the form
    %
    \[ \| \sum_{i = 1}^K c_i T_{R_i} f \|_{L^p(\RR^d)} \lesssim \sum |c_i|, \]
    %
    which is uniform in $K$ and $R_1, \dots, R_K$. In the first case, we may assume without loss of generality that $f \in C_c^\infty(\RR^d)$, and in the second, that $f$ is a trigonometric polynomial. The proof then follows by essentially the analogous techniques to above.
\end{proof}

\begin{remark}
    One can also show that transference holds between maximal functions bounded merely from $L^p(\RR^d)$ to $L^{p,\infty}(\RR^d)$, using the duality of Lorentz spaces in much the same way.
\end{remark}

Here are some other examples of transference.

\begin{example}
    TODO: ELABORATE ON THIS. For a given family of coefficients $\{ a_m : m \in \ZZ^d \}$, consider the periodization operator
    %
    \[ Tf = \sum_{m \in \ZZ^d} a_m \text{Trans}_m f. \]
    %
    Then, roughly speaking, $T$ is a Fourier multiplier operator with symbol $m(\xi) = \sum a_m e^{-2 \pi i \xi \cdot m}$, where this sum must be interpreted in a non-standard sense if the sum $\{ a_m \}$ does not converge, which means we might end up obtaining a tempered distribution $m$ rather than a function. But certainly $T$ is well defined for  any compactly supported input, since then the sum is locally finite. Let us assume $T$ is bounded on these inputs in the $L^p$ norm for some $1 < p < \infty$ with operator norm $A$, and thus extends uniquely to a bounded operator from $L^p(\RR^n)$ to itself. If we consider any family of coefficients $\{ c_m : m \in \ZZ^d \}$, and consider, for $\varepsilon < 1$, the function
    %
    \[ f(x) = \sum_{m \in \ZZ^d} c_m \varepsilon^{-d/p} \mathbf{I} \left(x \in \prod_{i = 1}^d [m_i, m_i + \varepsilon] \right), \]
    %
    then $\| f \|_{L^p(\RR^d)} = \| c \|_{l^p(\ZZ^d)}$. If $\| c_m \|_{l^p(\ZZ^d)}$, it follows by continuity that it must be true that
    %
    \begin{align*}
        Tf(x) &= \sum_{k \in \ZZ^d} \sum_{m + n = k} c_m a_n \varepsilon^{-d/p} \mathbf{I} \left( x \in \prod_{i = 1}^d [k_i, k_i + \varepsilon] \right)\\
        &= \sum_{k \in \ZZ^d} (a * c)(k) \varepsilon^{-d/p} \mathbf{I} \left( x \in \prod_{i = 1}^d [k_i, k_i + \varepsilon] \right).
    \end{align*}
    %
    It follows that
    %
    \[ \| Tf \|_{L^p(\RR^d)} = \| a * c \|_{l^p(\ZZ^d)}. \]
    %
    Thus we conclude that $\| a * c \|_{l^p(\ZZ^d)} \leq A \| c \|_{l^p(\ZZ^d)}$. Conversely, suppose convolution with $a$ is bounded from $l^p(\ZZ^d)$ to $l^p(\ZZ^d)$ with norm $A$. Then
    %
    \[ \left( \sum_{k \in \ZZ^d} |Tf(x+k)|^p \right)^{1/p} = \left( \sum_{k \in \ZZ^d} \left| \sum_m a_m f(x + k - m) \right|^p \right)^{1/p} \leq A \left( \sum_k |f(x + k)|^p \right)^{1/p}. \]
    %
    But
    %
    \begin{align*}
        \| Tf \|_{L^p(\RR^d)} &= \left( \int_{[0,1]^d} \left( \sum_{k \in \ZZ^d} |Tf(x+k)|^p \right) \right)^{1/p}\\
        &\leq A \left( \int_{[0,1]^d} \sum_k |f(x+k)|^p \right)^{1/p}\\
        &= A \| f \|_{L^p(\RR^d)}.
    \end{align*}
    %
    Thus we conclude that $T$ is bounded if and only if the associated discrete convolution operator is bounded. Thus we have shown studying the boundedness of multiplier operators associated to symbols with domain $\TT^d$, e.g. convolution operators from $l^p(\ZZ^d)$ to $l^q(\ZZ^d)$, via Fourier multiplier operators with \emph{periodic} symbols in the domain $\RR^d$. More precisely, we can define $M^{p,q}(\ZZ^d)$ to be the set of all distributions $f$ on $\TT^d$ such that convolution with $\widehat{f}$ gives a bound from $L^p(\ZZ^d)$ to $L^q(\ZZ^d)$ in a suitable domain so we can interpret this convolution, e.g. for compactly supported sequences. It then follows that $M^p(\ZZ^d)$ is isomorphic to the family of periodic symbols in $M^p(\RR^d)$.
\end{example}

\begin{example}
    Next, consider $m \in M^p(\RR^d)$ with compact support in $[0,1]^d$, and consider the periodization
    %
    \[ m_P(\xi) = \sum_{n \in \ZZ^d} m(\xi - n). \]
    %
    We claim that $m_P \in M^p(\RR^d)$. TODO (Look up Jodeit Paper?).
\end{example}













\chapter{Sobolev Spaces}














\chapter{Time Frequency Analysis}

In harmonic analysis, it is often useful to study a function $f: \RR^d \to \CC$ via it's Fourier transform $\widehat{f}: \RR^d \to \CC$. The goal of time-frequency analysis is to think of such a function as being a function living simultaneously in both spaces, i.e. a function on the domain $\RR^d \times \RR^d$, which can be either written in temporal coordinates, or frequential coordinates, and in certain special cases, a combination of the two. We call this space the \emph{phase plane}, combining both time and frequency information together. There are several difficulties with rigorously incorporating this approach, for instance, resulting from the uncertainty principle, but the utility makes this . Given a function $f$, we define a \emph{phase portrait} for $f$ to be a subset of $\RR^d \times \RR^d$ where the majority of the `mass' of $f$ and $\widehat{f}$ are concentrated (for an arbitrary locally compact abelian group $G$, phase space is $G^* \times G$). Let us consider a simple example.

\begin{example}
  Consider the Gaussian $f(t) = e^{- \pi t^2}$. Then $70\%$ of the mass of $f$ is concentrated on $[-1,1]$, and the mass decays exponentially away from this interval. Thus the function $f$ is concentrated in $[-1,1]$. We have $\widehat{f_\delta}(\omega) = e^{- \pi \omega^2}$, which similarily, is concentrated in $[-1,1]$. A natural choice of the phase portrait of $f$ is therefore $[-1,1] \times [-1,1]$.
\end{example}

\begin{example}
  The Fourier transform of the Dirac delta function $\delta$ at a point $x$ is the plane wave $\xi \mapsto e^{- 2 \pi i \xi \cdot x}$. Thus a natural phase portrait for the Dirac delta function is $\{ x \} \times \RR^d$. Similarily, the phase portrait of a pure plane wave $x \mapsto e^{2 \pi i \xi \cdot x}$ is $\RR^d \times \{ \xi \}$, since the Fourier transform is the Dirac delta function at $\xi$.
\end{example}

The symmetries of the Fourier transform have natural effects on the phase portrait of a function $f$, which has phase portrait $S$.

\begin{itemize}
  \item The phase portrait of $\text{Trans}_x f$ is obtained by translating $S$ horizontally by $x$ units, since on the Fourier side the translation acts as a modulation, and does not move mass. Similarily, the phase portrait of the modulation $\text{Mod}_\xi f$ is obtained by translating $S$ vertically by $\xi$ units, since modulation does not affect the position of mass on the spatial side of things.

  \item Scaling in physical space has a `dual' effect in phase space. More precisely, $\text{Dil}_\delta f$ has phase portrait
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (x/\lambda, \lambda \xi) \in S \} \]
  %
  More generally, given a linear transformation $T$, the phase portrait of $f \circ T^{-1}$ is equal to
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (T(x), T^{-t}(\xi)) \in S \}. \]
  %
  The rescaling above is a special case. In particular, if $T \in O(d)$, then $f \circ T^{-1}$ has phase portrait
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (T(x), T(\xi)) \in S \}. \]

  \item The phase portrait of $\widehat{f}$ is equal to
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (\xi,-x) \in S \}, \]
  %
  i.e. a clockwise rotation by ninety degrees.
\end{itemize}

Notice that all the transformations above preserve area, which is where symplectic geometry enters the picture.

We note that the phase portrait of a rescaled, translated, and modulated Gaussian has phase portrait consisting of an axis-oriented rectangle with sidelengths $\delta x$ and $\delta \xi$, where $\delta x \cdot \delta \xi \sim 1$. Such a rectangle in phase space is called a \emph{Heisenberg tile}, and functions whose phase portraits consist of Heisenberg tiles are called \emph{wave packets}. In light of the uncertainty principle, these functions are the best alternatives to a function which is compactly supported in a sidelength one interval, and whose Fourier transform is also supported in a sidelength one interval.

\section{Localization in Time and Space}

Physical space localization is easy, we just multiply by a function, either a rough cutoff, or a smooth cutoff. Frequency localization is only slightly harder, where we can apply a basic Fourier multiplier. To localize in both time and frequency, one approach is to first smoothly localize in space, then time, or vice versa. This works out fine, as long as we do not localize too finely in both time and space, i.e. breaking the uncertainty principle. Here is a characteristic result in this setting

\begin{lemma}
  Fix two cubes $I$ and $J$, and two smooth functions $\psi_I$ and $\psi_J$ adapted to $I$ and $J$, and consider the localization operator $\pi_{I \times J} = \psi_I(D) \circ \psi_J(X)$. Then $\pi_{I \times J} f$ has Fourier support in $I$, and is localized in $J$ in the sense that for $|x| \geq $
  %
  \[ (\pi_{I \times J} f)(x) \lesssim_n |I|^{1-n} |J|^{1/2} \| f \|_{L^2(\RR^d)} d(x,J)^{-n} \]
\end{lemma}
\begin{proof}
  If we let $K_I$ be the inverse Fourier transform of $\psi_I$, then for all $n > 0$,
  %
  \[ |K_I(x)| \lesssim_n |I|^{1-n} |x|^{-n}. \]
  %
  The proof then follows from Cauchy-Schwartz applied to the representation $\pi_{I \times J} f = K_I * (\psi_J \cdot f)$.
  %
  \[ (\int |K_I(x-y)|^2 |\psi_J(y)|^2)^{1/2} \| f \|_{L^2(\RR^d)} \]
  % d(x,J)^{-n}
\end{proof}

















\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A \emph{Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \ZZ$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
    The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
    In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
    %
    \[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
    %
    Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the \emph{Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
    A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
    If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
    %
    \[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
    %
    If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
    %
    \[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
    %
    Conversely, if $Tf$ is bounded, then
    %
    \[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
    %
    so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
    The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \ZZ} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
    \sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
    &= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
    &= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
    \left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
    &\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.







\chapter{Higher Dimensional Fourier Analysis}

The Fourier transform in dimensions greater than one have strange phenomena, which is not so obvious from the perspective given by the one dimensional theory. For instance, consider the Theorem of Marcel Riesz, which says that if we define the Dirichlet summation operator
%
\[ S_R f(x) = \int_{-R}^R \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi, \]
%
then for $1 < p < 2$, if $f \in L^p(\RR^d)$, $S_R f \to f$ in $L^p(\RR^d)$. The result follows because the operators $\{ S_R \}$ are uniformly bounded, and dilation symmetries show this is equivalent to showing that $S_1$ is a bounded operator on $L^p(\RR^d)$. Tensorization shows that Riesz's theorem continues to work in higher dimensions for the \emph{square summation operators}
%
\[ S_R^{\text{sq}} f(x) = \int_{-R}^R \cdots \int_{-R}^R \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi, \]
%
i.e. the operator $S_1^{\text{sq}}$ is bounded on $L^p(\RR^d)$ for $1 < p < \infty$. On the other hand, the \emph{spherical summation operators}
%
\[ S_R f(x) = \int_{|\xi| \leq R} \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi \]
%
act very differently than their one dimensional counterpart. In particular, Riesz's theorem completely fails in this situation. The \emph{ball multiplier} $S = S_1$ is \emph{only} bounded on $L^p(\RR^d)$ for $p = 2$ (in which case the bound follows trivially from Plancherel). The unboundedness in $L^p(\RR^d)$ for $1 < p < \infty$ follows from a clever result of Fefferman (1971).

\begin{theorem}
    The ball multiplier $S$ is \emph{only} bounded on $L^2(\RR^d)$.
\end{theorem}
\begin{proof}
    We rely on a geometric construction, together with the uncertainty principle. Duality implies that it suffices to show it is unbounded on $L^p(\RR^d)$ for $p > 2$. Thus we must find functions $f$ which are 'broad', or 'spread out', and show that $Sf$ can have parts which are large on a 'narrow', or 'concentrated' set. Our first observation is that the bad part of the multiplier occurs on the boundary of the unit ball $B$; the multiplier is $C^\infty$ away from this boundary, so behaves very nicely with functions with Fourier support away from the boundary of the unit ball. Thus, without loss of generality, we might as well try and find functions whose Fourier support is concentrated near $\partial B$.

    For any $R > 0$, we construct a function $f_R$ supported on the annulus given by the equation $1 - 1/10R \leq |\xi| \leq 1 + 1/R$. To apply the uncertainty principle, we find $\sim R^{d-1}$ rectangles $\{ \Theta \}$, which have dimensions $R^{-1}$ in the direction tangent to $\partial B$, but have dimension $R^{-1/2}$ in the $d-1$ directions tangent to the boundary of the sphere, and such that $\Theta$ has one tenth of it's mass in $B$, and half it's mass outside of $B$. We fix a compactly supported density function $\phi \in C_c^\infty(\RR^d)$ on the unit ball, and rescale it to density functions $\{ \phi_\Theta \}$ supported on $\Theta$ with magnitude roughly $R^{(d+1)/2}$ on $\Theta$. For any $x_1,\dots,x_N$, the uncertainty principle tells us that the function $\chi_{T_\Theta}$, with Fourier transform equal to
    % L^2 norm R^{(d+1)/4}
    \[ e^{-2 \pi i x_\Theta \cdot \xi} \phi_\Theta(\xi), \]
    %
    has mass concentrated on the dual rectangle $T_\Theta$ centered at $x_\Theta$ and with magnitude roughly $R^{(d+1)/2}$ on $T_\Theta$. The action of $S$ on $\chi_{T_\Theta}$ is to cut the Fourier support of $\Theta$ by a tenth. Thus we lose the $90 \%$ of the Fourier mass of $\Theta$, but our support is also made ten times thinner in the tangential direction. As a result, $S \chi_{T_\Theta}$ will now have mass concentrated on a tube $T_\Theta^*$, which is ten times longer than $T_\Theta$.

    Let $T_\Theta^+$ be the portion of $T_\Theta^*$ which lies at the opposite end of $T_\Theta^*$ to $T_\Theta$. Our construction now relies on \emph{Kakeya} like phenomena. For any $\varepsilon > 0$, there exists a large $R_0$ such that for $R \geq R_0$, we can pick $\{ x_\Theta \}$ such that tubes $\{ T_\Theta \}$ are disjoint from one another, but such that the tubes $\{ T_\Theta^+ \}$ have large overlap, in the sense that
    %
    \[ | \bigcup_\Theta T_\Theta^+ | \leq \varepsilon | \bigcup_\Theta T_\Theta|. \]
    %
    The supports of $S \chi_\Theta$ thus have lots of overlap on this set, but it is difficult to control the sum $\sum S \chi_\Theta$ since these functions might have different signs where they overlap. To fix this, we define
    %
    \[ f_R = \sum_\Theta \varepsilon_\Theta \chi_\Theta \]
    %
    where $\{ \varepsilon_\Theta \}$ are independent $\{ -1, +1 \}$ valued Bernoulli random variables, because Khintchine's inequality implies that we have the pointwise inequality, for any $1 < p < \infty$, of the form
    %
    \[ \left( \EE \left| \sum_\Theta \varepsilon_\Theta \chi_\Theta \right|^p \right)^{1/p} \sim \left( \sum_\Theta |\chi_\Theta|^2 \right)^{1/2}. \]
    %
    It follows that, since the tubes $T_\Theta$ are disjoint,
    %
    \begin{align*}
        \EE \| f_R \|_{L^p(\RR^d)}^p &\sim \int \left( \sum_\Theta |\chi_\Theta(x)|^2 \right)^{p/2}\; dx\\
        &\sim \left( R^{\frac{d+1}{2}} \right)^p \left| \bigcup_\Theta T_\Theta \right|.
    \end{align*}
    %
    Similarily, Khintchine's inequality can again be applied to
    %
    \begin{align*}
        Sf_R &= \sum_\Theta \varepsilon_\Theta S \chi_\Theta.
    \end{align*}
    %
    to conclude that
    %
    \begin{align*}
        \EE \| Sf_R \|_{L^p(\RR^d)}^p &\sim \int \left( \sum_\Theta |S \chi_\Theta(x)|^2 \right)^{p/2}\; dx\\
        &\gtrsim \left( R^{\frac{d+1}{2}} \right)^p \int \left( \sum_\Theta \mathbf{I}_{T_\Theta^+}(x) \right)^{p/2}\; dx.
    \end{align*}
    %
    If $S$ was bounded on $L^p(\RR^d)$, we would conclude that
    %
    \[ \int \left( \sum_\Theta \mathbf{I}_{T_\Theta^+}(x) \right)^{p/2}\; dx \lesssim \left| \bigcup_\Theta T_\Theta \right|. \]
    %
    The trivial bound
    %
    \[ \int \left( \sum_\Theta \mathbf{I}_{T_\Theta^+}(x) \right)\; dx \sim \left| \bigcup_\Theta T_\Theta \right| \]
    %
    combined with the fact that the sum is supported on the finite measure set $\bigcup_\Theta T_\Theta^+$ yields that
    %
    \[ \left| \bigcup_\Theta T_\Theta^+ \right|^{-(p/2 - 1)} \left| \bigcup_\Theta T_\Theta \right|^{p/2} \lesssim \int \left( \sum_\Theta \mathbf{I}_{T_\Theta^+}(x) \right)^{p/2}\; dx. \]
    %
    Thus we find that
    %
    \[ \left| \bigcup_\Theta T_\Theta \right|^{p/2 - 1} \lesssim  \left| \bigcup_\Theta T_\Theta^+ \right|^{p/2 - 1}. \]
    %
    Because of the Kakeya like specification of these sets, this is impossible in the range $p > 2$ specified.
\end{proof}

We thus see that understanding the behaviour of $S$ is closely connected to Kakeya phenomena. Indeed, one can generalize this problem to determining the behaviour of the \emph{Bochner-Riesz multipliers} $S_\delta$, which are the Fourier multipliers with symbol
%
\[ m^\delta(\xi) = (1 - |\xi|)_+^\delta. \]
%
For $\delta = 0$, $S_\delta$ is just the ball multiplier above. As $\delta$ increases, the singularity on the boundary of the unit ball becomes less and less bad, so it might be expected that $S_\delta$ becomes bounded on a larger range of $L^p$ spaces. Determining the precise range under which these operators are bounded is a major open problem of harmonic analysis, and is closely connected to a deeper understanding of Kakeya like phenomena.








\chapter{Oscillatory Integrals}

The goal of the theory of oscillatory integrals is to obtain estimates of integrals with highly oscillatory integrands, where standard techniques such as taking in absollute values, or various spatial decomposition strategies, fail completely to give tight estimates. A typical oscillatory integral is of the form
%
\[ I(\lambda) = \int a(x) e^{2 \pi i \lambda \phi(x)}\; dx, \]
%
where $a$ is the \emph{amplitude function}, and $\phi$ is the \emph{phase}. The value $\lambda$ is a parameter measuring the degree of oscillation. As $\lambda$ increases, the degree of the oscillatory factor increases, which implies more cancellation should occur on average. Thus we should expect $I(\lambda)$ to decay as $\lambda \to \infty$. One of the main problems in the study of oscillatory integrals is to measure the asymptotic decay more precisely.

\begin{example}
    The most basic example of an oscillatory integral is the Fourier transform, where for each function $f \in L^1(\RR)$, and each $\lambda \in \RR$, we consider the quantity
    %
    \[ \widehat{f}(\lambda) = \int_{-\infty}^\infty e^{- 2 \pi i \lambda x} f(x)\; dx. \]
    %
    Thus in the oscillatory integral defining the Fourier transform of $f$, the function $f$ plays the role of the amplitude, the phase function is $\phi(x) = x$. The basic theory of the Fourier transform hints that the decay of the oscillatory integral is related to the smoothness of the amplitude function $f$.
\end{example}

There are two main tools to estimate oscillatory integrals. Most classically, the method of steepest descent uses contour integration techniques from complex analysis to shift the integral to a domain where less oscillation occurs, so we can apply standard estimation strategies. However, it is difficult to apply this method to oscillatory integrals over multivariate domains. The second tool, known as the method of stationary phase, determines the behaviour of the decay of an oscillatory integral by isolating the oscillation of a smooth phase $\phi$ to points where $\nabla \phi$ is smooth. If the zeroes of $\nabla \phi$ are isolated, then the oscillatory integrals can be localized near these values. Roughly speaking, each zero $x_0$ contributes $\psi(x_0) e^{2 \pi i \lambda \phi(x_0)}$, times the volume of the region around $x_0$ where $\phi$ deviates by $\approx 1/\lambda$, to the asymptotic decay of $I(\lambda)$ as $\lambda \to \infty$.

\section{One Dimensional Theory}

Let us begin with a simple example of an oscillatory integral, i.e.
%
\[ I(\lambda) = \int_J e^{2 \pi i \lambda \phi(x)}\; dx, \]
%
where $J$ is a closed interval, and $\phi: J \to \RR$ is Borel measurable. Taking in absolute values shows that $|I(\lambda)| \leq |J|$ for all $\lambda$. If $\phi$ is a constant, then $I(\lambda) = |J| e^{i \lambda \phi}$, so in this case the estimate is sharp. But if $\phi$ varies, we expect $I(\lambda)$ to decay as $\lambda \to \infty$. For instance, there are various results, such as the Esse\'{e}n concentration inequality, which show that if we are to expect \emph{average} decay in the integral $I$ over a range of $\lambda$, then $\phi$ must not be concentrated around any point.

\begin{theorem}[Esse\'{e}n Concentration Inequality]
  Let $\phi: J \to \RR$ be Borel measurable, and for each $\lambda \in \RR$, set
  %
  \[ I(\lambda) = \int_J e^{2 \pi i \lambda \phi(x)}\; dx. \]
  %
  Then for any $\varepsilon > 0$,
  %
  \[ \sup_{a \in \RR} |\{ x \in J: |\phi(x) - a| \leq \varepsilon \}| \lesssim \varepsilon \int_0^{1/\varepsilon} |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of $\phi$.
\end{theorem}
\begin{proof}
  By rescaling, we may assume that $J = [0,1]$. Moreover, for any choice of $a$, we may replace $\phi$ with $\phi - a$, reducing the analysis to the case where $a = 0$. Similarily, replacing $\phi$ with $\phi/\varepsilon$ reduces us to the situation where $\varepsilon = 1$. Thus we must show
  %
  \[ |\{ x \in [0,1]: |\phi(x)| \leq 1 \}| \lesssim \int_0^1 |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of the function $\phi$. If $\psi$ is an integrable function supported on $[0,1]$, then Fubini's theorem implies
  %
  \begin{align*}
    \int_0^1 \psi(\lambda) I(\lambda)\; d\lambda &= \int_0^1 \int_0^1 \psi(\lambda) e^{2 \pi i \lambda \phi(x)}\; d\lambda\; dx\\
    &= \int_0^1 \widehat{\psi}(- \phi(x))\; dx.
  \end{align*}
  %
  In particular, this means that
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x))\; dx \right| \leq \| \psi \|_{L^\infty[0,1]} \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  If we choose a bounded function $\psi$ such that $\widehat{\psi}$ is non-negative, and bounded below on $[-1,1]$, then
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x))\; dx \right| \gtrsim |\{ x \in [0,1]: |\phi(x)| \leq 1 \}|, \]
  %
  and so the claim follows easily.
\end{proof}

\begin{remark}
    Recently, I have seen results that \emph{reverse} the concentration bound, for instance, a paper of Basu, Guo, Zhang, and Zorin-Kranich entitled ``A Stationary Set Method For Estimating Oscillatory Integrals'', and Wright's paper ``A Theory of Complex Oscillatory Integrals: A Case Study''. I do not know how general these techniques can be developed, but given an oscillatory integral in which we are able to prove stationary set estimates, but do not know asymptotics, it might be useful to look into these papers more.
\end{remark}

Thus if large cancellation happens in $I(\lambda)$ for the average $\lambda$, this automatically implies that $\phi$ cannot be concentrated around any particular point.  Conversely, we want to show that if $\phi$ varies significantly, then $I$ exhibits cancellation as $\lambda \to \infty$. One way to quantify this rate is through the derivative of the function $\phi$, i.e. if the derivative has a large magnitude, the phase is varying fast. A bound on $|\phi'|$ from below is not sufficient to guarantee cancellation independant of the function $\phi$, as the next example shows, if the integrand oscillates at a wavelength $1/\lambda$.

\begin{example}
  Fix a positive integer $\lambda_0$, and let $\phi_{\lambda_0}(x) = x + f(\lambda_0 x) / \lambda_0$, where $f$ is smooth and 1-periodic, $\| f' \|_{L^\infty(\RR)} \leq 1/2$, and
  %
  \[ \int_0^1 e^{2 \pi i (x + f(x))}\; dx \neq 0. \]
  %
  Then for each $x \in \RR$, $1/2 \leq |\phi_{\lambda_0}'(x)| \leq 2$, and in particular, is bounded independently of $\lambda_0$. Since $\phi_{\lambda_0}(x + 1/\lambda_0) = \phi_{\lambda_0}(x) + 1 / \lambda_0$, we find $e^{2 \pi i \lambda_0 \phi_{\lambda_0}(x)}$ is $1/\lambda_0$ periodic. In particular, this means
  %
  \begin{align*}
    I(\lambda_0) &= \int_0^1 e^{2 \pi i \lambda_0 \phi_{\lambda_0}(x)}\; dx\\
    &= \lambda_0 \int_0^{1/\lambda_0} e^{2 \pi i (\lambda_0 x + f(\lambda_0 x))}\; dx\\
    &= \int_0^1 e^{2 \pi i (x + f(x))}\; dx.
  \end{align*}
  %
  Thus $I(\lambda_0;\phi_{\lambda_0}) \sim 1$, independant of $\phi_0$, despite a uniform lower bound on the derivatives of the family of functions $\{ \phi_{\lambda_0} \}$.
\end{example}

One option is a uniform upper bound on $\phi''$, in addition to lower bounding $\phi'$, which eliminates the counterexample above, and yields a positive result.

\begin{theorem}
  Let $\phi: J \to \RR$ be twice continuously differentiable, and suppose there exists constants $A,B > 0$ with $|\phi'(x)| \geq A$ and $|\phi''(x)| \leq B$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} + \frac{B}{A^2} |J| \right). \]
\end{theorem}
\begin{proof}
  A dimensional analysis shows that the inequality is invariant under rescalings in $x$ and $\lambda$, so we may assume that $J = [0,1]$, and $\lambda = 1$. An integration by parts shows that
  %
  \begin{align*}
    \int_0^1 e^{2 \pi i \phi(x)}\; dx &= \int_0^1 \frac{1}{2 \pi i \phi'(x)} \frac{d}{dx} \left( e^{2 \pi i \phi(x)} \right)\; dx\\
    &= \left( \frac{e^{2 \pi i \phi(1)}}{2 \pi i \phi'(1)} - \frac{e^{2 \pi i \phi(0)}}{2 \pi i \phi'(0)} \right) - \int_0^1 \frac{d}{dx} \left( \frac{1}{2 \pi i \phi'(x)} \right) e^{2 \pi i \phi(x)}.
  \end{align*}
  %
  Now
  %
  \[ \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) = - \frac{\phi''(x)}{\phi'(x)^2}, \]
  %
  so taking in absolute values to the tree quantities in the sum above completes the proof.
\end{proof}

One can keep applying absolute values to obtain further bounds in terms of higher order derivatives of $\phi$. For instance, another integration by parts shows that if there is $A,B,C > 0$ such that for $x \in J$, if $\phi'(x) \geq A$, $\phi''(x) \leq B$, and $\phi'''(x) \leq C$, then
%
\[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} \right) + \frac{1}{\lambda^2} \left( \frac{B}{A^3} + \frac{C}{A^3} |J| + \frac{B^2}{A^4} |J| \right). \]
%
One can keep taking in absolute values, but the $1/\lambda$ decay will still remain. This is to be expected; for instance, if $\phi(x) = x$, and J$ = [0,1]$, then as $\lambda \to \infty$,
%
\[ I(\lambda) = \int_0^1 e^{2 \pi i \lambda x}\; dx = \frac{e^{2 \pi i \lambda} - 1}{2 \pi i \lambda} \]
%
and so
%
\[ \limsup_{\lambda \to \infty} |I(\lambda) \cdot \lambda| = 2, \]
%
so we cannot obtain any better decay than $1/\lambda$ here.

Another option is to not require control on the second derivative of the phase, but instead to assume that $\phi'$ is monotone, which prevents the kind of oscillation present in our counterexample.

\begin{lemma}[Van der Corput]
  Let $\phi: \RR \to \RR$ be a smooth phase such that $|\phi'(x)| \geq A$ for all $x \in J$, and $\phi'$ is monotone. Then for all $\lambda > 0$ we have
  %
  \[ |I(\lambda)| \lesssim \frac{1}{A \lambda}, \]
  %
  where the implicit constant is independent of $J$.
\end{lemma}
\begin{proof}
  We may rescale so that $\lambda = 1$ and $J = [0,1]$. Then the same integration by parts shows that
  %
  \begin{align*}
    \int_0^1 e^{2 \pi i \phi(x)}\; dx &= \left( \frac{e^{2 \pi i \phi(b)}}{2 \pi i \phi'(1)} - \frac{e^{2 \pi i \phi(0)}}{2 \pi i \phi'(0)} \right) + \frac{1}{2 \pi i} \int_0^1 \frac{d}{dx} \left( \frac{1}{2 \pi i \phi'(x)} \right) e^{2 \pi i \phi(x)}\; dx.
  \end{align*}
  %
  The two boundary terms are $O(1/A)$. For the integral, we apply a simple trick. Since $\phi'$ is monotone, so too is $1/\phi'$, so in particular, it's derivative has a constant sign. Thus by the fundamental theorem of calculus,
  %
  \begin{align*}
    \left| \int_J \frac{d}{dx} \left( \frac{1}{2 \pi i \phi'(x)} \right) e^{2 \pi i \phi(x)}\; dx \right| &\leq \int_J \left| \frac{d}{dx} \left( \frac{1}{2 \pi i \phi'(x)} \right)  \right|\; dx\\
    &= \left| \int_J \frac{d}{dx} \left( \frac{1}{2 \pi i \phi'(x)} \right) \right|\; dx\\
    &= \frac{1}{2 \pi \phi'(b)} - \frac{1}{2 \pi \phi'(a)}.
  \end{align*}
  %
  Again, this term is $O(1/A)$.
\end{proof}

Since the Van der Corput bound does not depend on $|J|$, it can be easily iterated using a decomposition strategy to give a theorem about higher derivatives of a function $\phi$.

\begin{lemma}
  Let $\phi: \RR \to \RR$ be smooth, and suppose there is some $k \geq 2$ such that $|\phi^{(k)}(x)| \geq A$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}, \]
  %
  where the implicit constant is independant of $J$.
\end{lemma}
\begin{proof}
  We perform an induction on $k$, the case $k = 1$ already proven. By scale invariance, we may assume $\lambda = 1$. Now $\phi^{(k-1)}$ is monotone, so for each $\alpha > 0$, outside an interval of length at most $O(\alpha/A)$, $|\phi^{(k-1)}(x)| \geq \alpha$. Thus applying the trivial bound in the excess region, and the case $k - 1$ on the other intervals, we conclude
  %
  \[ |I(\lambda)| \lesssim_k \frac{\alpha}{A} + \alpha^{-1/(k-1)} \]
  %
  Optimizing over $\alpha$, we find $|I(\lambda)| \lesssim_k A^{-1/k}$.
\end{proof}

\begin{remark}
    If $\phi^{(k-1)}$ vanishes at some point $x_0$ in $J$, then Taylor expansion shows that
    %
    \[ |\{ x \in J : |\phi(x) - \phi(x_0)| \leq \varepsilon \}| \gtrsim \varepsilon^{1/k}. \]
    %
    The Berry-Esseen theorem thus implies that the estimate $I(\lambda) \lesssim_k \lambda^{-1/k}$ is tight; we cannot have $I(\lambda) \lesssim \lambda^{-\alpha}$ for any $\alpha > 1/k$.
\end{remark}

Let us now consider a one dimensional oscillatory integral with a varying amplitude function $a$, i.e.
%
\[ I(\lambda) = \int_{-\infty}^\infty a(x) e^{2 \pi i \lambda \phi(x)}\; dx. \]
%
The Van der Corput lemma also applies here.

\begin{lemma}
  Fix $k \geq 1$. Suppose $a$ is supported on $J$, $|\phi^{(k)}(x)| \geq A$ for all $x \in J$, with $\phi'$ monotone if $k = 1$. Then
  %
  \[ |I(\lambda)| \lesssim_k \frac{\| a \|_{L^\infty(\RR)} + \| a' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
\end{lemma}
\begin{proof}
  Again, without loss of generality, we may assume $\lambda = 1$. Rescaling $x$ means we can assume $J = [0,1]$. For $x \in [0,1]$, define
  %
  \[ I_0(x) = \int_0^x e^{2 \pi i \lambda \phi(t)}\; dt. \]
  %
  The standard Van-der Corput lemma implies that for all $x$,
  %
  \[ |I_0(x)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}. \]
  %
  Integrating by parts, we find that
  %
  \begin{align*}
    \int_0^1 a(x) e^{2 \pi i \lambda \phi(x)}\; dx &= \int_0^1 a(x) I_0'(x)\; dx\\
    &= [a(1) I_0(1) - a(0) I_0(0)] - \int_0^1 a'(x) I_0(x)\; dx.
  \end{align*}
  %
  Now
  %
  \[ |a(1) I_0(b) - a(0) I_0(a)| \lesssim \frac{\| a \|_{L^\infty(\RR)}}{(A \lambda)^{1/k}} \]
  %
  and
  %
  \[ \left| \int_0^1 a'(x) I_0(x)\; dx \right| \lesssim_k \frac{\| a' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
  %
  Putting these two estimates together completes the proof.
\end{proof}

\begin{remark}
    Since the bound doesn't depend on the interval, if $a$ is not compactly supported, but $a'$ is integrable, and the other assumptions of the last result holds, then we still have a bound
    %
    \[ \sup_{a < b} \left| \int_a^b a(x) e^{2 \pi i \lambda \phi(x)}\; dx \right| \lesssim_k \frac{\| a \|_{L^\infty(\RR)} + \| a' \|_{L^1(\RR)}}{(A\lambda)^{1/k}} \]
\end{remark}

If $a$ is smooth and compactly supported, repeated integration by parts is very successful because there are no boundary terms, and so we get very fast decay as $\lambda \to \infty$.

\begin{theorem}
    Let $J$ be an interval, and fix $n > 0$. Consider a real-valued phase function $\phi \in C^{n+1}(\RR)$ with $\phi'(x) \neq 0$ on $J$, and an amplitude $a \in C^{n+1}(\RR)$ with $\text{supp}(a) \subset J$. Then
    %
    \[ |I(\lambda)| \lesssim_{n,K,\phi} \lambda^{-n} \sum_{k = 0}^n \| a^{(k)} |\phi'|^{k - 2n} \|_{L^\infty(J)}, \]
    %
    where the implicit constant is uniformly bounded over a family of phases $\phi$ which are bounded in $C^{n+1}(J)$.
\end{theorem}
\begin{proof}
  When $n = 0$, the result is trivial. The remaining cases we shall prove by induction. A single integration by parts gives
  %
  \begin{align*} I(\lambda) &= \frac{1}{\lambda} \int \frac{a(x)}{2 \pi i \phi'(x)} \frac{d}{dx} \left( e^{2 \pi i \lambda \phi(x)} \right)\\
  &= - \frac{1}{2 \pi i \lambda} \int \frac{d}{dx} \left( \frac{a(x)}{\phi'(x)} \right) e^{2 \pi i \lambda \phi(x)}\\
  &= \frac{1}{2 \pi i \lambda} \int \frac{\phi'(x) a'(x) - a(x) \phi''(x)}{\phi'(x)^2} e^{2 \pi i \lambda \phi(x)}.
  \end{align*}
  %
  Applying induction, this quantity is bounded up to a universal constant depending solely on the derivatives of $\phi$ up to order $n-1$ by
  %
  \[ \lambda^{-n} \sum_{k = 0}^{n-1} \left\| \left( \frac{\phi' a' - a \phi''}{(\phi')^2} \right)^{(k)} |\phi'|^{k - 2(n-1)} \right\|_{L^\infty(J)} \]
  %
  and applying the product rule, we see this term is bounded, up to a universal constant depending solely on derivatives of $\phi$ up to order $n$, by the required quantity.
\end{proof}

\begin{remark}
    Differentiation under the integration sign shows
    %
    \[ \left( \frac{d}{d\lambda} \right)^n I (\lambda) = (2 \pi i)^n \int \phi(x)^n a(x) e^{2 \pi i \lambda \phi(x)}\; dx. \]
    %
    Since $\phi^n a$ satisfies the same assumptions that $a$ does, it follows that for any $N$, we have
    %
    \[ \left| \left( \frac{d}{d\lambda} \right)^n I (\lambda) \right| \lesssim_{a,\phi,N,n} \lambda^{-N}. \]
    %
    Thus $I$ is actually a Schwartz function on the real line. %and moreover, with the same quantities $\delta$, $A$, $B$, and $V$ as above, and where $A_0$ denotes the maximum of $A$ and the $L^\infty$ norm of $\phi$, we conclude that
    %
    %\[ \left| \left( \frac{d}{d\lambda} \right)^n I (\lambda) \right| \lesssim_{N,n} \delta^{-2N} A^N A_0^n B V \lambda^{-N} \leq \delta^{-2n} A_0^{N+n} B V \lambda^{-N}. \]
\end{remark}

Let us now move onto a `stationary phase', i.e. a phase $\phi$ whose derivative vanishes at a point. The simplest example of such a phase is the integral
%
\[ I(\lambda) = \int_{-\infty}^\infty a(x) e^{2 \pi i \lambda x^2}\; dx, \]
%
where $a \in C_c^\infty(\RR)$. If $a$   is nonzero in a neighborhood of the origin, and if $\phi(x) = x^2$, then
%
\[ |\{ x \in \RR : |\phi(x)| \leq 1/\lambda \}| \} \lesssim \lambda^{-1/2}. \]
%
Thus our heuristics tell us that we should expect $I(\lambda)$ decays on the order of $\lambda^{-1/2}$, which agrees with the asymptotics we now find. A dyadic decomposition about the origin, combined with a single integration by parts at each scale yields a bound $|I(\lambda)| \lesssim \lambda^{-1/2}$
.
\begin{theorem}
  Let $a \in \mathcal{S}(\RR)$. Then
  %
  \[ I(\lambda) \sim e^{i \pi / 4} (2\lambda)^{-1/2} \sum_{n = 0}^\infty \left( i / 8 \pi \right)^n \frac{a^{(2n)}(0)}{n!} \cdot \frac{1}{\lambda^n} \]
  %
  That is, for each pair of nonnegative integers $N$ and $k$
  %
  \begin{align*}
    \left( \frac{d}{d\lambda} \right)^k I(\lambda) &= \left( \frac{d}{d\lambda} \right)^k \left\{ e^{i \pi / 4} \cdot (2\lambda)^{-1/2} \sum_{n = 0}^N \left( i / 8 \pi \right)^n \frac{a^{(2n)}(0)}{n!} \cdot \frac{1}{\lambda^n} \right\}\\
    &\quad\quad + O_{N,m,a}(1/\lambda^{N + m + 3/2}).
  \end{align*}
  %
  In particular, if $a$ equals one near the origin, then $I(\lambda) \sim e^{i \pi / 4} (2 \lambda)^{-1/2}$.
\end{theorem}
%\begin{comment}
%\begin{proof}
%  Rescaling, it suffices to prove the theorem when $\psi(x) = 1$ whenever $|x| < 1$. Let $\alpha(x)$ be a smooth function with $\alpha(x) = 1$ for $|x| \geq 1/2$, and with $\alpha(x) = 0$ for $|x| < 1/4$. Then for each $k \geq 1$, define
  %
%  \[ \beta_k(x) = \alpha(2^k x) - \alpha(2^{k-1} x). \]
  %
%  Then $\beta_k$ is supported on $1/2^{k+2} \leq |x| \leq 1/2^k$, and moreover, for each $x \in \RR$,
  %
%  \[ \alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1. \]
  %
%  It is simple to see that
  %
%  \begin{align*}
%    \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx &= \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx\\
%    &\ \ \ \ + \sum_{k = 1}^\infty \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx.
%  \end{align*}
  %
%  Now $\alpha \psi$ is a compactly supported amplitude supported away from the origin, so for each $N$,
  %
%  \[ \left| \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N} \lambda^{-N}. \]
%  %
%  The same argument works for $\beta_1$, and so by rescaling, for each $k$ and $M$,
%  %
%  \begin{align*}
%    \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| &\lesssim_{\alpha,\psi,M} 2^{(2M-1)k} \lambda^{-M}.
%  \end{align*}
  %
%  In particular, we may sum the inequality for small $k$, and with $M$ an appropriate multiple of $N$, to conclude
  %
%  \[ \sum_{k = 1}^{\lg(\lambda^{1/2-\varepsilon})} \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N,\varepsilon} \lambda^{-N}. \]
  %
%  If we set
  %
%  \[ \gamma(x) = \sum_{k = \lg(\lambda^{1/2-\varepsilon})}^\infty \beta_k(x), \]
  %
%  then $\gamma(x) = 0$ for $|x| \geq 1/\lambda^{3/4}$, and $\gamma(x) = 1$ for $|x| \leq 1/4\lambda^{3/4}$. Rescaling, we have
  %
%  \[ \int_{-\infty}^\infty \gamma(x) e^{\lambda i x^2} = \lambda^{-3/4} \int_{-\infty}^\infty \gamma(x \cdot \lambda^{3/4}) e^{ix^2 / \lambda^{1/2}}. \]
%\end{proof}
%
%
%IDEA: Sum up dyadically on intervals $|x| \sim 2^k \lambda^{-1/2}$, for $k = 1$ to $k = \lfloor \log( \lambda^{1/2} \varepsilon) - 2 \rfloor$, then hopefully the oscillatory integral with phase $x^2$ and amplitude $\psi(x) \sum_{k = \lfloor \lg(\lambda^{1/2} \varepsilon) - 2 \rfloor}^\infty \beta_k(x/\lambda^{1/2})$ decays arbitrarily fast in $\lambda$?
%
%
%Then for each $n$, define $\beta_n(x) = \alpha(x/2^n) - \alpha(x/2^{n-1})$. Thus we have $\alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1$ for all $x \in \RR$. Moreover, $\beta_k$ is supported on $[-2^n, -$
%
%\end{comment}
\begin{proof}
  Applying the multiplication formula for the Fourier transform, noting that the distributional Fourier transform of $e^{2 \pi i \lambda x^2}$ is
  %
  \[ (2 \lambda)^{-1/2} e^{i \pi / 4} e^{- i \pi \xi^2 / 2 \lambda} \]
  %
  Thus
  %
  \[ I(\lambda) = (2 \lambda)^{-1/2} e^{i \pi / 4} \int_{-\infty}^\infty e^{-i \pi \xi^2 / 2 \lambda} \widehat{a}(\xi)\; d\xi. \]
  %
  Now for any $N$, we can write
  %
  \begin{align*}
    e^{-i \pi \xi^2 / 2 \lambda} &= \sum_{n = 0}^N \frac{1}{n!} \left( \frac{- i \pi \xi^2}{2 \lambda} \right)^n + O_N \left( (\xi^2 / \lambda)^{N+1} \right)
  \end{align*}
  %
  Thus substituting in the Taylor series, and then applying the Fourier inversion formula, we find
  %
  \begin{align*}
    I(\lambda) &= (2 \lambda)^{-1/2} e^{i \pi / 4} \sum_{n = 0}^N \frac{1}{n!} \int_{-\infty}^\infty \left( \frac{-i \pi \xi^2}{2 \lambda} \right)^n \widehat{a}(\xi)\; d\xi + O_{a,N} \left( 1/\lambda^{N+3/2} \right)\\
    &= (2 \lambda)^{-1/2} e^{i \pi / 4} \sum_{n = 0}^N (i/8\pi)^n \frac{1}{n!} \frac{1}{\lambda^n} \int_{-\infty}^\infty (2\pi i \xi)^{2n} \widehat{a}(\xi)\; d\xi + O_{a,N} \left( 1 / \lambda^{N+3/2} \right)\\
    &= (2 \lambda)^{-1/2} e^{i \pi / 4} \sum_{n = 0}^N \left( i/8\pi \right)^n \frac{a^{(2n)}(0)}{n!} \frac{1}{\lambda^n} + O_{a,N} \left( 1 / \lambda^{N+3/2} \right). \qedhere
  \end{align*}
  %
  One obtains the asymptotic formula for the derivative of $I$ by noting that
  %
  \[ I^{(k)}(\lambda) = \int (-2 \pi i x^2)^k a(x) e^{-2 \pi i \lambda x^2}\; dx, \]
  %
  which reduces to the case where $k = 0$.
\end{proof}

%\begin{remark}
%  The implicit constant can be made independent of $a$ given uniform upper bounds on
  %
%  \[ \int_{-\infty}^\infty |\widehat{a}(\xi)| |\xi|^{2(N+m+1)}\; d\xi. \]
  %
%  In particular, this can be obtained by uniform bounds on the support of $a$, upper bounds on the magnitude of $a$, and upper bounds on the magnitude of the $(2N+4)$th derivative of $a$.
%\end{remark}

It requires only a simple change of variables to extend this theorem to arbitrary quadratic phases. We say a critical point of a function is \emph{non-degenerate} if the second derivative at that point is nonzero.

\begin{theorem}
  Let $\phi$ be a smooth phase with a single, non-degenerate critical point $x_0$, and let $a$ be a smooth compactly supported amplitude function. Then there exists a sequence of constants $\{ c_n \}$, depending solely on the derivatives of $a$ and $\phi$ at $x_0$, such that
  %
  \[ I(\lambda) \sim e^{2 \pi i \lambda \phi(x_0)} \lambda^{-1/2} \sum_{n = 0}^\infty c_n \lambda^{-n}. \]
  %
  The implicit constants in the asymptotic formula are uniform over a family of amplitude functions $a$ given uniform bounds on the support of $a$, and upper bounds on $2N$ derivatives of $a$. We can explicitly calculate that
  %
  \[ c_0 = \sqrt{ \frac{i}{\phi''(x_0)} } \cdot a(x_0). \]
  %
  More generally, in this case there exists a sequence of linear differential operators $\{ L_n \}$, with $L_n$ order $2n$, with coefficients depending on the derivatives of $\phi$ at $x_0$, such that $c_n = (L_n a)(x_0)$.
\end{theorem}
\begin{proof}
    Translating our integration variables if necessary, we may assume that the critical point $x_0$ lies at the origin. Partitioning the support of $a$, applying the principle of nonstationary phase away from the critical point, we may assume without loss of generality that $a$ is supported on an arbitrarily small neighborhood of the critical point. In particular, we may assume that $\phi(x) \neq 0$ for all nonzero $x$ in the support of $a$. A coordinate change $x \mapsto -x$ means we may assume that $\phi''(0) > 0$. We can then define a function
  %
  \[ y(x) = \text{sgn}(x) \cdot \phi(x)^{1/2}. \]
  %
  It follows from our assumptions that $y$ is a smooth diffeomorphism on the support of $a$. By the change of variables formula, there exists a smooth, compactly supported function $a_0(y)$ such that
  %
  \[ I(\lambda) = \int a(x) e^{2 \pi i \lambda \phi(x)}\; dx = \int a_0(y) e^{2 \pi i \lambda y^2}\; dy. \]
  %
  Thus we can apply the previous theorem to conclude that there exists a sequence of constants $\{ c_n \}$ such that for each $N$,
  %
  \[ \left( \frac{d}{d\lambda} \right)^k I(\lambda) = \left( \frac{d}{d\lambda} \right)^k \left\{ \lambda^{-1/2} \sum_{n = 0}^N c_n \lambda^{-n} \right\} + O_{\phi,a,N,k}(1/\lambda^{N+m+3/2}). \]
  %
  The existence in this theorem is a \emph{constructive} existence statement. The proof gives an effective algorithm to produce as many constants $c_n$ as required for any particular phase $\phi$, provided one can explicitly write out the function $y(x)$. In particular, if the phase has only a single stationary point at the origin,
  %
  \[ c_0 = 2^{-1/2} e^{i\pi/4} a_0(0) = 2^{-1/2} e^{i\pi/4} a(0) / y'(0). \]
  %
  Since
  %
  \begin{align*}
    y'(0) &= \lim_{x \to 0^+} y'(x) = \lim_{x \to 0^+} \frac{\phi'(x)}{2 \phi(x)^{1/2}}\\
    &= \lim_{x \to 0^+} (1/2) \frac{\phi'(x)}{x} \left( \frac{x^2}{\phi(x)} \right)^{1/2} = (\phi''(0)/2)^{1/2}.
  \end{align*}
  %
  This means that $c_0 = e^{i\pi/4} a(0) \phi''(0)^{-1/2}$.
\end{proof}

If the phase $\phi$ has a critical point of order greater than two, than the asymptotics of the oscillatory integral get worse. In particular, if $\phi$ has a zero of order $k$, then around this region $\phi$ differs by $1/\lambda$ on an interval of length $1/\lambda^{1/k}$, so we might expect $I(\lambda)$ to be proportional to $\lambda^{1/k}$. This is precisely what happens, but our proof will not rely on the Fourier transform since the computation of the Fourier transform of $e^{\lambda ix^k}$ is quite difficult to calculate when $k > 2$. The next proof also works for the case $k = 2$, but the proof involves some contour shifting. Since the large majority of the examples we consider will have nondegenerate critical points (this is the generic behaviour of critical points), these complicated asymptotics can be safely skipped on a first reading.

\begin{lemma}
  For any non-negative integers $l$ and $k$, there is a positive constant $A_{kl} > 0$ such that for any $\lambda \in \RR$ and $\varepsilon > 0$,
  %
  \[ \int_0^\infty e^{2 \pi i \lambda x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} (\varepsilon - 2 \pi i \lambda)^{-(l+1)/k}, \]
  %
  where the $k$th root is the principal root for non-negative complex numbers.
\end{lemma}
\begin{proof}
  If $z = (\varepsilon - 2 \pi i \lambda)^{1/k} x$, and if $\alpha_N$ is the ray between the origin and the point $N (\varepsilon - 2 \pi i \lambda)^{1/k}$, then
  %
  \[ \int_0^N e^{2 \pi i \lambda x^k} e^{- \varepsilon x^k} x^l\; dx = (\varepsilon - 2 \pi i \lambda)^{-(l+1)/k} \int_{\alpha_N} e^{-z^k} z^l\; dz. \]
  %
  Let $\theta \in (-\pi/2,0]$ be the argument of $(\varepsilon - 2 \pi i \lambda)^{1/k}$, and set $\beta_N$ to be the arc between $N ( \varepsilon - 2 \pi i \lambda)^{1/k}$ and $N (\varepsilon^2 + \lambda^2)^{1/2}$. Then $\beta_N$ has length $O(N)$, with implicit constant depending on $\lambda$ and $\varepsilon$. Moreover, any point $z$ on $\beta_N$ has modulus $N (\varepsilon^2 + \lambda^2)^{1/2}$ and argument less than or equal to $\theta / k$. But this implies that $\text{Re}(z^k) \geq N^k (\varepsilon^2 + \lambda^2)^{k/2} \cos(\theta)$, and so there exists a constant $c$ depending on $\varepsilon$ and $\lambda$ such that $|e^{-z^k}| \leq e^{c N^k}$. But this means that $|z^l e^{-z^k}| \leq N^l e^{-cN^k}$. Thus taking in absolute values gives that
  %
  \[ \lim_{N \to \infty} \int_{\beta_N} e^{-z^k} z^l\; dz = 0. \]
  %
  In particular, applying Cauchy's theorem, we conclude that
  %
  \[ \lim_{N \to \infty} \int_{\gamma_N} e^{-z^k} z^l\; dz = \int_0^\infty e^{-x^k} x^l\; dx. \]
  %
  If we denote the latter integral by $A_{kl} > 0$, then we have shown that
  %
  \[ \int_0^\infty e^{2 \pi i \lambda x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} \cdot (\varepsilon - 2 \pi i \lambda)^{-(l+1)/k}, \]
  %
  as was required to be shown.
\end{proof}

\begin{remark}
  In particular, this implies that for each $\varepsilon$, there exists constants $A_{kln}$ such that
  %
  \[ \int_0^\infty e^{2 \pi i \lambda x^k} e^{-x^k} x^l\; dx = (2 \pi \lambda)^{-(l+1)/k} \sum_{n = 0}^\infty A_{kln} (2 \pi \lambda)^{-n}. \]
  %
  This is obtained by taking the Laurent series of
  %
  \[ (1 - 2 \pi i \lambda)^{-(l+1)/k} = (2 \pi \lambda)^{-(l+1)/k} (\lambda^{-1} - 2 \pi i)^{-(l+1)/k}, \]
  %
  In particular, for each $N$ and for each $\lambda$, we conclude
  %
  \[ \int_0^\infty e^{2 \pi i \lambda x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^N A_{kln} (2 \pi \lambda)^{-n} + O_N \left(1/\lambda^{n + 1 + 1/k} \right). \]
\end{remark}

\begin{lemma}
  If $\eta$ is compactly supported and smooth, then
  %
  \[ \left| \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x)\; dx \right| \lesssim_{l,k,\eta} \lambda^{-(l + 1)/k}. \]
\end{lemma}
\begin{proof}
  Let $\alpha$ be a bump function supported on $[-2,2]$ with $\alpha(x) = 1$ for $|x| \leq 1$. For each $\varepsilon > 0$, write
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x)\; dx &= \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ \ + \int_{-\infty}^\infty e^{2 \pi \lambda x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx,
  \end{align*}
  %
  where we will bound each term and optimize for a small $\varepsilon$. We trivially have
  %
  \[ \left| \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx \right| \lesssim_\eta \varepsilon^{l+1}, \]
  %
  We apply an integration by parts to the second integral, noting that $e^{2 \pi i \lambda x^k}$ is a fixed point of the differential operator
  %
  \[ Df = \frac{1}{2 \pi i \lambda k x^{k-1}} \frac{df}{dx}. \]
  %
  If we consider the differential operator
  %
  \[ D^*g = \frac{d}{dx} \left( \frac{-f}{2 \pi i \lambda k x^{k-1}} \right) = \left( \frac{i}{2 \pi \lambda k} \right) \left( \frac{f'(x)}{x^{k-1}} - \frac{(k-1) f(x)}{x^k} \right), \]
  %
  then for any smooth $f$ and compactly supported $g$,
  %
  \[ \int_{-\infty}^\infty (Df)(x) g(x) = \int_{-\infty}^\infty f(x) (D^* g)(x). \]
  %
  In particular,
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx &= \int_{-\infty}^\infty D^N(e^{2 \pi i \lambda x^k})\; x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx\\
    &= \int_{-\infty}^\infty e^{2 \pi i \lambda x^k}\; (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}\; dx.
  \end{align*}
  %
  Write $g_N(x) = (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}$. Since $x^l \eta(x) (1 - \alpha(x/\varepsilon))$ vanishes for $|x| \leq \varepsilon$, so too does $g_N(x)$. For $N \geq l/(k-1)$, and $|x| \geq \varepsilon$, we have
  %
  \[ |g_N(x)| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{-N} |x|^{l - N(k-1)}, \]
  %
  where the implicit constant depends on upper bounds for the derivatives of $\eta$ of order to $N$. We can thus take in absolute values after integrating by parts to conclude that if $N > (l+1)/(k-1)$, then
  %
  \[ \left| \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx \right| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{l + 1 - Nk} \]
  %
  Thus we can put the two bounds together to conclude that
  %
  \[ \left| \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\eta} \varepsilon^{l+1} + \lambda^{-N} \varepsilon^{l+1-Nk}. \]
  %
  Picking $\varepsilon = \lambda^{-1/k}$ gives
  %
  \[ \left| \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\psi} \lambda^{-(l+1)/k}. \qedhere \]
  %
  But $N$ was chosen depending only on $k$ and $l$, so the implicit constants depend on the correct variables.
%  \[ D^* \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = c x^{l-k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+1-k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+1-k} \eta(x) \alpha'(x/\varepsilon) \]
%  \[ (D^*)^2 \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = x^{l-2k} (1 - \alpha(x/\varepsilon))
  %  (d/dx) \{ x^{l+1-2k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+2-2k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+2-2k} \eta(x) \alpha'(x/\varepsilon) \} \]
\end{proof}

%\begin{remark}
%  The implicit constants can be bounded uniformly given uniform upper bounds on the magnitude of the derivatives of $\eta$ of order up to
  %
%  \[ \lceil (l+1)/(k-1) \rceil, \]
  %
%  and upper bounds on the measure of the support of $\eta$.
%\end{remark}

We can now prove the asymptotics for the model case $\phi(x) = x^k$.

\begin{theorem}
  Suppose $a$ is a smooth compactly supported amplitude, and $\phi$ is a smooth phase with $\phi'(x) \neq 0$ on the support of $a$ except at some point $x_0$, where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, and $\phi^{(k)}(x_0) \neq 0$. Then there is a sequence $\{ c_n \}$ such that
  %
  \[ I(\lambda) \sim \lambda^{-1/k} \sum_{n = 0}^\infty c_n \lambda^{-n/k}. \]
\end{theorem}
\begin{proof}
  Let us begin with the model case $\phi(x) = x^k$. Let $\tilde{a}$ be a bump function with $\tilde{a}(x) = 1$ for all $x$ with $a(x) > 0$. Then
  %
  \[ I(\lambda) = \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} e^{-x^k} [e^{x^k} a(x)] \tilde{a}(x)\; dx. \]
  %
  For each $N$, perform a Taylor expansion, writing
  %
  \[ e^{x^k} a(x) = \sum_{n = 0}^N c_n x^n + x^{N+1} R_N(x). \]
  %
  Thus if $P_N(x) = \sum_{n = 0}^N c_n x^n$,
  %
  \begin{align*}
    \int_{-\infty}^\infty &e^{2 \pi i \lambda x^k} e^{-x^k} [e^{x^k} a(x)] \tilde{a}(x)\; dx\\
    & = \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} e^{-x^k} P_N(x)\; dx\\
    & + \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} e^{-x^k} P_N(x) (\tilde{a}(x) - 1)\; dx\\
    & + \int_{-\infty}^\infty e^{2 \pi i \lambda x^k} e^{-x^k} x^{N+1} R_N(x) \tilde{a}(x)\; dx.
  \end{align*}
  %
  The first integral can be expanded in the required power series. The second integral, since it is supported away from the origin, is $O_M(\lambda^{-M})$ for any $M > 0$. And in the last lemma we showed the third integral is $O(\lambda^{-(N+2)/k})$, so combining these three terms gives the required result. The general case follows from a change of variables.
\end{proof}

\begin{remark}
  As we saw in the case $k = 2$, if $k$ is even and $n$ is odd then
  %
  \[ \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^n = 0. \]
  %
  Thus we can actually improve the asymptotics to the existence of a sequence $\{ c_n \}$ such that
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N c_n \lambda^{-2n/k} + O_{\phi,a,N} \left( 1 / \lambda^{(2N + 3)/k} \right). \]
\end{remark}

\begin{comment}

Changing variables then proves the result for general $k$'th order phases.

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}
\begin{proof}
  Without loss of generality, we may rescale our integral so that $\phi^{(k)}(x_0) = k!$. Then we can write $\phi(x) = x^k + x^{k+1} R(x)$, where $R(x)$ is a smooth function. A Taylor series approach tells us that
  %
  \[ e^{\lambda i \phi(x)} = e^{\lambda i x^k} \left[ \sum_{n = 0}^M \frac{(\lambda i x^{k+1} R(x))^n}{n!} + Q(x) \right], \]
  %
  where
  %
  \[ Q(x) = \frac{(i\lambda)^{M+1}}{(M+1)!} x^{(k+1)(M+1)} R(x)^{M+1} \int_0^1 e^{\lambda i x^{k+1} R(x) s} (1 - s)^M\; ds \]
  %
  For each $n$, we let
  %
  \[ I_n(\lambda) = \frac{(\lambda i)^n}{n!} \int e^{\lambda i x^k} R(x)^n x^{n(k+1)} \psi(x)\; dx, \]
  %
  and let
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} R(x)^{M+1} e^{\lambda i x^{k+1} R(x) s} (1 - s)^M \psi(x)\; ds\; dx. \]
  %
  Then
  %
  \[ I(\lambda) = I_1(\lambda) + \dots + I_M(\lambda) + \frac{(i\lambda)^{M+1}}{(M+1)!} J(\lambda), \]
  %
  and so it suffices to obtain asymptotics on each term separately. From the previous argument, we know there are are constants $\{ a_{nm} \}$ such that for each $M$,
  %
  \[ I_n(\lambda) = \lambda^{-1/k} \sum_{m = 1}^M a_{nm} \lambda^{n-m/k} + O_{\psi,R,k,n} \left( 1/ \lambda^{(M+2)/k} \right). \]
  %
  Moreover, we can write
  %
  \[ I_n(\lambda) = \int e^{\lambda i x^k} x^{n(k+1)} \psi_n(x)\; dx, \]
  %
  where $\psi_n(x) = R(x)^n \psi(x)$ is smooth. But then we know
  %
  \[ |I_n(\lambda)| \lesssim_{n,k,\psi,R} 1/\lambda^{n + (n+1)/k}. \]
  %
  In particular, this means that $a_{nm} = 0$ for $m \leq (2k+1)n$. Thus we conclude $I_n(\lambda)$ can be expanded in positive powers of $\lambda^{1/k}$, up to an error $O(1/\lambda^{(M+2)/k})$. If we split the integrand for $J(\lambda)$ using a bump function into values $x$ with $|x| \leq \varepsilon$ and values $|x| \geq \varepsilon$, bound the former by bringing in absolute values, bound the latter using integration by parts, and then optimizing over $\varepsilon$ yields

  To complete the argument, we show that for sufficiently large $M$, we can treat $J$ as an error term. If we define
  %
  \[ \psi_M(x,s) = \psi(x) (1 - s)^M R(x)^{M+1}, \]
  %
  then
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s)\; dx\; ds. \]
  %
  We introduce a bump function $\alpha$ such that $\alpha(x) = 1$ for $|x| \leq 1$, and vanishes outside for $|x| \geq 2$. For $\varepsilon > 0$, we write
  %
  \begin{align*}
    J(\lambda) &= \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ + \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) (1 - \alpha(x/\varepsilon))\; dx.
  \end{align*}
  %
  The first integral is $O_{\psi,R,M}(\varepsilon^{(k+1)(M+1)+1})$. For the second, we employ an integration by parts in $x$. The value $e^{\lambda i x^k}$ is a fixed point of the differential operator $Df = f' / \lambda i x^{k-1}$, whose adjoint is
  %
  \[ D^* g = \frac{d}{dx} \left( \frac{g}{\lambda i x^{k-1}} \right). \]
  %
  For each $L$, there exists constants $c_n$ such that
  %
  \[ (D^*)^L g = \frac{1}{\lambda^L} \sum_{n = 0}^L \frac{c_n g^{(n)}}{x^{Lk - n}}. \]
  %
  If we write
  %
  \[ g_n(\lambda,x,s) = \frac{1}{x^{Lk-n}} \frac{d^n}{dx^n} \left\{ x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi(x,s) (1 - \alpha(x/\varepsilon)) \right\}, \]
  %
  then our oscillatory integral is bounded by an implicit constant depending on $L$ and $k$, and
  %
  \[ \sum_{n = 0}^L \frac{1}{\lambda^L} \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} g_n(x)\; dx. \]
  %
  Now $g_n$ has compact support depending on $\psi$, and vanishes for $|x| \leq \varepsilon$. For $|x| \geq \varepsilon$, we find that
  % \lambda \lesssim_{k,\phi} 1/\varepsilon
  \[ |g_n(\lambda,x,s)| \lesssim_{L,M,k,\alpha,\psi,n} \sum_{m = 0}^n \lambda^m \varepsilon^{m-n} x^{n-Lk+(k+1)(M+1) + km}. \]
  %
  Thus we conclude that for sufficiently large $L$
  %
  \[ |J(\lambda)| \lesssim_{\psi,R,M,L,k,\alpha} \varepsilon^{(k+1)(M+1) + 1} \left( 1 + \varepsilon^{- Lk} \sum_{m = 0}^L \lambda^{m-L} \varepsilon^{(k+1)m} \right). \]
  %
  TODO.
\end{proof}

\end{comment}

Let us now consider some examples of the method of stationary phase in one dimension.

\begin{example}
  The Bessel function of order $m$, denoted $J_m(r)$, is defined to be the oscillatory integral
  %
  \[ J_m(r) = \int_0^1 e^{2 \pi i r \sin(2 \pi \theta)} e^{-2 \pi i m \theta} d\theta. \]
  %
  We want to use the method of stationary phase to determine the decay of $J_m(r)$ as $r \to \infty$. The amplitude is $a(\theta) = e^{-2 \pi im \theta}$, and the phase is $\phi(\theta) = \sin(2 \pi \theta)$. We note that the phase $\phi(\theta) = \sin(2 \pi \theta)$ is stationary when $\theta = 1/4$ and $\theta = 3/4$, and that these stationary points are nondegenerate. Thus we might expect $|J_m(r)| = O_m(r^{-1/2})$. More precisely, we write $a = a_1 + a_2 + a_3$, where $a_1$ is supported in a small neighbourhood of $1/4$, $a_2$ in a neighbourhood of $3/4$, and $a_3$ is supported away from $1/4$ and $3/4$. Then $I_{a_1}(\lambda)$ and $I_{a_2}(\lambda)$ are oscillatory integrals with a unique nondegenerate stationary point. In fact, we find that
  % -4\pi^2 sin(2 \pi \theta)
  % At 1/4 : -4 pi^2
  % At 3/4 : 4 pi^2
  \[ I_{a_1}(r) = (1/2\pi) e^{2 \pi i(r - 1/8 - m/4)} + O(r^{-3/2}). \]
  \[ I_{a_2}(r) = (1/2\pi) e^{-2 \pi i(r - 1/8 - m/4)} + O(r^{-3/2}). \]
  %
  The integral $I_{a_3}(\lambda)$ can be shifted (using periodicity) into a compactly supported integral with smooth amplitude and no stationary points, and thus decays arbitrarily fast, i.e. $|I_{a_3}(\lambda)| = O(\lambda^{-3/2})$. Thus summing up these estimates gives
  %
  \begin{align*}
    I_a(r) &= (1/\pi) \cos(2 \pi r - \pi/4 - \pi m/2) + O(r^{-3/2}).
  \end{align*}
\end{example}

\begin{example}
  Consider the Airy function
  %
  \[ \text{Ai}(x) = \int_{-\infty}^\infty e^{2 \pi i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  which arises as a solution to the differential equation $y'' = xy$. Again, this integral is not defined absolutely. Nonetheless, for large $N$, an application of the Van der Corput lemma implies that for any finite interval $I$ containing only points $x$ with $|x| \geq N$,
  %
  \[ \int_I e^{2 \pi i(x \xi + \xi^3/3)}\; d\xi = O(1/N), \]
  %
  where the implicit constant is independant of $I$. Thus we can interpret the integral as
  %
  \[ \lim_{n \to \infty} \int_{a_n}^{b_n} e^{2 \pi i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  where $\{ a_n \}$ and $\{ b_n \}$ are any sequences with $a_n \to -\infty$, $b_n \to \infty$.

  Now consider the phase $\phi(\xi) = x \xi + \xi^3/3$. Then $\phi'(\xi) = x + \xi^2$. When $x$ is negative, there are two stationary points. Thus we can rescale the integral, writing $\nu = x^{-1/2} \xi$, so that for $x > 0$,
  %
  \[ \text{Ai}(-x) = x^{1/2} \int_{-\infty}^\infty e^{2 \pi i x^{3/2}(\nu^3/3 - \nu)}\; d\nu. \]
  %
  If we write $\phi_0(\nu) = \nu^3/3 - \nu$, then $\phi_0$ has two stationary points, at $\nu = \pm 1$. These stationary points are non-degenerate, so if we write $1 = a_1 + a_2 + a_3 + a_4$, where $a_1$ equal to one in a neighbourhood of $1$, $a_2$ equal to one in a neighbourhood of $-1$, and $a_3$ is supported in the region between $-1$ and $1$, and $a_4$ vanishes in all such regions, then we decompose $\text{Ai}(-x)$ as $I_1 + I_2 + I_3 + I_4$. Now the principle of stationary phase tells us that
  %
  \[ I_1 = (1/\sqrt{2}) e^{2 \pi i (-2/3 x^{3/2} + 1/8)} x^{-1/4} + O(x^{-7/4}) \]
  %
  \[ I_2 = (1/\sqrt{2}) e^{2 \pi i (2/3 x^{3/2} - 1/8)} x^{-1/4} + O(x^{-7/4}) \]
  %
  Moreover, $I_3 = O_N(x^{-N})$ for all $N \geq 0$. It remains to show $I_4 = O(x^{-1})$. Indeed, an integration by parts shows that
  %
  \begin{align*}
    I_4 &= x^{1/2} \int_{-\infty}^\infty e^{2 \pi i x^{3/2} \phi_0(\nu)} a_4(\nu)\; d\nu\\
    &= \frac{-1}{2 \pi i x} \int_{-\infty}^\infty e^{2 \pi i x^{3/2} \phi_0(\nu)} \frac{d}{d\nu} \left( \frac{a_4(\nu)}{\nu^2 - 1} \right)\; d\nu.
  \end{align*}
  %
  Taking in absolute values shows $|I_4| \lesssim 1/x$. Thus as $x \to \infty$,
  %
  \[ \text{Ai}(-x) = \sqrt{2} x^{-1/4} \cos((-4 \pi/3) x^{3/2} + \pi/4) + O(1/x), \]
  %
  which gives the first order asymptotics of the integral.

  On the other hand, let us consider large positive $x$. Then the phase $\phi$ has no critical points, and we therefore expect very fast decay. To achieve this decay, we employ a contour shift, replacing the oscillatory integral with a different oscillatory integral which \emph{has} a stationary point, so we can obtain asymptotics here. If we write $\phi(z) = xz + z^3/3$, then $\phi'(z) = 0$ when $z = \pm i x^{1/2}$. A simple contour shift argument to the line $\RR + i x^{1/2}$ gives
  %
  \begin{align*}
    \text{Ai}(x) &= \int_{-\infty}^\infty e^{2 \pi i \phi(\xi + ix^{1/2})}\; d\xi = e^{- (4\pi/3) x^{3/2}} \int_{-\infty}^\infty e^{- 2 \pi \xi^2 x^{1/2}} e^{2 \pi i \xi^3 / 3} \; d\xi.
  \end{align*}
  % (2/3) i x^{3/2} + xi^3/3 + i xi^2 x^{1/2}
  % x(xi + ix^{1/2}) + (\xi + ix^{1/2})^3/3
  %
  We have
  %
  \[ \int_{-\infty}^\infty e^{- 2 \pi \xi^2 x^{1/2}} e^{2 \pi i \xi^3/3}\; d\xi \approx x^{-1/4} \int_{-\infty}^\infty e^{- 2 \pi \xi^2} e^{2 \pi i x^{-3/4} \xi^3/3}\; d\xi. \]
  %
  Now a Taylor series shows
  %
  \[ e^{2 \pi i x^{-3/4} \xi^3/3} = 1 + O(x^{-3/4} \xi^3/3), \]
  %
  so, plugging in, we conclude
  %
  \[ \text{Ai}(x) = 2^{-1/2} x^{-1/4} e^{-(4 \pi /3) x^{3/2}} + O(x^{-3/4} e^{-(2/3) x^{3/2}}). \]
  %
  Thus Airy's function decreases exponentially as $x \to \infty$.
\end{example}

\begin{example}
  Let us consider the integral quantities
  %
  \[ \int_0^1 e^{2 \pi i x \xi} e^{2 \pi i/x} x^{-\gamma}\; dx \]
  %
  where to avoid technicalities we assume $0 \leq \gamma < 2$. These integral quantities are not defined absolutely, so we actually interpret this integral as
  %
  \[ \lim_{\varepsilon \to 0} \int_0^1 e^{2 \pi i x \xi} e^{2 \pi i/x} x^{-\gamma}\; dx \]
  %
  If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{2 \pi i x \xi} e^{2 \pi i/x} x^{-\gamma}\; dx = \int_0^1 e^{2 \pi i \phi(x)} x^{-\gamma}\; dx. \]
  %
  For $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$, since $\phi'(x) = \xi - 1/x^2$, an easy integration by parts shows that for $\varepsilon \leq \xi^{-1/2}/2$,
  %
  \begin{equation} \label{riemannsingularityibp}
  \begin{aligned}
    \int_{\varepsilon_1}^{\varepsilon_2} e^{2 \pi i\phi(x)} x^{-\gamma}\; dx &= \frac{1}{2 \pi i \xi} \int_{\varepsilon_1}^{\varepsilon_2} \frac{d}{dx} \left( e^{2 \pi i \phi(x)} \right) \frac{x^{2-\gamma}}{x^2 - 1/\xi}\; dx\\
    &= \frac{-1}{2 \pi i \xi} \int_{\varepsilon_1}^{\varepsilon_2} e^{2 \pi i \phi(x)} \frac{d}{dx} \left( \frac{x^{2-\gamma}}{x^2 - 1/\xi} \right) + O(\varepsilon^{2-\gamma})\\
    &= O(\varepsilon^{2-\gamma}),
  \end{aligned}
  \end{equation}
  %
  where the constant is independent of $\xi$. This implies the limit we study exists. We wish to prove an asymptotic formula for this integral as $\xi \to \infty$. If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{2 \pi i x \xi} e^{2 \pi i/x} x^{-\gamma}\; dx = \int_0^1 e^{2 \pi i \phi(x)} x^{-\gamma}. \]
  %
  Since $\phi$ has a nondegenerate stationary point when $x = \xi^{-1/2}$, our heuristics might suggest that if the phase and amplitude were smooth at the origin, then
  % phi'' = -2/x^3
  % phi' = xi - 1/x^2
  \[
    \int_0^1 e^{2 \pi i\phi(x)} x^{-\gamma} \approx (1/2)^{1/2} e^{4 \pi i \xi^{1/2}} e^{-i\pi/4} \xi^{\gamma/2-3/4}.
  \]
%    \left( \frac{1}{-i \phi''(\xi^{-1/2})} \right)^{1/2} e^{2 \pi i\phi(\xi^{-1/2})} \xi^{\gamma/2}\\
 %   &= \pi^{1/2} e^{i(2 \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4}.
 % \end{align*}
  %
  We shall show that these heuristics continue to hold, up to an error of $O(\xi^{\gamma/2 - 1})$.

  In an attempt to isolate the critical point, we split the interval $[0,1]$ into three parts, $[0,0.5 \xi^{-1/2}]$, $[0.5 \xi^{-1/2},1.5 \xi^{-1/2}]$, and $[1.5 \xi^{-1/2},1]$, obtaining three integrals $I_1$, $I_2$, and $I_3$. The calculation \eqref{riemannsingularityibp} shows that $|I_1| \lesssim \xi^{\gamma/2 - 1}$, and thus is neglible to our asymptotic formula. To obtain a bound on $I_3$, we use the Van der Corput lemma, noting that $\phi'(x) = \xi - 1/x^2$ is monotone, and $|\phi'(x)| \gtrsim \xi$ for $x \geq 1.5 \xi^{-1/2}$. Thus we find $|I_1| \lesssim \xi^{-1}$, and thus is also neglible to our formula. Thus we are left with the trick part of calculating $I_2$ accurately. It will be easiest to do this by renormalizing the integral, i.e. writing $y = \xi^{1/2} x$, and calculating
  %
  \[ I_2 = \int_{0.5 \xi^{-1/2}}^{1.5 \xi^{-1/2}} e^{2 \pi i \phi(x)} x^{-\gamma}\; dx = \xi^{\gamma/2 - 1/2} \int_{0.5}^{1.5} e^{2 \pi i \xi^{1/2}(y + 1/y)} y^{-\gamma}\; dy. \]
  %
  We consider a smooth amplitude function $\psi(x)$ supported on the interior of $[0.5,1.5]$. Then since $y + 1/y$ is stationary at $y = 1$, but non-degenerate, we can write
  %
  \[ \int e^{2 \pi i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = \xi^{-1/4} \pi^{1/2} e^{2 \pi i(2\xi^{1/2} + 1/4)} + O(\xi^{-1/2}), \]
  %
  from which we obtain our main term. On the other hand, we can apply the Van der Corput lemma to show that
  %
  \[ \int_{0.5}^{1.5} e^{2 \pi i \xi^{1/2}(y + 1/y)} y^{-\gamma} (1 - \psi(y))\; dy = \int e^{2 \pi i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = O(\xi^{-1/2}). \]
  %
  Combining all these estimates gives the theorem.

  On the other hand, consider the integral
  %
  \[ I(\xi) = \int_0^1 e^{-2 \pi i \xi x} e^{2 \pi i/x} x^{-\gamma}\; dx = \int_0^1 e^{2 \pi i \phi(x)} x^{-\gamma}, \]
  %
  where $\phi(x) = 1/x - \xi x$ is the phase. Then the phase has no critical points so we can assume that we can large decay for large $\xi$. We decompose the integral onto the intervals $[0,\xi^{-1/2}]$ and $[\xi^{-1/2},1]$, inducing the two quantities $I_1$ and $I_2$. Now applying the Van der Corput lemma to $I_2$ with $|\phi'(x)| = |1/x^2 + \xi| \geq \xi$ for $x \geq 0$, gives $|I_2| \lesssim \xi^{\gamma/2 - 1}$. On the other hand, renormalizing with $y = \xi^{1/2} x$, we have
  %
  \[ I_1 = \xi^{\gamma/2 - 1/2} \int_0^1 e^{2 \pi i \xi^{1/2} (1/y - y)} y^{-\gamma}\; dy. \]
  %
  For each $n$, we note that for the phase $\phi_0(x) = 1/y - y$, for $1/2^{n+1} \leq y \leq 1/2^n$, we have $|\phi_0'(x)| \gtrsim 4^n$. Thus we can apply the Van der Corput lemma to conclude
  %
  \[ \left| \int_{1/2^{n+1}}^{1/2^n} e^{2 \pi i \phi_0(x)} y^{-\gamma}\; dy \right| \lesssim \frac{2^{\gamma n}}{4^n \xi^{1/2}}. \]
  %
  Summing up over all $n \geq 0$, we conclude $|I_1| \lesssim \xi^{\gamma/2 - 1}$. Thus $|I(\xi)| \lesssim \xi^{\gamma/2 - 1}$.

  One way to interpret this asymptotic formula is through a \emph{Riemann singularity}, i.e. a tempered distribution $\Lambda$ supported on the half-life $x \geq 0$, that agrees with the oscillatory function $e^{2 \pi i/x} x^{-\gamma}$ for small $x$, but is compactly supported and smooth away from the origin. We consider the case $0 \leq \gamma < 2$ for simplicity. Thus for Schwartz $f \in \mathcal{S}(\RR)$, we have
  %
  \[ \Lambda(f) = \lim_{\varepsilon \to 0^+} \int_\varepsilon^\infty f(x) e^{2 \pi i/x} x^{-\gamma} \psi(x)\; dx, \]
  %
  where $\psi$ is smooth and compactly supported, and equals one in a neighbourhood of the origin. An easy integration by parts shows that for a fixed Schwartz $f$, and for $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$,
  %
  \[ \left| \int_{\varepsilon_1}^{\varepsilon_2} f(x) e^{2 \pi i/x} x^{-\gamma}\; dx \right| = O\left(\varepsilon^{2-\gamma} \right), \]
  %
  where the implicit constants depend on upper bounds for $f$ and $f'$ in a neighbourhood of the origin. Thus we find $\Lambda(f)$ is well defined, and moreover, $\Lambda$ is a distribution of order one. Since $\Lambda$ is compactly supported, the Paley-Weiner theorem implies that $\widehat{\Lambda}$ is a distribution represented by a locally integrable function, and
  %
  \[ \widehat{\Lambda}(\xi) = \int_0^\infty e^{2 \pi i/x} x^{-\gamma} e^{-2 \pi \xi i x}\; dx. \]
  %
  The calculations above give asymptotic formulas for this Fourier transform. In particular, we see that the Fourier transform of $\Lambda$ decays much faster to the right than to the left.
\end{example}

\section{Stationary Phase in Multiple Variables}

When we move from a single variable oscillatory integral to a multivariable oscillatory integrals. Thus we consider the oscillatory integral
%
\[ I(\lambda) = \int_{\RR^d} a(x) e^{2 \pi i \lambda \phi(x)}\; dx. \]
%
for large $\lambda$. The method of stationary phase becomes significantly more complicated in this setting because the stationary points of the phase function are no longer necessarily isolated. In certain basic situations, such as when the stationary points are isolated and satisfy a nondegeneracy condition, we can obtain asymptotic formulae.

\begin{theorem}
    Fix a compact set $K$ and a positive integer $n > 0$, and consider an amplitude $a \in C^n(\RR^d)$ with $\text{supp}(a) \subset K$, and a real-valued phase $\phi \in C^{n+1}(\RR^d)$, with $\nabla \phi(x) \neq 0$ on $K$. Then
    %
    \[ |I(\lambda)| \lesssim_{n,K,\phi} \sum_{|\alpha| \leq n} \| (D^\alpha a) |\nabla f|^{|\alpha| - 2n} \|_{L^\infty(\RR^d)}. \]
    %
    where the implicit constant can be made independant of $\phi$ for a family of phases if the partial derivatives of $\phi$ up to order $n+1$ are uniformly bounded in a neighborhood of $K$.
\end{theorem}

\begin{proof}
    Set $v = (\nabla \phi)/|\nabla \phi|^2$. Note that the phase $\phi$ is an eigenfunction of the differential operator $D$ defined such that
    %
    \[ Df(x) = \frac{v \cdot \nabla f}{2 \pi i \lambda}. \]
    %
    The adjoint operator of $D$ is the operator $D^*$ defined by setting
    %
    \[ D^*f(x) = \frac{\nabla \cdot (vf)}{-2 \pi i\lambda}, \]
    %
    i.e. for any smooth $f$ and $g$, with one of these functions compactly supported,
    %
    \[ \int Df(x) g(x)\; dx = \int f(x) (D^*g)(x)\; dx. \]
    %
    Thus
    %
    \[ I(\lambda) = \int D^n(e^{2 \pi i \lambda \phi(x)}) a(x)\; dx = \int e^{2 \pi i \lambda \phi(x)} ((D^*)^n a)(x)\; dx. \]
    %
    Taking absolute values in the last integral gives that
    %
    \[ |I(\lambda)| \leq \int |(D^*)^n a(x)|\; dx \lesssim_{\phi,a,n} \frac{1}{\lambda^n}, \]
    %
    and a more careful analysis of this gives the more precise estimates in the lemma.
\end{proof}

A tensorization argument establishes stationary phase asymptotics for a quadratic phase.

\begin{theorem}
  Let $A$ be an invertible $d \times d$ matrix, fix $x_0 \in \RR^d$, and consider the phase $\phi(x) = A(x - x_0) \cdot (x - x_0)$. Then for any compactly supported smooth amplitude $a$, there exists constants $\{ c_n \}$ depending only on the derivatives of $a$ at the origin, such that
  %
  \[ I(\lambda) \sim \lambda^{-d/2} \sum_{n = 0}^\infty c_n \lambda^{-n}. \]
  %
  Moreover,
  %
  \[ c_0 = a(x_0) \prod_{k = 1}^d (i/\mu_k)^{1/2}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of $A$.
\end{theorem}
\begin{proof}
  Suppose first that $a$ is a tensor product of $d$ compactly supported functions in $\RR$. The constant $c_0$ is invariant under affine changes of coordinates. Thus we may assume that $A$ is a diagonal matrix. But then the oscillatory integral splits into the product of single variable integrals, to which we can apply our one-dimensional asymptotics. A density argument then shows the argument generalizes to any smooth $a$.
\end{proof}

Morse's theorem says that if $x_0$ is a non-degenerate critical point of a smooth function $\phi$, then there exists a coordinate system around $x_0$ and $a_1, \dots, a_d \in \{ \pm 1 \}$ such that, in this coordinate system,
%
\[ \phi(x_0 + t) = a_1 t_1^2 + \dots + a_d t_d^2. \]
%
In one dimension, the same is true if $x_0$ has a higher order critical point, but this does not generalize to higher dimensions, which reflects the lack of as nice a theory in this case. But in the case of functions with finitely many non-degenerate critical points, we can obtain nice asymptotics. Applying Morse's theorem gives the following theorem.

\begin{theorem}
  Let $\phi$ and $a$ be smooth functions, with $a$ compactly supported. Suppose $\phi$ has a single critical point $x_0$ on the support of $a$, which is nondegenerate. Then there exists constants $\{ c_n \}$ depending only on finitely many derivatives of $\Phi$ and $\psi$ at $x_0$, such that
  %
  \[ I(\lambda) \sim e^{2 \pi i \lambda \phi(x_0)} \lambda^{-d/2} \sum_{n = 0}^\infty c_n \lambda^{-n}. \]
  %
  Moreover,
  %
  \[ c_0 = a(x_0) \cdot \prod_{k = 1}^d (i/\mu_k)^{1/2}, \]
  %
  where $\mu_1,\dots,\mu_d$ are the Eigenvalues of the Hessian of $\phi$ at $x_0$.
\end{theorem}

\section{Variable Coefficient Results}

We can also obtain results given amplitude functions that depend on $\lambda$, and also vary in a third variable, under suitable conditions. Consider a \emph{symbol} $a(x,y,\lambda)$, i.e. a smooth function such that $\text{supp}_y(a)$ is compact, and
%
\[ \left| \nabla_x^n \nabla_y^m \nabla_\lambda^k a(x,y,\lambda) \right| \lesssim_{n,m,k} \lambda^{\alpha + \delta k}, \]
%
for some $\alpha \in \RR$ and $\delta > 0$, where the implicit constant is \emph{locally uniform} in $x$. We can then consider the oscillatory integrals
%
\[ I(x,\lambda) = \int a(x,y,\lambda) e^{2 \pi i \lambda \phi(x,y)}\; dy. \]
%
Provided that $\delta < 1$, and $\nabla_y \phi \neq 0$ on the support of $a$, integration by parts gives that for any $n$ and $N$,
%
\[ \nabla_x^n \nabla_\lambda^m I (x,\lambda) \lesssim_{N,n,m} \lambda^{-N}, \]
%
where the implicit constant is locally uniform in $x$.

On the other hand, suppose that we have a nondegenerate critical point, i.e. there exists $(x_0,y_0)$ with $\nabla_y \phi(x_0,y_0) = 0$, but with $H_y \phi(x_0,y_0)$ invertible. Then by the implicit function theorem, there exists a unique solution $(x,y(x))$ to $\nabla_y \phi(x,y)$ in a small neighborhood of $y_0$, for $x$ in a small neighborhood of $x_0$. Intuitively, if $a$ is supported on the small neighborhood of $x_0$ and $y_0$, we should have
%
\begin{align*}
    I(x,\lambda) &= \int a(x,y,\lambda) e^{2 \pi i \lambda \phi(x,y)}\; dy\\
    &\approx \lambda^{-d/2} e^{2 \pi i \lambda \phi(x,y(x))} a(x,y(x),\lambda) \prod_{k = 1}^d (i/\mu_k)^{1/2},
\end{align*}
%
where $\mu_1, \dots, \mu_d$ are the eigenvalues of $H_y \phi(x,y(x))$. Ignoring the $e^{2 \pi i \lambda \phi(x,y(x))}$ factor (which introduces powers of $\lambda$), differentiating by $x$ should introduce negligible effects on the value of the oscillatory integral. In fact, it is not difficult to prove that if
%
\[ \left| \nabla_x^n \nabla_y^m \nabla_\lambda^k a(x,y,\lambda) \right| \lesssim_{n,m,k} \lambda^{-k}, \]
%
then, under the support assumptions on $a$,
%
\[ \nabla_x^n \nabla_\lambda^m \left\{ e^{- 2 \pi i \lambda \phi(x,y(x))} I (x,\lambda) \right\}  \lesssim_{N,n,m} \lambda^{-1/2 - m}. \]
%
The result is a simple calculation, left as an exercise. A discussion can be found in Sogge's book `Fourier Integrals in Classical Analysis'. On the other hand, if we have bounds of the form
%
\[ \left| \nabla_x^n \nabla_y^m \nabla_\lambda^k a(x,y,\lambda) \right| \lesssim_{n,m,k} \lambda^{\alpha + \delta k}, \]
%
for $\delta < 1/2$, then we can still obtain an asymptotic expansion of the form
%
\[ I(x,\lambda) \sim e^{2 \pi i \lambda \phi(x,y(x))} \lambda^{-d/2} \sum_{n = 0}^\infty c_n(x,\lambda) \lambda^{-n}, \]
%
locally uniform in $x$, where the coefficients $c_n$ are symbols of order TODO, equal to a linear differential operator applied to $a$ at $(x,y(x),\lambda)$, with coefficients depending solely on the behaviour of the Hessian matrix of $\phi$ in $y$, at $(x,y(x))$. In particular,
%
\[ c_0 = a(x,y(x),\lambda) \prod_{k = 1}^d (i/\mu_k(x))^{1/2}, \]
%
where $\mu_1(x),\dots,\mu_d(x)$ are the eigenvalues of the Hessian of $\phi$ at $(x,y(x))$. Duistermaat's book on Fourier Integral Operators includes an explicit description of these differential operators.






\section{Surface Carried Measures}

Let us consider oscillatory integrals on a `curved' version of Euclidean space. One most basic example is the Fourier transform of the surface measure of the sphere, i.e.
%
\[ \widehat{\sigma}(\xi) = \int_{S^{d-1}} e^{-2 \pi i \xi x} d\sigma(x). \]
%
Studying the decay of this surface measure is of much interest to many problems in analysis. One can reduce the study of this Fourier transform to the study of Bessel functions, to which we have already developed an asymptotic theory.

\begin{theorem}
  If $\sigma$ is the surface measure on the sphere $S^{d-1}$, then
  %
  \[ \widehat{\sigma}(\xi) = \frac{2\pi \cdot J_{d/2 - 1}(2 \pi |\xi|)}{|\xi|^{d/2 - 1}}. \]
  %
  In particular,
  %
  \[ \widehat{\sigma}(\xi) = \frac{2 \cos(2\pi |\xi| - (d/2 - 1)(\pi/2) - \pi/4)}{|\xi|^{(d-1)/2}} + O_d(1/|\xi|^{(d+1)/2}). \]
\end{theorem}
\begin{proof}
  Since $\sigma$ is rotationally symmetric, so too is $\widehat{\sigma}$. In particular, we can apply Fubini's theorem to conclude that if $V_{d-2}$ is the surface area of the unit sphere in $\RR^{d-2}$, then
  %
  \begin{align*}
    \widehat{\sigma}(\xi) &= \int_{S^{d-1}} e^{-2 \pi |\xi| x_1} d\sigma(x)\\
    &= V_{d-2} \int_{-1}^1 e^{-2 \pi |\xi| t} (1 - t^2)^{d/2-1} dt.
  \end{align*}
  %
  Setting $r = 2 \pi |\xi|$ completes the argument.
\end{proof}

Since the multivariate stationary phase approach is essentially `coordinate independant', we can also generalize the approach to manifolds. If $M$ is a $d$ dimensional Riemmannian manifold, and $\phi$ and $a$ are complex-valued functions on the manifold, we can consider the oscillatory integral
%
\[ I(\lambda) = \int_M a(x) e^{2 \pi i \lambda \phi(x)} d\sigma(x), \]
%
where $\sigma$ is the surface measure induced by the metric on $M$. If $\phi$ and $a$ are compactly supported, then this integral is well defined in the Lebesgue sense.

\begin{theorem}
  Suppose that $a$ is a compactly supported smooth amplitude on a Riemannian manifold $M$, $\phi$ is a smooth phase, and $\nabla \phi$ vanishes at a single critical point $x_0$ on the support of $\psi$, upon each of which the Hessian $H\phi$ is non-degenerate at each point. Then there exists constants $\{ c_n \}$ such that
  %
  \[ I(\lambda) \sim e^{2 \pi i \lambda \phi(x_0)} \lambda^{-d/2} \sum_{n = 0}^\infty c_n \lambda^{-n} + O(1/\lambda^{N + d/2 + 1}). \]
  %
  Moreover,
  %
  \[ c_0 = a(x_0) \prod_{k = 1}^d (i/\mu_k)^{1/2}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of the Hessian $H\phi$ at $x_0$.
\end{theorem}



The theorem is proved by a simple partition of unity approach which reduces to the Euclidean case. It has the following important corollary.

\begin{theorem}
  If a $d$ dimensional surface $\Sigma$ is a smooth submanifold of $\RR^{d+1}$, and has non-vanishing Gauss curvature, and if $a$ is a smooth, compactly supported function on $\Sigma$, then
    %
    \[ |\widehat{a \sigma}(\xi)| \lesssim_{a,\sigma} \frac{1}{|\xi|^{d/2}}, \]
    %
    where $\sigma$ is the surface measure of $\Sigma$.
\end{theorem}
\begin{proof}
  For each $\xi \in S^d$,
  %
  \[ \widehat{a \sigma}(\xi) = \int_M a(x) e^{- 2 \pi i \xi \cdot x}\; d\sigma(x) \]
  %
  If $\lambda = |\xi|$, for $|\xi| = 1$, we can write
  %
  \[ \widehat{a \sigma}(\lambda \xi) = \int_M a(x) e^{2 \pi i \lambda \phi(\xi,x)}\; d\sigma(x), \]
  %
  where $\phi(\xi,x) = - \xi \cdot x$. Then the gradient of $\phi$ on the
  surface $M$ vanishes at a point $(\xi,x)$ precisely when $\xi$ is normal to
  $\Sigma$. There are precisely two different smooth unit normal vector
  fields $n_1,n_2$ defined in a neighborhood of any given point $x_0$.


  We can find two smooth vector fields $n_1$ and $n_2$

  \[ I_\xi(\lambda) = \int_M a(x) e^{2 \pi i \lambda \phi(\xi,x)}\; d\sigma, \]
  %
  where $\phi(\xi,x) = -2 \pi i \xi \cdot x$. The derivatives of $\phi_\xi$ of order $\leq N$ on $M$ are $O_N(1)$, independently of $\xi$. Similarily, $H_M \phi_\xi$ is uniformly non-degenerate, in the sense that the operator norm of $(H_M \phi_\xi)^{-1}(x)$ is $O(1)$, independently of $\xi$. Working with $\Sigma$ as a local graph, and then applying the curvature condition on $\Sigma$ implies that for each $\xi \in S^d$, $\phi_\xi$ has $O(1)$ stationary points on the support of $\psi$. There also exists a constant $r$ such that if $x$ does not lie in any ball of radius $r$ around a stationary point, then $|\nabla_M \phi_\xi| \gtrsim 1$. Moreover, the Hessian $H_M \phi_\xi$ is uniformly non-degenerate in the radius $r$ balls around the critical point, independently of $\xi$. Thus we can apply the last result to conclude
  %
  \[ I_\xi(\lambda) \lesssim \lambda^{-d/2}, \]
  %
  where the implicit constant is independent of $\xi$, because all the required derivatives are uniformly bounded.
\begin{comment}

  Working locally, since the support of $\mu$ is precompact, we may consider a finite partition of unity $\{ \psi_\alpha \}$ with respect to an open family of sets $\{ U_\alpha \}$ covering $U$, such that for each $\alpha$, there exists a transformation $T$ composed of a rotation, translation, and dilation such that if $B$ is the open unit ball, then there is a smooth function $u: B \to \RR$ with $\nabla u(0) = 0$, such that
  %
  \[ T(U_\alpha) = \left\{ (x,u(x)): x \in B \right\}. \]
  %
  The fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $u$ is non-zero at each point, so in particular we may assume that $\nabla u$ does not equal to zero anywhere else on $B$. The asymptotics of the Fourier transform of $\mu \psi_\alpha$ is the same as the Fourier transform of the measure $T_*(\mu \psi_\alpha)$, so we may assume without loss of generality that $U_\alpha$ takes the form $T(U_\alpha)$. Then
  %
  \[ d\sigma = (1 + |\nabla u|^2)^{1/2}\; dx^1 \dots dx^d, \]
  %
  which can be incorporated into $\psi_\alpha$. Thus it suffices to show that for each $\xi = (\xi_0, \xi_1) \in \RR^d$,
  %
  \[ \left| \int_B e^{-2 \pi i(\xi_0 \cdot x + \xi_1 u(x))} \psi(x)\; dx \right| \lesssim_{\psi,u} \frac{1}{(|\xi_0|^2 + \xi_1^2)^{d/4}}. \]
  %
  Let us fix $\xi \in S^d$, and consider the oscillatory integral
  %
  \[ I_\xi(\lambda) = \int_B e^{\lambda i \phi_\xi(x)} \psi(x)\; dx, \]
  %
  where
  %
  \[ \phi_\xi(x) = -2\pi \left( \xi_0 \cdot x + \xi_1 u(x) \right). \]
  %
  Note that
  %
  \[ \nabla \phi_\xi(x) = -2\pi(\xi_0 + \xi_1 \nabla u(x)) \]
  %
  The inverse function theorem combined with our curvature condition tells us that if we choose our neighbourhoods $U_\alpha$ small enough, the map $x \mapsto \nabla u(x)$ is a smooth diffeomorphisms on $B$. In particular, for each $\xi$, there is at most one $x \in B$ such that $\phi_\xi$ is stationary at $x$. Even without the curvature condition, we can conclude that for each $x$, there is at most one $\xi \in S^d$, up to a negation, such that $\phi_\xi$ is stationary at $x$.

  Because of the curvature condition, one can verify that for each $\xi \in \RR^d$, there are $O(1)$ stationary points for the phase $\phi_\xi$. Moreover, if

  In particular, we conclude that for each $\xi$, there are $O(1)$ stationary points for the phase $\phi(\cdot | \xi)$ on the support of $\psi$.

  The curvature condition implies that, if we have chosen are neighbourhoods small enough, for each $\xi$ there is at most one $x \in B$ such $\phi(\cdot|\xi)$ is stationary at $x$.

  Then $\nabla_x \phi(x|\xi) = -2\pi( \xi_0 + \xi_1 \nabla u(x) )$. In particular, $\phi(\cdot|(0,1))$ has a stationary point at $0$. If we consider $D_x[\nabla_x \phi(x|\xi)] = -2\pi  \xi_1 H_x u(x)$, which is nonsingular by assumption in a neighbourhood of $(0,1)$. Thus there exists a relatively open set $V_\alpha \subset S^d$


  Applying the implicit function theorem, having chosen our sets $\psi_\alpha$ small enough, there exists a relatively open set $V_\alpha \subset S^d$ containing $(0,1)$ such that for each $\xi = (\xi_0,\xi_1) \in V_\alpha$, there is a unique $x(\xi) \in B$ such that $\nabla_x \phi(x(\xi)|\xi) = 0$

  such that for each $\xi \in \RR^d$ and $\alpha$, there is at most one point $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$. Moreover, we can find a relatively open subset $V_\alpha$ of $S^{d-1}$ such that for each $\xi \in V_\alpha$, there exists a unique $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$.

  we can write
  %
  \[ \widehat{\mu}(\xi) = \sum_\alpha \int e^{-2 \pi i \xi \cdot x} \psi_\alpha(x)\; d\mu. \]
  %


  $\Sigma$ is the smooth graph of a function $f: B \to \RR$, where $B$ is the closed unit ball in $\RR^d$, i.e.
  %
  \[ \Sigma = \{ (x,t) : x \in B, t = f(x) \}. \]
  %
  Then $d\sigma = (1 + |\nabla f|^2)^{1/2} dx^1 \dots dx^d$, and the fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $f$ is non-degenerate. It thus suffices to obtain a bound of the form
  %
  \[ \int e^{i (\xi \cdot x) + \eta f(x)} \psi(x)\; dx \lesssim_{\psi} \frac{1}{\sqrt{|\xi|^2 + \eta^2}}. \]
  %
  where $\psi$ is a compactly supported, smooth function on $B$. Fix $(\xi_0, \eta_0)$ such that $\xi_0^2 + \eta_0^2 = 1$, and consider the oscillatory integral
  %
  \[ I(\lambda) = \int_B e^{\lambda i (\xi_0 \cdot x) + \eta_0 f(x)} \psi(x)\; dx \]
  %
  This is an oscillatory integral with phase $\phi(x;\xi_0,\eta_0) = (\xi_0 \cdot x) + \eta_0 f(x)$.

  We are considering the oscillatory integral
  %
  \[ \int e^{-2 \pi i \xi x} d\Sigma(x). \]
  %
  If $\phi(x) = x \cdot \xi$. The nondegeneracy of the Hessian of $\phi$ on the support of $\mu$ corresponds precisely to the nonvanishing of the curvatures of $\Sigma$ on $\mu$. Then we may find a family of
\end{comment}
\end{proof}

If $\Omega$ is a bounded open subset of $\RR^{d+1}$ whose boundary is a smooth manifold with non-zero Gaussian curvature at each point, then it's Fourier transform has decay one order better than the Fourier transform of it's boundary.

\begin{corollary}
  If $\Omega$ is a bounded open subset of $\RR^d$ whose boundary is a smooth manifold $\Sigma$ with non-zero Gaussian curvature at each point. If $I_\Omega$ is the indicator function on $\Omega$, then
  %
  \[ |\widehat{I_\Omega}(\xi)| \lesssim_\Omega |\xi|^{-(d+1)/2}. \]
\end{corollary}
\begin{proof}
  We have
  %
  \[ \widehat{I_\Omega}(\xi) = \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \]
  % u div(V) dV = u (V . n) dS - Grad(u) . V dV
  % As long as V is smooth and div(V) is fine
  % If u = e^{-2 \pi i \xi . x}, Grad(u) = (-2\pi i \xi) e^{-2 \pi i \xi . x}
  % If V(x) = x_1
  %
  Then we can apply Stoke's theorem for each $1 \leq k \leq d+1$ to conclude
  %
  \[ \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx = \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n). \]
  %
  For each $k$, there is a smooth function $\psi_k$ such that
  %
  \[ dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n = \psi_k d\sigma. \]
  %
  Thus applying the last case, we find
  %
  \[ \left| \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n) \right| \lesssim \xi_k^{-1} |\xi|^{-(d-1)/2}. \]
  %
  At each point $\xi$, if we choose $\xi_k$ with the largest value, then $|\xi_k| \sim |\xi|$, so
  %
  \[ \left| \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \right| \lesssim |\xi|^{-(d+1)/2}. \qedhere \]
\end{proof}

The fact that curved surfaces have Fourier decay is of supreme importance to much of modern harmonic analysis. Let us see some basic consequences, which is a classical result due to Hardy, Littlewood, and Hlawka.

\begin{theorem}
    Let $B$ be the unit ball in $\RR^d$, and for each $\lambda > 0$, let $N(\lambda)$ denote the number of integer lattice points in $\lambda B$. Then
    %
    \[ N(\lambda) = |B| \cdot \lambda^d + O(\lambda^{n-2 + 2/(n+1)}). \]
\end{theorem}
\begin{proof}
    We have
    %
    \[ N(\lambda) = \widehat{f}(0), \]
    %
    where $f = \mathbf{I}_{\lambda B} \cdot \sum_{n \in \ZZ^d} \delta_n$. The Poisson summation formula implies that
    %
    \[ \widehat{f} = \widehat{\mathbf{I}_{\lambda B}} * (\sum_{n \in \ZZ^d} \delta_n) \]
    %
    Thus
    %
    \[ \widehat{f}(0) = \sum_{n \in \ZZ^d} \widehat{\mathbf{I}_{\lambda B}}(n) = \lambda^d \sum_{n \in \ZZ^d} \widehat{\mathbf{I}_B}(\lambda n) = |B| \lambda^d + \sum_{n \neq 0} \widehat{\mathbf{I}_B}(\lambda n). \]
    %
    We want to apply the estimate $\widehat{\mathbf{I}_B}(\lambda n) \lesssim (\lambda n)^{-(d+1)/2}$, but the decay here isn't enough for the sum in the Poisson summation formula to converge. To fix this, we mollify $\mathbf{I}_B$ slightly. Let $\beta$ be a non-negative bump function supported on $|x| \leq 1/2$ with $\int \beta(x)\; dx = 1$. Fix $\varepsilon > 0$, and define
    %
    \[ \chi_\lambda(x) = \varepsilon^{-d} \text{Dil}_\varepsilon \beta * \mathbf{I}_{\lambda B}. \]
    %
    Then set $\widetilde{N}(\lambda) = \sum_j \chi_\lambda(j)$. Then $\mathbf{I}_{\lambda B}$ is equal to $\chi_\lambda$ everywhere except on $\lambda - \varepsilon \leq |x| \leq \lambda + \varepsilon$, and since both functions are positive,
    %
    \[ \widetilde{N}(\lambda - \varepsilon) \leq N(\lambda) \leq \widetilde{N}(\lambda + \varepsilon). \]
    %
    We can apply the Poisson summation formula now as above to obtain that
    %
    \[ \widetilde{N}(\lambda) = \lambda^d |B| + \sum_{n \neq 0} \widehat{\mathbf{I}_B}(\lambda n) \widehat{\beta}(\varepsilon n). \]
    %
    The first term is bounded by $(\lambda n)^{-(d+1)/2}$, and the second by $(\varepsilon n)^{-K}$, where $n \geq 1/\varepsilon$ and $K$ is large, and bounded by $O(1)$ for $n \leq 1/\varepsilon$. Applying these bounds thus gives
    %
    \[ \widetilde{N}(\lambda) = \lambda^d |B| + O( \lambda^{-(d+1)/2} \varepsilon^{-(d-1)/2} ). \]
    %
    Thus
    %
    \[ N(\lambda) = \lambda^d |B| + O( \varepsilon \lambda^{d-1} + \lambda^{(d-1)/2} \varepsilon^{-(d-1)/2} ) \]
    %
    Choosing $\varepsilon = \lambda^{-(d-1)/(d+1)}$ completes the proof.
\end{proof}

\begin{remark}
    One can never have $N(\lambda) = |B| \lambda^d + O(\lambda^{d-2})$, because TODO
\end{remark}

\begin{example}
  If $M$ is a hypersurface in $\RR^d$, and $\psi$ is a smooth, compactly supported function on $M$, and $f$ is a smooth, compactly supported function on $\RR^d$, we can define a function $Af$ on $\RR^d$ by defining
  %
  \[ (Af)(y) = \int_M f(y - x) \psi(x)\; d\sigma(x). \]
  %
  We note that $Af$ is really the convolution of $f$ with $\psi \sigma$. Thus
  %
  \[ \widehat{Af}(\xi) = \widehat{f}(\xi) \widehat{\psi d\sigma}(\xi). \]
  %
  For each multi-index $\alpha$, the derivative $(Af)_\alpha$ is equal to
  %
  \[ \int_M f_\alpha(y-x) \psi(x)\; d\sigma(x) = f_\alpha * (\psi \sigma). \]
  %
  In particular, we have
  %
  \[ \widehat{(Af)_\alpha} = (2 \pi i \xi)^\alpha \widehat{f}(\xi) \widehat{\psi \sigma}(\xi). \]
  %
  Since we have shown
  %
  \[ |\widehat{\psi \sigma}(\xi)| \lesssim |\xi|^{-(d-1)/2}, \]
  %
  we conclude that if $|\alpha| \leq k$, where $k = (d-1)/2$,
  %
  \[ \| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}. \]
  %
  In particular, this implies that $A$ extends to a unique bounded operator from $L^2(\RR^d)$ to $L^2_k(\RR^d)$, i.e. to a map such that for each $f \in L^2(\RR^d)$, $Af$ is a square integrable function which has square integrable weak derivatives of all orders less than or equal to $k$, and moreover, $\| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}$ for all $|\alpha| \leq k$. Thus the operator $A$ is `smoothening', in a certain sense.

  The operator $A$ is obviously bounded from $L^1(\RR^d)$ to $L^1(\RR^d)$ and $L^\infty(\RR^d)$ to $L^\infty(\RR^d)$, purely from the fact that $\psi \sigma$ is a finite measure. Using curvature and some analytic interpolation, we will now also show that $A$ is bounded from $L^p(\RR^d)$ to $L^q(\RR^d)$, where $p = (d+1)/d$, and $q = d+1$. Interpolation thus yields a number of intermediate estimates. The trick here is to obtain an $(L^1,L^\infty)$ bound for an `improved' version of $A$, and an $(L^2,L^2)$ bound for a `worsened' version of $A$. Interpolating between these two results gives a bound for precisely $A$. It suffices to prove this bound `locally' on $M$, since we can then sum up these bounds, so we may assume that $M$ is given as the graph of some function, i.e. there exists $u$ such that
  %
  \[ M = \{ (x,u(x)):  \} \]


  For each $s$, we write $A_sf = K_s * f$, where
  %
  \[ K_s(x) = \gamma_s |x_d - \phi(x')|_+^{s-1} \psi_0(x). \]
  %
  Here $\gamma_s = s \dots (s + N) e^{s^2}$, where $N$ is some large parameter to be fixed in a moment. The $e^{s^2}$ parameter is to mitigate the growth of $\gamma_s$ as $|\text{Im}(s)| \to \infty$, which allows us to interpolate. The quantity $|u|_+^{s-1}$ is equal to $u^{s-1}$ where $u > 0$, and is equal to 0 when $u \leq 0$. And $\psi_0(x) = \psi(x) (1 + |\nabla_{x'} \phi(x')|^2)^{1/2}$.
\end{example}





\section{Oscillatory Integral Operators}

An oscillatory integral takes as input a particular frequency scale, and gives back a scalar value. The goal of the theory of stationary phase is to determine the decay of the outputs as we increase the value of the frequency scale. Oscillatory integral operators are a generalization of this property. Most often, these oscillatory operators are a family of operators $\{ T_\lambda \}$, where $\lambda$ parameterizes the frequency scale of some oscillatory factor. The goal is to understand how the properties of these operators is affected asymptotically as we increase the frequency factor.

Let us begin with a family of such operators given by the formula
%
\[ T_\lambda f(x) = \int_{\RR^n} a(x,y) e^{2 \pi i \lambda \phi(x,y)} f(y)\; dy, \]
%
where $a \in C_c^\infty(\RR^m \times \RR^n)$ is real-valued and $\phi \in C^\infty(\RR^m \times \RR^n)$. The regularity of all these parameters means that the operators $T_\lambda$ are defined even for a general distributional input $f$. For intuition, we recall the theory of oscillatory integral distributions, and in particular, canonical relations and wave front sets. The kernel $K_\lambda(x,y) = a(x,y) e^{2 \pi i \lambda \phi(x,y)}$ is an `oscillatory integral distribution' of `dimension zero'. Applying the theory of wave front sets for such distributions blindly, we obtain the formula
%
\[ \text{WF}(K_\lambda) \subset \{ (x,y; \lambda \nabla_x \phi(x,y), \lambda \nabla_y \phi(x,y)) : x \in \RR^m, y \in \RR^n \}. \]
%
Since $K_\lambda$ is a smooth function, the wave front set of $K_\lambda$ is actually empty, so this formula is pretty redundant. Nonetheless, this formula does give us some information about where the operator $T_\lambda$ may be singular in a quantitative sense. Consider the \emph{canonical relation}
%
\[ C_\phi = \{  (x,y; \nabla_x \phi(x,y), - \nabla_y \phi(x,y) ) : x \in \RR^m, y \in \RR^n \}. \]
%
A rudimentary Taylor expansion calculation shows that if $f(y) = \psi((y - y_0)/\delta_y) e^{2 \pi i \eta_0 \cdot y}$ for some $y_0$ and $\xi_0$, then for any particular $x_0$, if $|x - x_0| \leq \delta_x$,
%
\[ T_\lambda f_\delta(x) \approx \delta_y^n a(x_0,y_0) e^{2 \pi i \lambda(\phi(x_0,y_0) + \nabla_x \phi(x_0,y_0) \cdot (x - x_0))} \widehat{\psi}(- \delta_y [\lambda \nabla_y \phi(x_0,y_0) + \eta_0]), \]
%
where the left and right differ by $\delta_y^n \cdot O(\delta_x + \lambda \delta_x^2 + \lambda \delta_y^2)$. In particular, this approximation is good provided that $\delta_x \lesssim \lambda^{-1/2}$ and for $\delta_y \lesssim \lambda^{-1/2}$. We intuit from this that if $f$ is a wave packet with unit amplitude, localized in space near $y_0$ with an uncertainty of $\lambda^{-1/2}$, and localized near a frequency $\eta_0$, then, when localized in space near $x_0$, with an uncertainty of $\lambda^{-1/2}$, $T_\lambda f$ looks like a wave packet with amplitude
%
\[ O_N(\lambda^{-n/2} (1 + \lambda^{1/2} |\lambda \nabla_y \phi(x_0,y_0) + \eta_0 |)^{-N} ) \]
%
for all $N > 0$, and with frequency localized near $\lambda \nabla_x \phi(x_0,y_0)$. In particular, if $\eta_0 = - \lambda \nabla_y \phi(x_0,y_0)$, then we obtain a wave packet in the output with an amplitude of $\approx \lambda^{-n/2}$ when localized in a $\Theta(\lambda^{-1/2})$ radius neighbourhood of $x_0$. And if $\eta_0$ is chosen away from this value, the amplitude becomes very small as $\lambda \to \infty$. This indicates the canonical relation determines which wave packets induce a noticable effect on the output, and where this effect occurs. In particular, if we take $f$ with the former properties, then $\| T_\lambda f \|_{L^q(\RR^m)} \gtrsim \lambda^{-n/2} \lambda^{-m/2q}$, whereas $\| f \|_{L^p(\RR^n)} \sim \lambda^{-n/2p}$, which implies that the operator norm of $T_\lambda$ from $L^p(\RR^n)$ to $L^q(\RR^m)$ is at least $\Omega(\lambda^{(n/2)(1/p-1) - (m/2)(1/q)})$. In particular, we cannot expect to do any better than the trivial bound $\| T_\lambda f \|_{L^\infty(\RR^m)} \lesssim \| f \|_{L^1(\RR^n)}$ when $p = 1$ and $q = \infty$. In certain situations, we will be able to conclude that $T_\lambda$ actually does have an operator norm achieving this decay bound, provided we assume suitable geometric conditions on the canonical relation $C_\phi$.

To begin with, let us consider the case where the matrices $D_y \nabla_x \phi = (D_x \nabla_y \phi)^T$ always has full rank on the support of the function $a$. If $m \geq n$, this information can be expressed by saying that $C_\phi \to T^* \RR^n$ is a submersion, and $C_\phi \to T^* \RR^m$ is an immersion, with these properties swapped if $m \leq n$. Thus, locally speaking, we have a smooth map $T^* \RR^m \to C_\phi$ which is a left inverse to the corresponding projection map. For intuitions sake, let us assume this smooth map is globally defined, so we can obtain a smooth map $\alpha = (y,\eta): T^* \RR^m \to T^* \RR^n$ such that if $(x_0,y_0;\xi_0,\eta_0) \in C_\phi$, then $y_0 = y(x_0,\xi_0)$ and $\eta_0 = \eta(x_0,\xi_0)$. Thus, roughly speaking, the only possible wave packet $f$ localized spatially at a scale $\lambda^{-1/2}$ whose corresponding output $T_\lambda f$ has significant amplitude when localized at a scale $\lambda^{-1/2}$ near $x_0$ and oscillates at a frequency $\xi_0$ is a wave packet at position $y(x_0,\xi_0)$ and with frequency $\eta(x_0,\xi_0)$. The fact that $|\alpha(x_0,\xi_0) - \alpha(x_1,\xi_1)| \gtrsim |(x_0,\xi_0) - (x_1,\xi_1)|$ reflects a kind of `orthogonality property' of the operator $T_\lambda$. To understand this orthogonality, we rely on $L^2$ techniques, namely a $T^*T$ argument.

%we consider the case $n = m$. The optimal asymptotics of the operator norm of $T_\lambda$ from $L^p(\RR^n)$ to $L^q(\RR^m)$ in this regime is $\lambda^{(1/2)(1/p - 1/q - 1)}$. In particular, let us consider the case where $q$ is the dual of $p$. The optimal bound then reduces to showing that $\| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-1/q} \| f \|_{L^{q^*}(\RR^n)}$. In the case where $q = \infty$, the bound $\| T_\lambda f \|_{L^\infty(\RR^n)} \lesssim \| f \|_{L^{1}(\RR^n)}$ is trivial. Under a geometric assumption on $C_\phi$, we will justify a bound of the form $\| T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-1/2} \| f \|_{L^2(\RR^n)}$, and thus obtain optimal decay for $2 \leq q \leq \infty$. This assumption will be that $D_y \nabla_x \phi$ is an invertible matrix on the support of the function $a$. Equivalently, this means that the projection maps $C_\phi \to T^* \RR^n$ and $C_\phi \to T^* \RR^m$ from the canonical relation will be local diffeomorphisms, inducing a local diffeomorphism from $T^* \RR^n$ to $T^* \RR^m$. For intuition's sake, let us assume that this diffeomorphism is globally defined as a map $\alpha = (x,\xi): T^* \RR^n \to T^* \RR^m$. Then, roughly speaking, a wave packet $f$ localized spatially near $y_0$ at an uncertainty of $\lambda^{-1/2}$ and frequentially at a point $\eta_0$ will map to a wave packet localized spatially near $x(y_0,\eta_0)$ with an uncertainty of $\lambda^{-1/2}$, and localized in frequency near $\xi(y_0,\eta_0)$. Moreover, if $|(y_0,\eta_0) - (y_1,\eta_1)| \gtrsim 1$, then $|\alpha(y_0,\eta_0) - \alpha(y_1,\eta_1)| \gtrsim 1$, which indicates that $T$ has a `preservation of orthogonality' type property. 

\begin{theorem} Consider a family of oscillatory integral operators
%
\[ \{ T_\lambda: L^2(\RR^n) \to L^2(\RR^m) \} \]
%
with associated phase $\phi$. If $D_y \nabla_x \phi$ is injective, i.e. the map $C_\phi \to T^* \RR^m$ is an immersion, then
%
\[ \| T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-n/2} \| f \|_{L^2(\RR^n)}. \]
\end{theorem}
\begin{proof}
    Once sufficiently localized, the assumption above implies that
    %
    \[ |\nabla_x \phi(x,y_1) - \nabla_x \phi(x,y_2)| \gtrsim |y_1 - y_2|. \]
    %
    We calculate that
    %
    \[ T_\lambda^* g(y) = \int \overline{a(x,y)} e^{- 2 \pi i \lambda \phi(x,y)}\; dx. \]
    %
    Thus the kernel of the operator $T_\lambda^* T_\lambda$ is equal to
    %
    \[ K(y_1,y_2) = \int \overline{a(x,y_1)} a(x,y_2) e^{2 \pi i \lambda [\phi(x,y_1) - \phi(x,y_2)]}\; dx. \]
    %
    The principle of nonstationary phase thus tells us that
    %
    \[ |K(y_1,y_2)| \lesssim (1 + \lambda |y_1 - y_2|)^{-N}. \]
    %
    Thus for $|K(y_1,y_2)| \lesssim 1$ for $|y_1 - y_2| \lesssim 1/\lambda$, and $|K(y_1,y_2)| \lesssim_N \lambda^{-N} |y_1 - y_2|^{-N}$ for $|y_1 - y_2| \gtrsim 1/\lambda$. Schur's test thus gives that $\| T_\lambda^* T_\lambda f \|_{L^1(\RR^n)} \lesssim \lambda^{-n} \| f \|_{L^1(\RR^n)}$, and that $\| T_\lambda^* T_\lambda f \|_{L^\infty(\RR^n)} \lesssim \lambda^{-n} \| f \|_{L^\infty(\RR^n)}$, and interpolation that $\| T_\lambda^* T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-n} \| f \|_{L^2(\RR^n)}$, and so $\| T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-n/2} \| f \|_{L^2(\RR^n)}$.
\end{proof}

\begin{remark}
    The best possible decay bound for the operator norm of $T_\lambda$ for general $n$ and $m$ is $\lambda^{-(n+m)/4}$, and since the theorem above can only be applied when $n \leq m$, the result is only optimal when $n = m$.
\end{remark}

Interpolating between the trivial bound $\| T_\lambda f \|_{L^\infty(\RR^n)} \lesssim \| f \|_{L^1(\RR^n)}$ yields that for $2 \leq q \leq \infty$, if $p$ is the conjugate dual of $q$, then
%
\[ \| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}. \]
%
More generally, using the fact that $T_\lambda f$ only depends on the behaviour of $f$ on $\text{supp}_y(a)$, we conclude that we have a bound $\| T_\lambda f \|_{L^\infty(\RR^n)} \lesssim \| f \|_{L^p(\RR^n)}$ for any $1 \leq p \leq \infty$. Interpolating this bound with $\| T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-n/2} \| f \|_{L^2(\RR^n)}$ then gives $\| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}$ whenever $1/p + 1/q \leq 1$ and $1 \leq p \leq 2$ (equivalently, $2 \leq q \leq \infty$).

One might see an analogy with this family of inequalities to the Hausdorff-Young inequality $\| \widehat{f} \|_{L^q(\RR^n)} \lesssim \| f \|_{L^p(\RR^n)}$, which holds when $1/p + 1/q = 1$. Indeed, the Hausdorff-Young inequality actually follows from these bounds, since one can consider the truncated Fourier transforms
%
\[ F_\lambda f(\xi) = \int a(x/\lambda,\xi/\lambda) e^{2 \pi i \xi \cdot x} f(x)\; dx = \lambda^n \int a(x,\xi) e^{2 \pi i \lambda \xi \cdot x} f(\lambda x)\; dx \]
%
for some bump function $a \in C_c^\infty(\RR)$, which equal the normal Fourier transform in the limit as $\lambda \to \infty$ for suitably regular functions $f$. The operators $T_\lambda = \lambda^{-n} F_\lambda \circ \text{Dil}_\lambda$ are given by
%
\[ T_\lambda f(\xi) = \int a(x,\xi) e^{2 \pi i \lambda \xi \cdot x} f(x)\; dx, \]
%
and $D_\xi \nabla_x(\xi \cdot x)$ is the identity matrix, so the theory above implies that $\| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}$. Rescaling this inequality shows that $\| F_\lambda f \|_{L^q} \lesssim \| f \|_{L^p(\RR^n)}$, and taking limits as $\lambda \to \infty$ then yields Hausdorff Young. Thus we see obtaining results for oscillatory integral operators without compact support can be obtained from this theory if we can obtain oscillatory integral bounds with a decay of the form $\lambda^{-n/q}$.

One phase to which the last result does not imply is that phase $\phi(x,y) = |x - y|$, since, for $x \neq y$,
%
\[ \nabla_x \phi = \frac{x - y}{|x - y|} \quad\text{and}\quad \nabla_y \phi = \frac{y - x}{|y - x|}. \]
%
This implies that $D_y \nabla_x \phi$ cannot possibly be invertible, since the map $y \mapsto \nabla_x \phi(x,y)$ is not an open map (it's image lies in $S^{n-1}$). The canonical relation $C_\phi$ is a cone of points of the form
%
\[ \left\{ \left(x,y; \frac{x - y}{|x - y|}, \frac{x - y}{|x - y|} \right) \right\}, \]
%
and so each pair $(x_0,\xi_0)$ is related to a one dimensional family of points $(y,\xi_0)$, where $y$ lies on the half-line of points through $x_0$ pointing in the direction $-\xi_0$. Similarily, each pair $(y_0,\eta_0)$ is related to a one dimensional family of points $(x,\xi_0)$, where $x$ lies on a half-life of points pointing in the direction $\xi_0$. In particular, this means that obtaining a bound of the form $\| T_\lambda f \|_{L^2(\RR^n)} \lesssim \lambda^{-n/2} \| f \|_{L^2(\RR^n)}$ is impossible for such a phase. More precisely, fix $x_0 \in \text{supp}_x(a)$ and a half-line $l = \{ x \in \RR^n : (x - x_0) / |x - x_0| = \xi_0 \}$ starting at $x_0$ for some $|\xi_0| = 1$ whose intersection with $\text{supp}_y(a)$ has non-empty interior in $l$. Fix $N \sim \lambda^{1/2}$, and consider a family of $N$ wave packets $f_1, \dots, f_N$, each with pairwise disjoint support, but supported spatially near a family of $O(\lambda^{-1/2})$ separated points lying on $l \cap \text{supp}_y(a)$, with spatial uncertainty $\lambda^{-1/2}$, and with frequency concentrated near $\xi_0$. If $f = f_1 + \dots + f_N$, then the formula above implies that $T_\lambda f$ will have the majority of it's spatial support in the set 
%
\[ \{ x_0 \in \RR^n : |\lambda (x_0 - y_0)/|x_0 - y_0| - \xi_0| \lesssim \lambda^{-1/2} \}, \]
%
and have amplitude $\lambda^{-(n-1)/2}$ over there. Roughly speaking, this is a tube centered at $y_0$, pointing in the direction $\xi_0$, and with thickness $O(\lambda^{-1/2})$, and thus has volume $\Theta(\lambda^{-(n-1)/2})$. But this means that $\| T_\lambda f \|_{L^q(\RR^n)} \gtrsim \lambda^{-(n-1)/2} \lambda^{-(n-1)/2q}$, and so combined with the fact that $\| T_\lambda f \|_{L^p(\RR^n)} \sim \lambda^{-(n-1)/2p}$, this means the operator norm of $T_\lambda$ must be $\Omega(\lambda^{(n-1)/2 (1/p - 1/q - 1)})$, which for $p = q = 2$ gives $\Omega(\lambda^{-(n-1)/2})$. On the other hand, this does not preclude a bound of the form $\| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}$ from holding when $q \geq (n+1)/(n-1) \cdot p^*$, which forms a subset of the family of all of the cases we proved above when, in addition, $1 \leq p \leq 2$. We will show, using the fact that the projections of $C_\phi$ onto $T^* \RR^n$ are surfaces of constant curvature, that we can obtain the bound under this assumption when $1 \leq p \leq 2$, and even when $1 \leq p \leq 4$ when $n = 2$.

To analyze the operator, we consider a cutoff $\psi$ with $\psi(z) = 0$ for $|z| \lesssim 1$, and with $\psi(z) = 1$ for $|z| \gtrsim 1$. Write $T_\lambda = \tilde{T_\lambda} + R_\lambda$, where
%
\[ \tilde{T_\lambda} f(x) = \int a(x,y) \psi(x - y) e^{2 \pi i \lambda |x - y|} f(y)\; dy. \]
%
If we can establish that $\| \tilde{T_\lambda} f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}$, then we know that
%
\[ R_\lambda f(x) = \int a(x,y) (1 - \psi(x - y)) e^{2 \pi i \lambda |x - y|} \]
%
TODO: COMPLETE ARGUMENT.

To study $\tilde{T_\lambda}$, we can cover the support of $a$ by finitely many open sets $\{ U_\alpha \times V_\alpha \}$, upon each of which we may find a diffeomorphism $y_\alpha: W_\alpha \times I_\alpha \to V_\alpha$, where $W_\alpha \subset \RR^{n-1}$, $I_\alpha$ is an interval, and for any $x \in U_\alpha$ and $t \in I_\alpha$, the map
%
\[ v \mapsto \frac{y_\alpha(v,t) - x}{|y_\alpha(v,t) - x|} \]
%
is an immersion from $W_\alpha$ to $\RR^n$. Applying a partition of unity $\{ \psi_\alpha \}$ over these open sets, we can write $\tilde{T_\lambda} = \sum_\alpha T^\alpha_{\lambda}$. Moreover, we can write
%
\begin{align*}
    T^\alpha_\lambda &= \int a(x,y) \psi_\alpha(x,y) e^{2 \pi i \lambda |x - y|}\; dy\\
    &= \int \frac{ a(x,y_\alpha(v,t)) \psi_\alpha(x,y_\alpha(v,t))}{|\det(Dy_\alpha(v,t))|} e^{2 \pi i \lambda |x - y_\alpha(v,t)|} f(y_\alpha(v,t))\; dv\; dt\\
    &= \int_{I_\alpha} \int_{W_\alpha} a_\alpha(x,v;t) e^{2 \pi i \lambda |x - y_\alpha(v,t)|} f(y_\alpha(v,t))\; dv\; dt\\
    &= \int_{I_\alpha} T^{\alpha,t}_\lambda f_{t,\alpha}(x),
\end{align*}
%
where $f_{t,\alpha}(v) = f(y_\alpha(v,t))$, and if we set $\phi(x,v;t) = |x - y_\alpha(v,t)|$, then
%
\[ T^{\alpha,t}_\lambda f(x) = \int_{W_\alpha} a_\alpha(x,v;t) e^{2 \pi i \lambda \phi(x,v;t)} f(v)\; dv. \]
%
The next Lemma will justify that $\| T^{\alpha,t} f_{t,\alpha} \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f_{t,\alpha} \|_{L^p(W_\alpha)}$, from which, together with H\"{o}lder's inequality, it follows that
%
\begin{align*}
    \| T^\alpha_\lambda f \|_{L^q(\RR^n)} &\lesssim \int_{I_\alpha} \| T^{\alpha,t}_\lambda f_{t,\alpha} \|_{L^q(\RR^n)}\\
    &\lesssim \lambda^{-n/q} \int_{I_\alpha} \| f_{t,\alpha} \|_{L^p(W_\alpha)}\; dt\\
    &\lesssim \lambda^{-n/q} |I_\alpha|^{1 - 1/p} \left( \int \| f_{t,\alpha} \|_{L^p(W_\alpha)}^p \right)^{1/p}\\
    &\lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^n)}.
\end{align*}
%
Let us now prove this lemma, we note that the canonical relation associated with the family of operators $ \{ T^{\alpha,t}_\lambda \}$ is
%
\[ C^{\alpha,t} = \left\{ \left( x,v; \frac{|x - y_\alpha(v,t)|}{|x - y_\alpha(v,t)|}, D_v(y_\alpha)(v,t)^T \cdot \frac{x - y_\alpha(v,t)}{|x - y_\alpha(v,t)|} \right) \right\}. \]
%
Our assumptions on the coordinate system $y_\alpha$ implies that the projection map $C^{\alpha,t} \to T^* W_\alpha$ is an immersion, i.e. the matrix $D_v \nabla_x \phi_{t,\alpha}$ has full rank $n-1$ on the domain of the integral. And the image of the projection $C^{\alpha,t} \to T^* \RR^n$ is an open subset of the submanifold of unit vectors in $T^* \RR^n$, which, at each point $x$, is a $n-1$ dimensional manifold with non-vanishing curvature. These assumptions justify the application of the next Lemma.

\begin{lemma}
    Suppose $\phi: \RR^n \times \RR^{n-1}$ is a $C^\infty$ phase, that $\nabla_x D_y \phi$ has rank $n-1$ on the support of $a \in C_c^\infty(\RR^n \times \RR^{n-1})$, and that the image of the projection $C_\phi \to T* \RR^n$ is on each fibre a hypersurface of non-vanishing curvature. Then if $1/p + 1/q \leq 1$, $1 \leq p \leq 2$, and $q \geq [(n+1)/(n-1)] \cdot p^*$, then
    %
    \[ \| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^p(\RR^{n-1})}. \]
\end{lemma}

\begin{remark}
    Using a similar construction as for the operator associated with the phase $\phi(x,y) = |x - y|$, one can show from the assumption that there exists $f$ such that $\| T_\lambda f \|_{L^q(\RR^n)} \geq \lambda^{(n-2)/2p - (n-2)/2 - n/2q} \| f \|_{L^p(\RR^{n-1})}$, which shows that one can only obtain a bound of the form above when $q \geq [(n+1)/(n-1)] \cdot p^*$. We also note that the theorem above, once rescale, implies extension estimates of the form
    %
    \[ \left\| \int_{\RR^{n-1}} e^{2 \pi i x \cdot \phi(\xi)} f(\xi)\; d\xi \right\|_{L^q(\RR^n)} \lesssim \| f \|_{L^p(\RR^{n-1})} \]
    %
    for the same range of $p$ and $q$, which are dual to the corresponding restriction estimates for the hypersurface $H = \{ (\xi,\phi(\xi)) \}$.
\end{remark}

\begin{proof}
    To prove the result, we may assume that $q = [(n+1)/(n-1)] \cdot p^*$. Since the result is proved when $p = 1$, it suffices to show that
    %
    \[ \| T_\lambda f \|_{L^{(n+1)/2(n-1)}(\RR^n)} \lesssim \lambda^{-n(n-1)/2(n+1)} \| f \|_{L^2(\RR^{n-1})}. \]
    %
    The assumption that the surface $y \mapsto \nabla_x \phi(x,y)$ has non-vanishing curvature can be expressed in the following manner: I can, locally at least, for each $x \in \RR^n$ and $y \in \RR^{n-1}$, pick a unit normal vector $\nu(x,y) \in S^{n-1}$ to the surface $y \mapsto \nabla_x \phi(x,y)$ at the point $\nabla_x \phi(x,y)$. This means precisely that for each fixed $x_0$ and $y_0$,
    %
    \[ \nabla_y (\nabla_x \phi(x_0,y) \cdot \nu(x_0,y_0)) = 0 \]
    %
    when $y = y_0$. If $H(x_0,y_0)$ is the Hessian matrix of the operator $y \mapsto \nabla_x \phi(x_0,y) \cdot \nu(x_0,y_0)$, then this means precisely that
    %
    \[ \nabla_x \phi(x_0,y) \cdot \nu(x_0,y_0) = (y - y_0)^T H(x_0,y_0) (y - y_0) + O(|y - y_0|^3). \] 
    %
    The statement that the surface does not have vanishing curvature at $(x_0,y_0)$ is then equivalent to the fact that $H(x_0,y_0)$ is invertible.

    To prove the theorem, perhaps after localizing and taking a change of $x$-variables, we may assume that $x = (z,t)$, where $D_z \nabla_y \phi$ is invertible. Introduce the operators $T_\lambda^t$, mapping functions from $\RR^{n-1}$ to $\RR^{n-1}$ by the formula
    %
    \[ T_\lambda^t f(z) = \int a(z,y;t) e^{2 \pi i \lambda \phi(z,y;t)} f(y)\; dy. \]
    %
    Then
    %
    \[ \| T_\lambda f \|_{L^q(\RR^d)} \sim \left( \int \| T^t_\lambda f \|_{L^q(\RR^{n-1})}^q\; dt \right)^{1/q}, \]
    %
    and it suffices to bound this integral. The advantage of rephrasing the problem in terms of the oscillatory integral operators $T_\lambda^t$ is because we already have some tight estimates for such operators, namely
    %
    \[ \| T^t_\lambda f \|_{L^q(\RR^{n-1})} \lesssim \lambda^{-(n-1)/q} \| f \|_{L^p(\RR^{n-1})}. \]
    %
    However, directly plugging this into the inequality only gives a bound $\| T_\lambda f \|_{L^q(\RR^n)} \lesssim \lambda^{-n/q} \| f \|_{L^q(\RR^{n-1})}$. To gain a boost on what is essentially a trivial application of the triangle inequality, we need to know more about the interactions between the family of operators $\{ T^t_\lambda \}$. This is where the curvature of the canonical relation comes into play, since it implies a kind of orthogonality of the operators.

    To utilize this kind of orthogonality, we again apply adjoint techniques. There is $b \in C_c^\infty$ and $\Phi(z_1,z_2,y;t_1,t_2) = \phi(z_1,y,t_1) - \phi(z_2,y,t_2)$ such that the kernel of the operator $T_\lambda^{t_1} (T_\lambda^{t_2})^*$ is
    %
    \[ K_{t_1,t_2}(z_1,z_2) = \int a(z_1,z_2,y;t_1,t_2) e^{2 \pi i \lambda (\phi(z_1,y,t_1) - \phi(z_2,y,t_2))}\; dy. \]
    %
    Let's analyze this using stationary phase. We have $\nabla_y \Phi(z_0,z_0,y_0,t_0,t_0) = 0$ for any choice of $z_0,y_0$, and $t_0$, yet we have $D_{z_1} \nabla_y \Phi(z,z,y,t,t) = D_{z_1} \nabla_y \phi(z_1,y,t_1)$, which is an invertible matrix by assumption. Thus by the implicit function theorem, there exists a function $z_1 = z_1(z_2,y,t_1,t_2)$ defined in a neighborhood of $(z_0,y_0,t_0,t_0)$ which is a unique solution to the equation $\nabla_y \Phi(z_1, z_2, y, t_1, t_2) = 0$. By localizing in these variables, we may assume these are the only such stationary points. A Taylor expansion gives
    %
    \begin{align*}
        \nabla_y \Phi(z_1,z_2,y,t_1,t_2) &= D_z \nabla_y \phi(z_2,y,t_2) \cdot (z_1 - z_2)\\
        &\quad + D_t \nabla_y \phi(z_2,y,t_2) \cdot (t_1 - t_2)\\
        &\quad + O(|z_1 - z_2|^2 + |t_1 - t_2|^2).
    \end{align*}
    %
    Thus
    %
    \[ |D_z \nabla_y \phi(z_2,y,t_2) \cdot (z_1 - z_2) + D_t \nabla_y \phi(z_2,y,t_2) \cdot (t_1 - t_2)| \lesssim O(|z_1 - z_2|^2 + |t_1 - t_2|^2). \]
    %
    It follows from this that $(z_1 - z_2, t_1 - t_2)$ must be in a small, conical neighborhood of $\pm \nu(z_2,y,t_2)$ (For any matrix $A$, $|Ax| \gtrsim |x|$ unless $x$ is close to the kernel of $A$). If we write $x_i = (z_i,t_i)$ again, this means that for the apropriate sign $|(x_1 - x_2) \pm |x_1 - x_2| \nu(x_2,y)| \lesssim |x_1 - x_2|$. But then
    %
    \begin{align*}
        D_y \nabla_y \Phi(x_1,x_2,y) &= D_y \nabla_y \{ D_x \phi(x_2,y) \cdot (x_1 - x_2) \} + O(|x_1 - x_2|^2)\\
        &= |x_1 - x_2| D_y \nabla_y \{ D_x \phi(x_2,y) \cdot \nu(x_2,y) \} + O(|x_1 - x_2|),
    \end{align*}
    %
    If we choose all the localization values above carefully enough, our curvature assumption implies that this matrix is invertible with determinant $|x_1 - x_2|^{n-1}$, so we have nondegenerate stationary points. Thus isolating near these critical points, we obtain a decay in the oscillatory integral of the form $\lesssim (1 + \lambda |x_1 - x_2|)^{-(n-1)/2}$. Away from these critical points, we have $|\nabla_y \Phi(x_1,x_2,y)| \gtrsim |x_1 - x_2|$ (since if $|\nabla_y \Phi(x_1,x_2,y)| \ll |x_1 - x_2|$, then $x_1 - x_2$ will be in one of the neighborhoods we considered above), and so when we integrate here, nonstationary phase implies that we have a decay of the form $O_N ( (1 + \lambda |x_1 - x_2|)^{-N} )$ for all $N$. Putting together these estimates gives that
    %
    \[ |K^{t_1,t_2}(z_1,z_2)| \lesssim (1 + \lambda |t_1 - t_2| + \lambda |z_1 - z_2|)^{-(n-1)/2}. \]
    %
    This implies the estimates
    %
    \[ \| T_\lambda^{t_1} (T_\lambda^{t_2})^* f \|_{L^\infty(\RR^{n-1})} \lesssim \lambda^{-(n-1)/2} |t_1 - t_2|^{-(n-1)/2} \| f \|_{L^1(\RR^{n-1})}. \]
    %
    This looks like something we could apply the theory of fractional integrals to understand. And indeed we can, as the next result shows: TODO.
\end{proof}








\chapter{Restriction Theorems}

If a function $f$ lies in $L^p(\RR^d)$, there does not exist a numerically meaningful way to restrict $f$ to a set of measure zero, since $f$ is only defined up to measure zero. More precisely, for any $0 < p < \infty$, $0 < q \leq \infty$, and any Radon measure $\sigma$ supported on a set $S$ with Lebesgue measure zero, there does not exist a bound
%
\[ \| f \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for all $f \in C(\RR^d) \cap L^p(\RR^d)$, and thus there does not exist a bounded operator $T: L^p(\RR^d) \to L^q(S,\mu)$ which agrees with the standard restriction of continuous functions to sets of measure zero. We can consider a very similar problem for the Fourier transform; the Fourier transform of a function $f \in L^1(\RR^d)$ is continuous, and thus it is meaningful to consider the restriction $\widehat{f}|_S$. If there exists a bound of the form
%
\begin{equation}
  \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}
\end{equation}
%
for all $f \in L^1(\RR^d) \cap L^p(\RR^d)$, then the Hahn-Banach theorem ensures that there exists a bounded operator $R: L^p(\RR^d) \to L^q(S,\mu)$, such that $Rf = \widehat{f}|_S$ for $f \in L^1(\RR^d) \cap L^p(\RR^d)$; for $p < \infty$, $R$ will be unique since $L^1(\RR^d) \cap L^p(\RR^d)$ will be dense in $L^\infty(\RR^d)$. Thus we have a meaningful way of restricting the Fourier transforms of functions in $L^p(\RR^d)$ to $S$. In light of the failure to restrict elements of $L^p(\RR^d)$ to $L^q(S,\mu)$ without taking the Fourier transform, this indicates that the Fourier transform of $L^p(\RR^d)$ is a fairly special element of $L^q(\RR^d)$, in particular, taking values in a subclass of $L^q(\RR^d)$ in which it is meaningful to restrict to the set $S$. We refer to an estimate of the form above as a \emph{restriction estimate}.

The approximate translation invariance of restriction bounds implies, from Littlewood's principle, that $p \leq q$ holds for any meaningful restriction estimate. For $p = 1$, a restriction bound from $L^1(\RR^d)$ to $L^\infty(S,\mu)$ is trivial for any set $S$ and measure $\mu$. On the other hand, for $p = 2$ and $q > 0$, \emph{no such bound is possible} unless $\mu$ is absolutely continuous with respect to the Lebesgue measure. This follows from a simple application of Parseval's theorem, i.e. because the Fourier transform of an element of $L^2(\RR^d_x)$ in general behaves like an arbirary element of $L^2(\RR^d_\xi)$, and thus cannot be restricted to singular sets. Interpolation shows we also should not expect any bounds when $p > 2$, and indeed such restriction estimates even fail when $\mu$ is absolutely continuous with respect to the Lebesgue measure, for the Hausdorff-Young inequality fails in this setting. Thus the interesting bounds occur when $1 < p < 2$. For a particular pair $(S,\mu)$ and exponent $q$, the goal is to push the value of $p$ as close as possible to $\max(2,q)$.

%\begin{theorem}
%  Fix $0 < p < \infty$ and $0 < q \leq \infty$. If $S$ has measure zero, and $\sigma$ is a non-zero measure supported on $S$, then there does not exist a bounded operator $P: L^p(\RR^d) \to L^q(S,\sigma)$ such that for each function $f \in C_c(\RR^d) \cap L^p(\RR^d)$, $P(f)$ is the usual restriction of $f$ to $S$.
%\end{theorem}
%\begin{proof}
%  For each $\varepsilon > 0$, we can find an open set $U$ containing $S$ with $|U| < \varepsilon$. If we find an Urysohn function $f \in C_c(\RR^d)$ supported on $U$ with $\| f \|_{L^\infty(\RR^d)} \leq 1$, and with $f(x) = 1$ for all $x \in S$, then
  %
%  \[ \| f \|_{L^p(\RR^d)} \leq |U|^{1/p} \| f \|_{L^\infty(\RR^d)} < \varepsilon^{1/p}, \]
  %
%  yet for $q < \infty$, $\| Pf \|_{L^q(S,\sigma)} = \| 1 \|_{L^q(S,\sigma)} = \sigma(S)^{1/q} \gtrsim 1$, and for $q = \infty$, $\| Pf \|_{L^q(S,\sigma)} = 1$. Taking $\varepsilon \to 0$ shows that there cannot exist a bound
  %
%  \[ \| Pf \|_{L^q(S,\sigma)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
%  for all $f \in C_c(\RR^d)$.
%\end{proof}

%\begin{remark}
%  If $S$ has finite, positive measure, and $\sigma$ is the Lebesgue measure restricted to $S$, then a restriction is meaningful, and for each $f \in C_c(\RR^d)$,
  %
%  \[ \| Pf \|_{L^q(S)} \leq |S|^{1/q} \cdot \| f \|_{L^\infty(\RR^d)} \]
  %
%  and
  %
%  \[ \| Pf \|_{L^q(S)} \leq \| f \|_{L^q(\RR^d)}, \]
  %
%  so we can interpolate to conclude that for all $p \geq q$,
  %
%  \[ \| Pf \|_{L^q(S)} \leq |S|^{1/q - 1/p}  \| f \|_{L^p(S)}. \]
  %
%  Thus we can restrict functions to sets of positive measure meaningfully.
%\end{remark}

%For instance, if $f \in L^1(\RR^d)$, then we know $\widehat{f}$ is a \emph{continuous} function on $\RR^d$ vanishing at infinity, with $\| \widehat{f} \|_{L^\infty(\RR^d)}$. It follows that we \emph{do} have a bound
%
%\[ \| \widehat{f} \|_{L^\infty(S,\mu)} \leq \| f \|_{L^1(S)}, \]
%
%where $\widehat{f}$ is integrable on $S$ because it is continuous and bounded. Thus there does exist a bounded operator $R: L^1(\RR^d) \to L^\infty(S,\mu)$ such that $Rf$ is the restriction of the Fourier transform of $f$ to $S$. More generally, it is possible to define a bounded operator $R: L^p(\RR^d) \to L^q(S,\mu)$ such that $Rf = \widehat{f}|_S$ whenever $f \in L^1(\RR^d) \cap L^p(\RR^d)$ by the Hahn-Banach theorem if we have a bound $\| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}$ for any $f \in L^1(\RR^d) \cap L^p(\RR^d)$ (we have to restrict to $L^1(\RR^d)$ so that the Fourier transform is continuous, and can thus be easily restricted to singular sets). The existence of such an operator gives an indication that the structure of Fourier transforms of elements of $L^p(\RR^d)$ are distinguished from an arbitrary element of $L^{p^*}(\RR^d)$. These results are trivial for integrable functions, and \emph{always} fail for square integrable functions (unless $\mu$ is a.c. with respect to the Lebesgue measure). By interpolation, these results also fail on $L^p(\RR^d)$ for $p > 2$ (such bounds even do not even hold when $\mu$ is a.c. with respect to the Lebesgue measure because the Hausdorff-Young inequality fails). Thus the goal for a particular pair $(S,\mu)$ and exponent $q$ is to push the value of $p$ as close to $2$ as possible. Often, we study a smooth surface $S$, and consider a measure $\mu$ which is absolutely continuous with respect to the surface measure on $S$. We shall find that in this setting there is a rich theory relating the existence of restriction maps to the curvature of the surface $S$.

%It should be expected that restriction estimates always hold from $L^1(\RR^d)$ to $L^\infty(S,\mu)$. On the other hand, we do not have \emph{any} restriction estimates from $L^2(\RR^d)$ to $L^q(S,\mu)$ for any $1 \leq q \leq \infty$, unless $\mu$ is absolutely continuous with respect to the Lebesgue measure. The reason for this is Parsevel's theorem, which says that the Fourier transform of a square integrable function behaves like an arbitrary square integrable function; there is no way to meaningfully restrict a morphism from $L^2(\RR^d)$ to $L^q(S,\mu)$, and therefore no such bound holds. The next theorem argues this more rigorously.

%\begin{theorem}
%  For any $0 < q < \infty$, one cannot obtain a bound of the form
  %
%  \[ \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
%  unless $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{theorem}
%\begin{proof}
%  Suppose some such bound held, and $E$ is a compact subset of $\RR^d$ with $|E| = 0$. Then for any $\varepsilon > 0$, we can find $f_\varepsilon \in L^2(\RR^d)$ such that $\widehat{f_\varepsilon}$ is a non-negative function supported on $E_\varepsilon$, equal to one on $E_{\varepsilon/2}$, and satisfying $\| \widehat{f_\varepsilon} \|_{L^\infty(\RR^d)} = 1$. It follows that
  %
%  \[ \| f_\varepsilon \|_{L^2(\RR^d)} = \| \widehat{f_\varepsilon} \|_{L^2(\RR^d)} \leq |E_\varepsilon|. \]
  %
%  On the other hand,
  %
%  \[ \| \widehat{f_\varepsilon} \|_{L^q(S,\mu)} \geq \mu(E_{\varepsilon/2})^{1/q}. \]
  %
%  It follows from outer regularity that
  %
%  \[ \mu(E) \leq \lim_{\varepsilon \to 0} \mu(E_{\varepsilon/2}) \lesssim \lim_{\varepsilon \to 0} |E_\varepsilon|^q = |E|^q = 0. \]
  %
%  Thus $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{proof}

%\begin{remark}
%  Interpolation shows that we cannot have any restriction estimate from $L^p(\RR^d)$ to $L^q(S,\mu)$ for $p \geq 2$ unless $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{remark}

%\begin{remark}
%  The most classical, though slightly trivial, example of a restriction inequality is the Hausdorff-Young inequality, which shows that for $1 \leq p \leq 2$,
  %
%  \[ \| \widehat{f} \|_{L^{p'}(\RR^d)} \leq \| f \|_{L^p(\RR^d)}. \]
  %
%  This is the largest range of exponents for which a bound of this forms, and can be viewed as a restriction inequality when $S = \RR^d$, and where $\mu$ is the Lebesgue measure.
%\end{remark}

There is a dual problem associated with the pair $(S,\mu)$. For $g \in L^1(S,\mu)$, we consider the \emph{extension operator}
%
\[ E_S g(x) = \int_S g(\xi) e^{2 \pi i \xi \cdot x}\; d\mu(\xi). \]
%
In other words, $E_S g$ is the inverse Fourier transform of the finite Borel measure $g \cdot \mu$. Analogous to the restriction operator, it is simple to verify the estimate
%
\[ \| E_S g \|_{L^\infty(\RR^d)} \leq \| g \|_{L^1(S,\mu)}, \]
%
and that unless $\mu$ is absolutely continuous with respect to the Lebesgue measure, no bound of the form
%
\[ \| E_S g \|_{L^2(\RR^d)} \lesssim \| g \|_{L^p(S,\mu)} \]
%
exists. The restriction and extension operators are connected by adjointness for all cases of interest, i.e. using Fubini's theorem that if $f \in L^1(\RR^d)$ and $g \in L^1(S,\mu)$, then
%
\[ \int_S (R_S f)(\xi) \overline{g(\xi)}\; d\mu(\xi) = \int_{\RR^d} f(x) \overline{(E_S g)(x)}\; dx. \]
%
A density argument allows us to conclude that for $1 \leq p < \infty$ and $1 < q \leq \infty$, there exists a bound of the form
%
\[ \| R_S f \|_{L^q(S,\mu)} \leq C \| f \|_{L^p(\RR^d)} \]
%
for all $f \in L^p(\RR^d)$ if and only if there exists a bound of the form
%
\[ \| E_S f \|_{L^{p^*}(\RR^d)} \leq C \| f \|_{L^{q^*}(\RR^d)}. \]
%
But this covers all the cases of interest anyway, since interesting results only hold in the regime $1 < p < 2$ and $p \leq q$.

Restriction bounds for product sets reduce to bounds on their projections. Thus the interesting sets $S$ we consider will never be product sets.

\begin{theorem}
  Consider two pairs $(S_1,\mu_1)$ and $(S_2,\mu_2)$ in $\RR^n$ and $\RR^m$, and let $S = S_1 \times S_2$, $\mu = \mu_1 \times \mu_2$. Then for $0 < p \leq q \leq \infty$, a restriction bound of the form
  %
  \[ \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^{n+m})} \]
  %
  for all $f \in \mathcal{S}(\RR^{n+m})$ is equivalent to a pair of bounds of the form
  %
  \[ \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \lesssim \| f_1 \|_{L^p(\RR^n)} \quad\text{and}\quad \| \widehat{f_2} \|_{L^q(S_2,\mu_2)} \lesssim \| f_2 \|_{L^p(\RR^m)}. \]
  %
  for all $f_1 \in \mathcal{S}(\RR^n)$ and $f_2 \in \mathcal{S}(\RR^m)$. Moreover, the operator norm of the restriction operator to $S$ is the product of the operator norms of the restriction operators to $S_1$ and $S_2$.
\end{theorem}
\begin{proof}
  We calculate that for any pair $f_1,f_2$,
  %
  \[ \| \widehat{f_1 \otimes f_2} \|_{L^q(S,\mu)} = \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \| \widehat{f_2} \|_{L^q(S_2,\mu_2)}. \]
  %
  and
  %
  \[ \| f_1 \otimes f_2 \|_{L^p(\RR^{n+m})} = \| f_1 \|_{L^p(\RR^n)} \| f_2 \|_{L^p(\RR^m)}. \]
  %
  If a restriction estimate held on $(S,\mu)$, it would then follow that
  %
  \[ \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \lesssim \frac{\| f_2 \|_{L^p(\RR^d)}}{\| \widehat{f_2} \|_{L^q(S_2,\mu_2)}} \| f_1 \|_{L^p(\RR^n)}. \]
  %
  Choosing any nontrivial choice of $f_2$ gives a restriction estimate on $(S_1,\mu_1)$. By symmetry, we also get a restriction estimate on $(S_2,\mu_2)$.

  Conversely, suppose we have a restriction estimate on $(S_1,\mu_1)$ and $(S_2,\mu_2)$, and $f \in L^1(\RR^{n+m}) \cap L^p(\RR^{n+m})$. Without loss of generality, we may assume by Littlewood's principle that $q \geq p$. If we let $\mathcal{F}_x$ and $\mathcal{F}_y$ denote the Fourier transform in the first and second variables respectively, then by applying Minkowski's inequality and Fubini's theorem we find that
  %
  \begin{align*}
    \| \widehat{f} \|_{L^q(S,\mu)} &= \left( \int_{\RR^m} \int_{\RR^n} |\mathcal{F}_x \mathcal{F}_y f(\xi,\eta)|^q\; d\mu_1(\xi) d\mu_2(\eta) \right)^{1/q}\\
    &\lesssim \left( \int_{\RR^m} \left( \int_{\RR^n} |(\mathcal{F}_y f)(x,\eta)|^p dx \right)^{q/p}\; d\mu_2(\eta) \right)^{1/q}\\
    &\leq \left( \int_{\RR^n} \left( \int_{\RR^m} |(\mathcal{F}_y f)(x,\eta)|^q\; d\mu_2(\eta) \right)^{p/q}\; dx_1 \right)^{1/p}\\
    &\lesssim \left( \int_{\RR^n} \int_{\RR^m} |f(x,y)|^p dy dx \right)^{1/p} = \| f \|_{L^p(\RR^d)}. \qedhere
  \end{align*}
\end{proof}

The main example of current research into restriction theory occurs when $S$ is a smooth surface, and where $\mu = \psi \sigma$, where $\psi \in C_c^\infty(S)$. If $S \subset \RR^d$ is the graph of some smooth function $\phi: U \to \RR$, where $U$ is an open subset of $\RR^{d-1}$, then the restriction estimate is equivalent to an estimate of the form
%
\[ \| \widehat{f}(\eta,\phi(\eta)) \|_{L^q_\eta(U,\psi)} \lesssim \| f \|_{L^p_x}, \]
%
and an extension estimate, equivalent to an estimate of the form
%
\[ \left\| \int_U \psi(\eta) g(\eta) e^{2 \pi i (\eta \cdot x + \phi(\eta) t)}\; d\eta \right\|_{L^{p^*}_x L^{p^*}_t} \lesssim \| g \|_{L^{q^*}(U,\psi)}. \]
%
Since one may always localize a restriction estimate to one of this form if one works with a compactly supported measure, such estimates are no more specific than a general restriction estimate to a compact section of a hypersurface. We shall find that in this setting there is a rich theory relating the existence of restriction maps to the curvature of the surface $S$. The complete resolution of the restriction problem in this setting is not solved, though much is known.

Restriction estimates often appear in the theory of partial differential equations. For instance, a tempered distribution $u$ on $\RR^d$ which solves the free Schr\"{o}dinger equation $\partial_t u = (i / 2 \pi) \Delta_x u$ has space-time Fourier transform supported on the parabola defined by the equation $\tau + |\xi|^2 = 0$, and so there exists a tempered distribution $v$ on $\RR^d$ such that
%
\[ u(x,t) = \int v(\xi) e^{2 \pi i ( \xi \cdot x - |\xi|^2 t )}\; d\xi. \]
%
Similarily, a tempered distribution $u$ on $\RR^n$ which solves the free wave equation $\partial_t^2 u = \Delta_x u$ has space-time Fourier transform support on the light cone defined by the equation $\tau^2 = |\xi|^2$, and thus there exists two tempered distributions $v_1$ and $v_2$ on $\RR^n$ such that
%
\[ u(x,t) = \int v_1(\xi) e^{2 \pi i (\xi \cdot x + |\xi| t )}\; d\xi + \int v_2(\xi) e^{2 \pi i (\xi \cdot x - |\xi| t)}. \]
%
Thus understanding the regularity of solutions to these equations relates to understanding the extension problem for the parabola and light cone.

\begin{example}
    If $S$ is a hyperplane, then \emph{no nontrivial estimates are possible} for the restriction problem. This is because the only possible extension-type estimates of the form
    %
    \[ \left\| \int_{\RR^d} \psi(\eta) g(\eta) e^{2 \pi i (\eta \cdot x)} \right\|_{L^{p^*}_x L^{p^*}_t} \lesssim \| g \|_{L^{q^*}(U,\psi)} \]
    %
    \emph{must have} $p = 1$, since the integral on the left hand side is independent of $t$. The general heuristic that has been developed in restriction theory is that `flatness' is the main feature of the hyperplane preventing better estimates. For curved surfaces, one expects to get a much wider range of estimates.
\end{example}

Since flatness prevents getting good restriction estimates, we are lead to begin our study with the study of surfaces with non-vanishing curvature. The classical model examples of such results are the restriction estimates for the paraboloid and the sphere, where we have additional symmetries to use not present in all surfaces. There are several simple examples which limit the range of estimates one can get for hypersurfaces of nonvanishing curvature. No improvements to these limitations is known, and it is conjecture that outside of these limitations, one can always get an estimate. This is the \emph{restriction conjecture}.

The first limitation follows from stationary phase. Let $S$ be a hypersurface with nonvanishing curvature containing, without loss of generality, the origin. The standard theory of stationary phase shows that if $\psi \in C_c^\infty(\RR^d)$ is supported on a small enough neighborhood of the origin, then for $x$ lying in a cone around the normal vector to the surface at the origin, we have
%
\[ |E_S \psi(x)| \gtrsim |x|^{-(d-1)/2}. \]
%
Thus $E_S \psi \in L^{p^*}(\RR^d)$ if and only if $p^* > 2d/(d-1)$, i.e. if $p < 2d/(d+1)$. Thus we can only have a restriction estimate for $p < 2d/(d+1)$.

The second example is due to Knapp, and called the `Knapp example' in the literature, which is really just studying the extension operator applied to a wave packet. It is obtained by exploiting the uncertainty principle. To construct the Knapp example, by translating and rotating (which by symmetry does not change any estimates in the Fourier transform) we may assume our surface $S$ contains the origin and has normal vector pointing directly upwards at the origin. Consider a bump function $\eta \in C_c^\infty(S)$ supported on a small ball of radius $r$ about the origin, with $\eta(x) = 1$ for $|x| \leq 1$, but with $\| \eta \|_{L^\infty(S)} \leq 1$. Then
%
\[ \| \psi \|_{L^{q^*}(S,\mu)} \sim r^{(d-1)(1 - 1/q)} \]
%
On the other hand, $\eta \cdot \mu$ is support on a `cap'
%
\[ \Theta_r = \{ (\xi,\tau) : |\xi| \leq r, |\tau| \leq c r^2 \} \]
%
for some constant $c > 0$ depending on the surface, but independant of $r$. The uncertainty principle heuristically implies that $E_S \eta$, which is the Fourier transform of $\eta \cdot \mu$, is locally constant on translations of the `tube'
%
\[ \Theta_r^* = \{ (x,t) : |x| \leq 1/r, |t| \leq C/r^2 \}. \]
%
Since $\eta \cdot \mu$ has total mass $\sim r^{d-1}$, we conclude that $E_S \eta(x,t) \gtrsim r^{d-1}$ for $(x,t) \in \Theta_r^*$, and thus that
%
\[ \| E_S \eta \|_{L^{p^*}(\RR^d)} \gtrsim r^{d-1} |\Theta_r^*|^{1/p^*} = r^{(d+1)/p - 2}. \]
%
To be more rigorous, since $E_S \eta(0) \gtrsim r^{d-1}$, it follows from (TODO: record Prop 5.5 of Wolff's notes in these notes) that
%
\[ \int |E_S \eta(x,t)| (1 + rx + r^2t)^{-N}\; dx\; dt \gtrsim_N |\Theta_r^*| r^{d-1} \gtrsim r^{-2} \]
%
H\"{o}lder's inequality implies that if $N$ is chosen larger than $d$, then
%
\begin{align*}
  \int |E_S(\psi)(x,t)| (1 + rx + r^2 t)^{-N}\; dx\; dx_d \lesssim r^{-(d+1)(1/p)} \| E_S \phi \|_{L^{p^*}(\RR^d)},
\end{align*}
%
and so we conclude that $\| E_S \phi \|_{L^{p^*}(\RR^d)} \geq r^{(d+1)(1/p) - 2}$. But this inequality implies that we must have $(d+1)/p - (d-1)/q \leq 2$ if we want an estimate of the form $\| E_S \eta \|_{L^{p^*}(\RR^d)} \lesssim \| \eta \|_{L^{q^*}(S,\mu)}$ to hold.

\begin{remark}
  TODO: If $S$ is a surface passing through the origin whose derivatives vanish to order $k$, consider a variant of the Knapp example which shows how restriction fails in this domain.
\end{remark}

The general belief in the field is that these examples are essentially the only barriers to restriction. Thus for any such pair $1 \leq p,q < \infty$ such that $p < 2d/(d+1)$ and $(d+1)/p - (d-1)/q \leq 2$, we have restriction (and thus extension) bounds from $L^{q^*}(S,\mu)$ to $L^{p^*}(\RR^d)$, and thus a restriction bound from $L^p(\RR^d)$ to $L^q(S,\mu)$. This is the \emph{restriction conjecture}, which, to a large extent, still remains an open problem.



\section{Stein-Tomas Theorem}

The classical result for restriction estimates on surfaces with non-vanishing curvature is the \emph{Stein-Tomas theorem}. If $S$ is a hypersurface in $\RR^d$ with nonvanishing curvature, and $\mu = \psi \sigma$ for some $\psi \in C_c^\infty(\RR^d)$, where $\sigma$ is the surface measure on $S$, then for $p \leq 2(d+1)/(d+3)$,
%
\[ \| \widehat{f} \|_{L^2(S)} \lesssim \| f \|_{L^p(\RR^d)}. \]
%
This result is tight, as shown by the Knapp example. There are many proofs of the Stein-Tomas theorem. The simplest, a proof by Tomas (1975), uses the theory of stationary phase, but has the disadvantage that it does not include the endpoint case where $p = 2(d+1)/(d+3)$.

\begin{theorem}
    Let $S$ be a hypersurface with nonvanishing curvature, and let $\mu = \psi d\sigma$, where $\sigma$ is the surface measure on $S$, and $\psi \in C_c^\infty(S)$. Then if $p < 2(d+1)/(d+3)$, then for $f \in L^1(\RR^d)$,
  %
  \[ \| R_S f \|_{L^2(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}. \]
\end{theorem}
\begin{proof}
  We apply a $TT^*$ argument, which can be used to study the boundedness of any operator whose codomain is a Hilbert space. For $f \in L^1(\RR^d)$,
  %
  \[ (E_S R_S f)(x) = \int_S \widehat{f}(\xi) e^{2\pi i \xi \cdot x} d\mu(\xi) = \mu(-D) f, \]
  %
  The $TT^*$ method implies that the restriction estimate we wish to prove holds if and only if we have a bound of the form
  %
  \[ \| E_S R_S f \|_{L^{p^*}(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
  %
  If $k$ is the convolution kernel associated with $\mu(-D)$, then $E_S R_S f = k * f$, which is a much easier operator to understand than the individual restriction and extension operators. In particular, the fact that $S$ has nonvanishing curvature means that
  %
  \[ |k(x)| \sim \langle x \rangle^{-(d-1)/2}. \]
  %
  This implies that $k \in L^r(\RR^d)$ for $r > 2d/(d-1)$, and lies in $L^{r,\infty}(\RR^d)$ for $r = 2d/(d-1)$. Thus Young's inequality, and it's weak variant, implies that
  %
  \[ \| k * f \|_{L^{p^*}(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  for $p \leq 4d/(3d + 1)$. To improve this bound to hold for $p < 2(d+1)/(d-1)$, we must exploit the oscillation of $k$, which is completely discarded by Young's inequality.

  To argue this, we consider a dyadic decomposition, writing $k(x) = \sum_{j = 0}^\infty k_i(x)$, where $k_0$ is smooth and compactly supported on a ball of radius $O(1)$, and for $j > 0$, $k_j(x) = \text{Dil}_{2^j} \psi \cdot k(x)$ for some $\psi \in C_c^\infty(\RR^d)$. Since $k_0$ is smooth and compactly supported, we immediately obtain that
  %
  \[ \| k_0 * f \|_{L^{p^*}(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
  %
  For $j > 0$, $k_j$ has magnitude $O(2^{-j(d-1)/2})$ on this set, so we obtain from Young's inequality that
  %
  \[ \| k_j * f \|_{L^\infty(\RR^d)} \lesssim 2^{-j(d-1)/2} \| f \|_{L^1(\RR^d)}. \]
  %
  We wish to obtain an $(L^2,L^2)$ bound using orthogonality. We have
  %
  \[ \widehat{k_j} = 2^j (\widehat{k} * \text{Dil}_{1/2^j} \widehat{\psi}) = 2^{jd} (\mu * \text{Dil}_{1/2^j} \widehat{\psi}) = 2^{jd} \int \widehat{\psi}(2^j (\cdot - \xi)) d\mu(\xi). \]
  %
  Now $\mu$ is compactly supported on a hypersurface and has total mass $O(1)$ there. Since $\text{Dil}_{1/2^j} \widehat{\psi}$ is supported in a ball of radius $1/2^j$, we should expect $\widehat{k_j}$ to distribute the mass of $\mu$ onto a $1/2^j$ thickening of a portion of a hypersurface, which has total mass $O(2^{-j(d-1)})$, so that the expect height of the convolution should be $O(2^{j(d-1)})$. Thus
  %
  \[ \| \widehat{k_j} \|_{L^\infty(\RR^d)} \lesssim 2^{jd} \cdot 2^{-j(d-1)} = 2^j. \]
  %
  The rigorous argument is not too interesting (just use the fact that $\widehat{\psi}$ is Schwartz) and left to the reader. Thus we conclude that
  %
  \[ \| k_j * f \|_{L^2(\RR^d)} \lesssim 2^j \| f \|_{L^2(\RR^d)}. \]
  %
  For any $p < 2(d+1)/(d+3)$, interpolation therefore tells us that there is $\varepsilon > 0$ such that
  %
  \[ \| k_j * f \|_{L^{p^*}(\RR^d)} \lesssim 2^{-i \varepsilon} \| f \|_{L^p(\RR^d)}. \]
  %
  Summing up gives the required bounds.
%  Let us recall the more precise formula for $k$. Namely, if $\psi$ is supported on a small enough neighborhood, then the curvature assumption, together with stationary phase, implies that there exists two smooth, radial functions $c_1,c_2: \RR^n \to \CC$ supported on a conically compact set containing $e_n$, and a smooth radial function $\alpha: \RR^n \to \CC$ such that
  %
%  \[ k(x) = \left( c_1(x) e^{2 \pi i |x| \alpha(x)} + c_2(x) e^{- 2 \pi i |x| \alpha(x)} \right) r^{-(n-1)/2} + O(r^{-(n+1)/2}) \]
  %
%  such that $\alpha(e_n) = 0$ and $\nabla \alpha(e_n) = 0$,
  % x = e_n, xi = 0
  % nabla_xi alpha = (nabla n_2)(xi)
%  \[ \alpha(x) = n_1(\xi) \cdot \xi + n_2(\xi) \cdot \phi(\xi) \]
  % Suppose phi(xi) = |xi|^2
  % Then n(xi) is the normalization of (-2xi, 1), i.e. n(xi) = ( -2xi / sqrt(1 + 4|xi|^2) , 1/sqrt(1 + 4|xi|^2),  )
  % Given (x,t) with |(x,t)| = 1, this is the normal vector for xi = -x/2t, which lies in our domain provided that t is closed enough to one.
  % Thus alpha(x,t) = (x,t) \cdot (-x/2t, |x|^2 / 4t^2) = -|x|^2/4t
  % alpha(x,t) = - |x|^2 / 4t sqrt(|x|^2 + t^2)
  %
%  \[ k(r n(\eta_0)) = \int \psi(\eta) e^{- 2 \pi i r n(\eta_0) \cdot (\eta, \phi(\eta))}\; d\eta = c(\eta_0) \psi(\eta_0) e^{- 2 \pi i r n(\eta_0) \cdot \phi(\eta_0)} \]
\end{proof}

\begin{remark}
  The only structure we used about $S$ and $\mu$ here is that $\mu$ has a uniform, Frostman type bound, and that $\widehat{\mu}$ has a geometric decay as frequencies become large. For such a pair one has a bound
  %
  \[ \| R_S f \|_{L^2(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  provided that $1 \leq p < 2(d + \beta - \alpha)/(2d + \beta - 2\alpha)$, where $0 < \alpha < n$, $\beta > 0$, where $|\widehat{\mu}(\xi)| \lesssim \langle \xi \rangle^{-\beta}$ and $|\mu(B_r(x)) \lesssim r^\alpha$.
\end{remark}

The endpoint proof $p = 2(d+1)/(d+3)$ was first given by Stein (1975, unpublished). It involves the same idea, namely, to consider a dyadic decomposition, but to replace the inefficient use of the triangle inequality
%
\[ \| k * f \|_{L^{p^*}(\RR^d)} \leq \sum_{i = 0}^\infty \| k_i * f \|_{L^{p^*}(\RR^d)} \]
%
with a complex interpolation argument. Namely, we prove that for all $t \in \RR$,
%
\[ \left\| \sum_{j > 0} 2^{[\frac{n-1}{2} + i t] j} (f * k_j) \right\|_{L^\infty(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)} \]
%
and that
%
\[ \left\| \sum_{j > 0} 2^{[-1 + it] j} (f * k_j) \right\|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}, \]
%
so that we can apply analytic interpolation. From Young's inequality, the first inequality follows if we can show that
%
\[ \left\| \sum_{j > 0} 2^{[\frac{d-1}{2} + it] j} k_j \right\|_{L^\infty(\RR^d)} \lesssim 1. \]
%
This just follows from the fact that all but consecutive kernels in the sequence $\{ k_j \}$ have disjoint support (this is much more efficient than the triangle inequality), and the appropriate decay. To establish the second inequality, we must show that
%
\[ \left\| \sum_{j > 0} 2^{[(d-1) + it] j} (\mu * \text{Dil}_{1/2^j} \widehat{\psi}) \right\|_{L^\infty(\RR^d)}. \]
%
We must be slightly more efficient than we were before. TODO: See Tao's Notes.

Here is an argument that gives the endpoint for the special case of the sphere, relying on an alternate property of the sphere than curvature.

\begin{lemma}
  Let $\sigma$ be the surface measure of the sphere $S = S^{n-1}$. Then $\sigma * \sigma$ is absolutely continuous with respect to the Lebesgue measure, supported on $|\xi| \leq 2$, and on this set,
  %
  \[ (\sigma * \sigma)(\xi) \lesssim \begin{cases} 1/|\xi| &: 0 < |\xi| \leq 1, \\ (2 - |\xi|)^{(n-3)/2} &: 1 \leq |\xi| \leq 2. \end{cases} \]
\end{lemma}
\begin{proof}
  For each $\varepsilon > 0$, let $\sigma_\varepsilon = (1/\varepsilon) \mathbf{I}_{S_\varepsilon}$. Then $\sigma_\varepsilon$ converges weakly to $\sigma$ as $\varepsilon \to 0$, which implies that $(\sigma_\varepsilon * \sigma_\varepsilon)$ converges to $\sigma * \sigma$ weakly. Now $\sigma_\varepsilon * \sigma_\varepsilon$ is radial. Thus it suffices to bound $(\sigma_\varepsilon * \sigma_\varepsilon)(\xi)$ for $\xi = (r,0)$, where $0 < r \leq 2$. Now
  %
  \[ (\sigma_\varepsilon * \sigma_\varepsilon)(\xi) = |S_\varepsilon \cap (\xi + S_\varepsilon)|. \]
  %
  If $(\alpha,\beta) \in S_\varepsilon \cap (\xi + S_\varepsilon)$, where $\alpha \in \RR$, $\beta \in \RR^{n-1}$, then
  %
  \[ 1 - 2\varepsilon \leq \alpha^2 + \beta^2 \leq 1 + 3\varepsilon\quad\text{and}\quad 1 - 2\varepsilon \leq (\alpha - r)^2 + \beta^2 \leq 1 + 3\varepsilon. \]
  %
  Together, these inequalities imply that $\alpha = r/2 + O(\varepsilon/r)$ and thus $\beta^2 = 1 - r^2/4 + O(\varepsilon + \varepsilon^2/r)$, so $\beta = \sqrt{1 - r^2/4} + O()$. TODO Thus $\alpha$ ranges over an interval of length $O(\varepsilon/r)$, and for each $\alpha$, $\beta$ can vary over a region of $n-1$ dimensional volume $O(\varepsilon)$, so we conclude that
\end{proof}

\section{Bochner-Riesz Multipliers}

One consequence of the Stein-Tomas theorem is a characterization of the boundedness for the Bochner-Riesz multipliers
%
\[ m^\delta(\xi) = (1 - |\xi|^2)_+^\delta. \]
%
Herz showed a necessary condition for boundedness.

\begin{theorem}
    If $m^\delta \in M^p(\RR^d)$, then
    %
    \[ \delta > n \left| \frac{1}{p} - \frac{1}{2} \right| - 1/2. \]
\end{theorem}
\begin{proof}
    An oscillatory integral calculation shows that if $\widehat{K^\delta} = m^\delta$, then
    %
    \[ K_\delta(x) = \frac{C_d \cos(2 \pi |x|)}{|x|^{\frac{d+1}{2} + \delta}} + O(|x|^{- \frac{n+3}{2} + \delta}). \]
    %
    If $\chi$ is the indicator function of the unit ball, then Minkowski's inequality shows that for $1 \leq p \leq \infty$,
    %
    \[ \| K^\delta \|_{L^p(\RR^d)} \lesssim \| m^\delta(D) \chi \|_{L^p(\RR^d)} \lesssim \| m^\delta \|_{M^p(\RR^d)}. \]
    %
    Without loss of generality, we may assume that $p \geq 2$, in which case it suffices to show that one can only have a bound if $d(1/2 - 1/p) - 1/2 < \delta$. But $K^\delta$ lies in $L^p(\RR^d)$ precisely for this range.
\end{proof}

The Bochner Riesz conjecture is that this is \emph{precisely} the range for which the operator is bounded.

\begin{theorem}
    Suppose that
    %
    \[ \| R \]
\end{theorem}
\begin{proof}
    Assume $p \geq 2$. We break the kernel $K^\delta$ into dyadic space regions, i.e.
    %
    \[ K^\delta = \sum_{j = 0}^\infty K^\delta_j, \]
    %
    where $K^\delta_0$ is supported in the ball of radius 2, and
    %
    \[ K^\delta_j(x) = \psi(x/2^j) K^\delta(x) = \psi_j(x) K^\delta(x). \]
    %
    Our proof will be complete if we can show that
    %
    \[ \| K^\delta_j * f \|_{L^p(\RR^d)} \lesssim 2^{[n(1/p - 1/2) - 1/2 - \delta] j} \| f \|_{L^p(\RR^d)}. \]
    %
    Since the support of $K^\delta_j * f$ lies on a $2^j$ thickening of the support of $f$, a decomposition argument implies that it suffices to show the result for any function $f$ supported on a ball of radius $2^j$ at the origin. To make this look more like Tomas-Stein, we note that for such a function $f$, $K^\delta_j * f$ is supported on a ball of radius $O(2^j)$, and thus
    %
    \[ \| K^\delta_j * f \|_{L^p(\RR^d)} \lesssim 2^{dj(1/p - 1/2)} \| K^\delta_j * f \|_{L^2(\RR^d)}. \]
    %
    Thus it suffices to show that
    %
    \[ \| K_\delta^j * f \|_{L^2(\RR^d)} \lesssim 2^{-(1/2 + \delta)j} \| f \|_{L^p(\RR^d)}. \]
    %
    Plancherel shows that it suffices to prove that
    %
    \[ \| [ \widehat{\psi_j} * m^\delta] \cdot \widehat{f}(\xi) \|_{L^2_\xi} \lesssim 2^{-(1/2 + \delta) j} \| f \|_{L^p_x} \]
    %
    Now $\psi_j$ is supported away from the origin, and thus it's Fourier transform is highly oscillatory. The multiplier $m^\delta$ is also proportionally smooth. Thus we should expect $\widehat{\psi_j} * m^\delta$ to have some decay by virtue of some cancellation. The `high frequency' terms that make up $m^\delta$ are supported near the boundary of the sphere, since the function is smooth everywhere else. We will actually obtain that
    %
    \[ |(\widehat{\psi_j} * m^\delta)(\xi)| \lesssim_N 2^{-\delta j} \langle 2^j ||\xi| - 1| \rangle^{-N}. \]
    %
    Thus we get rapid decay outside of the annulus of thickeness $1/2^j$. It thus suffices to show that if $N$ is suitably large, then
    %
    \[ \int \frac{|\widehat{f}(\xi)|^2}{\langle 2^j ||\xi| - 1| \rangle^N}\; d\xi \lesssim \| f \|_{L^p(\RR^n)}. \]
    %
    The fact that $f$ is compactly supported allows us to use the pointwise bound $|\widehat{f}(\xi)| \lesssim 2^{O(j)} \| f \|_{L^p(\RR^d)}$, which gives the estimate for $||\xi| - 1| \geq 1/2$. The remaining integrand then follows by switching to polar coordinates, and then applying the restriction theorem.

    Now let us justify that
    %
    \[ |(\widehat{\psi_j} * m^\delta)(\xi)| \lesssim_N 2^{-\delta j} \langle 2^j ||\xi| - 1| \rangle^{-N}. \]
    %
    This motivates us to perform the decomposition
    %
    \[ m^\delta(\xi) = m^\delta(\xi) \phi(2^j(|\xi| - 1)) + m^\delta(\xi) [1 - \phi(2^j(|\xi| - 1))] = m^\delta_1(\xi) + m^\delta_2(\xi), \]
    %
    where $\phi \in C_c^\infty[0,\infty)$ equals one in a neighborhood of the origin. The symbol $m^\delta_1(\xi)$ is now supported on the annulus of thickness $O(2^{-j})$ and radius 1. The height of the symbol is also $O(2^{- \delta j})$. Thus
    %
    \[ |(\widehat{\psi_j} * m^\delta_1)(\xi)| \lesssim \int_{| r - 1| \sim 2^{-j}} 2^{- \delta j} (|\widehat{\psi_j}| * \sigma_r)\; dr. \]
    %
    The fact that $\sigma_r * |\widehat{\psi}_j| \lesssim_N 2^j \langle 2^j ||x| - 1| \rangle^{-N}$ shows this contribution is acceptable. The remaining term is estimated via integration by parts (one may antidifferentiate $\psi_j$ without introducing any problems since it vanishes near the origin). TODO.
\end{proof}

\section{Restriction on the Paraboloid}

The main way we can extend local estimates to global estimates is to apply some kind of symmetry property, normally scaling. Let us use this technique to show that we can extend the result of the Tomas-Stein theorem to give the same bounds for restriction to the non-compact elliptic paraboloid
%
\[ S = \{ (\xi,\omega) \in \RR^{d-1} \times \RR: |\xi|^2 = \omega \}. \]
%
We work with extension estimates, setting, for a function $f: \RR^{d-1} \to \CC$,
%
\[ Ef(x,t) = \int_{\RR^{d-1}} e^{2 \pi i (|\xi|^2 t + \xi \cdot x)} f(\xi)\; d\xi. \]
%
Our goal is to show bounds of the form $\| Ef \|_{L^p(\RR^d)} \lesssim \| f \|_{L^2(\RR^{d-1})}$. This is possible, provided that$p = 2(d+1)/(d+3)$.

\begin{theorem}
  If $p = 2(d+1)/(d+3)$, then for any $f \in \mathcal{S}(\RR^{d-1})$,
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^2(\RR^{d-1})}. \]
\end{theorem}
\begin{proof}
  The Tomas-Stein theorem gives the required bound for any $f \in C_c^\infty(\RR^d)$, where the implicit constant depends on the support of $f$. For such $f$, define
  %
  \[ Ef(x,t) = \int_{\RR^{d-1}} e^{2 \pi i (|\xi|^2 t + \xi \cdot x)} f(\xi)\; d\xi. \]
  %
  We note that $E(\text{Dil}_{\xi,a} f) = a^{d-1} \cdot \text{Dil}_{a^{-2},t} \text{Dil}_{a^{-1},x}(Ef)$, in light of the `parabolic symmetry' of the extension operator. Given a function $f \in C_c^\infty(\RR^d)$ supported on a ball of radius $R$ at the origin, $\text{Dil}_{\xi,1/R} f$ is supported on a ball of radius 1 at the origin, and so Tomas-Stein says that
  %
  \[ \| E(\text{Dil}_{\xi,1/R} f) \|_{L^{p'}(\RR^d)} \lesssim \| \text{Dil}_{\xi,1/R} f \|_{L^2(\RR^{d-1})} = R^{-(d-1)/2} \cdot \| f \|_{L^2(\RR^{d-1})}, \]
  %
  where the implicit constant is independent of $f$. But we also know that
  %
  \begin{align*}
    \| E(\text{Dil}_{\xi,1/R} f) \|_{L^{p'}(\RR^d)} &= R^{1-d} \| \text{Dil}_{R^2,t} \text{Dil}_{R,x}(Ef) \|_{L^{p'}(\RR^d)}\\
    &= R^{1-d} R^{2/p'} R^{(d-1)/p'} \| Ef \|_{L^{p'}(\RR^d)},
  \end{align*}
  %
  and so we conclude that
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim R^{(d-1)/2-(d+1)/p'} \| f \|_{L^2(\RR^{d-1})} = \| f \|_{L^2(\RR^{d-1})}. \]
  %
  In other words, we have found a bound independant of the support of $f$. A simple approximation argument extends the bound to general $f \in \mathcal{S}(\RR^d)$.
\end{proof}

\begin{remark}
  The same scaling symmetries show that we can only have an extension bound
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(\RR^{d-1})} \]
  %
  if $(d+1)/p' = (d-1)/q$. For $q = 2$, this shows the above result is tight.
\end{remark}

It is a general heuristic that the extension theory for the paraboloid is essentially the same as the extension theory for a cap of a curve point. In particular, if we have a bound of the form
%
\[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(S,\mu)}, \]
%
where $(d+1)/p' = (d-1)/q$, and where $\mu$ is a smooth measure supported on a small cap around the neighbourhood of a point with non-vanishing curvature. One can then approximate the paraboloid by a rescaling of the cap, and thus obtain a bound of the form
%
\[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(\RR^{d-1})} \]
%
for any $f \in \mathcal{S}(\RR^{d-1})$, where $E$ is the extension function on the paraboloid TODO: Prove This. Thus, despite one theory being local and the other being global, the theories of these two extension operators are roughly equivalent. Every result obtained in one setting can essentially be translated to the other setting.

\begin{comment}
for all $f \in C_c^\infty(\RR^d)$. For large $R > 0$, let $T_R(x,x_d) = (Rx,R^2x_d + R^4)$, and let $S_R = T_R(S^{d-1})$. Then
%
\[ S_R = \left\{ (x,x_d): |x_d - R^4|^2 = R^4 \left(1 - |x|^2/R^2 \right) \right\}. \]
%
For $f \in L^{q'}(S_R)$, $T_R^*f \in L^{q'}(S^{d-1})$, and
%
\[ \| T_R^* f \|_{L^{q'}(S^{d-1})} = R^{-d/q'} \| f \|_{L^{q'}(S_R)}. \]
%
If we let $E_R f = \widehat{f \cdot \sigma_R}$ be the extension operator associated with $S_R$, where $\sigma_R$ is the surface measure in $S_R$, and let $Ef = \widehat{f \cdot \sigma}$ be the extension operator associated with $S^{d-1}$, where $\sigma$ is the surface area on the unit sphere. Then $(T_R)_* \sigma = R^{-d} \sigma_R$, and so for any given $f \in C_c^\infty(\RR^d)$, we calculate simply that
%
\[ E(T_R^* f)(x,x_d) = R^{-d} e^{2 \pi i x_d} E_R f(x/R,x_d/R^2). \]
%
Thus
%
\[ \| E(T_R^* f) \|_{L^{p'}(\RR^d)} = R^{(d+1)/p'-d} \| E_R f \|_{L^{p'}(\RR^d)} \]
%
Thus we conclude that
%
\[ \| E_R f \|_{L^{p'}(\RR^d)} \lesssim R^{d-(d+1)/p'} \|T_R^* f \|_{L^{q'}(S^{d-1})} = R^{d(1-1/q')-(d+1)/p'} \| f \|_{L^{q'}(S_R)}. \]
%
TODO: Show that restriction for the sphere implies restriction for the paraboloid, and vice versa.
\end{comment}

\section{Restriction to the Cone}

TODO: Conjectured Estimates

TODO: Lorentz Invariant

TODO: Application to the wave equation.

\section{TODO: Hardy Littlewood Majorant Conjecture}




\chapter{Almost Orthogonality}

It is a standard result of Hilbert space theory that if $\{ e_n \}$ are a family of pairwise orthogonal vectors in a Hilbert space $H$, then Parseval's inequality
%
\[ \| \sum_n a_n e_n \|_H = \left( \sum |a_n|^2 \right)^{1/2} \]
%
holds. In many cases in analysis, we do not have \emph{perfect} orthogonality, but we know that $\langle e_n, e_m \rangle$ is small for most pairs $n$ and $m$. For general non-orthogonal vectors we do have the identity
%
\[ \| \sum_n a_n e_n \|_H^2 = \sum a_n \overline{a_m} \langle e_n, e_m \rangle. \]
%
Here is a simple result which exploits this identity.

\begin{lemma}
  Suppose $\{ e_n : n \in \ZZ^d \}$ is a family of vectors such that there is $\delta > 0$ with
  %
  \[ \langle e_n, e_m \rangle \leq \frac{C}{\langle n - m \rangle^{d + \delta}}. \]
  %
  Then
  %
  \[ \| \sum_n a_n e_n \| \lesssim_\delta C^{1/2} \left( \sum |a_n|^2 \right)^{1/2} \]
\end{lemma}
\begin{proof}
  Applying Cauchy-Schwartz and Young's convolution inequality, we conclude that
  %
  \begin{align*}
    \| \sum_n a_n e_n \|_H^2 &\leq C \sum_n |a_n| \sum_m \frac{|a_m|}{\langle n - m \rangle^{d + \delta}}\\
    &\leq C \left( \sum_n |a_n|^2 \right)^{1/2} \left( \sum_n \left( \sum_m \frac{|a_m|}{\langle n - m \rangle^{d + \delta}} \right)^2 \right)^{1/2}\\
    &\lesssim_\delta C \left( \sum_n |a_n|^2 \right).
  \end{align*}
  %
  We then just take square roots on both sides of the formula.
\end{proof}

Let us consider some examples of almost orthogonal systems.

\begin{example}
  Consider $f \in L^2(\RR^d)$ with compact support, and set $e_n = \text{Trans}_n f$. The $\langle e_n, e_m \rangle \neq 0$ only if $|n - m| \lesssim 1$, and then we have the trivial bound $\langle e_n, e_m \rangle \leq \| f \|_{L^2(\RR^d)}^2$. Thus we conclude that
  %
  \[ \| \sum a_n e_n \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)} \left( \sum |a_n|^2 \right)^{1/2}. \]
  %
  In this situation, another way to prove this inequality is to break up the sum into arithmetic subsequences which have a high enough gap so that the sums \emph{are} over functions with disjoint support, in which case we have true orthogonality. Summing up the subsums then gives the result.
\end{example}

\begin{example}
  Given $\phi \in C_c^\infty(\RR^d)$, and consider $e_n = \text{Mod}_n f$. Then
  %
  \[ \langle e_n, e_m \rangle = \int |\phi(x)|^2 e^{2 \pi i (n - m) \cdot x}\; dx. \]
  %
  We can then apply the theorem of nonstationary phase, which gives
  %
  \[ |\langle e_n, e_m \rangle \lesssim_k \frac{1}{\langle n - m \rangle^k} \]
  %
  for any $k$. Thus this is an almost orthogonal system.
\end{example}

For almost orthogonal systems, we do \emph{not} have a lower bound
%
\[ \| \sum a_n e_n \|_{L^2(\RR^d)} \gtrsim \left( \sum |a_n|^2 \right)^{1/2}. \]
%
Indeed, the decay does not preclude us from choosing the same two vectors for different indices, which give complete cancellation for appropriately chosen constants.

\begin{example}
  Consider a family of vectors $\{ e_n \}$ in $L^2(\RR^d)$ such that for each $n$, the support of $e_n$ intersects the support of $O(1)$ other vectors $e_m$. Do we have almost orthogonality here?
\end{example}



The most well used almost orthogonality result is the Cotler-Stein lemma, which enables us to bound sums of operators which are almost orthogonal (the bounded operators from a Hilbert space to itself form a Hilbert space). To begin with, let us treat the case where we are dealing with a family of operators which are pairwise orthogonal.

\begin{lemma}
    Let $\{ T_n \}$ be a sequence of operators on a Hilbert space $H$ with $\sup_n \| T_n \| < \infty$ for each $n$, and such that $T_i^* T_j = T_i T_j^* = 0$ for any $i \neq j$. If
    %
    \[ S_N = \sum_{n = 1}^N T_n, \]
    %
    then $S_N$ converges in the strong topology to an operator $S$ with $\| S \| \leq 1$.
\end{lemma}
\begin{proof}
    Since $T_i^* T_j = 0$ for $i \neq j$, it follows that the image of $T_j$ is contained in the kernel of $T_i^*$, which is the orthogonal complement of the image of $T_i$. Thus the images $\{ V_i \}$ of the operators $\{ T_i \}$ are all orthogonal to one another. By symmetry, the images $\{ W_i \}$ of the operators $\{ T_i^* \}$ are all orthogonal to one another. Now $W_i$ is the orthogonal complement of the kernel of $T_i$. Thus if $x = x_0 + \sum_i x_i$, with $x_0$ perpendicular to all $W_i$, and $x_i \in W_i$, then $\| T_ix \| = \| T_i x_i \|$. But this means that for any $x \in H$,
    %
    \begin{align*}
        \| S_N x \|^2 &= \sum \| T_i x \|^2\\
        &= \sum \| T_i x_i \|^2\\
        &\leq \sum \| x_i \|^2\\
        &\leq \| x \|^2.
    \end{align*}
    %
    Thus $\| S_N x \| \leq \| x \|$, and so $\| S_N \| \leq 1$. Now since $\sum_{i > N} \| x_i \|^2 \to 0$ as $i \to \infty$ for any $x \in H$, it follows that $\{ S_N x \}$ is Cauchy, and so there exists a limit $S x$. It is now simple to prove $S$ is a bounded linear operator with $\| S \| \leq 1$.
\end{proof}

\begin{remark}
    The important point here is that not only are the outputs to all the operators mutually orthogonal, i.e. $T_i^* T_j = 0$, nor are the important imputs to each of the operators mutually orthogonal, i.e. $T_i T_j^* = 0$, but both points are actually true. If only one of these was true, we could only get a bound of the form $\| S_N \| \lesssim \sqrt{N}$.
\end{remark}

Cotler-Stein gives an analogous result for almost orthogonal families of operators.

\begin{theorem}[Cotler Stein]
  Let $H_1$ and $H_2$ be Hilbert spaces, and consider a family of bounded operators $\{ T_\alpha : H_1 \to H_2 \}$. Let $a_{\alpha \beta} = \| T_\alpha T_\beta^* \|$ and let $b_{\alpha \beta} = \| T_\alpha^* T_\beta \|$. Then if
  %
  \[ A = \sup_\alpha \sum_\beta \sqrt{a_{\alpha \beta}} \quad\text{and}\quad B = \sup_\alpha \sum_\beta \sqrt{b_{\alpha \beta}} \]
  %
  are both finite, then $\sum T_\alpha$ converges unconditionally in the strong operator topology, and
  %
  \[ \left\| \sum T_\alpha \right\| \leq \sqrt{AB}. \]
\end{theorem}

One can often extend almost orthogonality to obtain bounds in other $L^p$ spaces via applying interpolation. Here is such a version I encountered in Heo, Nazarov, and Seeger's paper \emph{Radial Fourier Multipliers in High Dimensions}.

\begin{theorem}
  Consider a family of functions $\{ f_n : n \in \ZZ^d \}$ in $L^2(\RR^d)$, together with a family of sidelength one cubes $\{ Q_n \}$ in $\RR^d$ such that $\text{supp}(f_n) \subset Q_n$. Suppose
  %
  \[ |\langle f_n, f_m \rangle| \leq \frac{1}{\langle n - m \rangle^\beta}. \]
  %
  for some $\beta \in (0,d)$. Then for $p < 2d/(2d - \beta)$,
  %
  \[ \left\| \sum a_n f_n \right\|_{L^p(\RR^d)} \lesssim_{d,\beta,p} \left( \sum |a_n|^p \right)^{1/p} \]
\end{theorem}

\begin{remark}
  If $\beta > d$, then Young's convolution inequality implies that
  %
  \begin{align*}
    \left\| \sum a_n f_n \right\|_{L^2(\RR^d)} &= \left( \sum_{n,m} a_n \overline{a_m} \langle f_n,f_m \rangle \right)^{1/2}\\
    &\leq \left( \sum_{n,m} \frac{a_n \overline{a_m}}{\langle n - m \rangle^\beta} \right)^{1/2}\\
    &\leq \left( \sum_n |a_n|^2 \right)^{1/4} \left( \sum_n \left| \sum_m \frac{\overline{a_m}}{\langle n - m \rangle^\beta} \right|^2 \right)^{1/2}\\
    &\leq \left( \sum_n |a_n|^2 \right)^{1/2} \left( \sum_n \frac{1}{\langle n \rangle^\beta} \right)\\
    &\lesssim_{\beta,d} \left( \sum_n |a_n|^2 \right)^{1/2}
  \end{align*}
  %
  Thus one can view $\beta < d$ as a case where we have some, but not enough orthogonality to prove an $L^2$ orthogonality bound.
\end{remark}

\begin{proof}
  We view this result as proving the boundedness of the operator
  %
  \[ a \mapsto \sum_n a_n f_n \]
  %
  from $l^p(\ZZ^d)$ to $L^p(\RR^d)$. We shall prove that for $1 \leq p \leq 2d/(2d - \beta)$, a \emph{restricted strong type inequality holds}, from which the general bound holds by interpolation. It suffices to show that for any finite set of indices $I \subset \ZZ^d$,
  %
  \[ \| \sum_{n \in I} f_n \|_{L^p(\RR^d)} \lesssim \#(I)^{1/p}. \]
  %
  Partition $\RR^d$ into an almost disjoint family of sidelength one cubes $\{ R_\alpha \}$, define $I_\alpha = \{ n \in I : Q_n \cap R_\alpha \neq \emptyset \}$, and set $F_\alpha = \sum_{n \in I_\alpha} f_n$. Now for each $x \in \RR^d$, there are at most $3^d$ indices $\alpha$ such that $F_\alpha(x) \neq 0$. Thus
  %
  \[ \| \sum_{n \in I} f_n \|_{L^p(\RR^d)} = \| \sum_\alpha F_\alpha \|_{L^p(\RR^d)} \leq 3^d \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p}. \]
  %
  Applying the almost-orthogonality of the functions $\{ f_n \}$,
  %
  \begin{align*}
    \| F_\alpha \|_{L^2(\RR^d)}^2 &\leq \sum_{n,m \in I_\alpha} \frac{1}{\langle n - m \rangle^\beta}\\
    &\leq \sum_{n \in I_\alpha} \sum_{|m| \lesssim \#(I_\alpha)^{1/d}} \frac{1}{\langle n - m \rangle^\beta}\\
    &\lesssim \#(I_\alpha) \cdot \#(I_\alpha)^{1-\beta/d}
  \end{align*}
  %
  Thus $\| F_\alpha \|_{L^2(\RR^d)} \lesssim \#(I_\alpha)^{1 - \beta/2d}$. Combined with the fact that $F_\alpha$ is supported on a sidelength $O(1)$ cube, we conclude that for $0 < p \leq 2$, $\| F_\alpha \|_{L^p(\RR^d)} \lesssim_p \| F_\alpha \|_{L^2(\RR^d)}$. But putting this together means that
  %
  \[ \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p} = \left( \sum_\alpha \#(I_\alpha)^{p(1 - \beta/2d)} \right)^{1/p} \]
  %
  Provided that $p(1 - \beta/2d) \leq 1$, i.e. $p \leq 2d/(2d - \beta)$, we have
  %
  \[ \sum_\alpha \#(I_\alpha)^{p(1 - \beta/2d)} \leq \sum \#(I_\alpha) = \#(I) \]
  %
  and so we conclude that
  %
  \[ \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p} \lesssim \#(I)^{1/p}, \]
  %
  which completes the proof of the restricted strong type bound.
\end{proof}







\chapter{Weighted Estimates}

\section{Hardy-Littlewood Maximal Function}

Let us consider a basic weighted estimate for the Hardy-Littlewood maximal function.

\begin{theorem}
  Suppose $w > 0$ is a measurable function. Then for any $f \in L^1_{\text{loc}}(\RR^d)$, we have the weak type bound
  %
  \[ \int_{\RR^d} \mathbf{I} \left( |Mf(x)| > \lambda \right) w(x)\; dx \lesssim_d \frac{1}{\lambda} \int_{\RR^d} |f(x)| Mw(x)\; dx, \]
  %
  and for all $1 \leq p \leq \infty$, we have the strong type bound
  %
  \[ \left( \int_{\RR^d} |Mf(x)|^p w(x)\; dx \right)^{1/p} \lesssim_{d,p} \left( \int_{\RR^d} |f(x)|^p Mw(x)\; dx \right)^{1/p}. \]
\end{theorem}
\begin{proof}
  The result automatically follows for $p = \infty$, so by the Stein-Weiss interpolation theorem it suffices to obtain the weak-type bound. We work similarily to the standard Vitali-type approach. Renormalizing, to complete the proof it suffices to show that for any compact set $K$ such that $|Mf(x)| > 1$ for all $x \in K$,
  %
  \[ \int_K w(x)\; dx \lesssim_d \int_{\RR^d} |f(x)| Mw(x)\; dx. \]
  %
  Find a disjoint family of balls $B_1,\dots,B_N$ such that $3B_1,\dots,3B_N$ covers $K$, and $\int_{B_i} |f(x)|\; dx \gtrsim_d 1$ for each $i$. Then
  %
  \[ \int_K w(x)\; dx \leq \sum_{i = 1}^N \int_{3B_i} w(x)\; dx \]
  %
  and so it suffices to show that
  %
  \[ \int_{3B_i} w(x)\; dx \lesssim_d \int_{B_i} |f(x)| Mw(x)\; dx. \]
  %
  But for $x \in B_i$, we have
  %
  \[ Mw(x) \gtrsim_d \frac{1}{|B_i|} \int_{3B_i} w(y)\; dy \]
  %
  from which the claim follows.
\end{proof}

A simple corollary is a vector-valued generalization of the Hardy-Littlewood inequality.

\begin{theorem}
  If $1 < p,q < \infty$  and $\{ f_n \}$ are any sequence of functions in $L^1_{\text{loc}}(\RR^d)$, then
  %
  \[ \left\| \left( \sum_n |Mf_n|^p \right)^{1/p} \right\|_{L^q(\RR^d)} \lesssim_{d,p,q} \left\| \left( \sum_n |f_n|^p \right)^{1/p} \right\|_{L^q(\RR^d)} \]
  %
  and
  %
  \[ \left| \left\{ x : \left( \sum_n |Mf_n(x)|^p \right)^{1/p} \geq \lambda \right\} \right| \lesssim_{d,p} \frac{1}{\lambda} \cdot \left\| \left( \sum_n |f_n(x)|^p \right)^{1/p} \right\|_{L^1(\RR^d)}. \]
\end{theorem}
\begin{proof}
  For $p = q$, the theorem follows from the standard Hardy-Littlewood maximal inequality. For $p < q$ we apply the equivalence between vector-valued bounds and weight bounds. To prove the remaining case, it suffices to prove the weak-type estimate for $p > 1$. By linearization, we may find radii $r_n(y)$ such that
  %
  \[ |Mf_n(y)| \leq \frac{1}{|B(y,r_n(y))} \int_{\RR^d} \psi_n(x,y) f_n(y)\; dy, \]
  %
  where $\psi_n(x,y)$ is a smooth bump function which equals one for $x \in B(y,r_n(y))$ and vanishes for $x \not \in 2B(y,r_n(y))$. Thus it suffices to obtain a weak-type bound for the vector-valued operator
  %
  \[ T(\{ f_n \})(y) = \left\{ \int_{\RR^d} \frac{1}{|B(y,r_n(y))|} \psi_n(x,y) f_n(x)\; dx \right\}. \]
  % 
  This is a vector-valued kernel operator with kernel $K(x,y)$ the diagonal matrix with entry. TODO: SEE TAO.
\end{proof}





\chapter{Bellman Function Methods}

It is interesting to ask whether we can obtain bounds of the form
%
\[ \| M f \|_{L^p(\RR^d)} \lesssim_{d,p} \| f \|_{L^p(\RR^d)} \]
%
without employing any interpolation techniques. This is possible, though nontrivial. We begin with a Bellman function approach, which works best in the dyadic scheme, i.e. proving bounds on $M_\Delta$.

The idea here is to perform an \emph{induction on scales}, i.e. to induct on the complexity of the function $f$. For a fixed $f \in L^p(\RR^d)$, our goal is to obtain bounds of the form
%
\[ \left( \int |M_\Delta f(x)|^p\; dx \right)^{1/p} \lesssim \left( \int |f(x)|^p \right)^{1/p} \]
%
where the implicit constant is independent of $p$.

We begin by applying some monotone convergence arguments to simplify our analysis. For each $x \in \RR^d$, $|M_\Delta f(x)| = \lim_{m \to -\infty} |M_{\geq m} f(x)|$, where $M_{\geq m}$ is the operator giving a maximal average over all dyadic cubes containing a point with sidelength exceeding $2^m$, and the limit is monotone increasing. It follows that for any $f \in L^p(\RR^d)$,
%
\[ \| M_\Delta f \|_{L^p(\RR^d)} = \lim_{m \to -\infty} \| M_{\geq m} f \|_{L^p(\RR^d)}. \]
%
Thus if we can obtain a bound
%
\[ \| M_{\geq m} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
with a bound independant of $m$, we would obtain the required bound on $M_\Delta$. But if we could obtain a bound
%
\[ \| M_{\geq 0} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for all $f \in L^p(\RR^d)$, then a rescaling argument, using the fact that
%
\[ M_{\geq m} f = \text{Dil}_{1/2^d} M_{\geq 0} \text{Dil}_{2^d} f \]
%
shows that we in fact have
%
\begin{align*}
  \| M_{\geq m} f \|_{L^p(\RR^d)} &= 2^{d/p} \| M_{\geq 0} \text{Dil}_{2^d} f \|_{L^p(\RR^d)}\\
  &\lesssim 2^{d/p} \| \text{Dil}_{2^d} f \|_{L^p(\RR^d)} = \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus we need only concentrate on the operator $M_{\geq 0}$. Finally, we note we can \emph{localize} our estimates. Given a function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, and given $x \not \in Q$, then there exists a smallest value $m_x > n$ such that $x$ is contained in a dyadic cube with sidelength $2^{m_x}$ which also contains $Q$. It then follows that
%
\[ (M_{\geq 0} f)(x) = \frac{\int_Q |f(y)|\; dy}{2^{dm_x}} = \frac{\| f \|_{L^1(Q)}}{2^{dm_x}} \]
%
For each $m > n$, if we set $E_m = \{ x \in \RR^d: m_x = m \}$, then $E_m$ is contained in a dyadic cube of sidelength $2^m$, so $|E_m| \leq 2^{dm}$. Thus we have
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q^c)} &= \left( \sum_{m = n+1}^\infty \| M_{\geq 0} f \|_{L^p(E_m)}^p \right)^{1/p}\\
  &\leq \left( \sum_{m = n+1}^\infty \left( \| f \|_{L^1(Q)}^p / 2^{dpm} \right) 2^{dm} \right)^{1/p}\\
  &\lesssim_{d,p} \| f \|_{L^1(Q)} 2^{dn(1/p - 1)} = \| f \|_{L^1(Q)} |Q|^{1/p-1} \leq \| f \|_{L^p(Q)}.
\end{align*}
%
Thus, if we obtained the bound $\| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}$, then we would find
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &\leq \| M_{\geq 0} f \|_{L^p(Q)} + \| M_{\geq 0} f \|_{L^p(Q^c)} \lesssim \| f \|_{L^p(Q)}.
\end{align*}
%
Thus if $f$ is supported on a dyadic cube $Q$, it suffices to estimate $M_{\geq 0} f$ on the support of $f$. But by a final monotone convergence argument, it suffices to bound such functions, since given any $n$ we can write $[-2^n,2^n]$ as the almost disjoint union of $2^d$ sidelength $2^d$ dyadic cubes $Q_{n,1},\dots,Q_{n,2^d}$. For any $f \in L^p(\RR^d)$, we consider a pointwise limit $f = \lim_{n \to \infty} f_{n,1} + \dots + f_{n,2^d}$, where $f_{n,i}$ is equal to $f$ restricted to $Q_{n,i}$, and the limit is monotone. We also have
%
\[ M_{\geq 0} f = \lim_{n \to \infty} M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d}. \]
%
where the limit is pointwise and monotone, so
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &= \lim_{n \to \infty} \| M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d} \|_{L^p(\RR^d)}\\
  &\lesssim \lim_{n \to \infty} \| f_{n,1} \|_{L^p(\RR^d)} + \dots + \| f_{n,2^d} \|_{L^p(\RR^d)} \lesssim 2^d \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus, after a technical reduction argument, we now show that we only have to establish a bound
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}, \]
%
where $f \in L^p(Q)$, $Q$ is a dyadic cube with sidelength $\geq 1$, and the implicit constant is independant of $Q$.

To carry out the inequality, we perform an \emph{induction on scales}. For each $n \geq 0$, we let $C(n)$ denote the optimal constant such that for any function $f \in L^p(\RR^d)$ supported on a dyadic cube $Q$ of sidelength $2^n$,
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n) \cdot \| f \|_{L^p(Q)}. \]
%
If $n = 0$, the problem is trivial, since if $Q$ is dyadic with sidelength $1$ and $x \in Q$, then
%
\[ M_{\geq 0} f = \fint_Q |f(y)|\; dy \]
%
so $\| M_{\geq 0} f \|_{L^p(Q)} = \| f \|_{L^1(Q)}$, and $C(0) = 1$. Our goal is to show that $\sup_{n \geq 0} C(n) < \infty$. Given $f$ supported on a cube $Q$ with sidelength $2^n$, the cube has $2^d$ children $Q_1,\dots,Q_{2^d}$ with sidelength $2^{n-1}$. If we decompose $f = f_1 + \dots + f_{2^d}$ onto these cubes, then by induction we know that
%
\[ \| M_{\geq 0} f_i \|_{L^p(Q_i)} \leq C(n-1) \| f_i \|_{L^p(Q_i)}. \]
%
Now for $x \in Q_i$,
%
\[ (M_{\geq 0} f)(x) = \max \left(M_{\geq 0} f_i(x), \fint_Q |f(y)|\; dy \right). \]
%
Thus if $A = \fint_Q |f(y)|\; dy$, then
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q)} &= \left( \| M_{\geq 0} f \|_{L^p(Q_1)}^p + \dots + \| M_{\geq 0} f \|_{L^p(Q_{2^d})}^p \right)^{1/p}\\
  &= \left( \| \max(M_{\geq 0} f_1, A) \|_{L^p(Q_1)}^p + \dots + \| \max(M_{\geq 0} f_{2^d}, A) \|_{L^p(Q_{2^d})}^p \right)^{1/p}
\end{align*}
%
The bound $\max(M_{\geq 0} f_i, A) \leq M_{\geq 0} f_i + A$ gives
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n-1) \| f \|_{L^p(Q)} + 2^{d/p} |Q|^{1/p} A = (C(n-1) + 2^{d/p}) \| f \|_{L^p(Q)}. \]
%
This gives $C(n) \leq C(n-1) + 2^{d/p}$, which is not enough to obtain a uniform bound. The idea here is to include more information in our induction hypothesis which gives control on $\max(M_{\geq 0} f_i, A)$. Since $Q$ contains points not in $Q_i$, we need to treat $A$ as an arbitrary quantity in our hypothesis.

To do this, we introduce \emph{cost functions}. For each $A,B,D > 0$ and any integer $n \geq 0$, we let $V_n(A,B,D)$ be the optimal constant such that
%
\[ \| \max(M_{\geq 0} f, A)^p \|_{L^p(Q)} \leq V_n(A,B,D) \]
%
For any function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, with
%
\[ \| f \|_{L^1(Q)} = B\quad\text{and}\quad \| f \|_{L^p(Q)} = D. \]
%
Our goal will be to show $V_n(A,B,D) \lesssim_p 2^{-dn/p} A + D$ which completes the proof. The role of $B$ is subtle, but will soon become apparan. Of course, we have $\| f \|_{L^1(Q)} \leq 2^{dn(1-1/p)} \| f \|_{L^p(Q)}$, so we have $V_n(A,B,D) = -\infty$ unless $B \leq 2^{dn(1 - 1/p)} D$.

The recursive inequality gives an inequality for the values $V_n(A,B,D)$. TODO: COMPLETE THIS PROOF.






\chapter{Maximal Averages Over Curves}

\section{Averages over a Parabola}

Given any measurable function $f: \RR^2 \to \CC$ we can consider the maximal average
%
\[ (Mf)(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{-\varepsilon}^\varepsilon|f(x+t,y+t)|\; dt. \]
%
Thus $Mf$ gives a maximal average over parabolas. Our goal is to show $\| Mf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for $1 < p < \infty$.

It will be convenient to look at the operator
%
\[ \tilde{M} f(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{\varepsilon/2}^{\varepsilon} |f(x+t,y+t^2)|\; dt. \]
%
A dyadic decomposition shows that $L^p$ bounds for $\tilde{M}$ imply $L^p$ bounds for $M$.

For each $k \in \ZZ$, let $\tilde{M_k} f(x,y) = 2^{-k} \int_{2^k}^{2^{k+1}} f(x+t,y+t^2)\; dt$. Rescaling shows that
%
\[ \| \tilde{M}_k \|_{L^p(\RR^2) \to L^p(\RR^2)} = \| \tilde{M}_0 \|_{L^p(\RR^2) \to L^p(\RR^2)} \]
%
so it suffices to focus on $\tilde{M}_0$. The operator is translation invariant and therefore has a Fourier multiplier
%
\[ \tilde{m}(\xi,\eta) = \int_1^2 e^{2 \pi i (\xi t + \eta t^2)}\; dt. \]
%
Note that $\tilde{m}$ is defined by an oscillatory integral with phase $\phi(t) = \xi t + \eta t^2$. We note that $\phi'(t) = \xi + 2 \eta t$, so Van der Corput's lemma implies that for $|\xi| \geq 10|\eta|$,
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\xi|}. \]
%
Similarily, $\phi''(t) = 2 \eta$, so we find
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\eta|^{1/2}}. \]
%
If $f \in L^2(\RR^2)$ and $\widehat{f}$ is supported on the region
%
\[ E_0 = \{ (\xi,\eta) : |\eta| \geq 1\ \text{or}\ |\xi| \leq 1\ \text{and} |\eta| \geq 10 \} \]
%
then $\| \tilde{m} \|_{L^\infty(E_0)} \lesssim 1$ and so
%
\[ \| \tilde{M}_0 f \|_{L^2(\RR^2)} = \| \tilde{m} \widehat{f} \|_{L^2(\RR^2)} \lesssim \| \widehat{f} \|_{L^2(\RR^2)} = \| f \|_{L^2(\RR^2)}. \]
%
On the other hand, we can decompose $\RR^2 - E_0$ into

suppose $\widehat{f}$ is supported on the region
%
\[ E_1 = \{ (\xi,\eta) : |\xi| \leq 1\ \text{and}\ |\eta| \leq 10 \}. \]
%
Then the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x| \leq 1$ and $|\Delta y| \leq 1/10$, which should imply good bounds for the maximal average. More precisely, $\widehat{f}$ is supported on the ellipsoid
%
\[ \left\{ (\xi,\eta) \in \RR^2 : \xi^2/2 + \eta^2/20 \leq 1 \right\}. \]
%
Thus the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x|^2 \leq 1/2$ and $|\Delta y|^2 \leq 1/20$,
%
\[ s \]
%
\[ \phi(x) = \frac{1}{( 1 + 2 x^2 + 20 y^2 )^N} \]  
