\input{../../style.tex}

%\newcommand{\vvvert}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 
%    \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}

\title{Functional Analysis}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}
\maketitle
\tableofcontents
\pagenumbering{arabic}

\part{Vector Spaces with a Metric}

Functional analysis is the interlace of algebra and analysis, in which algebraic structures are endowed with topological structure. The approach's utility counts for the rapid growth of applications over the past century, be it in quantum mechanics, statistics, or computing science. Rarely are we concerned with a single object, like a function, a random variable, or a measure, but instead consider large classes of such objects. To handle all these objects at once, we add both algebraic and analytic structure to the class of objects.

\begin{example}
    We rarely analyze a measurable function $f$ in isolation. Instead, we prove theorems about a class of measurable functions defined on the same measurable space. If $f$ and $g$ are measurable, then we may consider their addition $f + g$, their multiplication $fg$, and scaling $\lambda f$, which are all measurable. Thus the space of measurable functions on a set is a vector space. Similarily, the sum and product of two continuous functions on a topological space is continuous, so, we may consider $C[0,1]$, the space of all continuous scalar-valued functions on the unit interval $[0,1]$, as a vector space.
\end{example}

The most common analytic operations are scaling, rotation, and reflection. As a result, the most common vector spaces which occur in functional analysis are defined over the real and complex numbers. More specifically, real vector spaces $X$ are those spaces equipped with scaling operations $x \mapsto \lambda x$ for $\lambda > 0$, and a `reflection' operators $x \mapsto -x$. If $X$ is a real vector space with a specified `oriented twisting', i.e. a linear map $J: X \to X$ with $J^2(x) = -x$ for all $x \in X$, then there is a natural way to turn $X$ into a complex vector space by defining $(a + ib)x = ax + b(Jx)$. The geometry of the complex numbers then enables us to define an oriented twist by any angle $\theta$, by the operation $x \mapsto e^{i\theta} x$. Thus we have a natural operation of the complex numbers over the space.





\chapter{Basics of Banach Spaces}

The most natural way to associate a space with topological structure is by equipping the space with a metric. On a vector space, there is an even more powerful way of equipping the space with a metric. We can think of elements of a vector space as `arrows' extending from the origin. Thus a natural way to add a topology is to give these arrows a `length in themselves'. A function associating a vector with it's length is known as a {\it norm}. More precisely, a \emph{seminorm} on a vector space $X$ is a map $\| \cdot \|: X \to [0,\infty)$ which is {\it homogenous}, in the sense that for each $\alpha \in \mathbf{K}$ and $x \in X$, $\| \alpha x \| = |\alpha| \| x \|$, and satisfies the {\it triangle inequality} $\| x_1 + x_2 \| \leq \| x_1 \| + \| x_2 \|$ for each $x_1,x_2 \in X$. If in addition, we have $\| x \| = 0$ only when $x = 0$, then we say $\| \cdot \|$ is a {\it norm}. A vector space $X$ equipped with a norm is called a {\it norm space}. Then $X$ is naturally a metric space if we define $d(x_1,x_2) = \| x_1 - x_2 \|$. If $X$ is a \emph{complete} metric space, we say $X$ is a \emph{Banach space}.

On finite dimensional spaces, there is essentially a unique way to define a norm on the space. We say two norms $\| \cdot \|_1$ and $\| \cdot \|_2$ on a vector space $X$ are {\it comparable} if for each $x \in X$, $\| x \|_1 \sim \| x \|_2$. If $X$ is finite dimensional with basis $\{ e_1,\dots,e_n \}$, then for any norm on $X$, by Cauchy-Schwartz
%
\[ \| x \| = \| x_1 e_1 + \dots = x_n e_n \| \leq |x_1| \| e_1 \| + \dots + |x_n| \| e_n \| \lesssim |x_1| + \dots + |x_n|. \]
%
It follows from this inequality that, if we equip $X$ with the Euclidean topology induced via the basis $\{ e_1, \dots, e_n \}$, then the set $S = \{ x \in X : \| x \| = 1 \}$ is closed and bounded, and thus compact by the Heine-Borel theorem. If we let $f: S \to (0,\infty)$ be defined by
%
\[ f(x) = |x_1| + \dots + |x_n| \]
%
then $f$ is continuous, and thus is bounded from below by some $\delta > 0$ on $S$. But this means that for any $x \in X$,
%
\[ |x_1| + \dots + |x_n| \geq \delta \| x \| \gtrsim \| x \|. \]
%
Thus we have shown that all norms on $X$ are comparable to the norm $x \mapsto |x_1| + \dots + |x_n|$. Thus there is only a single notion of `size' on such spaces. On the other hand, there are many ways to measure the size of a function, or more general vectors in infinite dimensional norm spaces, which give a rich family of qualitatively different norm spaces.

\begin{example}
    Let $X$ be a measure space. For each $0 < p < \infty$, let $\mathcal{L}^p(X)$ denote the space of all measurable functions $f: X \to \mathbf{K}$ such that
    %
    \[ \| f \|_{L^p(X)} = \int |f(x)|^p\; dx < \infty. \]
    %
    Minkowski's inequality tells us that $\| \cdot \|_{L^p(X)}$ is a seminorm on $\mathcal{L}^p(X)$. Notice that if $u$ is a function such that $u(x) = 0$ for almost every $x$, then $\| f \|_{L^p(X)} = \| f + u \|_{L^p(X)}$. In particular, this means that $\| \cdot \|_{L^p(X)}$ is a well defined operation on the quotient space of $\mathcal{L}^p(X)$ by the vector space of functions which are equal to zero almost everywhere. We denote this quotient space by $L^p(X)$. Since $\| f \|_{L^p(X)} = 0$ if and only if $f$ is equal to zero almost everywhere, this implies that $L^p(X)$, equipped with the induced norm $\| \cdot \|$, is a norm space.
\end{example}

\begin{example}
    Given a measurable function $f$ on a measure space $X$, we can define the $L^\infty$ seminorm
    %
    \[ \| f \|_{L^\infty(X)} = \inf \{ t > 0: |f(x)| \leq t\ \text{for almost every $x \in X$} \}. \]
    %
    The space of functions with finite $L^\infty$ seminorm is denoted by $\mathcal{L}^\infty(X)$, and the quotient space by the class of functions equal to zero almost everywhere is denoted $L^\infty(X)$. The space $L^\infty(X)$ is then a norm space.
\end{example}

\begin{example}
    On a compact topological space $K$, we can consider the family of all continous, scalar-valued functions with domain $K$, denoted $C(K)$. The quantity
    %
    \[ \| f \|_{L^\infty(K)} = \sup \{ |f(x)|: x \in K \}, \]
    %
    gives $C(K)$ the structure of a norm space. More generally, if $X$ is any norm space, we can consider the family of all bounded continuous functions from $K$ to $X$, with associated norm
    %
    \[ \| f \|_{C(K,X)} = \sup \{ \| f(x) \|: x \in K \}. \]
    %
    If $X$ is a Banach space, then $C(K,X)$ is a Banach space.
\end{example}

For the purposes of the general theory of functional analysis, measure theory is not too essential. The most important norm spaces for intuition are the simplest infinite dimensional examples of the spaces $L^p(X)$, namely, the space $l^p$, which consists of all infinite sequences $a = \{ a_n : n > 0 \}$ with the norm
%
\[ \| a \|_{l^p} = \left( \sum_{n = 1}^\infty |a_n|^p \right)^{1/p} < \infty. \]
%
For $p = \infty$, $l^\infty$ is the collection of all bounded sequences, with the norm
%
\[ \| a \|_{l^\infty} = \sup |a_n|. \]
%
We can also define the norm spaces $l^p_n$ and $l^\infty_n$, which consists of length $n$ sequences. But the fact that the underlying vector spaces of these norm spaces are finite dimensional makes them behave quite differently to the infinite dimensional examples. 

\begin{remark}
    We have performed a particular example of a general construction when moving from the spaces $\mathcal{L}^p(X)$ to the spaces $L^p(X)$. If $X$ is a vector space equipped with a seminorm $\| \cdot \|$, then it is simple to verify that the set
    %
    \[ X_0 = \{ x \in X: \| x \| = 0 \} \]
    %
    is a subspace of $X$, and for any $x \in X$ and $x_0 \in X_0$, $\| x \| = \| x + x_0 \|$. Thus the seminorm $\| \cdot \|$ is well defined on the quotient space $X' = X/X_0$. Moreover, the seminorm is now a \emph{norm} on this space. Thus one can almost always reduce questions about spaces equipped with seminorms to spaes equipped with norms. For the spacial case of $\mathcal{L}^p(X)$, the set $X_0$ is precisely the family of measurable functions $f$ which are equal to zero almost everywhere.
\end{remark}

It is proved in a first course in real analysis that the spaces $C(K)$ are complete, i.e. since the uniform limit of a family of continuous functions is continuous. Thus $C(K)$ is a Banach space. Let us now that the spaces $L^p(X)$ are complete norm spaces, i.e. Banach spaces.

\begin{theorem}
    For any measure space $X$, $L^p(X)$ is a Banach space.
\end{theorem}
\begin{proof}
    We leave the $p = \infty$ case to the reader, since the argument is elementary. Let $f_1, f_2, \dots$ be a Cauchy sequence in $L^p(X)$. Then we can find a subsequence $f_{k_i}$ such that
    %
    \[ \| f_{k_{i + 1}} - f_{k_i} \|_{L^p(X)} \leq 1/2^i. \]
    %
    By the monotone convergence theorem, we find that the infinite sum
    %
    \[ F(x) = \sum_{i = 1}^\infty | f_{k_{i+1}}(x) - f_{k_i}(x)| \]
    %
    is absolutely convergent for almost every $x \in X$. Thus we can define a measurable function $f$ almost everywhere by the formula
    %
    \[ f(x) = \lim_{i \to \infty} f_{k_i}(x). \]
    %
    Fatou's lemma and Minkowski's inequality imply that
    %
    \begin{align*}
        \| f - f_{k_i} \|_{L^p(X)} &= \left( \int \left| \lim_{j \to \infty} f_{k_j}(x) - f_{k_i}(x) \right|^p\; dx \right)^{1/p}\\
        &\leq \liminf_{j \to \infty} \left( \int \left| f_{k_j}(x) - f_{k_i}(x) \right|^p \right)^{1/p}\\
        &\leq \liminf_{n \to \infty} \| f_{k_j} - f_{k_i} \|_{L^p(X)} \leq 1/2^{i-1}.
    \end{align*}
    %
    Thus the sequence $\{ f_{k_i} \}$ converges to $f$ in the $L^p(X)$ norm. But since $\{ f_k \}$ is Cauchy, this means that $\{ f_k \}$ converges to $f$ in the $L^p(X)$ norm as well. Thus Cauchy sequences converge in $L^p(X)$, and this means $L^p(X)$ is complete.
\end{proof}

\begin{remark}
    Studying Banach spaces is not too much more general than studying norm spaces. Given any norm space $X$, we can always find a Banach space $X'$ containing $X$, which is unique up to isomorphism, such that $X$ is dense in $X'$. The space $X'$ is known as the {\it completion} of $X$. One can view the elements of $X' - X$ as `asymptotic' elements of $X$, since they are limits of elements of $X$. For instance, if we equip $C[0,1]$ with the $L^1$ norm induced by the Lebesgue measure, then $C[0,1]$ is an incomplete norm space. The completion of $C[0,1]$ with respect to this norm is the space $L^1[0,1]$ of integrable functions. Thus the behaviour of integrable functions can be thought of as representing the asymptotic properties of a family of continuous functions, which we are familiar with integrating from our first years of university.
\end{remark}

The examples above provide most of the intuition we will need for the basic Banach space theory. But it is useful to know other examples for applications in other areas of analysis.

\begin{example}
    For any Hausdorff space $X$, let $M(X)$ denote the family of finite Borel measures on $X$. We can define the \emph{total variation norm} on $X$ by setting, for a measure $\mu$ on $X$, $\| \mu \|_{M(X)} = |\mu|(X)$. Then $M(X)$ becomes a Banach space under this norm, which can be proved in a manner similar to the proof that $L^1(X)$ is complete.
\end{example}

\begin{example}
    Let $K$ be a compact metric space. For each $0 < p \leq 1$, we say a scalar-valued function $f$ on $K$ is {\it Lipschitz of order $p$} if $|f(x) - f(y)| \lesssim d(x,y)^p$ for each $x,y \in K$. The set of such functions forms a vector space $\text{Lip}_p(K)$, which is a subspace of $C[0,1]$, but not a closed subspace. For each $f \in \text{Lip}_p [0,1]$, we define the Lipschitz norm
    %
    \[ \| f \|_{\text{Lip}_p(K)} = \| f \|_{L^\infty(K)} + \sup \frac{|f(x) - f(y)|}{d(x,y)^p}. \]
    %
    This norm makes $\text{Lip}_p(K)$ into a Banach space. If $\{ f_n \}$ is a Cauchy sequence in $\text{Lip}_p(K)$, the completeness of $L^\infty(K)$ shows there exists $f \in L^\infty(K)$ such that $f_n \to f$ in the $L^\infty$ norm. Since $\{ f_n \}$ is Cauchy,  there exists a constant $M$ such that for all $n$, $|f_n(x) - f_n(y)| \leq M |x - y|^p$. In particular, the uniform convergence of $f_n$ to $f$ implies that $|f(x) - f(y)| \leq M |x - y|^p$, so $f \in \text{Lip}_p(K)$. Now
    %
    \begin{align*}
        \lim_{n \to \infty} &\sup_{x,y \in K} \frac{|[f(x) - f_n(x)] - [f(y) - f_n(y)]|}{d(x,y)^p}\\
        &= \lim_{n \to \infty} \sup_{x,y \in K} \lim_{m \to \infty} \frac{[f_m(x) - f_n(x)] - [f_m(y) - f_n(y)]}{d(x,y)^p}\\
        &\leq \lim_{n \to \infty} \limsup_{m \to \infty} \sup_{x,y \in K} \frac{[f_m(x) - f_n(x)] - [f_m(y) - f_n(y)]}{d(x,y)^p}\\
        &\leq \lim_{n \to \infty} \limsup_{m \to \infty} \| f_m - f_n \|_{\text{Lip}_p(K)} = 0.
    \end{align*}
    %
    Thus $\{ f_n \}$ converges to $f$ in the $\text{Lip}_p(K)$ metric as well as in $C(K)$. Thus $\text{Lip}_p(K)$ is a complete metric space.
\end{example}

\begin{example}
    As another example of this, if $K$ is a compact subset of $\RR^d$, then we define $C^n(K)$ to be the space of all $k$-times continuously differentiable functions on $K$, with the norm
    %
    \[ \| f \|_{C^n(K)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(K)}. \]
    %
    Then $C^n(K)$ is a Banach space.
\end{example}

Let us consider an example of a norm space where a completion is necessary.

\begin{example}
    Let $K$ be a compact subset of $\RR^d$, and define $\mathcal{W}^{n,p}(K)$ to be the space of all $f \in C^n(K)$ such that for any multi-index $\alpha$ with $|\alpha| \leq n$, $D^\alpha f \in L^p(K)$, and equip $\mathcal{W}^{n,p}(K)$ with the norm
    %
    \[ \| f \|_{W^{n,p}(K)} = \sup_{|\alpha| \leq n} \| D^\alpha f \|_{L^p(K)}. \]
    %
    Then $\mathcal{W}^{n,p}(K)$ is a norm space, but is \emph{not} complete. The completion of this space is the \emph{Sobolev space} $W^{n,p}(K)$, and elements of this space can be identified with measurable functions possessing \emph{weak}, or \emph{distributional} derivatives in $L^p(K)$ up to order $n$, but we leave a further discussion of this to more advanced contexts.
\end{example}

Let $X$ be a norm space. It is easy to see that the addition map $X \times X \to X$ is continuous, as is scaling map $\mathbf{K} \times X \to X$. The norm itself it seen to be a continuous function $X \to [0,\infty)$. For a fixed $x_0 \in X$, the translation map $x \mapsto x + x_0$ is a homeomorphism of $X$, and for $\lambda \neq 0$, $x \mapsto \lambda x$ is also a homeomorphism of $X$.

We can develop the theory of series in a norm space, i.e. a sum converges if it's partial sums converge. Given a sequence $\{ x_n \}$. We say the sequence is absolutely summable if $\sum \| x_n \| < \infty$. The same proof as for $\RR$ shows that such a sequence is {\it unconditionally summable}, i.e. that for each permutation $\pi: \mathbf{N} \to \mathbf{N}$,
%
\[ \sum_{n = 1}^\infty x_{\pi(n)} = \sum_{n = 1}^\infty x_n. \]
%
Instead of defining a Banach space in terms of Cauchy sequences, we could also define a Banach space as a space in which every absolutely summable series converges, which was a fact which somewhat underlied our proof that $L^p(X)$ was a Banach space.

\begin{remark}
    Note that, unlike sequences in $\RR^n$, in \emph{any} infinite dimensional Banach space $X$ there are sequences which are unconditionally summable, but \emph{not absolutely summable}. This is a result of A. Dvoretzky and C.A. Rogers. For a particular example, consider the sequence $\{ e_n \}$ in $l^\infty$, where $e_n$ is the sequence which is equal to zero except in the $n$th position, where it takes the value one. Set $x_n = e_n / n$. Then the sequence $\{ x_n \}$ is not absolutely summable, yet it is unconditionally summable to the sequence $\sum_{n = 1}^\infty e_n / n = (1,1/2,1/3,\dots)$.
\end{remark}

Before we move on to more interesting concepts, let us introduce some notation and describe some easily proved properties of Banach spaces. For any norm space $X$, we let $B_X$ denote the closed unit ball in $X$, and $S_X$ the unit sphere, i.e.
%
\[ B_X = \{ x \in X: \| x \| \leq 1 \}\quad\text{and}\quad S_X = \{ x \in X: \| x \| = 1 \}. \]
%
Given two sets $A$ and $B$, we let $A + B = \{ a + b : a \in A, b \in B \}$. Then for each $a \in X$, $a + B_X$ is the closed unit ball centered at $a$. Similarily, we can define $A - B = \{ a - b : a \in A, b \in B \}$, and for each scalar $\alpha$, $\alpha A = \{ \alpha a : a \in A \}$.

\section{Subspaces}

If $Y$ is a vector subspace of a norm space $X$, then $Y$ inherits the property of being a norm space from $X$. But if $X$ is a Banach space, then $Y$ will only be complete when $Y$ is a \emph{closed} subspace of $X$. Here are some examples.

\begin{example}
    Let $c_0$ be the subspace of $l^\infty$ consisting of the family of all sequences $\{ x_n \}$ such that $\lim_{n \to \infty} x_n = 0$. Then $c_0$ is a closed subspace of $l_\infty$, and is thus a Banach space. The space $c_{00}$ of all sequences $\{ x_n \}$ which are only non-zero for finitely many values is a subspace of $c_0$, but it is not closed, and therefore not a Banach space. In fact, $c_{00}$ is dense in $l^p$ for all $1 \leq p < \infty$, and dense in $c_0$, but not dense in $l^\infty$.
\end{example}

\begin{example}
    Let $\mathbf{T}$ be the interval $[-\pi,\pi)$ equipped with the Lebesgue measure. For each $f \in L^p(\mathbf{T})$, and any integer $n \in \mathbf{Z}$, we define
    %
    \[ \widehat{f}(n) = \frac{1}{2\pi} \int_{-\pi}^\pi f(x) e^{-nix}\; dx. \]
    %
    H\"{o}lder's inequality shows that
    %
    \[ |\widehat{f}(n)| \leq \| f \|_{L^1(\TT)} \leq \| f \|_{L^p(\TT)} \]
    %
    for each $n \in \mathbf{Z}$. In particular, this means the set
    %
    \[ H^p(\mathbf{T}) = \{ f \in L^p(\mathbf{T}) : \widehat{f}(n) = 0\ \text{if $n < 0$} \} \]
    %
    is closed in $L^p(\TT)$, and is therefore a Banach space. These are examples of {\it Hardy spaces} on $\mathbf{T}$. They can be identified with a family of holomorphic functions on the unit disk under the identification of $f$ with the analytic function
    %
    \[ u(z) = \sum_{n = 0}^\infty \widehat{f}(n) z^n, \]
    %
    which converges for $|z| < 1$ since $\{ \widehat{f}(n) \}$ is a bounded sequence. The family of all analytic functions obtained in this way can be described as the space
    %
    \[ H^p(\DD) = \left\{ f \in \mathcal{O}(\DD) : \left( \sup_{0 < r < 1} \int_{|z| = r} |f(w)|^p\; dw \right)^{1/p} < \infty \right\}. \]
    %
    We require some more powerful tools in harmonic analysis to prove this fact, but we do note that we can prove $H^p(\DD)$ is a Banach space with the norm
    %
    \[ \| f \|_{H^p(\DD)} = \sup_{0 < r < 1} \left( \int_{|z| = r} |f(w)|^p\; dw \right)^{1/p}, \]
    %
    if we take for granted Cauchy's integral formula.
\end{example}

If $Y$ is a subspace of $X$, then $\overline{Y}$ will be a \emph{closed subspace} of $X$. For a set $E \subset X$, we let $\langle E \rangle$ denote the smallest subspace of $X$ containing $E$, and $[E]$ denote the smallest {\it closed} subspace.

\section{Convexity}

A critical notion in functional analysis is {\it convexity}. A set $E \subset X$ is {\it convex} if for each $x,y \in E$ and $\lambda \in (0,1)$, $\lambda x + (1 - \lambda) y \in E$. A set $E$ is {\it balanced} if $\alpha E \subset E$ for each $|\alpha| \leq 1$, and {\it symmetric} if $-E = E$. And a set $E$ is {\it absorbing} if, for each $x \in X$, there exists $t$ such that for $|\alpha| \geq t$, $x \in \alpha E$. As an example, the unit ball $B_X$ is closed, convex, and absorbing. In the future, we will make heavy use of the following result.

\begin{theorem}
    Every closed, convex, absorbing set in a Banach space contains a neighbourhood of the origin.
\end{theorem}
\begin{proof}
    Let $E \subset X$ be a closed, convex, absorbing set. Then $E \cap (-E)$ is closed, convex, and absorbing, so we may assume without loss of generality that $E$ is symmetric. It suffices to show $E^\circ$ is nonempty, for then $E^\circ/2 + (-E^\circ)/2$ is a neighbourhood of the origin contained in $E$. Now assume $E^\circ = \emptyset$. This means that for each $n$, $F_n = (nE)^c$ is an open, dense set. Thus $\bigcap F_n$ is dense. But this is impossible by the Baire category theorem, since $\bigcup nE = X$. Thus we conclude $E^\circ \neq \emptyset$.
\end{proof}

For each set $E \subset X$, we let $\text{co}(E)$ denote the smallest convex subset of $X$ containing $E$. This is the {\it convex hull} of $E$.

\section{Bounded Linear Operators}

A natural object of study in linear algebra is to understand the family of linear maps between two vector spaces $X$ and $Y$. In the theory of norm spaces, we want to understand the family of {\it continuous} linear maps. As the last part of the next theorem shows, it is also natural to call these linear maps \emph{bounded} linear maps.

\begin{theorem}
    Let $X$ and $Y$ be norm spaces, and $T: X \to Y$ a linear map. Then the following are equivalent:
    %
    \begin{itemize}
        \item $T$ is continuous.
        \item $T$ is continuous at $0 \in X$.
        \item $T$ is uniformly continuous.
        \item There exists $M \geq 0$ such that $\| Tx \| \leq M \| x \|$ for all $x \in X$.
    \end{itemize}
\end{theorem}
\begin{proof}
    We leave the proof of the equivalence of (1), (2), and (3) to the reader. If $T$ is continuous at the origin, then in particular, since $T(0) = 0$, for each $\varepsilon > 0$, there exists $\delta > 0$ such that if $\| x \| \leq \delta$, $\| Tx \| \leq \varepsilon$. But this means that $\| Tx \| \leq (\varepsilon / \delta) \| x \|$ if $\| x \| \leq \delta$, and by scaling an arbitrary $x$, one sees that this inequality actually holds for all $x \in X$. Conversely, if $M$ exists such that $\| Tx \| \leq M \| x \|$, and $\varepsilon > 0$, and we set $\delta = \varepsilon / M$, then if $\| x \| \leq \delta$, $\| Tx \| \leq \varepsilon$, so $T$ is continuous at the origin.
\end{proof}

We let $B(X,Y)$ denote the class of bounded linear operators from $X$ to $Y$. For each such operator, we define the {\it operator norm}
%
\[ \| T \| = \sup_{x \neq 0} \frac{\| Tx \|}{\| x \|}. \]
%
This quantity is finite if and only if the operator is continuous. One can verify that this definition gives $B(X,Y)$ the structure of a norm space, and moreover, if $Y$ is a Banach space, then $B(X,Y)$ is a Banach space. Moreover, given $T \in B(X,Y)$ and $S \in B(Y,Z)$, we can form the composition operator $S \circ T \in B(X,Z)$, and one verifies that
%
\[ \| S \circ T \| \leq \| S \| \| T \|. \]
%
Thus spaces of operators have even more algebraic and analytic structure than norm spaces. This structure is heavily exploited in the theory of {\it operator algebras}, covered later in these notes.

\begin{example}
    If $Y$ is not a Banach space, then $B(X,Y)$ can fail to be a Banach space. For instance, if $Y$ is $c_{00}$ equipped with the same norm as $l_1$, then $B(l_1,Y)$ is not a Banach space. For instance, if
    %
    \[ T_n(a) = \sum_{k = 1}^n \frac{1}{k^2} \left( \sum_{i = k}^\infty a_i \right) e_k, \]
    %
    then $\| T_n - T_{n + m} \| \leq \sum_{k = n}^\infty (1/k)^2$, so $\{ T_n \}$ is Cauchy. However, the limit of these sequence of operators is the map
    %
    \[ T(a) = \sum_{k = 1}^\infty \frac{1}{k^2} \left( \sum_{i = k}^\infty a_i \right) e_k \]
    %
    which is an element of $B(l_1,l_1)$, but not an element of $B(l_1,Y)$.
\end{example}

If $\{ T_n \}$ is a sequence of operators in $B(X,Y)$ which coverges in the operator norm to an operator $T$, then it is obvious that $Tx = \lim_{n \to \infty} T_nx$ for each $x \in X$. Pointwise convergence does not imply convergence in the operator norm, as the next example shows.

\begin{example}
    Recall the Banach space $c_0$, and define a sequence of operators $T_n: c_0 \to \mathbf{K}$ by letting $T_n(a) = a_n$. Then each $T_n$ is a bounded operator, with $\| T_n \| = 1$. Thus the sequence $\{ T_n \}$ does not converge to zero in the operator norm. However, for each $a \in c_0$, $\lim_{n \to \infty} T_n(a) = 0$, so the sequence $\{ T_n \}$ does converge pointwise to zero.
\end{example}

In the example above, we would say $\{ T_n \}$ converges in the \emph{strong operator topology}, but does not converge in the \emph{norm topology}, a concept we return to later in these notes.

The theory of bounded operators for finite dimensional norm spaces is effectively trivial.

\begin{theorem}
    Every linear map from a finite dimensional norm space $X$ to a norm space $Y$ is bounded.
\end{theorem}
\begin{proof}
    Let $\{ e_1, \dots, e_d \}$ be a basis for $X$, for which, without loss of generality, we may assume $\| e_i \| = 1$ for each $i$. Define, for each $x \in X$ with $x = a_1e_1 + \dots + a_d e_d$,
    %
    \[ |x| = (|a_1|^2 + \dots + |a_d|^2)^{1/2}. \]
    %
    Notice that the triangle inequality implies that
    %
    \[ \| x \| \leq |a_1| + \dots + |a_d| \leq \sqrt{d} \left( |a_1|^2 + \dots + |a_d|^2 \right)^{1/2}. \]
    %
    Thus $\| \cdot \|$ is continuous with respect, to the topology induced by $|\cdot|$. If $S$ is the unit sphere with respect to the norm $|\cdot|$, then the Heine-Borel theorem implies that $S$ is compact, and in particular, $\| \cdot \|$ attains a maximum and a minimum on $S$. In particular, since $\| x \| \neq 0$ for each $x \in S$, this implies that there is $\varepsilon > 0$ such that $\| x \| \geq \varepsilon$ for each $x \in S$. And rescaling thus shows that $\| x \| \geq \varepsilon |x|$ for each $x \in X$. In particular, this means that $|\cdot|$ and $\| \cdot \|$ are comparable. In particular, $T$ is continuous with respect to $\| \cdot \|$ if and only if it is continuous with respect to $| \cdot |$. And we then find that for any $x = a_1e_1 + \dots + a_de_d$, the triangle inequality implies
    %
    \begin{align*}
        \| Tx \| &\leq |a_1| \| Te_1 \| + \dots + |a_d| \| Te_d \|\\
        &\leq (|a_1| + \dots + |a_d|) \max \| Te_i \|\\
        &\leq \sqrt{d} |x| \| Te_i \|.
    \end{align*}
    %
    Thus $T$ is a continuous linear map.
\end{proof}

Conversely, if $X$ is infinite dimensional, and $Y \neq 0$, then there exist discontinous linear maps from $X$ to $Y$. For instance, if we consider a basis $\mathcal{B}$ for $X$ containing at least countably many elements $\{ e_1, e_2, \dots \}$, such that $\| e_i \| = 1$ for each $i$, and we find $y \neq 0$ is in $Y$, then we can define a linear map such that $T(e_i) = i \cdot y$, and $T(f) = 0$ for each $f \in \mathcal{B}$ with $f \neq e_i$ for each $i$. Then $T$ is unbounded since $\| T e_i \| \geq i \| e_i \|$ for each $i > 0$.

\begin{remark}
    A key component of the proof above was the fact that $X$ possessed a norm whose respective topology satisfied the Heine-Borel property. If $X$ is infinite dimensional, no such norm can exist. This can be shown by showing that for any norm $\| \cdot \|$ on an infinite dimensional space $X$, and any $n$, there is a countable collection $\{ x_1, x_2, \dots \} \subset S_X$ such that $\| x_i - x_j \| \geq 1$ for $i \neq j$. Clearly this sequence can have no accumulation points. We can define such a sequence inductively. Given $\{ x_1, \dots, x_n \}$, let $X_n = \langle x_1, \dots, x_n \rangle$. Then $X_n$ is a finite dimensional norm space, hence a Banach space, hence closed in $X$. In particular, if $y \not \in X_n$, then $d(X_n,y) > 0$. If $\alpha = d(X_n,y)$, then $d(X_n,y/\alpha) = 1$. But this means that $\| x_i - y/\alpha \| \geq 1$ for each $i \in \{ 1, \dots, n \}$, so we can set $x_{n+1} = y/\alpha$.
\end{remark}

We say a map $T: X \to Y$ between two norm spaces is an {\it isomorphism} if for each $x \in X$, $\| Tx \| \sim \| x \|$. In particular, this implies $T$ is continuous and injective, but importantly, \emph{not necessarily surjective}. We say $X$ is {\it embedded} in $Y$. If $T$ is surjective, we can define an inverse map $T^{-1}: Y \to X$, which is continuous, and we then say $X$ and $Y$ are isomorphic. Note that if $X$ is a Banach space, then $T(X)$ is also a Banach space. In most other areas of math, an isomorphism has to be surjective, but unfortunately, the definition of isomorphism above has become standardized in Banach space theory. A stronger notion than an isomorphism is an {\it isometry}, which is a map $T: X \to Y$ such that $\| Tx \| = \| x \|$ for all $x \in X$. Again, $T$ need not be surjective, and we say $X$ has been {\it embedded} in $Y$. If $T$ is surjective, $T^{-1}$ is also an isometry, and we say $X$ and $Y$ are isometrically isomorphic. Isomorphic spaces have many of the same properties, but in order to transfer all properties about norm spaces, one really needs an isometry.

\begin{example}
    Let $c$ be the subspace of $l^\infty$ consisting of all convergent, bounded sequences. Then $c$ is a closed subspace, and thus a Banach space. In fact, $c$ is isomorphic to $c_0$, since we can define an operator $T: c_0 \to c$ by setting
    %
    \[ T(a) = (a_0 + a_1,a_0 + a_2,\dots). \]
    %
    We have $\| T a \|_\infty \leq 2 \| a \|_\infty$, so $T$ is continuous. Furthermore, $T$ is invertible, with
    %
    \[ T^{-1}(b) = \left( \lim_{n \to \infty} b_n, b_0 - \lim_{n \to \infty} b_n, b_1 - \lim_{n \to \infty} b_n, \dots \right), \]
    %
    and $\| T^{-1}(b) \|_\infty \leq 2 \| b \|_\infty$. Thus we conclude
    %
    \[ (1/2) \| a \|_\infty \leq \| Ta \|_\infty \leq 2 \| a \|_\infty, \]
    %
    and so $c$ and $c_0$ are isomorphic. Nonetheless, these spaces are \emph{not} isometric. One property that $c_0$ has, but $c$ does not have, is that if $a \in S_{c_0}$, then there are $b, c \in S_{c_0}$ with $b \neq c$ such that $a = (b + c)/2$. In the language of convexity, we would say that $S_{c_0}$ has {\it no extreme points}. To see why, we define
    %
    \[ b_n = \begin{cases} a_n &: |a_n| \geq 1/2 \\ a_n/2 &: |a_n| < 1/2 \end{cases}\quad\text{and}\quad c_n = \begin{cases} a_n &: |a_n| \geq 1/2 \\ 3a_n/2 &: |a_n| < 1/2 \end{cases}. \]
    %
    Clearly $a = (b+c)/2$, and $\| b \|_\infty = \| c \|_\infty = 1$. Since $\lim_{n \to \infty} a_n = 0$, eventually $|a_n| \leq 1/2$, and so $b_n \neq c_n$. On the other hand, the sequence $a = (1,1,\dots)$ lies in $S_c$, yet it $b,c \in S_c$ satisfy $a = (b + c)/2$, then $b = c = a$.
\end{example}

Linear operators into $\mathbf{K}$ are given a special name, they are known as \emph{linear functionals}, and form the simplest class of linear operators. The space $B(X,\mathbf{K})$ is then known as the {\it dual space} of $X$, denoted by $X^*$.

\section{Three Fundamental Theorems}

We now turn to fundamental results which are a consequence of the completeness of a Banach space, in particular, the Baire category theorem. These are the \emph{open mapping theorem}, the \emph{uniform boundedness principle}, and the \emph{closed graph theorem}. We will prove these three theorems as a consequence of a lemma called Zabreiko's Lemma.

\begin{lemma}
    Every countably subadditive seminorm on a Banach space is continuous.
\end{lemma}
\begin{proof}
    Let $X$ be a Banach space, and $\rho: X \to [0,\infty)$ a countably subadditive seminorm. Our goal is to find $s > 0$ and $\varepsilon > 0$ such that $\rho(x) < s$ whenever $\| x \| < \varepsilon$, because it would then follow by homogeneity that for any $x \in X$,
    %
    \[ \rho(x) < (s/\varepsilon) \| x \| \lesssim \| x \|, \]
    %
    which shows $\rho$ is continuous by virtue of the fact that
    %
    \[ |\rho(x) - \rho(y)| \leq \rho(x - y) \lesssim \| x - y \|. \]
    %
    Set
    %
    \[ G = \{ x \in X: \rho(x) < 1 \} \]
    %
    then $G$ is convex and absorbing, so $\overline{G}$ is closed, convex, and absorbing, and thus contains a neighborhood of the origin. Thus there is $\varepsilon > 0$ such that $x \in \overline{G}$ if $\| x \| < \varepsilon$. Given $x$ with $\| x \| < \varepsilon$, we can therefore find $x_0 \in G$ with $\| x - x_0 \| < \varepsilon / 2$. But this means that $x - x_0 \in \overline{G/2}$, so that we may find $x_1 \in G/2$ such that $\| x - x_0 - x_1 \| < \varepsilon / 4$. Continuing this process gives a sequence $\{ x_1, x_2, \dots \}$, with $x_i \in G/2^i$ for each $i \geq 0$, such that
    %
    \[ x = \sum_{i = 0}^\infty x_i. \]
    %
    But then by countably subadditivity, we conclude that
    %
    \[ \rho(x) \leq \sum_{i = 0}^\infty \rho(x_i) < \sum_{i = 0}^\infty 1/2^i \leq 2. \]
    %
    Thus setting $s = 2$ completes the proof of what was required.
\end{proof}

Now we prove the three important theorems of functional analysis, which relate \emph{qualitative properties} of an operator with \emph{quantitative properties}. We have already seen this kind of relation before, where we saw a linear operator was continuous (a qualitative property), if and only if it is bounded (a quantitative property), though the three theorems we now describe offer a deeper relation of this form. The first result is also known as the Banach-Steinhaus Theorem.

\begin{theorem}[The Uniform Boundedness Theorem]
    Let $\{ T_\alpha: X \to Y \}$ be a family of bounded operators from a Banach space $X$ to a norm space $Y$. Then the following are equivalent:
    %
    \begin{itemize}
        \item (Uniform Boundedness): $\sup_\alpha \| T_\alpha \| < \infty$.
        \item (Pointwise Boundedness): For any $x \in X$, $\sup_\alpha \| T_\alpha x \| < \infty$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Let $\rho(x) = \sup_\alpha \| T_\alpha x \|$. If the family of operators is pointwise bounded, then $\rho$ is finite-valued, and countably subadditive. It follows that $\rho$ is continuous, i.e. we have $\rho(x) \leq M \| x \|$ for all $x \in X$. But this means that for all $x \in X$
    %
    \[ \sup_\alpha \| T_\alpha x \| \leq M \| x \|, \]
    %
    and thus $\sup_\alpha \| T_\alpha \| \leq M$.
\end{proof}

\begin{corollary}
    Let $\{ T_\alpha: X \to Y \}$ be a net of bounded linear operators between two Banach spaces $X$ and $Y$. Then the following are equivalent:
    %
    \begin{itemize}
        \item For every $x \in X$, $\lim_\alpha T_\alpha x$ converges as $\alpha \to \infty$.
        \item There is a bounded operator $T: X \to Y$ such that $Tx = \lim_\alpha T_\alpha x$ for all $x \in X$.
        \item The operators $\{ T_\alpha \}$ are uniformly bounded, and there exists a dense subspace $X_0$ of $X$ such that $\lim_\alpha T_\alpha x$ exists for all $x \in X_0$.
    \end{itemize}
\end{corollary}
\begin{proof}
    Assume the first point. The conditions imply that the family $\{ T_\alpha \}$ is pointwise bounded, and thus uniformly bounded, which means that if we define $T: X \to Y$ by the limit, then
    %
    \[ \| Tx \| \leq \sup_\alpha \| T_\alpha x \| \leq \sup_\alpha \| T_\alpha \| \| x \|. \]
    %
    If $T$ is bounded, then the family $\{ T_\alpha \}$ is pointwise bounded, and thus uniformly bounded, which implies the third point. Finally, if the operators $\{ T_\alpha \}$ are uniformly bounded (let's say, with $\| T_\alpha \| \leq M$ for all $\alpha$), and a dense subspace $X_0$ of the form above exists, then we claim that for each $x \in X$, the net $\{ T_\alpha x \}$ is Cauchy, and thus converges. Indeed, for any $\varepsilon > 0$, there exists $x_0 \in X_0$ such that $\| x - x_0 \|_X \leq \varepsilon / 2M$. Since $T_\alpha x_0$ converges, there exists $\alpha_0$ such that for $\alpha_1,\alpha_2 \geq \alpha_0$, $\| T_{\alpha_1} x_0 - T_{\alpha_2} x_0 \| \leq \varepsilon / 2$. But this means that for those same $\alpha_1$ and $\alpha_2$,
    %
    \[ \| T_{\alpha_1} x - T_{\alpha_2} x \| \leq \| T_{\alpha_1} x - T_{\alpha_1} x_0 \| + \| T_{\alpha_2} x - T_{\alpha_2} x_0 \| + \| T_{\alpha_1} x_0 - T_{\alpha_2} x_0 \| \leq \varepsilon. \]
    %
    Thus we have shown that the net is Cauchy, and thus must converge.
\end{proof}

A classic example of this result being applied is in the theory of Fourier series. If $f \in L^2(\TT)$, then one can consider the partial summation operators $S_N: L^2(\TT) \to L^2(\TT)$ such that
%
\[ S_N f(t) = \sum_{n = -N}^N \widehat{f}(n) e^{nit}, \]
%
and orthogonality shows that $\| S_N f \|_{L^2(\TT)} \leq \| f \|_{L^2(\TT)}$ for all $N > 0$. What's more, we can verify that for $f \in C^\infty(\TT)$, $S_N f$ converges uniformly to $f$ as $N \to \infty$, and thus converges to $f$ in the $L^2(\TT)$ norm. The last corollary thus implies that for any $f \in L^2(\TT)$, $S_N f$ converges in $L^2(\TT)$ to $f$ as $N \to \infty$.

On the other hand, if we consider the analogous operators $S_N: C(\TT) \to C(\TT)$, then these operators are \emph{not} uniformly bounded, namely $\| S_N \| \gtrsim \log(N)$. By the uniform boundedness theorem, these operators cannot be \emph{pointwise bounded}, i.e. there exists $f \in C(\TT)$ such that $\{ S_N f \}$ is not bounded in $C(\TT)$. Thus we have proved (nonconstructively) the existence of an integrable function $f$ whose partial Fourier sums does not converge uniformly to $f$. It is quite difficult to actually construct a \emph{particular} example of a continuous function whose Fourier sums do not converge uniformly to $f$, which shows the power of nonconstructive techniques.

Now we move on to the open mapping theorem, which related qualitative and quantitative solvability.

\begin{theorem}[Open Mapping Theorem]
    Let $T: X \to Y$ be a bounded linear map between Banach spaces. Then $T$ is surjective if and only if $T$ is open.
\end{theorem}
\begin{proof}
    Suppose that $T$ is an open map. Then $T(B_X)$ contains an open neighborhood of $B_Y$, which must be absorbing, which implies $T(X) = Y$. Thus $T$ is surjective. Conversely, suppose $T$ is surjective. To show $T$ is open, it suffices to show that $U = T(B_X^\circ)$ is open. Let $\rho(y) = \inf \{ \| x \| : Tx = y \}$. Then $\rho$ is a countable subadditive seminorm on $Y$, and thus continuous. But this means $U = \{ y \in Y: \rho(y) < 1 \}$ is an open set, completing the proof.
\end{proof}

A bounded linear map $T: X \to Y$ is open if and only if there exists $M > 0$ such that for any $y \in Y$, there is $x \in X$ such that $Tx = y$, and $\| x \| \leq M \| y \|$. This formulation shows that a linear map is open precisely when the equation $Tx = y$ is solvable for each $y \in Y$ in a \emph{quantitatively-stable sense} for each $y \in Y$. The open mapping theorem says this quantitative solvability is equivalent to the qualitative property of being surjective, i.e. the equation $Tx = y$ merely being solvable for each $y \in Y$. Note, however, that working in the quantitatively-stable regime, like in the uniform boundedness theorem, has several advantages. For instance, we need only solve the equation stably for each $y$ lying in some dense subspace $Y_0$ of $Y$, since the quantitative result then follows for all elements of $Y$ by an approximation argument.

This technique is used all the time, for instance, in partial differential equations, where we show that if $Lf = g$ for smooth $f$ and $g$, then $\| f \|_X \leq \| g \|_X$ (using an appropriate norm space $X$ containing smooth functions), and then the open mapping justifies that the equation is solvable for any given $g \in X$, which is not necessarily smooth.

\begin{corollary}
    A bijective, bounded linear map $T: X \to Y$ between Banach spaces is an isomorphism.
\end{corollary}

If $T: X \to Y$ is a surjective map, then there exists a linear map $S: Y \to X$ such that $T \circ S$ is the identity. It is tempting to conclude that we can find a choice of $S$ which is bounded. But one must be careful, because there may not be a \emph{bounded} choice of $S$ when the problem is underdetermined (the corollary above shows that this is not a problem when the problem is determined, i.e. a unique $S$ exists).

If we take $X_1$ to be the kernel of $T$, then we see that the problem is essentially equivalent to finding a closed subspace $X_2$ of $X$ such that $X$ is the algebraic direct sum of $X_1$ and $X_2$, because then $T$ restricts to an isomorphism between $X_2$ and $Y$. Thus the problem is equivalent to finding a \emph{complementary subspace} of $X$ for $X_1$. We will see in the next chapter that finding complementary subspaces is easy when $X$ is a Hilbert space. But in general, complementary subspaces of Banach spaces do not exist (and by a result of Lindenstrauss-Tzafriri, which says any infinite dimensional Banach space which isn't a Hilbert space contains a closed subspace which is not complemented, we should expect finding these complements to be a nontrivial task in any other regime).

Now we turn to the closed graph theorem. Recall that a function $f: X \to Y$ between two topological spaces is closed when it's graph $\Gamma(f)$ is a closed subset of $X \times Y$. This is a weaker notion than continuity. If $X$ and $Y$ are metric spaces, then $f$ is closed precisely under the condition that whenever $\{ x_n \}$ is a sequence in $X$ converging to some $x \in X$, and $\{ f(x_n) \}$ converges to some $y \in Y$, then $Tx = y$.

\begin{theorem}[Closed Graph Theorem]
    Let $T: X \to Y$ be a linear map between Banach spaces. Then $T$ is bounded if and only if it is closed.
\end{theorem}
\begin{proof}
    Let $\rho(x) = \| Tx \|$. The continuity of $\rho$ would prove the claim, so it suffices to show that $\rho$ is countable subadditive. If $\{ x_n \}$ is a sequence in $X$ such that $\sum_{n = 1}^\infty x_n$ converges, then it suffices to show that
    %
    \[ \| T(\sum x_n) \| \leq \sum \| Tx_n \|. \]
    %
    We may therefore assume without loss of generality that $\sum \| Tx_n \| < \infty$, which means that $\sum Tx_n$ converges absolutely. But since $T$ is closed, we then know that $T(\sum_{n = 1}^\infty x_n) = \sum_{n = 1}^\infty Tx_n$, which gives the required subadditivity.
\end{proof}

One method to verify an operator is closed, separate from the direct method, is to find a Hausdorff topology on $Y$ which is coarser than the norm topology, but such that $T$ is continuous from $X$ to $Y$ in this new topology. If $\{ x_n \}$ converges to $x \in X$, then it follows that $\{ Tx_n \}$ converges to $Tx$ in this coarser topology. If it also converges to $y$ in the norm topology, then it must also converge to $y$ in the coarser topology, so $Tx = y$, i.e. $T$ is closed.

We might state this in a slightly more elegant way. Let $X$ and $Y$ be Banach spaces, and let $Z$ be a Hausdorff topological vector space containing $Y$ as a subspace. Let $T: X \to Z$ be a continuous linear map. Then $Tx \in Y$ for all $x \in X$ (qualitative regularity) if and only if we have a bound of the fomr $\| Tx \|_Y \lesssim \| x \|_X$ for all $x \in X$ (or only on a dense subclass of $X$).

This kind of approach is often used in harmonic analysis / partial differential equations, where we might only be able to justify that $T$ is a continuous map from some function space $X$ to, say, a space of distributions $Z$, and we must then work to justify that $T$ actually induces some additional regularity properties. For instance, one can easily justify that the Fourier transform acts as a continuous linear operator $\mathcal{F}: L^p(\RR^d) \to \mathcal{S}(\RR^d)^*$. Provided that we can show that for any $f \in \mathcal{S}(\RR^d)$, and $1 \leq p \leq 2$, the Hausdorff-Young inequality
%
\[ \| \mathcal{F} f \|_{L^{p^*}(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \]
%
is true, the closed graph theorem shows that for \emph{any} $f \in L^p(\RR^d)$, we actually have $\mathcal{F} f \in L^{p^*}(\RR^d)$. Here is a somewhat analogous example.

\begin{theorem}
    Suppose $T: L^p(X) \to L^q(X)$ is a linear operator such that for any sequence $\{ f_n \}$ in $L^p(X)$ which converges almost everywhere to a function $f \in L^p(X)$, the sequence $\{ Tf_n \}$ converges almost everywhere to $Tf \in L^q(X)$. Then $T$ is a bounded operator.
\end{theorem}
\begin{proof}
    We apply the closed graph theorem. Suppose $\{ f_n \}$ is a sequence converging to some function $f$ in the $L^p$ norm, and $Tf_n$ converges to $g$ in the $L^q$ norm. Then $\{ f_n \}$ has a subsequence $\{ f_{n_k} \}$ converging almost everywhere to $f$, so $Tf_{n_k}$ converges almost everywhere to $Tf$. But this implies that $Tf = g$, since $\{ Tf_{n_k} \}$ must have a further subsequence converging almost everywhere to $g$.
\end{proof}

\begin{theorem}
    No Banach space $X$ has a countably infinite basis.
\end{theorem}
\begin{proof}
    Suppose $X$ has a countable infinite basic $\{ e_1, e_2, \dots \}$. For each $n$, let $X_n = \langle e_1, \dots, e_n \rangle$. Then $X_n$ is closed and has non-empty interior (if it's interior was non-empty, it would be absorbing, and thus $X_n = X$. But then the Baire category theorem says that $\bigcup X_n$ is nowhere dense, which is impossible since $X = \bigcup X_n$.
\end{proof}


\section{The Hahn-Banach Theorem}

\begin{theorem}
    If $X$ is a Banach space, and $Y \subset X$ is a finite dimensional subspace, then there exists a closed subspace $Z$ of $X$ such that $X = Y \oplus Z$.
\end{theorem}
\begin{proof}
    Let $\{ y_1, \dots, y_n \}$ be a basis for $Y$. Hahn-Banach enables us to find $\lambda_1,\dots,\lambda_n \in X^*$ such that $\lambda_i(y_i) = 1$. Consider the continuous linear operator $\lambda: X \to \CC^n$ given by
    %
    \[ \lambda(x) = (\lambda_1(x), \dots, \lambda_n(x)). \]
    %
    Set $Z = \text{Ker}(\lambda)$. Then $X = Y \oplus Z$.
\end{proof}

\section{Quotient Spaces}

Let $X$ be a norm space, and $Y$ a closed subspace. We can then associate a natural norm on the quotient space $X/Y$. We define
%
\[ \| x + Y \| = \inf_{y \in Y} \| x + y \|. \]
%
If $X$ is a Banach space, then $X/Y$ is a Banach space. More generally, being a Banach space is a {\it three space property}, in the sense that if any two of $\{ X, Y, X/Y \}$ are Banach spaces, then the third space is also a Banach space. The quotient map $\pi: X \to X/Y$ is continuous and surjective, since $\| x + Y \| \leq \| x \|$ for each $x \in X$. The open mapping theorem thus implies that $\pi$ is an open map.

\begin{example}
    The space $c_0$ is a closed subspace of $l_\infty$, so we can consider the quotient space $l_\infty / c_0$. For any sequence $a \in l_\infty$, and any integer $n$, we have $a + c_0 = a^n + c_0$, where $a^n_k = 0$ for $k < n$, and $a^n_k = a_k$ for $k \geq n$. Thus we have
    %
    \[ \| a + c_0 \| \leq \inf \| a^n \|_\infty = \limsup_{n \to \infty} |a_n|. \]
    %
    Conversely, for any sequence $a$, and for any sequence $b \in c_0$, we have
    %
    \[ \| a + b \| = \sup |a_n + b_n| \geq \limsup |a_n + b_n| = \limsup |a_n|. \]
    %
    Thus we have $\| a + c_0 \| = \limsup |a_n|$.
\end{example}

\begin{theorem}
    Let $T: X \to Y$ be a (not necessarily continuous) linear map, and let $Z$ be a closed subspace of the kernel of $T$. Then there is a unique map $S: X/Z \to Y$ such that $T = S \circ \pi$, $T$ is bounded if and only if $S$ is bounded, and $\| T \| = \| S \|$.
\end{theorem}
\begin{proof}
    The existence and uniqueness of $S$ is provided by linear algebra. If $T$ is bounded, then
    %
    \[ \| S(x + Z) \| = \| Tx \| \lesssim \| x \|, \]
    %
    Thus
    %
    \[ \| S(x + Z) \| \lesssim \inf_{z \in Z} \| x + z \| = \| x + Z \|, \]
    %
    which shows $S$ is bounded and $\| S \| \leq \| T \|$. Conversely, if $S$ is bounded, then $T = S \circ \pi$ is bounded, and $\| T \| \leq \| S \| \| \pi \| = \| S \|$.
\end{proof}

This theorem leads to a `first isomorphism theorem' for Banach spaces. If $T: X \to Y$ is a bounded linear map, and $K$ is the kernel then the induced map $S: X/K \to Y$ is an isomorphism. We conclude with an application to the theory of finite rank operators.

\begin{theorem}
    Let $T: X \to Y$ be a finite rank linear map from $X$ to $Y$. Then $T$ is bounded if and only if it's kernel is closed in $X$.
\end{theorem}
\begin{proof}
    Suppose the kernel $K$ of $T$ is closed. Then $X/K$ is a finite dimensional norm space, and so $S: X/K \to Y$ is automatically continuous, hence $T$ is continuous.
\end{proof}

If $T$ is a linear functional, a much stronger statement can be made.

\begin{theorem}
    Let $T: X \to \mathbf{K}$ be a non-zero linear functional. Then $T$ is bounded if and only if it's kernel $K$ is not dense in $X$.
\end{theorem}
\begin{proof}
    The kernel $K$ of $T$ has codimension one in $X$. If $K$ is not dense in $X$, then $\overline{K}$ is a closed, proper subspace of $X$, which implies $K = \overline{K}$, and thus the last theorem implies that $T$ is continuous.
\end{proof}

Another application deals with sums of closed subspaces. If $M$ and $N$ are closed subspaces of a norm space $X$, then $M + N$ need not be closed. But in one special case, the sum is closed.

\begin{theorem}
    Let $M$ be a finite dimensional subspace of $X$, and let $N$ be a closed subspace. Then $M + N$ is closed.
\end{theorem}
\begin{proof}
    Since $N$ is closed, we can consider the quotient space $X/N$. For the resultant projection map $\pi: X \to X/N$, $\pi(M + N) = \pi(M)$ is a finite dimensional subspace of $X/N$, hence closed. By continuity, this implies that $\pi^{-1}(\pi(M)) = M + N$ is closed.
\end{proof}















\chapter{Hilbert Spaces}

\section{Real Inner Product Spaces}

Hilbert spaces are those infinite dimensional vector spaces which behave analytically as close to $\RR^n$ as is possible. They are therefore the spaces where we have the most powerful. Just like in a Banach space, in a Hilbert space we can measure the distances between two points via a norm. But unlike in Banach spaces, in Hilbert spaces, we can measure the angle between two vectors with an \emph{inner product} connected to this norm.

Recall that in $\RR^2$, the angle $\theta \in [0,\pi]$ between two vectors $v$ and $w$ in $\RR^n$ satisfies the equation
%
\[ v_1w_1 + \dots + v_n w_n = |v||w| \cos \theta, \]
%
Where $|v|^2 = v_1^2 + \dots + v_n^2$ and $|w|^2 = w_1^2 + \dots + w_n^2$. The left hand quantity is often easier to work with than the angle $\theta$ itself, because it is \emph{bilinear} in the two vectors $v$ and $w$. It is called the \emph{scalar product} of the two vectors, and we denote it by $v \cdot w$. The length of a vector $v$ can then be described via the scalar product via the equation $|v|^2 = v \cdot v$.

Inner product spaces generalize the scalar product on $\RR^n$ to more general settings. An inner product on a vector space $V$ is a map associating to any two vectors $v$ and $w$ a scalar value $\langle v, w \rangle$, which is \emph{bilinear}, \emph{symmetric}, and \emph{positive definite}, in the sense that $\langle v, v \rangle > 0$ for $v \neq 0$. A n inner product space is then a vector space equipped with a fixed inner product.

\begin{example}
    For each $n \geq 0$, the vector space $\RR^n$ is an inner product space equipped with the scalar product $v \cdot w$.
\end{example}

\begin{example}
    For any measure space $X$, the space $L^2(X)$ of square-integrable real-valued functions is an inner product space, where the inner product of $f,g \in L^2(X)$ is
    %
    \[ \langle f, g \rangle = \int_{-\infty}^\infty f(x) g(x)\ dx. \]
    %
    The Cauchy-Schwartz inequality guarantees that this quantity is finite for any two functions. A particular example is $L^2(\RR)$, the square-integrable functions on the real line. Often more tractable for feeling out the basic theory is the space $l^2(\ZZ)$ of functions $f: \ZZ \to \RR$, such that
    %
    \[ \sum_{n \in \mathbf{Z}} f(n)^2 < \infty, \]
    %
    i.e. the space of square-integrable sequences.
\end{example}

Any inner product space $V$ is naturally a norm space if we define the length of a vector $v \in V$ by the equation $\| v \|^2 = \langle v, v \rangle$. One can see immediately that $\| \lambda v \| = |\lambda| \| v \|$, and that $\| v \| = 0$ if and only if $v = 0$. The triangle inequality will follow shortly, once we prove the most fundamental inequality in analysis, the Cauchy-Schwartz inequality, in the abstract setting of inner product spaces. One way to view the Cauchy-Schwartz inequality here is in terms of a generalization of the Pythagorean theorem in this setting. We say two vectors $v_1,v_2$ in an inner product space $V$ are \emph{orthogonal}, or \emph{perpendicular}, if $\langle v_1, v_2 \rangle = 0$. This means precisely that the two vectors form a right angle with one another.

\begin{theorem}[Pythagorean Theorem]
    If $v_1,\dots,v_n \in V$ are orthogonal,
    %
    \[ \| v_1 + \dots + v_n \|^2 = \| v_1 \|^2 + \dots + \| v_n \|^2 \]
\end{theorem}
\begin{proof}
    We just calculate that
    %
    \begin{align*}
        \| v_1 + \dots + v_n \|^2 &= \langle v_1 + \dots + v_n, v_1 + \dots + v_n \rangle\\
        &= \sum_{i,j = 1}^n \langle v_i, v_j \rangle\\
        &= \sum_{i = 1}^n \langle v_i, v_i \rangle\\
        &= \sum \| v_1 \|^2 + \dots + \| v_n \|^2. \qedhere
    \end{align*}
\end{proof}

\begin{corollary}
    Let $V$ be an inner product space. Fix $v_0 \in V$. Then for any $v \in V$, the projection
    %
    \[ P_{v_0}(v) = \frac{\langle v, v_0 \rangle}{|v_0|^2} v \]
    %
    is the closest vector on the line spanned by $v_0$ to the vector $v$.
\end{corollary}
\begin{proof}
    The vector $v - P_{v_0}(v)$ is orthogonal to any scalar multiple of $v_0$, and so the Pythagorean theorem guarantees that for any $\lambda \in \RR$,
    %
    \begin{align*}
        \| v - \lambda v_0 \|^2 &= \| v - P_{v_0}(v) + P_{v_0}(v) - \lambda v_0 \|^2\\
        &= \| v - P_{v_0}(v) \|^2 + \| P_{v_0}(v) - \lambda v_0 \|^2\\
        &\geq \| v - P_{v_0}(v) \|^2,
    \end{align*}
    %
    with equality if and only if $\lambda v_0 = P_{v_0}(v)$.
\end{proof}

\begin{theorem}[Cauchy Schwartz Inequality]
    Let $V$ be an inner product space. Then for any $v_1,v_2 \in V$,
    %
    \[ |\langle v_1, v_2 \rangle| \leq |v_1||v_2|. \]
\end{theorem}
\begin{proof}
    The idea of this proof, in two dimensions, is intuitively simple, a trivial consequence of the Pythagorean theorem: the hypotenuse of a triangle is it's longest side. We just rephrase this argument in terms of an inner product space. The two vectors $v_2 - P_{v_1}(v_2)$ and $P_{v_1}(v_2)$ are orthogonal to one another, and so the Pythagorean theorem guarantees that
    %
    \[ |v_2|^2 = \| P_{v_1}(v_2) \|^2 + \| v_2 - P_{v_1}(v_2) \|^2 \geq \| P_{v_1}(v_2) \|^2 = \frac{\langle v_1, v_2 \rangle^2}{|v_1|^2} \]
    %
    Rearranging the equation and taking square roots gives the inequality.
\end{proof}

\begin{remark}
    The inequality in this proof shows the Cauchy-Schwartz inequality is only tight when $v_1$ and $v_2$ are close to being scalar multiplies to one another, i.e. when $\| v_2 - P_{v_1}(v_2) \|$ is small. In particular, the Cauchy-Schwartz inequality is an \emph{equality} if and only if $v_1$ and $v_2$ are scalar multiples of one another.
\end{remark}

This theorem justifies the fact that we can define the angle $\theta \in [0,\pi]$ between two vectors by the equation
%
\[ \langle v, w \rangle = \|v\| \|w\| \cos \theta \]
%
The result also implies that the norm we have defined satisfies the triangle inequality.

\begin{theorem}[Triangle Inequality]
    Let $V$ be an inner product space. Then for any $v_1,v_2 \in V$,
    %
    \[ \| v_1 + v_2 \| \leq \| v_1 \| + \| v_2 \| \]
\end{theorem}
\begin{proof}
    We just calculate
    %
    \[ \| v_1 + v_2 \|^2 = \| v_1 \|^2 + 2 \langle v_1, v_2 \rangle + \| v_2 \|^2 \leq \| v_1 \|^2 + 2 \|v_1\| \|v_2\| + \|v_2\|^2 = \left(\|v_1 \| + \|v_2\| \right)^2 \]
    %
    and then we take square roots.
\end{proof}

We can now think of an inner product space as a kind of `infinite dimensional' Euclidean space, with a topology given by the length function, and induced by the triangle inequality. If the metric structure is {\it complete}, then we say that the inner product space is a \emph{Hilbert space}.

\section{Complex Inner Product Spaces}

Generalizing inner product spaces to vector spaces over the complex numbers presents several difficulties, because unless $V = 0$, there is no bilinear, symmetric, positive-definite form $\langle \cdot, \cdot \rangle$ on $V$, since we would then have for any $v \in V$,
%
\[ \langle iv, iv \rangle = i^2 \langle v, v \rangle = - \langle v, v \rangle. \]
%
To obtain a definition that works in this setting, we turn to our most basic example, the real vector space $\RR^2$, which we can identify with $\CC$. Here, complex conjugation plays a role in defining the distance function, removing the rotation properties of a complex number. The length of a particular complex number $z$ is given by the equation $|z|^2 = z \overline{z}$. Over $\mathbf{C}^n$, we then introduce the scalar {\it Hermitian product}
%
\[ (v,w) = v_1 \overline{w_1} + \dots + v_n \overline{w_n} \]
%
this equation agrees with the standard scalar product when $v$ and $w$ have real coordinates, and also gives a notion of length, since $(v,v) > 0$ for any $v \neq 0$. Unlike the scalar product, the hermitian product is not bilinear, but instead \emph{sesquilinear} (`one and a half linear' in Greek), i.e. linear in the first argument, but {\it antilinear} in the second, i.e. that
%
\[ (v, w + u) = (v,w) + (v,u) \quad\text{and}\quad (v, \lambda w) = \overline{\lambda} (v,w). \]
%
In general, we define a \emph{Hermitian inner product} $(\cdot, \cdot)$ over a complex vector space to be a sesquilinear symmetric map which is positive definite. A Hermitian inner product space is just a space with a Hermitian inner product. A complex Hilbert space is just a Hermitian inner product space whose norm gives a complete metric space structure. These spaces have much the same basic theory as their real counterpart, and we will treat them identically in the sequel until we get to more advanced contexts.

\begin{example}
    For any measure space $X$, the space $L^2(X)$ of square integrable functions is a  Hermitian inner product spaces under the inner product
    %
    \[ (f,g) = \int_X f(x) \overline{g(x)}\ dx. \]
    %
    As a special case, so is the space $l^2(\ZZ)$ of square integrable sequences, equipped with the inner product
    %
    \[ (f,g) = \sum_{n \in \mathbf{Z}} f(n) \overline{g(n)} \]
    %
    The conjugation generalize these spaces to complex functions.
\end{example}

\begin{example}
    We define the \emph{Hardy space} $H^2(\mathbf{D})$ to be the space of all functions $f(z)$, defined on the interior of the unit disk, and holomorphic there, such that the quantity
    %
    \[ \| f \|_{H^2(\mathbf{D})} = \sup_{0 \leq r < 1} \left( \frac{1}{2\pi} \int_{-\pi}^\pi |f(re^{it})|^2 \right)^{1/2} \ dt \]
    %
    is finite. This norm is induced by the inner product
    %
    \[ (f,g) = \sup_{0 \leq r < 1} \frac{1}{2\pi} \int_{-\pi}^\pi f(re^{it}) \overline{g(re^{it})} \]
    %
    which is finite by the Cauchy Schwartz inequality on $L^2[-\pi,\pi]$. Thus $H^2(\mathbf{D})$ is a Hermitian inner product space.

    We claim $H^2(\mathbf{D})$ is complete, so that it is a complex Hilbert space. To do this, we will show that, as an inner product space, it is isomorphic to $l^2(\NN)$. Let us begin by noting that any $f \in H^2(\mathbf{D})$ must have a power series expansion of the form
    %
    \[ f(z) = \sum_{n = 0}^\infty a_n z^n, \]
    %
    which converges on the interior of the unit disk. Moreover, for any $0 < r < 1$, Cauchy's integral formula shows that
    %
    \[ a_n = \frac{r^{-n}}{2 \pi} \int_{-\pi}^\pi f(re^{it}) e^{-nit}\; dt. \]
    %
    Thus Parseval's inequality, and the orthogonality of the exponentials on any disk centred at the origin, shows that
    %
    \[ \frac{1}{2\pi} \int_{-\pi}^\pi |f(re^{it})|^2 = \sum |a_n|^2 r^{2n}. \]
    %
    One immediate consequence of this is that the quantities
    %
    \[ \frac{1}{2\pi} \int_{-\pi}^\pi |f(re^{it})|^2 \]
    %
    are monotonically increase in $r$, so that
    %
    \[ \| f \|_{H^2(\mathbf{D})} = \lim_{r \to 1} \left( \frac{1}{2\pi} \int_{-\pi}^\pi f(re^{it})^2 \right)^{1/2} \ dt. \]
    %
    Moreover, we have $\| f \|_{H^2(\mathbf{D})} = \| a \|_{l^2(\NN)}$. Thus we have found an isometry $H^2(\mathbf{D}) \to l^2(\NN)$. For any $a \in l^2(\NN)$, $\limsup_{n \to \infty} |a_n|^{1/n} \leq 1$, and so the power series
    %
    \[ f(z) = \sum_{n = 0}^\infty a_n z^n \]
    %
    is holomorphic on the interior of the unit disk, and Cauchy Schwartz shows this is clearly the inverse map to the one above. Thus $H^2(\mathbf{D})$ is a complete Hermitian inner product space.

    It is a standard result of basic Fourier analysis that if $a = \{ a_n \}$ lies in $l^2(\NN)$, and we consider the square integrable function
    %
    \[ u(z) = \sum_{n = 0}^\infty a_n z^n, \]
    %
    in $L^2(\TT)$, then the Poisson kernels
    %
    \[ (P_r * u)(z) = \sum a_n r^n z^n \]
    %
    converge pointwise almost everywhere to $u$. Thus we obtain from our discussion \emph{Fatou's theorem}, that for any $f \in H^2(\mathbf{D})$, and for almost every $|z| = 1$, the \emph{radial limit}
    %
    \[ \lim_{r \to 1} f(rz) \]
    %
    is well defined, and on the boundary defines a square-integrable function in $L^2(\TT)$. The family of all functions obtained in this way is denoted $H^2(\TT)$. It is precisely the family of functions $f \in L^2(\TT)$ such that
    %
    \[ \widehat{f}(n) = 0 \]
    %
    for any $n < 0$.

    The function $f(z) = (1 - z)^{-i}$ lies in $H^2(\TT)$, but does not have a radial limit on the arc to one. If $\delta > 0$ is suitably small, it follows that for any countable set $\{ w_k \}$ on $\TT$
    %
    \[ g(z) = \sum_{i = 1}^\infty \delta^i f( z \overline{w_k} ) \]
    %
    lies in $H^2(\DD)$, but does not have radial limits on the arc towards any of the points $w_k$.

    For any $0 < s < 1$ and $w \in \TT$, the set $\Gamma_s(w)$ is defined to be the smallest convex set containined $w$ and the ball of radius $s$ at the origin. The \emph{tangential limit} of a function $f$ defined on the open unit disk at a point $w$ is
    %
    \[ \lim_{\substack{z \to w\\z \in \Gamma_s(w)}} f(z). \]
    %
    For any $0 < s < 1$, there exists $\varepsilon > 0$ such that for $z \in \Gamma_s(w)$,
    %
    \[ |(z - w) \cdot w| \geq \varepsilon \cdot (z - w). \]
    %
    Thus Cauchy Schwartz implies that if $w = e^{it_0}$, and $z \in \Gamma_s(w)$ can be written as $r e^{it}$, then there is $C > 0$ such that
    %
    \[ |t - t_0| \leq C (1 - r). \]
    %
    Thus if $f \in L^1(\TT)$, and $t_0$ lies in the Lebesgue set of $f$, then
    %
    \[ |(P_r * f)(t) - f(t_0)| \leq \int |f(s + t_0) - f(t_0)| P_r(s - (t - t_0))\; ds = (P_{r,t-t_0} * f)(t_0) - f(t_0), \]
    %
    where $P_{r,s_0}(s) = P_r(s - s_0)$. Now we know $\{ P_r \}$ satisfies bounds of the form
    %
    \[ |P_r(s)| \leq C_1 / (1 - r) \quad\text{and}\quad |P_r(s)| \leq C_1 (1 - r) / |s|^2, \]
    %
    and these bounds are sufficient to prove that $(P_r * f)(t_0)$ converges to $f(t)$ for any $t_0$ in the Lebesgue set of $f$. Similarily, where $C$ is as above, let $P_{r,s_0}(s) = P_r(s - s_0)$ for any $|s_0| \leq C (1 - r)$. We claim that we have uniform bounds of the form
    %
    \[ |P_{r,s_0}(s)| \leq C_2 / (1 - r) \quad\text{and}\quad |P_{r,s_0}(s)| \leq C_2 (1 - r) / |s|^2. \]
    %
    It would then follow that as $r \to 1$, $(P_{r,s_0} * f)(t)$ converges to $f(t_0)$ for any $t_0$ in the Lebesgue set of $f$, which would complete our argument. The first bound here follows immediately from the corresponding bound for $P_r$. On the other hand, if $|s| \geq 2C (1 - r)$, then
    %
    \[ |P_{r,s_0}(s)| = |P_r(s - s_0)| \leq C_1 (1 - r) / |s - s_0|^2 \leq 2 C_1 (1 - r) / |s|^2. \]
    %
    If $|s| \leq 2C (1 - r)$, then
    %
    \[ |P_{r,s_0}(s)| = |P_r(s - s_0)| \leq C_1 / (1 - r) = C_1 (1 - r) / (1 - r)^2 \leq 4C^2 C_1 (1 - r) / |s|^2. \]
    %
    Thus setting $C_2 = \max(2C_1,4C^2 C_1)$ implies we have shown what was required.
\end{example}

If $W$ is a closed subspace of a Hilbert space $H$, in the sense that it is a subspace, and it is a closed set under the topology induced by the metric structure of the hermitian product, then $W$ is also a Hilbert space, because a closed subset of a complete metric space is also complete. Conversely, a complete subspace is also closed. In the example above, the space $H^2(\TT)$ is a closed subspace of $L^2(\TT)$, and thus a Hilbert space.

\begin{example}
    If $\Omega$ is an open subset of the complex plane, the space $L^2_a(\Omega)$ of holomorphic square-integrable functions is a Hilbert space. If $B_r(x)$ is a ball of radius $r$ centered at $x$ whose closure is contained in $\Omega$, and $f$ is analytic in $\Omega$, then the mean value property guarantees that
    %
    \[ f(x) = \fint_{B_r(x)} f(y)\ dy \]
    %
    It follows from Cauchy Schwarz that if $0 < r < \text{dist}(x,\partial \Omega)$, then
    %
    \[ |f(x)| \leq \frac{1}{r\sqrt{\pi}} \|f \|_2 \]
    %
    In particular, this implies that if a sequence of analytic functions in $L^2_a(\Omega)$ converges in $L^2$ norm to some function, then they must also converge locally uniformly, so the resultant function is analytic. It follows that $L^2_a(\Omega)$ is closed in $L^2(\Omega)$, and so $L^2_a(\Omega)$ is a Hilbert space. In particular, since
    %
    \[ \| f \|_{L^2_a(\mathbf{D})}^2 \lesssim \| f \|_{H^2(\mathbf{D})}, \]
    %
    the Hardy space $H^2(\mathbf{D})$ is a closed subspace of $L^2_a(\mathbf{D})$.
\end{example}

There is some way to recover the intuition of the inner product measuring angles between vectors in the Hermitian setting. As we have seen in real spaces, the normalized inner product
%
\[ \frac{\langle v, w \rangle}{|w|^2} \]
%
is the scalar needed to projection $v$ onto the line spanned by the vector $w$. In complex vector spaces, the space spanned by a single vector is a {\it complex line}, or a one dimensional plane. If we set
%
\[ \frac{\langle v, w \rangle}{|w|^2} \]
%
to be the value we must scale $w$ by to obtain the projection of $v$ onto the plane spanned by $w$, then we might have to rotate $w$, hence $\langle v, w \rangle$ might have a rotational part. Indeed, this is exactly the correct geometrical definition of the inner product, if we already have a well defined projection operation. The Pythagorean theorem, Cauchy Schwartz inequality,and triangle inequality goes through for Hermitian product spaces unperturbed, and the proofs are essentially the same, as the reader can verify. Ultimately, however, the reason that everything for real inner product spaces `seems' to work for Hermitian products, is one of the main reasons we push through the initial lack of intuition.

Another approach to understanding Hermitian inner products is to use the fact that we can construct a Hermitian inner product from a real inner product. Recall that a complex vector space $V$ is just a real vector space with a fixed twisting linear map $J: V \to V$ with $J^2 = -1$. If we already have a {\it real} inner product $\langle \cdot, \cdot \rangle$ on $V$, then our hope is to extend the real inner product to a complex inner product $(\cdot,\cdot)$, where the real part of the Hermitian inner product is our original real product, so that
%
\[ \Re((v,w)) = \langle v, w \rangle \]
%
By geometric intuition, it is reasonable to assume that $J$ is a twist by a right angle, so that $\langle v, Jv \rangle = 0$ for all vectors $v$, and that $J$ is an isometry with respect to the inner product. It then follows that
%
\[ \langle v, Jw \rangle = \langle Jv, J^2w \rangle = \langle -Jv, w \rangle \]
%
so we cannot hope for the extension to be complex linear, only sesquilinear. If $(\cdot, \cdot)$ is a sesquilinear form, then we calculate
%
\[ \Im (v,w) = \Re(-i (v,w)) = \Re (v,iw) = \langle v, iw \rangle \]
%
so the {\it only} way to define $(\cdot, \cdot)$ properly is as
%
\[ (v,w) = \langle v, w \rangle + i \langle v, iw \rangle \]
%
The fact that $(v,w)$ measures the projection of $v$ onto the complex line containing $w$ appears again, because over the real numbers, the complex line is spanned over real scalars by $w$ and $Jw$, and the value above, once normalized, gives the real projection onto this two dimensional plane.

If $V$ is any real inner product space, then we can always complexify it by embedding $V$ in $V \oplus V$ by the trivial map $v \mapsto (v,0)$, and defining a real inner product $\langle (v_1,v_2), (w_1,w_2) \rangle = \langle v_1,w_1 \rangle + \langle v_2,w_2 \rangle$. We can then add an artifical twisting map $J(v,w) = (-w,v)$ gives $V \oplus V$ a complex structure, and since it satisfies the properties of the discussion above, the real inner product extends to give a complex inner product. The space with all these gadgets attached is called the \emph{complexification} of $V$, denoted $V^\mathbf{C}$. If $V$ is a Hilbert space, then so $V^\mathbf{C}$ will also be a Hilbert space. In particular, because of this fact, most results for inner product spaces can be proved first for hermitian inner products, and then reduced to inner products by this embedding.

\section{Orthogonality}

Recall the notion of orthogonal, that two vectors $x,y$ in an inner product space are orthogonal if $(x,y) = 0$. We sometimes write this statement in shorthand as $x \perp y$. Orthogonality is a symmetric relation, since if $(v,w) = 0$,
%
\[ (w,v) = \overline{(v,w)} = \overline{0} = 0 \]
%
The theory of right triangles essentially manifests in the theory of equations involving two to three vectors, as we have already seen in the case of the Pythagorean identity.

\begin{theorem}[Parallelogram Law]
    Let $H$ be a Hermitian inner product space. If $x,y \in H$, then
    %
    \[ \| x + y \|^2 + \| x - y \|^2 = 2 \| x \|^2 + 2 \| y \|^2 \]
    %
    which is geometrically intuitive, viewing $0, x, y$, and $x + y$ as vertices of a parallelogram.
\end{theorem}
\begin{proof}
    We simply calculate
    %
    \begin{align*}
        \| x + y \|^2 + \| x - y \|^2 &= \langle x + y, x + y \rangle + \langle x - y, x - y \rangle\\
        &= 2 \| x \|^2 + 2 \| y \|^2 + \langle x, y \rangle + \langle y, x \rangle - \langle x, y \rangle - \langle y, x \rangle\\
        &= 2 \| x \|^2 + 2 \| y \|^2
    \end{align*}
    %
    and this shows the theorem is true.
\end{proof}

\section{Optimizing over Convex Sets}

One of the biggest advantages of Hilbert spaces is that we have powerful theorems about the structure of convex sets in the space. A \emph{convex set} in a vector space is a set $C$ such that the line between any two points is contained in $C$. That is, for any $x, y \in C$, and $\lambda \in [0,1]$, $\lambda x + (1 - \lambda) y \in C$.

\begin{theorem}
    If $C$ is any closed convex subset of a Hilbert space, and $x \in H$ is arbitrary, then there is a unique point $y \in C$ which minimizes $\| x - y \|$, over all choices of $y$ in the convex set.
\end{theorem}
\begin{proof}
    Since $C - x$ is a convex set, we may assume without loss of generality that $x = 0$, and so we are trying to minimize the norm over $C$. If $x,y \in C$ minimize this norm, with $\| x \| = \| y \| = d$, then
    %
    \[ d \leq \left\| \frac{x + y}{2} \right\| \leq \frac{1}{2}(d + d) = \frac{d}{2} \]
    %
    Hence the parallogram law implies
    %
    \[ d^2 = \left\| \frac{x + y}{2} \right\|^2 = d^2 - \left\| \frac{x - y}{2} \right\|^2 \]
    %
    which implies $x = y$. We know that there must a sequence $x_i \in C$ with $\| x_i \| \to d$ monotonically, and then the parallelogram law implies that if $\| x_n \|, \| x_m \| \leq d + \varepsilon$, then since $(x_n + x_m)/2 \in C$, then
    %
    \[ \left\| \frac{x_n - x_m}{2} \right\|^2 = \frac{1}{2} \| x_n \|^2 + \frac{1}{2} \| x_m \|^2 - \left\| \frac{x_n + x_m}{2} \right\|^2 \leq 2 d \varepsilon + \varepsilon^2 \to 0 \]
    %
    hence $\{ x_n \}$ is a Cauchy sequence, and therefore converges to a point $x$, which satisfies $\| x \| = d$.
\end{proof}

Linear subspaces of a vector spaces are trivially verified to be convex sets, and we find that

\begin{theorem}
    If $V$ is a closed linear subspace of a Hilbert space $H$, and $v \in V$ is the closest point to a fixed point $x$, then $v - x \perp V$, in the sense that $v - x \perp w$ for any $w \in V$. Conversely, if $v - x \perp V$, then $v$ is the closest point to $x$.
\end{theorem}
\begin{proof}
    If $\langle v - x, w \rangle \neq 0$, then by multiplying $w$ by a scalar value, we may assume that $\langle v - x, w \rangle < 0$, and $\| w \| = 1$, and then for $\alpha > 0$,
    %
    \[ \| \alpha w + v - x \|^2 = \| v - x \|^2 + 2 \alpha \Re \langle w, v - x \rangle + |\alpha|^2 \| w \|^2  \]
    %
    and so as $\alpha \to 0$, we find that eventually $\| \alpha w + v - x \|^2 < \| v - x \|^2$. Conversely, if $\langle v - x, w \rangle = 0$ for all $w$, then for any $w$,
    %
    \[ \| w - x \|^2 = \| (w - v) + (v - x) \|^2 = \| w - v \|^2 + \| v - x \|^2 \geq \| v - x \|^2 \]
    %
    so $v$ minimizes the distance to $x$ among all vectors in $V$.
\end{proof}

For any subset $X$ of an inner product space $V$, define $X^\perp$ to be the set of vectors $v$ such that $\langle x, v \rangle = 0$ for all $x \in X$. It is clearly a closed linear subspace of $V$. If $V$ is a closed linear subspaces of a Hilbert space $H$, then for any $x \in H$, there is a unique $y \in V$ with $y - x \perp V$, and we may define a map $P: H \to V$ such that $Px = y$, which we call the \emph{orthogonal projection} of $H$ onto $V$.

\begin{theorem}
    If $P: H \to V$ is defined as above, then
    %
    \begin{enumerate}
        \item $P$ is a linear map.
        \item $\| Px \| \leq \| x \|$.
        \item $P^2 = P$.
        \item $\ker P = V^\perp$, and $\im P = V$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    If $x_0 - y_0 \perp V$ and $x_1 - y_1 \perp V$, then $(\alpha x_0 - \alpha y_0) + (\beta x_1 - \beta y_1) \perp V$, hence $P(\alpha x_0 + \beta x_1) = \alpha y_0 + \beta y_1$, and so $P$ is a linear map. It is obvious that $P$ is a contraction, because $\| x \|^2 = \| Px \|^2 + \| x - Px \|^2$, and $\| x - Px \|^2 \geq 0$. For any $y \in V$, $y - y \perp V$, hence $Py = y$, and so $P^2 = P$. Finally, $Py = 0$ if and only if $y \perp V$, in which case we find $y \in V^\perp$.
\end{proof}

\begin{example}
    Given $f \in L^2[-\pi,\pi]$, we can consider an $L^2$ Fourier expansion
    %
    \[ f(x) = \sum_{n = -\infty}^\infty \widehat{f}(n) e^{nit}. \]
    %
    The partial sum operators are
    %
    \[ S_N f(x) = \sum_{n = -N}^N \widehat{f}(n) e^{nit} \]
    %
    and these operators are \emph{precisely} the projection operators onto the finite dimensional subspace of $L^2[-\pi,\pi]$ spanned by $\{ e_{-N}, \dots, e_N \}$. We also have an orthogonal projection
    %
    \[ Pf(x) = \sum_{n = 0}^\infty \widehat{F}(n) e^{nit} = \frac{1}{2 \pi i} \int_{\partial \mathbf{D}} \frac{f(w)}{w - z}\; dw. \]
    %
    whose image we can identify with $H^2(\TT)$, e.g. the space of all functions which form the boundary values of holomorphic functions in $H^2(\mathbf{D})$.
\end{example}

\begin{corollary}
    For any closed subspace $V$ of a Hilbert space $H$, $(V^\perp)^\perp = V$. If $X$ is an arbitrary subset of a Hilbert space $H$, then $(X^\perp)^\perp = \overline{\text{span}}(X)$ is the closure of the linear span of the elements of $X$.
\end{corollary}
\begin{proof}
    If $P$ is the orthogonal projection of $H$ onto $V$, and $Q$ is the orthogonal projection of $H$ onto $V^\perp$, then $Px + Qx = x$ for all $x \in H$, and so the kernel of $Q$ is exactly the set of vectors $x$ for which $Px = x$, from which we conclude that $x \in V$. If $X$ is arbitrary, then $\overline{\text{span}}(X)$ is contained in $(X^\perp)^\perp$, because $(X^\perp)^\perp$ is a closed subspace of $H$ containing all elements in $X$. Conversely, we conclude that $X^\perp = \overline{\text{span}}(X)^\perp = X^\perp$, because if $\langle y, x \rangle = 0$ for all $x \in X$, then surely $\langle y, \sum \alpha_i x_i \rangle = \sum \alpha_i \langle y, x_i \rangle = 0$, so $y \perp \text{span}(X)$, and if $v_i \to v$, with $v_i \in \text{span}(X)$, then by continuity of the inner product we find that $0 = \langle y, v_i \rangle \to \langle y, v \rangle$, hence $\langle y, v \rangle = 0$, and so $y \perp \overline{\text{span}}(X)$.
\end{proof}

\begin{corollary}
    A subspace $V$ is dense in $H$ if and only if $V^\perp = 0$.
\end{corollary}
\begin{proof}
    For then the closure of $V$ is $(V^\perp)^\perp = 0^\perp = H$.
\end{proof}

Given two Hilbert spaces $H_0$ and $H_1$, we can define a canonical Hilbert space structure on $H_0 \oplus H_1$ by letting $\langle x_0 + x_1, y_0 + y_1 \rangle = \langle x_0, y_0 \rangle + \langle x_1, y_1 \rangle$. The induced topology is precisely the product topology, because $x_i + y_i \to x + y$ if and only if $x_i \to x$, and $y_i \to y$. The orthogonal projection of $H$ onto $V$ is incredibly important to the theory of Hilbert spaces, because it gives us a direct sum decomposition of $H$ into $V \oplus V^\perp$. The Pythagorean theorem tells us that for any $v \in V$ and $w \in V^\perp$,
%
\[ \| v + w \|^2 = \| v \|^2 + \| w \|^2 \]
%
and so the map $x \mapsto Px + (1 - P)x$ is actually an \emph{isometry} between vector spaces (it preserves the inner product). This is the basic notion of equivalence between various Hilbert spaces, and so we really can think of $H$ as being composed of the two closed subspaces $V$ and $V^\perp$.

\section{The Riesz Representation Theorem}

Many problems in functional analysis can be reduced to the analysis of certain linear functions between vector spaces. The easiest linear functions to analyze are the \emph{linear functionals}, which are linear maps $f: V \to K$, where $K$ is the base field of the vector space $V$. We will say a linear functions $f: V \to K$ is \emph{bounded} if there exists $M > 0$ such that $|f(x)| \leq M \| x \|$ for all $x \in V$. The bounded linear maps are exactly the continuous linear maps (and to verify continuity, we need only verify continuity at zero, so bounded linear maps are essentially `uniformly continuous'). If $f$ and $g$ are continous, then $\lambda f + \gamma g$ is continuous, and so the set $V^*$ of bounded linear functionals on $V$ is a vector space, called the \emph{dual space} of $V$. On the dual space of a norm space, we may define a dual norm by letting $\| f \|$ be the smallest number $M$ such that $|f(x)| \leq M \| x \|$ holds for all $x$. Since $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, we find $\| f + g \| \leq \| f \| + \| g \|$, and it is easy to verify that $\| \lambda f \| = |\lambda| \| f \|$.

Given a Hilbert space $H$, we can use the inner product structure on $H$ to transport vectors in $H$ to functionals in $H^*$. That is, for a given $x \in H$, we define $x^* \in H^*$ to be the functional $x^*(y) = \langle x, y \rangle$. The Cauchy-Schwarz inequality tells us that $\| x^* \| = \| x \|$, so the dual map is an isometry. The Riesz representation theorem tells us that this isometry is actually invertible.

\begin{theorem}[Riesz]
    For any bounded linear function $f \in H^*$, there exists a unique vector $x \in H$ such that $f(y) = \langle x, y \rangle$ for all $y \in H$.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $f \neq 0$. Let $V$ be the kernel of $f$. Then $V$ is a closed linear subspace of $H$, and $V^\perp$ is one dimensional by the first isomorphism theorem. Consider the orthogonal projection $P$ onto $V^\perp$. If $x$ is a nonzero vector in $V^\perp$, with $\| x \| = 1$ and $f(x) = \gamma$, then for each $y$ there is $\lambda(y)$ for which $f(y) = f(Py) = \lambda(y)$, and what's more, $\langle y, x \rangle = \langle Py, x \rangle = \lambda(y)$, and so we have found a unique $y$ as specified, and $y$ is unique because the dual map is an isometry.
\end{proof}

\begin{example}
    For any measure space $X$, $L^2(X)$ is a Hilbert space, and so for any bounded linear functional $\alpha: L^2(X)^*$, there is a unique $g \in X$ such
    %
    \[ \alpha(f) = \int_X f(x) \overline{g(x)}\; dx. \]
    %
    Thus studying linear functionals on $L^2(X)$ reduces to integration theory.
\end{example}

\section{Constructing an Orthonormal Basis}

In the theory of general infinite dimension vector spaces, the standard definition of a basis (which in the seuqle we will call a \emph{Hamel basis}, expanding a vector in a finite linear combination of basis elements, does not necessarily lead to a useful theory because of analytical problems. In the setting of Banach spaces, we can get around this by instead considering infinite linear combinations of vectors. A set $\{ e_n \}$ is a \emph{Schauder basis} for a Banach space $X$ such that for any $x \in X$, there is a unique family of scalars $\lambda_n$ such that $x = \sum_n \lambda_n e_n$, where $\sum_n \lambda_n e_n$ is defined as the limit of the net of finite sums corresponding to the sequence. In the sequel, by a basis, we will mean a Schauder basis.

If $\{ e_1, \dots, e_n \}$ are an \emph{orthonormal} family of vectors in an inner product space $V$, in the sense that they are pairwise orthogonal, and $\| e_n \| = 1$ for all $i$, then the Pythagorean identity implies
%
\[ \| \sum_n a_ne_n \| = \left( \sum |a_n|^2 \right)^{1/2}. \]
%
Using slightly more analysis, and using the fact that we are working in a Hilbert space $H$, this result remains true for an infinite family of orthonormal vectors $\{ e_n \}$, provided that $\sum |a_n|^2 < \infty$, because then the partial sums of $\sum a_n e_n$ are Cauchy, and because a Hilbert space is \emph{complete}, the partial sums must converge to an infinite sum. For any vector $v$, the sum $\sum_n (v,e_n) e_n$ also converges to some vector in $H$, and by continuity of the inner product, the vector $v - \sum (v,e_n) e_n$ is orthogonal to all of the vectors $\{ e_n \}$. Thus we find that
%
\[ \| v \|^2 = \| v - \sum (v,e_n) e_n \|^2 + \sum_n |(v,e_n)|^2 \geq \sum_n |(v,e_n)|^2. \]
%
This inequality is \emph{Bessel's inequality}. If $v = \sum (v,e_n) e_n$, then we find that
%
\[ \| v \|^2 = \sum_{i = 1}^\infty |(v,e_n)|^2. \]
%
This equation is known as {\it Parsevel's identity}. We now give a series of conditions on $\{ e_n \}$ guaranteeing that for any $v \in H$, $v = \sum_n (v,e_n) e_n$.

\begin{theorem}
    The following properties of an orthonormal family $\{ e_n \}$ are equivalent:
    %
    \begin{itemize}
        \item[(a)] For any vector $v \in H$, $v = \sum_n (v,e_n) e_n$.
        \item[(b)] Finite linear combinations of the $e_i$ are dense in $H$.
        \item[(c)] If $(v,e_n) = 0$ for all $n$, then $v = 0$.
        \item[(d)] Parseval's identity holds.
    \end{itemize}
    %
    We then say the sequence is an \emph{orthonormal basis} for the space.
\end{theorem}
\begin{proof}
    (a) clearly implies (b). Assuming (b), note that if $(v,e_i) = 0$ for all $i$, then in particular, $(v,w) = 0$ for all $w$ which can be expressed as finite linear combinations of the $e_i$. But we may choose $w_n$ with $w_n \to v$ in $L^2$, and then since $|(v,w_n - v)| \leq \|v\|\|w_n - v\| \to 0$, we conclude that $0 = (v,w_n) = (v,v) + (v,w_n-v)$ converges to $(v,v)$, so $(v,v) = 0$, and hence $v = 0$. If $v$ is given, then Bessel's inequality ensures that
    %
    \[ \sum_{i = 1}^\infty |(v,e_i)|^2 \leq \| v \| < \infty \]
    %
    and so the partial sums of the sequence $\sum_{i = 1}^\infty |(v,e_i)|^2$ are Cauchy, and because we are working in a Hilbert space, converge to some vector $w$. Now $v - w$ is orthogonal to $e_i$ for each $i$, since
    %
    \[ (w,e_i) = \lim \sum_{j = 1}^n (v,e_j)(e_j,e_i) = (v,e_i) \]
    %
    and therefore $v = w$, proving (a). (a) implies (d) is trivial, and if (d) holds, then Pythagoras' identity implies that
    %
    \[ \| v - \sum_{i = 1}^n (v,e_i) e_i \|^2 = \sum_{i = n+1}^\infty |(v,e_i)|^2 \to 0 \]
    %
    so (a) holds.
\end{proof}

A topological space is {\it separable} if it has a countable dense subset. If $H$ is a separable Hilbert space, then by performing the Gram Schmidt process to a countable dense subset, one finds an orthogonal sequence, which is easily verified to be an orthonormal basis for the Hilbert space. Thus \emph{every separable Hilbert space has a orthonormal basis}. With some more work on the geometry of Hilbert spaces, and the axiom of choice, we can show that an arbitrary Hilbert space has an orthonormal basis, if we allow bases ranging over an uncountable index set. Before we do this, however, we consider some applications.

\begin{example}
    Fourier analysis was the first area of mathematics where the ideas of orthogonality were employed in infinite dimensions. Since $[-\pi,\pi]$ is a finite measure space, the space $L^2[-\pi,\pi]$ is contained within $L^1[-\pi,\pi]$, and so if $f \in L^2[-\pi,\pi]$, we can consider it's Fourier series
    %
    \[ \widehat{f}(n) = \frac{1}{2\pi} \int_{-\pi}^\pi f(x) e^{-nix}\ dx. \]
    %
    If we define $e_n(x) = e^{nix}$, then $\widehat{f}(n) = (f,(2\pi)^{-1} e_n)$, and
    %
    \[ (e_n,e_m) = \int_{-\pi}^\pi e^{(n-m)ix} = \begin{cases} 2 \pi & n = m \\ 0 & n \neq m \end{cases} \]
    %
    It follows that $\{ (2 \pi)^{-1} e_n \}$ is an orthonormal sequence in $L^2[-\pi,\pi]$. Using the basic fact from Fourier analysis that for any $f \in C[-\pi,\pi]$ with $f(-\pi) = f(\pi)$, the partial sums of
    %
    \[ \sum \widehat{f}(n) e^{nix} \]
    %
    converge uniformly to $f$, and the fact that continuous functions are dense in $L^2[-\pi,\pi]$, we conclude that the exponentials $\{ (2\pi)^{-1} e_n \}$ are an orthonormal basis for $L^2[-\pi,\pi]$. As a result, we obtain the classic Parseval's inequality
    %
    \[ \fint_{-\pi}^\pi |f(x)|^2\ dx = \sum_{n = -\infty}^\infty |\widehat{f}(n)|^2, \]
    %
    and that for any $f \in L^2[-\pi,\pi]$, the partial sums of
    %
    \[ \sum \widehat{f}(n) e^{nix} \]
    %
    converge in $L^2[-\pi,\pi]$ to $f$.
\end{example}

\begin{example}
    Viewing $\TT$ as the boundary of the unit disk in $\CC$, equipped with the normalized Lebesgue measure. Then for appropriately smooth $f,g \in L^2(\TT)$, we can interpret $(f,g)$ as a contour integral, i.e.
    %
    \[ (f,g) = \int_{\TT} \frac{f(z) \overline{g(z)}}{2 \pi iz}\; dz, \]
    %
    where the torus is given the standard orientation. Now consider the M\"{o}bius transformation
    %
    \[ z = \frac{i - x}{i + x}, \]
    %
    which is an oriented mapping from $\RR$ to $\TT - \{ -1 \}$. Now
    %
    \[ dz = -2i \frac{1}{(x + i)^2}. \]
    %
    Thus
    %
    \[ (f,g) = \frac{1}{\pi} \int_{-\infty}^\infty f \left( \frac{i - x}{i + x} \right) \overline{g \left( \frac{i - x}{i + x} \right)} \frac{1}{1 + x^2}\; dx. \]
    %
    Thus if we consider the map $T: L^2(\TT) \to L^2(\RR)$ given by
    %
    \[ Tf(x) = f \left( \frac{i - x}{i + x} \right) \frac{\pi^{-1/2}}{x + i}, \]
    %
    then $T$ is an \emph{isometry}, i.e. $(Tf, Tg) = (f,g)$ for each $f,g \in L^2(\TT)$. In particular, since $L^2(\TT)$ has an orthonormal basis of the form $\{ z^n : n \in \ZZ \}$, we conclude that $L^2(\RR)$ has an orthonormal basis of the form
    %
    \[ \pi^{-1/2} \left( \frac{i - x}{i + x} \right)^n \frac{1}{i + x}. \]
\end{example}

We can generalize to non separable spaces by an application of Zorn's lemma. If $\{ S_\alpha \}$ is a chain of orthonormal sets, then $\bigcup S_\alpha$ is an orthonormal set, so we may apply Zorn's lemma to conclude that a maximal orthonormal set $S$ exists. We claim this is an orthonormal basis, which is equivalent to showing that $S^\perp = \{ 0 \}$. And indeed, if $S^\perp$ was nontrivial, we could find $x \in S^\perp$ with $\| x \| = 1$, and then $S \cup \{ x \}$ would be an orthonormal set, contradicting maximality. Thus orthonormal bases exist on any Hilbert space.

\begin{theorem}
    Any two orthonormal bases of a Hilbert space $H$ have equal cardinality.
\end{theorem}
\begin{proof}
    If $S$ is an orthonormal basis for a Hilbert space $H$, then one of two possibilities hold:
    %
    \begin{itemize}
        \item Some orthonormal basis of $H$ is finite: Then $H$ is finite dimensional, and the result follows by standard linear algebra.
        \item There does not exist a finite orthonormal basis for $H$: Let $T$ be another orthonormal basis. For each $x \in H$, the set $T_x = \{ e \in T: (e,x) \neq 0 \}$ is at most countable, since the sum $\sum |(e,x)|^2$ converges. But $T = \bigcup_{s \in S} T_s$ since $S$ is an orthonormal basis, which means that
        %
        \[ \#(T) \leq \#(S) \cdot \#(\NN) = \#(S). \qedhere \]
    \end{itemize}
\end{proof}

We may therefore define the \emph{dimension} of a Hilbert space to be the cardinality of any orthonormal basis. This actually uniquely defines the Hilbert space, for if $H_0$ and $H_1$ are Hilbert spaces with orthonormal bases $\{ e_i \}$ and $\{ f_i \}$, then we have an isometry $T: H_0 \to H_1$ given by
%
\[ T(\sum a_i e_i) = \sum a_i f_i. \]
%
This is well defined, for the sum $\sum a_x x$ converges if and only if $\sum |a_x|^2 < \infty$, and the same criterion shows $\sum a_x f(x)$ converges.

\begin{example}
    For any set $X$ equipped with the counting measure, we have an orthonormal basis on $l^2(X)$, given by the family of functions $\{ e_x : x \in X \}$, where $e_x(y) = \mathbf{I}(x = y)$. The family is certainly orthonormal. If $f \in l^2(X)$ satisfies $f(x) = \langle f, e_x \rangle = 0$ for all $x \in X$, then $f = 0$, so the set is a basis. Thus the dimension of the Hilbert space $l^2(X)$ is $\#(X)$. If $X$ is not countable, then $l^2(X)$ is not separable.
\end{example}

\begin{example}
    Define an inner product on the space $\text{AP}_0(\RR)$ of all finite linear combinations of exponentials on $\RR$, i.e. an inner product on the span of $\{ e^{2 \pi i \lambda x} : \lambda \in \RR \}$, by declaring the set to be orthonormal. For any two $f,g \in \text{AP}_0(\RR)$, one can verify that
    %
    \[ \langle f,g \rangle = \lim_{T \to \infty} \frac{1}{2T} \int_{-T}^T f(t) \overline{g(t)}\; dt, \]
    %
    i.e. this is an inner product space in which each of the exponentials in $\{ e^{2 \pi i \lambda x} \}$ are separable. Write the resulting norm as $\| f \|_{\text{AP}(\RR)}$. The \emph{completion} of $\text{AP}_0(\RR)$ is denoted $\text{AP}(\RR)$. Note that since $\text{AP}(\RR)$ has an uncountable basis, it is \emph{not separable}.

    A continuous function $f \in C_b(\RR)$ is called \emph{uniformly almost periodic} if it is the uniform limit of a family of functions in $\text{AP}_0(\RR)$. By virtue of the fact that $\| f \|_{\text{AP}(\RR)} \leq \| f \|_{L^\infty(\RR)}$, almost periodic functions can be identified with a certain subfamily of elements of $\text{AP}(\RR)$. If $f_0$ is uniformly almost periodic, and $0 < \varepsilon \leq 1$, then we can find $f \in \text{AP}_0(\RR)$ such that $\| f - f_0 \|_{L^\infty(\RR)} \leq \varepsilon$. The function $f$ is the linear combination of finitely many exponentials oscillating at a certain family of frequencies $\{ \lambda_1,\dots,\lambda_n \}$, i.e. we can write $f = \sum a_i e_{\lambda_i}$. If $|\lambda_1|, \dots, |\lambda_n| \leq \alpha$, then
    %
    \begin{align*}
        |f(t + s) - f(t)| &\leq \sum a_i |e_{\lambda_i}(t+s) - e_{\lambda_i}(t)|\\
        &\leq \left( \sum |a_i|^2 \right)^{1/2} \left( \sum |\lambda_i s + \ZZ|^2 \right)^{1/2}\\
        &= \| f \|_{\text{AP}(\RR)} \left( \sum |\lambda_i s + \ZZ|^2 \right)^{1/2}\\
        &\leq 2 \| f_0 \|_{L^\infty(\RR)} \left( \sum |\lambda_i s + \ZZ|^2 \right)^{1/2}.
    \end{align*}
    %
    Consider the sequence $X(n)_i = \lambda_i n + \ZZ$ in $\TT^n$. Then
    %
    \[ |X(n)| = \left( \sum |\lambda_i n + \ZZ|^2 \right)^{1/2}. \]
    %
    By Weyl equidistribution, this sequence is either periodic, or equidistributed on some finite union of cosets of a subtorus of $\TT^n$. Fix some $R > 0$ large enough such that $X(1), \dots, X(R)$ is a $\varepsilon$ cover of this finite union of cosets. Then, given any interval $I \subset \RR$ of length $R+1$, we can find an integer $n_0 \in I$ such that $[n_0 - R, n_0] \subset I$. Find $n \in [1,R]$ such that $|X(n) - X(n_0)| \leq \varepsilon$, then $n - n_0 \in I$, and $|X(n - n_0)| = |X(n) - X(n_0)| \leq \varepsilon$. Thus
    %
    \[ |f_(t + n) - f(t)| \leq |f(t + n) - f(t)| + \varepsilon \leq (1 + 2\| f_0 \|_{L^\infty(\RR)}) \cdot \varepsilon. \]
    %
    Adjusting parameters, we conclude that for any almost periodic function $f_0$, and any $\varepsilon > 0$, we can find $L > 0$ such that any interval $I$ of length $L$ contains an `almost period' $x_0$, such that $|f_0(x + x_0) - f_0(x)| \leq \varepsilon$ for all $x \in \RR$. Conversely, suppose that for each $\varepsilon > 0$, we can find $L > 0$ such that any interval of length $L$ contains a $\varepsilon$ almost period for $f$. Consider a trigonometric polynomial $g$, periodic on $[-10L,10L]$, such that $\| f - g \|_{L^\infty[-10L,10L]} \leq \varepsilon$. Then for any $x_1 \in \RR$, we can find $x_0 \in \RR$ with $|x_1 - x_0| \leq L$ such that $|f(x + x_0) - f(x)| \leq \varepsilon$ for all $x \in \RR$. Then
    %
    \[ f(x_1) = f(x_1 - x_0) + O(\varepsilon) = g(x_1 - x_0) + O(\varepsilon) = g(x_1 - x_0 + 10L) \]
    %
    \[ |f(x + x_0) - f(x)| \leq \varepsilon. \]
    %
    We can then find a trigonometric polynomial $g = \sum a_n e_{n/x_0}$ such that $\| f - g \|_{L^\infty[0,x_0]} \leq \varepsilon$. TODO FINISH THIS PROOF PLUS LOOK UP BESICOVITCH, ALMOST PERIODIC FUNCTIONS.
\end{example}




\chapter{Basics of Operator Theory}

Let us now further develop the theory of bounded operators. Recall that given two Banach spaces $X$ and $Y$, we let $B(X,Y)$ denote the family of bounded linear operators between them.

\section{Adjoints of Operators on Banach Spaces}

Recall that if $T: X \to Y$ is a linear map between two vector spaces, then we can consider it's \emph{algebraic adjoint} $T^*$ mapping linear functionals on $Y$ to linear functionals on $X$ by the formula
%
\[ (T^* \lambda)(x) = \lambda(Tx). \]
%
If $T$ is a \emph{bounded} linear map between two Banach spaces, and $\lambda$ is a \emph{bounded} linear functional on $Y$, then $T^* \lambda$ will \emph{also} be a bounded linear functional, since for any $x \in X$,
%
\[ |T^* \lambda(x)| = |\lambda (Tx) | \lesssim \| Tx \|_Y \lesssim \| x \|_X. \]
%
Thus given any bounded linear map $T: X \to Y$ between two Banach spaces, we obtain a bounded linear operator $T^*: Y^* \to X^*$ between the dual spaces of $X$ and $Y$, called the \emph{adjoint} of the operator $T$. It is not too difficult to argue that $T$ is bounded if and only if $T^*$ is bounded, which is often a useful way to verify an operator $T$ is bounded in the first place.

The calculation above shows that
%
\[ \| T^* \lambda \|_{X^*} \leq \| T \| \| \lambda \|_{Y^*}. \]
%
Thus $\| T^* \| \leq \| T \|$. This means that $\| T^{**} \| \leq \| T^* \|$, and we have
%
\[ \| Tx \|_Y = \| T^{**} x^{**} \|_{Y^{**}} \leq \| T^* \| \| x^{**} \|_{X^{**}} = \| T^* \| \| x \|_X. \]
%
Thus we conclude that $\| T \| \leq \| T^* \|$, and so we actually have $\| T \| = \| T^* \|$, so the correspondence $T \mapsto T^*$ is a linear isometry from $B(X,Y)$ to $B(Y^*,X^*)$. We remark that this is not always an onto isometry unless $X$ and $Y$ are reflexive, but we have a characterization of the image of this isometry.

\begin{theorem}
    A (not necessarily bounded) operator $S: Y^* \to X^*$ can be written as $T^*$ for some bounded operator $T: X \to Y$ if and only if $S$ is continuous from the weak-$*$ topology to the weak-$*$ topology.
\end{theorem}
\begin{proof}
    First we should show adjoints of bounded operators are weak $*$ to weak $*$ continuous. If $\{ \gamma_\alpha \}$ is a net in $Y^*$ converging in the weak $*$ topology to some $\gamma \in Y^*$, then for any $x \in X$,
    %
    \[ (T^* \gamma_\alpha) x = \gamma_\alpha (Tx) \to \gamma(Tx) = T^* \gamma(x). \]
    %
    Thus the net $\{ T^* \gamma_\alpha \}$ converges to $T^* \gamma$ in the weak-$*$ topology, and so $T^*$ is weak $*$ continuous. Note that we never assumed $T$ was bounded in this proof, and we will later apply this result for a not necessarily bounded operator later in this argument (though we will conclude that weak $*$ continuity implies boundedness).

    Conversely, suppose $S: Y^* \to X^*$ is weak $*$ continuous. We rely on the fact that for any Banach space $Z$, if $Q_Z: Z \to Z^{**}$ is the natural double dual map, then $Q_Z(Z)$ consists \emph{precisely} of the weak $*$ continuous functionals on $Z^*$, and that any linear operator continuous from the weak topology to the weak topology is bounded. For each $x \in X$, we would like to define $Tx \in Y$ such that for any $\lambda \in Y^*$,
    %
    \[ \lambda(Tx) = (S\lambda)(x). \]
    %
    This determines the value of $Tx$ on any linear functional on $Y$, so by the Hahn-Banach theorem, this set of equations determines $Tx$ uniquely, if it exists. To prove existence, we note that we can certainly define $\alpha \in Y^{**}$ by the equation
    %
    \[ \alpha(\lambda) = (S\lambda)(x). \]
    %
    Since $S$ is weak $*$ continuous, so too is $\alpha$, and so it follows that $\alpha = y^{**}$ for some $y \in Y$, which means that we can set $Tx = y$. We thus trivially obtain a linear map $T: X \to Y$. To verify this map is bounded, we show it is bounded from the weak topology to the weak topology. Suppose that $\{ x_\alpha \}$ is a net in $X$ converging to some $x \in X$ is the weak topology. Then $x_\alpha^{**}$ converges in the weak $*$ topology to $x^{**}$. Since $S^*$ is weak $*$ continuous, $S^*(x_\alpha^{**})$ converges in the weak $*$ topology to $S^*(x^{**})$. But this means that for any $\gamma \in Y^*$,
    %
    \[ \gamma(Tx_\alpha) = S^*(x_\alpha^{**})(\gamma) \to S^*(x^{**})(\gamma) = \gamma(Tx). \]
    %
    Thus $\{ Tx_\alpha \}$ converges in the weak topology to $Tx$, and so $T$ is continuous in the weak topology.
\end{proof}

\section{Operators on Hilbert Spaces}

If $H$ is a Hilbert space, then the characterization of $H^*$ is very easy - it is naturally isomorphic to $H$ itself. And Hilbert spaces form very neat isomorphism classes, so, roughly speaking, the theory of problems about the elements of Hilbert spaces is roughly speaking, a solved problem. Modern research on Hilbert spaces is really about the bounded operators on a Hilbert space, which form a rich and nontrivial class for which many open problems remain unsolved. Let us begin a deeper study of these operators.

The first powerful tool in the study of operators on Hilbert spaces is the existence of \emph{adjoints}. Given a linear map $T: X \to Y$ between Banach spaces, we obtain a natural adjoint map $T^*: Y^* \to X^*$. If $X$ and $Y$ are Hilbert spaces, then $X$ is naturally isomorphic to $X^*$, and $Y$ is naturally isomorphic to $Y^*$. Thus we can actually define the adjoint as a map $T^*: Y \to X$. Let us introduce the adjoint more precisely.

\begin{lemma}
    If $( \cdot, \cdot )$ is a continuous sesquilinear form on a Hilbert space $H$, then there is a unique $T \in B(H)$ such that $(x,y) = \langle x, Ty \rangle$ for all $x,y \in H$.
\end{lemma}
\begin{proof}
    Since $( \cdot, \cdot)$ is continuous, the uniform boundedness principle implies that there exists a quantity $L > 0$ such that for any $x,y \in H$,
    %
    \[ |(x,y)| \leq L \| x \| \| y \|. \]
    %
    For each $x$, $(\cdot, x)$ is a bounded linear functional, so there is a unique $Tx \in H$ such that $(y,x) = \langle y, Tx \rangle$. Now
    %
    \begin{align*}
        \langle y, T(ax_1 + bx_2) \rangle &= (y, ax_1 + bx_2)\\
        &= \overline{a} (y,x_1) + \overline{b} (y,x_2)\\
        &= \overline{a} \langle y, Tx_1 \rangle + \overline{b} \langle y, Tx_2 \rangle\\
        &= \langle y, a Tx_1 + b Tx_2 \rangle,
    \end{align*}
    %
    it follows that $T$ is a linear map, i.e. $T(ax_1 + bx_2) = aTx_1 + b T x_2$. Moreover, since
    %
    \[ |\langle x, Ty \rangle| = |(x,y)| \leq L \| x \| \| y \|, \]
    %
    it follows that $\| Ty \| \leq L \| y \|$.

    \[ \langle x, My \rangle = (x,y) \leq \|(\cdot, \cdot)\| \| x \| \| y \| \]
    %
    So $\| M \| \leq \|(\cdot,\cdot)\|$, but also
    %
    \[ (x,y) = \langle x, My \rangle \leq \| M \| \| x \| \| y \| \]
    %
    so $\|(\cdot, \cdot)\| \leq \| M \|$, and we have equality of norms.
\end{proof}

\begin{theorem}
    Let $H_1$ and $H_2$ be Hilbert spaces. If $T: H_1 \to H_2$ is a bounded linear map, then there is a unique bounded linear map $T^*: H_2 \to H_1$ such that
    %
    \[ \langle Tx, y \rangle = \langle x, T^*y \rangle \]
    %
    The map $T^*$ is the \emph{adjoint} of $T$. We have $T^{**} = T$, and $\| T^* \| = \| T \|$.
\end{theorem}
\begin{proof}
    The map $(x,y) = \langle Tx, y \rangle$ is a sesquilinear form, so there is a unique $T^*$ such that $(x,y) = \langle x, T^*y \rangle$. By taking suprema over $x \in H$ with $\| x \| = 1$ on the right hand side of the equation defining $T^*$, we have
    %
    \[ \| T^* y \| = \sup_{\| x \| = 1} \langle Tx, y \rangle \leq \| T \| \| y \|. \]
    %
    Thus $\| T^* \| \leq \| T \|$. It is simple to see that $T^{**} = T$, because for any $x \in H_1$ and $y \in H_2$,
    %
    \[ \langle T^{**} x, y \rangle = \langle x, T^* y \rangle = \langle Tx, y \rangle. \]
    %
    But this means by symmetry that $\| T \| = \| T^{**} \| \leq \| T^* \|$, which implies $\| T \| = \| T^* \|$.
\end{proof}

\begin{example}
    If we are working over the field $\RR$, then every operator $B(\RR^n, \RR^m)$ can be identified with a unique matrix in $M_{n,m}(\RR)$, and the adjoint corresponds to taking the transpose of a matrix. Working over the field $\CC$, every operator $B(\CC^n, \CC^m)$ can be identified with a unique matrix in $M_{n,m}(\CC)$, and the adjoint here is the conjugate tranpose.
\end{example}

\begin{example}
    Given $\phi \in L^\infty(X)$, where $X$ is a $\sigma$-finite measure space, we have an operator $M_\phi \in B(L^2(X))$ defined by $M_\phi(f) = \phi f$. Then
    %
    \[ \langle M_\phi f, g \rangle = \int \phi f \overline{g} = \int f \overline{g \overline{\phi}} = \langle f, \overline{\phi} g \rangle \]
    %
    Thus $M_\phi^* = M_{\overline{\phi}}$.
\end{example}

The adjoint operation $*$ is an antilinear operator from $B(H_1,H_2)$ to $B(H_2,H_1)$, such that $(ST)^* = T^*S^*$. This is verified by calculation, since
%
\[ \langle ST x, y \rangle = \langle Tx, S^* y \rangle = \langle x, T^*S^* y \rangle \]
%
We also have $\| T^*T \| = \| T \|^2$, since
%
\[ \langle T^*T x, x \rangle = \langle Tx, Tx \rangle = \| T \|^2 \| x \| \]
%
so $\| T^*T \| \leq \| T \|^2$, and this is inequality is attained in the suprema, since if $x_i \in B_H$ is such that $\| T x_i \| \to \| T \|$, then
%
\[ \langle T^*T x_i, x_i \rangle = \| T x_i \|^2 \to \| T \|^2 \]
%
Thus $*$ is what is known as an \emph{involution}, and makes $B(H)$ into a \emph{$C^*$ algebra}.

Next, we prove a result which generals the rank-nullity theory theorem from finite dimensional linear algebra.

\begin{theorem}
    Fix a linear operator $T: H \to H$ on a Hilbert space $H$. Then
    %
    \[  H = \text{Im}(T) \oplus \text{Ker}(T^*) = \text{Ker}(T) \oplus \text{Im}(T^*). \]
\end{theorem}
\begin{proof}
    By symmetry, it suffices to prove the first equality. The kernel of $T^*$ is closed, and so it suffices to show that $\text{Ker}(T^*) = \text{Im}(T)^\perp$. If $x \in \text{Im}(T)$ and $y \in \text{Ker}(T^*)$, then we can write $x = Tx'$, and then
    %
    \[ \langle x, y \rangle = \langle Tx', y \rangle = \langle x', T^* y \rangle = \langle x', 0 \rangle = 0. \]
    %
    Thus $\text{Ker}(T^*) \subset \text{Im}(T)^\perp$. Conversely, if $y \in \text{Im}(T)^*$, then for any $x \in H$,
    %
    \[ \langle T^* y, x \rangle = \langle y, Tx \rangle = 0. \]
    %
    This means $T^* y = 0$.
\end{proof}

In the special case where $T$ is \emph{self adjoint}, i.e. $T^* = T$, we conclude that
%
\[ H = \text{Ker}(T) \oplus \text{Im}(T). \]
%
We will later see this remains true for the class of normal operators, and we can continue refining this orthogonal decompositions into approximate eigenspaces, which, when $T$ is compact, can be completely refined to give a complete eigenfunction expansion.

Any operator $M: H \to H$ can be expressed as $M = T + iS$, where $T$ and $S$ are self adjoint operators, by defining
%
\[ T = \frac{1}{2}(M + M^*)\ \ \ \ \ S = \frac{1}{2i}(M - M^*) \]
%
That $T$ and $S$ are unique follows because if $T_1$ and $T_2$ are self-adjoint, and $T_1 = iT_2$, then we also have
%
\[ T_1 = T_1^* = (iT_2)^* = -i T_2^* = -iT_2 \]
%
Thus $iT_2 = -iT_2$, which means $T_1 = T_2 = 0$. We denote $T$ by $\text{Re}(M)$ and $S = \text{Im}(M)$. An operator $M: H \to H$ is \emph{normal} if $M^* M = MM^*$, or equivalently, if $\text{Re}(M) \text{Im}(M) = \text{Im}(M) \text{Re}(M)$.

\begin{theorem}
    If $T$ is a self-adjoint operator, then
    %
    \[ \| T \| = \sup \{ \langle Tx, x \rangle: \| x \| \leq 1 \} \]
\end{theorem}
\begin{proof}
    Let $M$ be the supremum. Clearly $M \leq \| T \|$. If $\| x \|, \| y \| \leq 1$,
    %
    \begin{align*}
        \langle T(x \pm y), x \pm y \rangle &= \langle Tx, x \rangle \pm \langle Ty, x \rangle \pm \langle Tx, y \rangle + \langle Ty, y \rangle\\
        &= \langle Tx, x \rangle \pm \overline{\langle Tx, y \rangle} \pm \langle Tx, y \rangle + \langle Ty, y \rangle\\
        &= \langle Tx, x \rangle \pm 2 \Re \langle Tx, y \rangle + \langle Ty, y \rangle
    \end{align*}
    %
    Then, subtracting, we find
    %
    \[ 4\Re \langle Tx, y \rangle = \langle T(x+y),x+y \rangle - \langle T(x - y), x - y \rangle \]
    %
    Thus
    %
    \[ 4 \Re \langle Tx, y \rangle \leq M(\|x + y\|^2 + \|x - y\|^2) = 2M(\|x\|^2 + \|y\|^2) \leq 4M \]
    %
    Let $\lambda$ be such that $\langle Tx, y \rangle = \lambda |\langle Tx, y \rangle|$. If we replace $x$ by $\lambda x$, we find
    %
    \[ |\langle Tx, y \rangle| = \overline{\lambda} \langle Tx, y \rangle = \langle T(\overline{\lambda}x), y \rangle \leq M \]
    %
    Hence
    %
    \[ \| Tx \| = \sup \{ |\langle Tx, y \rangle| : y \in B_H \} \leq M \]
    %
    and therefore $\| T \| \leq M$.
\end{proof}

\begin{remark}
    We will later see that this result remains true for all \emph{normal operators} $T$, using the spectral theory of such operators. The main idea is that the spectral theory implies the existence of an \emph{approximate eigenvalue} $\lambda \in \CC$ for $T$ with $|\lambda| = \| T \|$, i.e. a scalar such that for any $\varepsilon > 0$, there is $x \in H$ with $\| x \| = 1$ such that $\| Tx - \lambda x \| \leq \varepsilon$. This implies that if $M$ is as in the proof above, then
    %
    \[ M \geq \left| \langle Tx, x \rangle \right| \geq |\lambda| - \varepsilon = \| T \| - \varepsilon, \]
    %
    and we can take $\varepsilon \to 0$.
\end{remark}

\begin{corollary}
    Let $T: H \to H$ be self adjoint. Then
    %
    \[ \langle Tx, x \rangle = 0 \]
    %
    for all $x \in H$ if and only if $T = 0$.
\end{corollary}

\begin{lemma}
    An operator $T \in B(H)$ in a complex Hilbert space is self adjoint if and only if $\langle Tx, x \rangle \in \mathbf{R}$ for each $x \in H$.
\end{lemma}
\begin{proof}
    If $T$ is self adjoint, then
    %
    \[ \langle Tx, x \rangle = \langle x, Tx \rangle = \overline{\langle Tx, x \rangle} \]
    %
    Conversely, if $\langle Tx, x \rangle \in \RR$ for each $x \in H$, then
    %
    \[ \langle Tx, x \rangle = \overline{\langle x, Tx \rangle} = \langle x, Tx \rangle = \langle T^*x, x \rangle \]
    %
    for each $x$. This means that if $S = i(T - T^*)$, then $S$ is self-adjoint, and $\langle Sx, x \rangle = 0$ for all $x \in H$. This implies $S = 0$, which can only be true if $T = T^*$. Thus $T$ is self-adjoint.
\end{proof}

\begin{corollary}
    If $\langle Tx, x \rangle = \langle Sx, x \rangle$ for each $x \in H$, then $T = S$.
\end{corollary}

\begin{corollary}
    An operator $T: H \to H$ is normal if and only if for any $x \in H$,
    %
    \[ \| Tx \| = \| T^*x \|. \]
\end{corollary}
\begin{proof}
    If $T$ is normal, then for any $x \in H$, we calculate that
    %
    \[ \| Tx \|^2 = \langle Tx, Tx \rangle = \langle T^*Tx, x \rangle = \langle TT^*x, x \rangle = \langle T^*x, T^*x \rangle = \| T^* x \|^2. \]
    %
    Conversely if $\| Tx \| = \| T^* x \|$ for all $x \in H$, then we find for any $x \in H$,
    %
    \[ \langle T^*Tx, x \rangle = \langle TT^*x, x \rangle. \]
    %
    Since $T^*T$ and $TT^*$ are both self-adjoint, this means that $T^*T = TT^*$, i.e. $T$ is normal.
\end{proof}

The next few lemmas show that these are the unique self-adjoint operators with this property. This is essentially like beginning with $\mathbf{C}$, and identifying $\mathbf{R}$ as those elements invariant under complex conjugation.

\begin{theorem}
    $T$ is normal if and only if $\| Tx \| = \| T^* x \|$ for each $x$.
\end{theorem}
\begin{proof}
    For then, for each $x$,
    %
    \[ \| Tx \|^2 = \langle Tx, Tx \rangle = \langle T^*Tx, x \rangle \]
    \[ \| T^*x \|^2 = \langle T^*x, T^*x \rangle = \langle TT^*x, x \rangle \]
    %
    which implies $T^*T = TT^*$. The converse repeats backwards through the proof, since the norm of $\| T \|$ is specified by its action through the inner product.
\end{proof}

\begin{theorem}
    Any normal operator $T$ has the following properties.
    %
    \begin{enumerate}
        \item[(a)] $\text{ker}(T) = \text{ker}(T^*)$.
        \item[(b)] $T(H)$ is dense in $H$ if and only if $T$ is injective.
        \item[(c)] $T$ is a surjective isomorphism if and only if $\| Tx \| \geq C \| x \|$ for some $C$.
        \item[(d)] If $Tx = \lambda x$, then $T^*x = \overline{\lambda} x$.
        \item[(e)] If $\lambda$ and $\gamma$ are distinct eigenvalues, then the eigenspaces are orthogonal to one another.
    \end{enumerate}
\end{theorem}
\begin{proof}
    To prove $(a)$ notice that $\| Tx \| = 0$ if and only if $\| T^*x \| = 0$. $(b)$ follows since
    %
    \[ T(H)^\perp = \text{ker}(T^*) = \text{ker}(T) \]
    %
    If $\| Tx \| \geq C \| x \|$, then $T(H)$ is closed, and dense, therefore $T(H) = H$. The converse follows by definition. If $T$ is normal, then $\lambda - T$ is also normal, since $(\lambda - T)^* = \overline{\lambda} - T^*$, so $\text{ker}(\lambda - T) = \text{ker}(\lambda - \overline{\lambda})$. Finally, if $Tx = \lambda x$, and $Ty = \gamma y$, then
    %
    \[ \lambda \langle x, y \rangle = \langle Tx, y \rangle = \langle x, T^*y \rangle = \langle x, \overline{\gamma} y \rangle = \gamma \langle x, y \rangle \]
    %
    so if $\lambda \neq \gamma$, then $\langle x,y \rangle = 0$.
\end{proof}

The natural automorphisms in the category of Hilbert spaces are the \emph{unitary operators}, which we now introduce.

\begin{theorem}
    If $U \in B(H)$, then the following are equivalent.
    %
    \begin{enumerate}
        \item[(a)] $U$ is unitary.
        \item[(b)] $GL(H) = H$ and $\langle Ux, Uy \rangle = \langle x, y \rangle$.
        \item[(c)] $GL(H) = H$ and $\| Ux \| = \| x \|$, so $U$ is an isometry from $H$ to itself.
    \end{enumerate}
    %
    If any of these results are true, we say $U$ is a \emph{unitary operator}.
\end{theorem}
\begin{proof}
    If $U$ is unitary, then $U$ is invertible, so $GL(H) = H$, and
    %
    \[ \langle Ux, Uy \rangle = \langle U^*Ux, y \rangle = \langle x, y \rangle \]
    %
    If $(b)$ holds, then
    %
    \[ \| Ux \|^2 = \langle Ux, Ux \rangle = \langle x, x \rangle = \| x \|^2 \]
    %
    If $(c)$ holds, then
    %
    \[ \langle U^*Ux, x \rangle = \langle Ux, Ux \rangle = \|Ux\|^2 = \|x\|^2 = \langle x, x \rangle \]
    %
    Thus $U^*U$ is the identity. Since $U$ is injective and surjective, the open mapping theorem tells us $U$ is invertible, so $U^* = U^{-1}$.
\end{proof}

We have already seen the importance of orthogonal projections in the basic theory of Hilbert spaces, and now we offer an operator theoretic characterization of these orthogonal projections.

\begin{theorem}
    If $P: H \to H$ whose image is a subspace $W$ of $H$, then the following are equivalent:
    %
    \begin{enumerate}
        \item[(a)] $P$ is self-adjoint.
        \item[(b)] $P$ is normal.
        \item[(c)] $W = \text{ker}(P)^\perp$.
        \item[(d)] $\langle Px, x \rangle = \| Px \|^2$.
    \end{enumerate}
    %
    In any of the three cases, we say $P$ is the \emph{orthogonal projection} onto $W$, and $W$ uniquely defines $P$.
\end{theorem}
\begin{proof}
    If $P$ is self-adjoint, then $P$ is trivially normal. If $P$ is normal, then
    %
    \[ P(H) = \text{ker}(P^*)^\perp = \text{ker}(P)^\perp \]
    %
    If (c) holds, then every $x = y + Px$, where $Py = 0$. Then
    %
    \[ \langle P(y + Px), y + Px \rangle = \langle Px, y + Px \rangle = \langle Px, Px \rangle = \| Px \|^2 \]
    %
    If (d) holds, then $\langle Px, x \rangle \in \mathbf{R}$ for each $x$, so $P$ is self-adjoint. If (c) holds, then $\langle Px, x \rangle$
\end{proof}

If $H$ is a Hilbert space, then two orthogonal projections $P_1$ and $P_2$ might not necessarily commute. A simple computation verifies that if $P_1$ and $P_2$ are one-dimensional projections, then $P_1 P_2 = P_2 P_1$ if and only if these lines are orthogonal to one another, or if $P_1 = P_2$. We have a more general characterization of commuting projections.
% As a basic example, let us consider only projections onto a line. Fix $\| v_1 \| = \| v_2 \| = 1$, and consider $P_i x = \langle x, v_i \rangle v_i$. Then
%
%\[ P_1 P_2 x = \langle x, v_2 \rangle \langle v_2, v_1 \rangle v_1 \]
%
%and
%
%\[ P_2 P_1 x = \langle x, v_1 \rangle \langle v_1, v_2 \rangle v_2. \]
%
%If the lines are orthogonal, i.e. $\langle v_1, v_2 \rangle = 0$, then $P_1 P_2 = P_2 P_1 = 0$ trivially commute. On the other hand, if the lines are not orthogonal, then we find that $v_1$ and $v_2$ are scalar multiplies of one another, in which case $P_1 = P_2$. Thus one dimensional projections only commute if they are equal to one another, or projections onto orthogonal subspaces.

\begin{theorem}
    Let $H$ be a Hilbert space, and let $P_1$ and $P_2$ be orthogonal projections onto subspaces $W_1$ and $W_2$ of $H$. Let $U_1 = (W_1 \cap W_2)^\perp \cap W_1$ and $U_2 = (W_1 \cap W_2)^\perp \cap W_2$. Then the following are equivalent:
    %
    \begin{itemize}
        \item $P_1$ and $P_2$ commute.
        \item $P_1 P_2$ is an orthogonal projection.
        \item $U_1$ is perpendicular to $U_2$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Suppose $P_1$ and $P_2$ commute, and let $P = P_1 P_2 = P_2 P_1$. Then
    %
    \[ P^2 = P_1 P_2 P_1 P_2 = P_1^2 P_2^2 = P_1 P_2 = P. \]
    %
    Thus $P$ is a projection. Moreover,
    %
    \[ P^* = (P_1 P_2)^* = P_2 P_1 = P_1 P_2 = P. \]
    %
    Thus $P$ is an orthogonal projection. Since $P = P_1 P_2$, the image of $P$ is contained in $W_1$. Since $P = P_2 P_1$, the image of $P$ is contained in $W_2$. Thus the image of $P$ is contained in $W_1 \cap W_2$. Conversely, if $x \in W_1 \cap W_2$, then $Px = x$. Thus $P$ is projection onto $W_1 \cap W_2$. On the other hand, suppose $P_1 P_2$ is an orthogonal projection. Then $P_1 P_2$ is self adjoint, so $P_1 P_2 = (P_1 P_2)^* = P_2 P_1$, so $P_1$ and $P_2$ commute.

    Now suppse $P_1$ and $P_2$ commute. Write $P_i = P_0 + P_{U_i}$, where $P_0$ is orthogonal projection onto $W_1 \cap W_2$, and $\tilde{U_i}$ is orthogonal projection onto $U_i$. Then
    %
    \[ P_1 P_2 = (P_0 + P_{U_1})(P_0 + P_{U_2}) = P_0 + P_{U_1} P_{U_2} \]
    %
    and
    %
    \[ P_2 P_1 = (P_0 + P_{U_2}) (P_0 + P_{U_1}) = P_0 + P_{U_2} P_{U_1}. \]
    %
    If $P_1$ and $P_2$ commute, $P_1 P_2 = P_2 P_1 = P_0$, and so $P_{U_1} P_{U_2} = P_{U_2} P_{U_1} = 0$. Thus $U_1$ is orthogonal to $U_2$. Conversely, if $U_1$ is orthogonal to $U_2$, then $P_{U_1} P_{U_2} = P_{U_2} P_{U_1} = 0$, and from the equations above we see $P_1$ and $P_2$ commute.
\end{proof}




\section{Compact Operators}

We already know operators on an infinite dimensional Banach space are more tricky than there finite dimensional counterparts. Thus we restrict our attention to operators which do not `spread themselves out' too much. An operator is \emph{compact} if the image of any bounded set is precompact. It suffices to verify that the image of the unit ball is precompact. Given two Banach spaces $X$ and $Y$, we shall let $K(X,Y)$ denote the space of all compact operators from $X$ to $Y$.

\begin{theorem}
    The space $K(X,Y)$ of compact operators forms a closed subspace of $B(X,Y)$ closed under multiplication on the left and right, in the sense that for any $M \in K(X,Y)$, and any pair of bounded operators $N \in B(Y,Y')$ and $L \in B(X',X)$, $NML \in K(X',Y')$.
\end{theorem}
\begin{proof}
    Suppose $M_0$ and $M_1$ are compact. Let $U$ be a bounded susbet of $X$. Then
    %
    \[ (\lambda M_0 + \gamma M_1)(U) = \lambda M_0(U) + \gamma M_1(U) \]
    %
    And the sum of two precompact sets is precompact. Thus $\lambda M_0 + \gamma M_1$ is precompact, so $K(X,Y)$ is a subspace of $B(X,Y)$. If $U$ is a bounded subset of $X'$, then $L(U)$ is a bounded subset of $X$, so $ML(U)$ is a precompact subset of $Y$, implying $NML(U)$ is a precompact subset of $Y'$, for if every net $\{ y_\alpha \}$ in $ML(U)$ has a convergent subnet, then the corresponding subnet of $\{ N(y_\alpha) \}$ must also converge.

    To prove $K(X,Y)$ is closed we rely on the fact that a subset of a complete metric space is precompact if and only if, for any $\varepsilon > 0$, the subset can be covered by finitely many balls of radius $\varepsilon$. Now suppose we have $M_1, M_2, \dots \in K(X,Y)$, and $M_i \to N$. We claim $N$ is compact. Let $U$ be a bounded subset of $X$, such that $\| x \| < K$ for each $x \in U$. Then for each $\varepsilon > 0$, there are finitely many balls of radius $\varepsilon$ which cover $M_i(U)$, for each $i$. If $\| M_i - N \| < \varepsilon / K$, then $\| (M_i - N)(x) \| < \varepsilon$ for each $x \in U$, so that if $M_i x$ is contained in some ball with center $y$ of radius $\varepsilon$, then $Nx$ is contained in the ball with center $y$ and radius $2 \varepsilon$. Thus $N(U)$ can be covered with finitely many balls of radius $2\varepsilon$, and is therefore precompact.
\end{proof}

\begin{corollary}
    $K(X)$ is a closed, two-sided ideal of $B(X)$.
\end{corollary}

\begin{remark}
    It is a theorem of Calkin that $K(H)$ is the only closed, two-sided ideal of $B(H)$ for any Hilbert space $H$. Thus we are lead to consider the \emph{Calkin Algebra} $B(H)/K(H)$, which is simple, and useful in the $K$-theory of operator algebras.
\end{remark}

The most basic examples of compact operators are bounded \emph{finite rank} operators, i.e. operators whose range is finite dimensional. Indeed, bounded operators map bounded sets to bounded sets, and a closed bounded set in a finite dimensional space is compact. Because $K(X,Y)$ is closed, any limit of a family of finite rank operators is compact. Conversely, the family of all finite-rank operators is dense in $K(H)$ for any Hilbert space $H$ (we say $H$ possesses the \emph{approximation property}.

\begin{theorem}
    Let $H$ be a Hilbert space. A bounded operator $T: H \to H$ is compact if and only if $T$ is the limit in the operator norm of a sequence of finite rank operators $\{ T_n \}$.
\end{theorem}
\begin{proof}
    Suppose $T$ is compact. Then the image $H_0$ of $T$ must be separable. Let $\{ e_n \}$ be a basis for $H_0$, and let $T_{\leq N} = P_{\leq N} T$, where $P_N$ is the projection onto the first $N$ elements of the basis for $H_0$. If it was not true that $T_{\leq N}$ converged to $T$ in the operator norm, we could find $\varepsilon > 0$, and two sequences $\{ N_i \}$ and $\{ x_i \}$ such that $\| x_i \| = 1$ for all $i$, and $\| P_{\leq N_i} T x_i - T x_i \| \geq \varepsilon$. Since $T$ is compact, by thinning the subsequence we may assume that $Tx_i \to y$. Then
    %
    \[ \| P_{\leq N_i} y - y \| \geq \| P_{\leq N_i} Tx_i - Tx_i \| - \| P_{\leq N_i} (Tx_i - y) \| - \| Tx_i - y \| \geq \varepsilon - 2 \| Tx_i - y \|. \]

    %
    Now $P_{\leq N_i} y \to y$, so
    %
    \[ 0 = \limsup_{i \to \infty} \| P_{\leq N_i} y - y \| \geq \limsup_{i \to \infty} \varepsilon - 2 \| Tx_i - y \| = \varepsilon, \]
    %
    which gives a contradiction. Thus $T_{\leq N}$ converges to $T$.
\end{proof}

\begin{remark}
    Finding a Banach space \emph{without} the approximation property (i.e. finding a compact operator which cannot be approximated by finite rank operators) proved to be an incredibly difficult problem in 20th century research on functional analysis. Such an operator was only found by Per Enflo in 1972 using tools from the geometry of Banach spaces.
\end{remark}

\begin{corollary}
    Let $H$ be a Hilbert space. If $T$ has finite rank, then $T^*$ has finite rank. A bounded operator $T$ on $H$ is compact if and only if $T^*$ is compact.
\end{corollary}
\begin{proof}
    Suppose $T$ has finite rank. Then we can find an orthogonal basis $\{ e_n \}$ for $H$ such that
    %
    \[ Tx = \sum_{i,j = 1}^M a_{ij} \langle x, e_i \rangle e_j = \sum_{i,j = 1}^M a_{ij} S_{ij} x. \]
    %
    But
    %
    \[ \langle S_{ij} x, y \rangle = \langle x, e_i \rangle \langle e_j, y \rangle = \langle x, \langle y, e_j \rangle e_i \rangle = \langle x, S_{ji} y \rangle. \]
    %
    Thus $S_{ij}^* = S_{ji}$, and so by linearity,
    %
    \[ T^* y = \sum_{i,j = 1}^M \overline{a_{ij}} S_{ji} y. \]
    %
    Thus $T^*$ has finite rank.

    Now if $T$ is a compact operator on $H$, then $T = \lim T_n$, where $T_n$ is a finite rank operator. Then $T^* = \lim T_n^*$ is the limit of finite rank operators, so $T^*$ is also compact. The reverse follows by symmetry.
\end{proof}

\begin{example}
    The simplest operators on a Hilbert space are the diagonal operators, i.e. those operators $T: H \to H$ given in terms of an orthogonal basis $\{ e_n \}$ and $\{ \lambda_n \}$ such that $Te_n = \lambda_n e_n$. Then
    %
    \[ \| T \| = \sup_n |\lambda_n|, \]
    %
    If $S(\varepsilon) = \{ n : |\lambda_n| \geq \varepsilon \}$ is infinite for any $\varepsilon$, then $\{ e_n : n \in S \}$ is a bounded subset of $H$, but $Te_n = \lambda_n e_n$ does not have a convergent subsequence, and so $T$ is not a compact operator. It follows that if $T$ is compact, $\lambda_n \to 0$ as $n \to \infty$. Conversely, if $\lambda_n \to 0$ as $n \to \infty$, then the finite rank operators
    %
    \[ T_{\leq N} x = \sum_{n = 1}^N \lambda_n \langle x, e_n \rangle e_n \]
    %
    converge in operator norm to $T$ as $N \to \infty$, and so $T$ is a compact operator. Thus a bounded diagonalizable operator on a separable Hilbert space is compact precisely when it's eigenvalues converge to zero. More generally, for a diagonal operator on a non separable Hilbert space, every subsequence of eigenvalues must converge to zero, which implies all but countably many eigenvalues are zero.
\end{example}

Note that the operator above, despite it's range contains all the elements of a basis of $H$, \emph{is not surjective}. To see this, note that it does not contain any vector of the form $x = \sum a_n e_n$ such that $\sum (a_n / \lambda_n)^2 = \infty$. On the other hand, it's range is certainly a \emph{dense} subspace of $H$. This is a general phenomenon for compact operators.

\begin{lemma}
    Let $X$ and $Y$ be Banach spaces, and let $T: X \to Y$ be a compact operator. Then the range of $T$ cannot be closed unless $T$ is of finite rank.
\end{lemma}
\begin{proof}
    If the range $Y_0$ of $T$ is closed, then $T$ induces a surjective operator $T_0: X \to Y_0$ between two Banach spaces, and $T_0$ remains compact. By the open mapping theorem, $T_0$ is open. But this implies $Y_0$ is finite dimensional since $Y_0$ then contains an open, precompact set.
\end{proof}

The range of any compact operator is also \emph{separable}, even if it is not the limit of a family of finite rank operators.

\begin{lemma}
    Let $X$ and $Y$ be Banach spaces. Then the range of any compact operator $T: X \to Y$ is separable.
\end{lemma}
\begin{proof}
    Let $B_X$ be the unit ball in $X$. Then $T(B_X)$ is precompact, and therefore separable. But this implies the (non-closed) linear span of $T(B_X)$ is separable, and the linear span of $T(B_X)$ is equal to the range of $T$.
\end{proof}

A useful way to verify compactness in spaces of continuous functions is to use the Arzela-Ascoli criterion. A family of functions $\{ g_\alpha : X \to \mathbf{C} \}$ on a topological space $X$ is \emph{equicontinuous} at $x \in X$ if, for any $\varepsilon > 0$, there is an open set $U$ containing $x$ such that $\| g_\alpha(a) - g_\alpha(b) \| < \varepsilon$ for any $a,b \in U$ and any index $\alpha$.

\begin{theorem}[Arzela-Ascoli]
    If $X$ is a compact metric space, the precompact subsets of $C(X)$ are precisely those subsets which are bounded and equicontinuous.
\end{theorem}
\begin{proof}
    TODO
\end{proof}

Thus if $X$ is a Banach space, and $Y$ is a compact metric space, then a bounded operator $T: X \to C(Y)$ is compact precisely when $T$ maps bounded subsets of $C(X)$ to equicontinuous subsets of $C(Y)$.

\begin{example}
    The best examples of compact operators are given by integral operators with an appropriately regular kernel. Given two compact Hausdorff spaces $X$ and $Y$ equipped with finite Borel measures $\mu$ and $\nu$, and a continuous function $K: X \times Y \to \CC$, we can define an operator by the integral formula
    %
    \[ Tf(y) = \int_X K(x,y) f(x)\; dx. \]
    %
    Then for any $f \in L^1(X)$, $Tf \in C(X)$, which indicates a gain of regularity and a possible compactness of the operator $T$. We claim $T$ is compact from $L^p(X)$ to $L^q(Y)$ for any $1 \leq p,q \leq \infty$. To see this, we note that any integral operator with kernel
    %
    \[ \tilde{K}(x,y) = \sum a_{ij} f_i \otimes g_j \]
    %
    for some continuous functions $f_i \in C(X)$ and $g_j \in C(Y)$, has finite rank and is therefore compact. The Stone-Weirstrass theorem implies such functions are dense in $C(X \times Y)$. Thus we can approximate any $K \in C(X \times Y)$ by a kernel $\tilde{K}$ of the form above. But for any $1 \leq p,q \leq \infty$ we have
    %
    \[ \| T \|_{L^p \to L^q} \lesssim \| K \|_{L^\infty(X \times Y)}, \]
    %
    so it follows that $T$ is a limit in the operator norm of finite rank operators, and thus compact.
\end{example}

\begin{example}
    A \emph{Hilbert-Schmidt} operator between two Hilbert spaces $H_1$ and $H_2$ is a bounded operator $T: H_1 \to H_2$ such that in two orthogonal bases $\{ e_i \}$ and $\{ f_j \}$,
    %
    \[ \| T \|_{HS} = \left( \sum_{i,j} |\langle Te_i, f_j \rangle|^2 \right)^{1/2} = \left( \sum_i \| Te_i \|^2_{H_2} \right)^{1/2} < \infty. \]
    %
    This norm is independant of the choice of bases, as can be verified by a simple expansion. If $T$ is Hilbert Schmidt, so is $T^*$, and $\| T^* \|_{HS} = \| T \|_{HS}$. Moreover, we have a bound $\| T \| \leq \| T \|_{HS}$. Any Hilbert-Schmidt operator is compact, because if $P_{\leq N}$ is projection onto the first $N$ vectors in a basis $\{ e_k \}$, then $P_{\leq N} T$ has finite rank, and $P_{\leq N} T \to T$ as $N \to \infty$ in the operator norm, because it converges in the Hilbert-Schmidt norm. A basic example of a Hilbert-Schmidt operator is an integral operator $T$ between two measure spaces $X$ and $Y$ with kernel $K \in L^2(X \times Y)$, in which case $\| T \|_{HS} = \| K \|_{L^2(X \times Y)}$. To see this, we let $\{ e_i \}$ and $\{ f_j \}$ be orthogonal basis on $L^2(X)$ and $L^2(Y)$. Since $\overline{e_i} \otimes f_j$ is then an orthogonal basis for $L^2(X \times Y)$, we calculate that
    %
    \[ \| T \|_{HS}^2 = \sum |\langle Te_i, f_j \rangle|^2 = \sum |\langle K, \overline{e_i} \otimes f_j \rangle|^2 = \| K \|_{L^2(X \times Y)}. \]
    %
    The space of all Hilbert-Schmidt operators between two Hilbert spaces $H_1$ and $H_2$ forms a Hilbert space itself, $B_{HS}(H_1,H_2)$, where the inner product is
    %
    \[ \langle T_1, T_2 \rangle_{HS} = \sum \langle T_1e_i, f_j \rangle \overline{\langle T_2 e_i, f_j \rangle}. \]
    %
    One can also consider slightly different variants of Hilbert-Schmidt operators. For instance, the family of Hilbert-Schmidt operators between two measure spaces $X$ and $Y$ are the family of all operators $T: L^2(X) \to L^2(Y)$ induced by $K \in L^2(X \times Y)$ by setting
    %
    \[ Tf(x) = \int K(x,y) f(y)\; dy. \]
    %
    If $\{ e_n \}$ is an orthogonal basis for $L^2(X)$, and $\{ e_m \}$ is an orthogonal basis for $L^2(Y)$, then $e_n \otimes e_m$ is a basis for $L^2(X \times Y)$, and so
    %
    \[ \| K \|_{L^2(X \times Y)}^2 = \sum |\langle K, e_n \otimes e_m \rangle|^2 = \sum_{n,m} |\langle Te_n, e_m \rangle|^2. \]
    %
    Thus a Hilbert-Schmidt integral operator is a Hilbert Schmidt operator of the kind above. Conversely, if $T$ is a normal, compact operator from $L^2(X)$ to itself, then there exists an orthonormal basis $\{ e_n \}$ diagonalizing $T$ with eigenvalues $\{ \lambda_n \}$. If $K(x,y) = \sum_n \lambda_n e_n(x) e_n(y)$, then $K$ is a Hilbert-Schmidt kernel which gives the operator $T$. 
\end{example}

\begin{example}
    Let $B$ be the unit ball in $\RR^d$, and consider a kernel $K: B \times B \to \CC$ such that $|K(x,y)| \lesssim |x - y|^{-(d-s)}$, for some $s > 0$. Then
    %
    \[ \| K \|_{L^\infty_y(B) L^1_x(B)}\quad\text{and}\quad \| K \|_{L^\infty_x(B) L^1_y(B)} < \infty, \]
    %
    so Schur's Lemma implies that if $T$ is the integral operator corresponding to $K$, then $\| T f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}$ for $1 \leq p \leq \infty$. For $s > d/2$, this operator is a Hilbert-Schmidt operator, but not for $s \leq d/2$. Nonetheless, for any $s > 0$, $T$ is a compact operator. To see this, for each $n$, define $T_n$ to be the integral operator corresponding to the kernel $K_n(x,y) = \mathbf{I}(|x - y| \geq 1/n) K(x,y)$. Then $K_n$ is a Hilbert-Schmidt kernel, and so every operator in the family $\{ T_n \}$ is compact. Moreover, we have
    %
    \[ \lim_{n \to \infty} \| K - K_n \|_{L^\infty_y L^1_x} = \lim_{n \to \infty} \| K - K_n \|_{L^\infty_x L^1_y} = 0, \]
    %
    and so $T_n \to T$ in the operator norm. Thus $T$ is compact.
\end{example}

We now turn to a result of Schauder, which we have already proved in the case where $T: H \to H$ is a compact operator on a Hilbert space (and more generally, the same proof follows for any pair $X$ and $Y$ such that $B(X,Y)$ has the approximation property).

\begin{theorem}
    Let $X$ and $Y$ be Banach spaces. Then a bounded operator $T: X \to Y$ is compact if and only if it's adjoint $T^*: Y^* \to X^*$ is compact.
\end{theorem}
\begin{proof}
    Suppose first that $T$ is a bounded compact operator. We apply the Arzela-Ascoli theorem. Let $K$ be the compact set formed from the closure of $T(B_X)$, where $B_X$ is the unit ball in $X$. Let $R_1: Y^* \to C(K)$ and $R_2: X^* \to C_b(B_X)$ be the natural restriction operators. Then Arzela-Ascoli implies that $R_1$ is a compact linear operator. Thus $R(B_{Y^*})$ is a precompact subset of $C(K)$. But if $T^*_C: C(K) \to C_b(B_X)$ is the natural linear pullback operator correspoding to $T: B_X \to K$, then $R_2 \circ T^* = T^*_C \circ R_1$. Since $R(B_{Y^*})$ is precompact, so too is $R_2(T^*(B_{Y^*})) = T^*_C(R(B_{Y^*}))$. But this means that $T^*(B_{Y^*})$ is precompact.

    Conversely, suppose $T^*$ is a bounded, compact operator. Then $T^{**}$ is compact. If $\{ x_\alpha \}$ is a bounded net in $X$, then $\{ x_\alpha^{**} \}$ is a bounded net in $X^{**}$, so $T^{**} x_\alpha^{**} = (Tx_\alpha)^{**}$ has a convergent bounded subnet $\{ (Tx_{\alpha_\beta})^{**} \}$. But convergence of $\{ (Tx_{\alpha_\beta})^{**} \}$ is equivalent to convergence of $\{ Tx_{\alpha_\beta} \}$, so $\{ Tx_\alpha \}$ has a convergent subnet. Thus $T$ is a compact, bounded operator. 
\end{proof}

TODO: Trace class operators.







\section{Spectral Theory for Compact Operators}

The spectral theory of operators on finite dimensional vector spaces shows that any self-adjoint matrix can be diagonalized. Here we try and generalize this result to infinite dimensional spaces. In general, this is not so simple to generalize. The most basic reformulation (any self-adjoint operator on a Hilbert space has a basis of eigenvectors) is \emph{not correct}, because of the existence of \emph{almost eigenvectors}.

\begin{example}
    A self-adjoint operator on an infinite dimensional Hilbert space need not have any eigenvalues. For instance, if $T: L^2[0,1] \to L^2[0,1]$ is given by $Tf(x) = x f(x)$, then $T$ is self-adjoint, but has no eigenvalues, for if $Tf = \lambda f$, for any $\lambda$, then $x f(x) = \lambda f(x)$, which implies $f = 0$. On the other hand, $T$ any $\lambda \in [0,1]$ is \emph{almost} an eigenvalue, in the following sense. If $f(x) = \mathbf{I}(x \in I)$, where $I$ is an interval of length $\delta$ containing $\lambda$, then $|Tf(x) - \lambda f(x)| \leq \delta \mathbf{I}(x \in I)$, and so
    %
    \[ \| Tf - \lambda f \|_{L^2[0,1]} \leq \delta |I|^{1/2} \leq \delta \| f \|_{L^2[0,1]}. \]
    %
    Thus if $\delta$ is small, then we have $Tf \approx \lambda f$, and we can take $\delta$ as small as we like, for any $\lambda \in [0,1]$. Thus this calculation shows $T - \lambda$ is not invertible for any $\lambda \in [0,1]$. Since $T - \lambda$ \emph{does} have an inverse for $\lambda \not \in [0,1]$, we have actually calculated that $\sigma(T) = [0,1]$. Thus the spectrum detects not only eigenvalues, but also \emph{almost} eigenvalues.
\end{example}

In the finite dimensional setting, the existence of an eigenvalue $\lambda$ for a linear map $T: X \to X$ is equivalent to the operator $T - \lambda: X \to X$ being \emph{invertible}. The problem here is that having an eigenvalue is now \emph{not equivalent to being invertible}, because an operator can fail to be invertible in three different ways:
%
\begin{itemize}
    \item $T - \lambda$ can \emph{fail to be injective}: This happens if and only if there is a non-zero point $x \in X$ such that $Tx = \lambda x$, i.e. $\lambda$ is a true eigenvalue for $T$.
    \item $T - \lambda$ is injective, but fails to be bounded from below: Then for any $\varepsilon > 0$ we can find $x \in X$ with $\| x \| = 1$ such that $\| Tx - \lambda x \| \leq \varepsilon$. Thus $\lambda$ is an \emph{almost} eigenvalue of $T$.
    \item $T - \lambda$ can be injective and bounded from below, but fail to be surjective: Thus $T - \lambda$ gives an isomorphism of $X$ onto a proper, closed subspace of $X$.
\end{itemize}
%
We call the set of values $\lambda$ for which the first property holds the \emph{point spectrum} of $T$, denoted $\sigma_p(T)$, the second set the \emph{continuous spectrum} $\sigma_c(T)$, and the third set the \emph{residual spectrum} $\sigma_r(T)$. These form three disjoint sets, whose union is the \emph{spectrum} of $T$, denoted $\sigma(T)$, which consists precisely of the set of $\lambda$ such that $T - \lambda$ is \emph{not invertible}. The residual spectrum is difficult to detect, but we will find that for a large class of operators that occur in practice (most importantly, the normal operators on a Hilbert space), $\sigma_r(T)$ is empty, so we do not have to analyze this spectrum very often.

\begin{example}
    Let $\{ \lambda_n \}$ be an enumeration of all rational numbers in $[0,1]$. Then consider the bounded operator $T: l^2(\NN) \to l^2(\NN)$ given by
    %
    \[ (Ta)(n) = \lambda_n a(n) \]
    %
    We see that $\langle Ta, a \rangle \geq 0$ for all $a \in l^2(\NN)$, and $\| Ta \|_{l^2(\NN)} \leq \| a \|_{l^2(\NN)}$ for all $a \in H$, from which it follows that $\sigma_p(T) \subset [0,1]$. In fact, we have $\sigma_p(T) = [0,1] \cap \QQ$, since
    %
    \[ Te_n = \lambda_n e_n \]
    %
    for each $n$, so $[0,1] \cap \QQ \subset \sigma_p(T)$, and conversely, if $Ta = \lambda a$, then $\lambda a(n) = \lambda_n a(n)$ for all $n$, which implies that $\lambda = \lambda_n$ or $a(n) = 0$ for all $n$, and thus if $\lambda \neq \lambda_n$ for some $n$, then $a = 0$. Thus we have fully calculated the point spectrum. On the other hand, for any $\lambda \in [0,1] - \QQ$, we can find a sequence $\{ \lambda_{n_i} \}$ in $\QQ \cap [0,1]$ converging to $\lambda$, and then we have
    %
    \[ \| T e_{n_i} - \lambda e_{n_i} \| \to 0, \]
    %
    so $\lambda \in \sigma_c(T)$. Thus we see that $\sigma(T) = [0,1]$, and $\sigma_r(T) = \emptyset$. That the residual spectrum of $T$ is empty will follow from the general theory because $T$ is a self-adjoint operator.
\end{example}

The main case where the finite dimensional theory carries over to infinite dimensions is in the case of a \emph{compact}, normal operator $T: H \to H$ on a Hilbert space $H$. We will prove that any normal operator has no residual spectra, so $\sigma_r(T) = \emptyset$. Moreover, the compactness actually implies $\sigma_c(T) = \emptyset$. To see this, note that if there is a sequence of vectors $\{ x_n \}$ in $H$ such that $\| x_n \| = 1$ and $\lim_{n \to \infty} \| Tx_n - \lambda x_n \|$ for some $\lambda \neq 0$, then the compactness of $T$ shows that $Tx_n / \lambda$ must have a convergent subsequence, converging to some $y \in H$ with $\| y \| = 1$, and then continuity shows that
%
\[ \| Ty - \lambda y \| = \lim_{n \to \infty} \| T^2 x_n / \lambda - T x_n \| \leq \lambda^{-1} \| T \| \lim_{n \to \infty} \| Tx_n - \lambda x_n \| = 0. \]
%
Thus $Ty = \lambda y$, a sequence of almost eigenvectors implies the existence of an \emph{exact eigenvector}. Thus any almost eigenvalue is actually an \emph{exact} eigenvalue. Thus we see that $\sigma(T) = \sigma_p(T)$. The normality of $T$ will imply that if we define for each $\lambda \in \CC$ a subspace
%
\[ H_\lambda = \{ x : Tx = \lambda x \} \]
%
of $H$, then $\{ X_\lambda : \lambda \in \sigma(T) \}$ are a family of pairwise orthogonal subspaces of $H$. The compactness of $T$ will then imply that each of the spaces $X_\lambda$ is finite dimensional, $\sigma(T)$ is countable, and it's only limit point is at the origin. Finally, general spectral theory will imply that $H$ is the direct sum of the spaces $H_\lambda$, and so we have `diagonalized' the operator $T$ into $\text{Ker}(T)$, and a family of orthogonal, finite dimensional eigenspaces.

The main result of this section is that a compact operator on a Hilbert space $H$ can always be diagonalized, with a sequence of eigenvalues $\lambda_i$ converging to zero, and such that $H$ can be decomposed into the orthogonal sum of the eigenspaces $H_{\lambda_i}$, and for $i \neq 0$, $H_{\lambda_i}$ is finite dimensional. We begin by proving the family of spaces $\{ H_\lambda \}$ is pairwise orthogonal.

\begin{lemma}
    If $H$ is a Hilbert space, $T: H \to H$ is bounded and normal, and $\lambda_1 \neq \lambda_2$, then $H_{\lambda_1}$ and $H_{\lambda_2}$ are orthogonal.
\end{lemma}
\begin{proof}
    Let us begin by assuming $T$ is self adjoint. Then $\lambda_1$ and $\lambda_2$ are real, since a self-adjoint operator can only have real eigenvalues. If $x_1 \in H_{\lambda_1}$ and $x_2 \in H_{\lambda_2}$, then
    %
    \[ \lambda_1 \langle x_1, x_2 \rangle = \langle Tx_1, x_2 \rangle = \langle x_1, Tx_2 \rangle = \lambda_2 \langle x_1, x_2 \rangle, \]
    %
    so since $\lambda_1 \neq \lambda_2$, $\langle x_1, x_2 \rangle = 0$.

    Now assume $T$ is bounded and normal. Since it then follows that $\| Tx \| = \| T^* x \|$ for all $x \in H$, it follows that $Tx = \lambda x$ for some $x \in H$ and some scalar $\lambda$ if and only if $T^*x = \overline{\lambda} x$. Thus if $T = T_1 + i T_2$, where $T_1$ and $T_2$ are self-adjoint, then $T_1 x = \text{Re}(\lambda) x$ and $T_2 x = \text{Im}(\lambda) x$. Thus, for a linear operator $S: H \to H$, if we temporarily adopt the notation $H_\lambda(S)$ for the eigenspace of $H$ for $S$ with eigenvalue $\lambda$, then $H_\lambda(T) = H_{\text{Re}(\lambda)}(T_1) \cap H_{\text{Im}(\lambda)}(T_2)$. But this is sufficient to justify that the family $\{ H_\lambda(T) \}$ is orthogonal, since the spaces $\{ H_{\lambda_1}(T_1) \}$ and $\{ H_{\lambda_2}(T_2) \}$ are both orthogonal.
\end{proof}

We have already provided the argument for the following theorem, i.e. that compact operators do not have approximate eigenvalues that are not actual eigenvalues.

\begin{theorem}
    Let $X$ be a Banach space. If $T: X \to X$ is a compact operator, then
    %
    \[ \sigma_c(T) = \emptyset. \]
\end{theorem}

\begin{corollary}
    Let $T: X \to X$ be a compact operator. If $\lambda \in \sigma(T)$ is non-zero, then $\dim(X_\lambda) < \infty$, $(T - \lambda)X$ is closed and $\text{codim}(T - \lambda) < \infty$, and there is $n$ such that
    %
    \[ \ker[(T - \lambda)^n] = \ker[(T - \lambda)^{n+1}] \]
    %
    and
    %
    \[ (T - \lambda)^n X = (T - \lambda)^{n+1} X \]
\end{corollary}
\begin{proof}
    First note that $T = \lambda$ restricted to $X_\lambda$. Since $X_\lambda$ is closed, this implies the identity operator is compact on $X_\lambda$, hence $X_\lambda$ is finite dimensional. Since $X_\lambda$ is finite dimensional, we can apply Hahn-Banach to find a closed subspace $X'$ of $X$ such that $X$ is the algebraic direct sum of $X_\lambda$ and $X_1$. Since $T$ remains compact when restricted to $X$, the last theorem implies that $T$ has no almost eigenvalues on $X_1$. Since $T - \lambda$ is bounded and injective when restricted to $X_1$, this means there is $C > 0$ such that
    %
    \[ \| (T - \lambda) x \| \geq C \| x \|. \]
    %
    Thus $T - \lambda$ is an isomorphism from $X_1$ to some closed subspace $X_2$ of $X$. Thus $(T - \lambda) X$ is complete, and thus closed in $X$. Note that
    %
    \[ X_2^\perp = [(T - \lambda)X]^\perp = \{ \phi \in X^*: \phi \circ (T - \lambda) = 0 \} = \ker( T^* - \lambda). \]
    %
    Since $T$ is a compact, so is $T^*$, and so $\ker(T^* - \lambda)$ is finite dimensional. But this means that $\codim(T - \lambda) = \dim(X_2^\perp)$ is finite.
\end{proof}

Now we restrict to the study of compact self-adjoint operators on a Hilbert space. It follows from the following theorem that if $T$ is a compact self-adjoint operator on a separable Hilbert space, then $\sigma(T)$ is precisely the set of eigenvalues for $T$.

\begin{theorem}
    If $T: H \to H$ is a compact self-adjoint operator on a separable Hilbert space, then $H$ has an orthonormal basis $\{ e_i \}$ such that $Te_i = \lambda_i e_i$, where $\{ \lambda_i \}$ have no limit point but zero.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $T \neq 0$. Since
    %
    \[ \| T \| = \sup \langle Tx, x \rangle \]
    %
    we can find a sequence $x_i$ with $\| x_i \| = 1$, such that
    %
    \[ \langle Tx_i, x_i \rangle \to \lambda, \]
    %
    where $\lambda = \pm \| T \|$. Since $T$ is compact, we may assume $Tx_i \to y$. Then
    %
    \[ \langle y, x_i \rangle \to \| T \|, \]
    %
    so $y \neq 0$. But
    %
    \[ \| Tx_i - \lambda x_i \|^2 = \| Tx_i \|^2 + \lambda^2 - 2 \lambda \text{Re}( \langle Tx_i, x_i \rangle ) \to 0. \]
    %
    Thus $\lambda x_i \to y$, which means $T y = \lim T(\lambda x_i) = \lambda y$, so an eigenvector exists. A Zorn's lemma argument then allows us to find a orthogonal basis of eigenvectors for $T$.
\end{proof}

\begin{remark}
    Let $\{ T_\alpha \}$ be a family of \emph{commuting} self-adjoint compact operators on a Hilbert space $H$. Then we claim that $H$ has an orthogonal basis simultaneously diagonalizing the operators $T_\alpha$. We can do this by an application of the well-ordering principle. Suppose we have a basis $\{ e_i \}$ which simultaneously diagonalizes $\{ T_\alpha \}$ for $\alpha < \alpha_0$. Then the eigenspaces $\bigcap_{\alpha < \alpha_0} H_{\alpha,\lambda_\alpha}$ are $T_{\alpha_0}$-invariant for all choices of scalars $\lambda_\alpha$, since if $x \in \bigcap_{\alpha < \alpha_0} H_{\alpha,\lambda_\alpha}$,
    %
    \[ T_\alpha (T_{\alpha_0} x) = T_{\alpha_0} (T_\alpha x) = \lambda_\alpha T_{\alpha_0} x. \]
    %
    Because each of these spaces is $T_{\alpha_0}$-invariant, we can diagonalize each of these spaces, finding an orthonormal basis on each one, and then put them back together, and we will have found a basis which simultaneously diagonalizes $\{ T_\alpha : \alpha \leq \alpha_0 \}$. This means there is no smallest index $\alpha_0$ such that we cannot simultaneously diagonalize $\{ T_\alpha : \alpha \leq \alpha_0 \}$, which means we can simultaneously diagonalize all of the operators.
\end{remark}










\section{Strong and Weak Convergence}

It is often a useful tool to weaken the notion of convergence of operators. We say a sequence of operators $\{ T_n: X \to Y \}$ \emph{converges in norm} to an operator $T: X \to Y$ if $\| T - T_n \| \to 0$. We say $\{ T_n \}$ \emph{strongly converges} to $T$ if $T_n x$ converges in norm of $Tx$ for every $x \in X$ (note that this is, somewhat confusingly, \emph{weaker} than norm convergence). Finally, $\{ T_n \}$ \emph{weakly converges} to $T$ if $T_n x$ converges to $Tx$ in the weak topology for every $x \in X$.

\begin{example}
    The only operators which are the norm limit of a family of finite rank operators are compact operators. On the other hand, \emph{every} operator on a Hilbert space is a strong limit of a sequence of finite rank operators. TODO WHAT ABOUT BANACH SPACE?
\end{example}

























\chapter{Vector Valued Integration}

Ubiquitous to analysis is the integral, defined to be $\int f(x)\; dx$, defined to be an average of the infinitisimal values of the function $f$ across a certain domain. In this context, $f$ is almost always real or complex valued. But there are many spaces in which an average can be taken. Indeed, in order to define the average of a set of values $a_1, \dots, a_N$, given by
%
\[ \frac{a_1 + \dots + a_N}{N} \]
%
we need only that we can add the $a_n$, and multiply them by a scalar. Thus the natural place to generalize the integration of functions is to those which take their values in a topological vector space. In this chapter we analyze such a theory.

The weakest definition of the integral exploits the fact that the integral is linear. Because integration is the limit of finite sums, and linear functions are interchangable with summation, for any continuous linear operator $\Lambda: X \to Y$, and function $f: \Omega \to X$, we ought to have
%
\[ \Lambda \left( \int_\Omega f \right) = \int_\Omega (\Lambda \circ f) \]
%
In particular, if $\Lambda$ is a linear functional, the right hand side is just a scalar-valued function, and we know how to integrate those. In fact, we can {\it define} the \emph{weak integral} $\int_\Omega f$ such that this equation holds for any continuous linear functional $\Lambda$. In particular, if $X^*$ separates $X$, then such an integral is unique, and the only question of applicability is when such an integral exists. The conditions of the next theorem, which show that such an integral exists, are automatically satisfied if $X$ is a Fr\'{e}chet space.

\begin{theorem}
    If $X$ is a topological vector space such that $X^*$ separates points, and $\mu$ is a Borel probability measure on a compact Hausdorff space $\Omega$, and $f: \Omega \to X$ is a continuous function such that the closed convex hull of $f(\Omega)$ is compact, then the weak integral exists.
\end{theorem}
\begin{proof}
    Let $H$ be the closed convex hull of $f(\Omega)$. Given a finite family of linear functionals $L = \{ \Lambda_1, \dots, \Lambda_N \}$, we consider the family $E_L$ of all points $x \in H$ such that
    %
    \[ \Lambda_n(x) = \int_\Omega (\Lambda_n \circ f)(x)\; d\mu \]
    %
    If we can prove that each $E_L$ is non-empty, then by the compactness of $H$, the intersection of all such $E_L$ will be nonempty, and this will be the required weak integral. If we define a vector $y$ by
    %
    \[ y_n = \int_\Omega (\Lambda_n \circ f)\; d\mu \]
    %
    then it suffices to show that the image of $H$ under the map $L(x) = (\Lambda_1 x, \dots, \Lambda_N x)$ contains $y$. Because $L$ is a linear map into $\mathbf{C}^n$, $L(H)$ is compact and convex. Thus if $y$ was not an element of this set, we can separate $y$ from $H$ by a linear functional. In other words, there are constants $c_1, \dots, c_N$ such that for any $x \in H$,
    %
    \[ \sum c_n y_n < \sum c_n \Lambda_n x \]
    %
    In particular,
    %
    \[ \sum c_n y_n < \sum c_n (\Lambda_n \circ f) \]
    %
    Now integrating the right hand side gives
    %
    \[ \sum c_n y_n < \sum c_n y_n \]
    %
    which contradicts the fact that $y$ was not in the convex hull.
\end{proof}

Thus the integral of a continuous function is defined in a great many circumstances. TODO: ESTABLISH PROPERTIES ALA RUDIN.

\begin{example}
    Convolution of functions can be realized as a vector valued integral. The normal definition
    %
    \[ (f * g)(x) = \int f(x - y) g(y)\; dy \]
    %
    By removing the value $x$, can be realized as the function-valued integral
    %
    \[ f * g = \int f_y g(y)\; dy \]
    %
    If $g$ is integrable, then we can consider this as integration of the function $f_y$ against the finite measure $g\; dy$, so provided that the map $y \mapsto f_y$ is continuous, then the weak integral exists. The weak convolution is the normal convolution, because if $h$ is a bounded function, then since $|f| * |g|$ is integrable, $(|f| * |g|)h$ is also integrable, so
    %
    \[ \int |(f * g)(x)| |h(x)|\; dx \leq \int (|f| * |g|)(x) h(x)\; dx < \infty \]
    %
    and so we may apply Fubini's theorem to conclude that
    %
    \[ \int \left( \int f(x-y) g(y)\; dy \right) h(x)\; dx = \int \left( \int f(x-y) h(x)\; dx \right) g(y)\; dy \]
\end{example}

\section{The Riesz Calculus}

\subsection{Vector-valued integration}

We would like to define the integral of arbitrary measurable functions $f: \Omega \to X$, where $(\Omega, \mu)$ is a measure space, and $X$ is some Banach space, to be some element $\int f d\mu \in X$. This is not so easy as in the real case, as we have no canonical order through which we can carry summations.

We would like our definition to have properties that ordinary integrals have, namely
%
\[ \Lambda \left( \int f d\mu \right) = \int (\Lambda f) d\mu \]
%
for every $\Lambda \in X^*$. This is certainly true of other measures, since it is true of finite sums, and the integral can be fort of as some limit of a net of sums.

We shall define a function $f: \Omega \to X$ to be \emph{measurable} if $\Lambda f$ is measurable for each $\Lambda \in X^*$, where $\Lambda f = \Lambda \circ f$. This is equivalent to the fact that $(\Lambda \circ f)^{-1}(U)$ is measurable for each measurable subset $U$ of the complex plane, and therefore that $f$ is Borel measurable when $X$ has the weak topology. We shall say that a measurable $f$ is \emph{Pettis Integrable} if there is $x \in X$ for which
%
\[ \Lambda x = \int (\Lambda f) d\mu \]
%
for all $\Lambda \in X^*$. We say $x$ is the integral of $f$, and denote $x$ by $\int f d\mu$. It is clear that $x$ is unique, for if $y$ also has the property, then $x - y$ is annihilated by all linear maps, hence $x - y = 0$.

\begin{theorem}
    Suppose $(\Omega, \mu)$ is a compact measure space with a positive Borel measure, $f: \Omega \to X$ is a continuous map into a Banach space, and $\overline{co}(f(\Omega))$ is compact in $X$, then $f$ is integrable, and $\int f d\mu \in \overline{co}(f(\Omega))$.
\end{theorem}
\begin{proof}
    Assume, without loss of generality, that $\mu$ is a probability measure. Let $H = \text{co}(f(Q))$. For a finite set $L$ is a finite set of functionals, let
    %
    \[ E_L = \left\{ x \in \overline{H} : \Lambda_i(x) = \int (\Lambda_i f) d\mu \right\} \]
    %
    Then $E_L \cap E_{L'} = E_{L \cup L'}$, and each $E_L$ is compact, and therefore has the finite intersection property. If we can show that $E_L$ is non-empty for each $L$, then $\bigcap E_L$ is non-empty, and $\int f d\mu$ exists. Given $L$, fix an ordering $(\Lambda_1, \dots, \Lambda_n)$, which defines a function from $X$ to $\mathbf{R}^n$, and consider $m = (m_1, \dots, m_n)$, where
    %
    \[ m_i = \int (\Lambda_i f) d\mu \]
    %
    We shall show that $m$ is in the convex hull of $(L \circ f)(\Omega)$. If $m$ were not in the hull, then, since $\{ m \}$ is a convex set, there is a linear functional which separates $m$ and the convex hull of $(L \circ f)(\Omega)$, and since we know the structure of linear functionals on $\mathbf{R}^n$, there would be $c_1, \dots, c_n \in \mathbf{R}$ for which
    %
    \[ \sum c_i v_i < \sum c_i m_i \]
    %
    whenever $v = (v_1, \dots, v_n)$ is in the hull. But then
    %
    \[ \sum c_i [(\Lambda_if) (\omega)] < \sum c_i m_i \]
    %
    and integrating,
    %
    \[ \sum c_i m_i = \sum c_i \int (\Lambda_i f) < \sum c_i m_i \]
    %
    Hence $m$ is in the convex hull. Since $L$ is linear, $m = Ly$ for some $y \in H$. At this $y$, we have
    %
    \[ \Lambda_i y = m_i = \int (\Lambda_i f) d\mu \]
    %
    so $y \in E_L$. Thus $\int f d\mu$ exists, and it lies in $\overline{\text{co}}(f(\Omega))$.
\end{proof}

This theorem may be generalized to arbitrary complex valued measures by Jordan decomposition.

\begin{theorem}
    If $X$ is a Banach space, $K \subset X$ is compact, and $\overline{H} = \overline{\text{co}}(K)$, then for each $x \in \overline{H}$ there is a regular Borel probability measure $\mu$ for which $x = \int \text{id}_K d\mu$.
\end{theorem}
\begin{proof}
    The Riesz representation theorem identifies $C(K)^*$ with the space $R$ of all Borel probability measures on $K$. Define $\phi: C(K)^* \to X$ by $\phi(\mu) = \int \text{id}_K d\mu$. The theorem says that $\phi(R) = \overline{H}$. Certainly $K \subset \phi(R)$, for if $\delta_x$ is the unit measure at $x \in K$, then $\phi(\delta_x) = x$, for $\Lambda x = \int \Lambda d \delta_x$. Since $R$ is convex, $\phi(R)$ is convex, and we know from the last theorem that it is a subset of $\overline{H}$. Thus all we need verify is that $\phi(R)$ is closed. This is a consequence of the fact that $R$ is weak $*$ compact in $C(Q)^*$, and $\phi$ is weak $*$ continuous into the weak topology on $X$, so $\phi(R)$ is weakly closed, and all weakly closed sets are strongly closed.

    To see that $R$ is weak $*$ compact, notice that each probability measure has unit variation, and thus lies within the unit ball of $C(K)^*$, which is weak $*$ compact. For $f \in C(K)^*$, let $E_f = \{ \mu : \int f d\mu \geq 0 \}$. Then each $E_f$ is weak $*$ closed, since the map $f \mapsto f(x)$ is weak $*$ continuous. Hence $\bigcap E_f$ is weak $*$ closed. Similarily, the set $E = \{ \mu : \int 1 d\mu = 1 \}$ is weak $*$ closed, and $E \cap \bigcap E_f = R$ is therefore weak $*$ closed.

    It is sufficient to show $\phi$ is weak $*$ continuous at the origin. $X$ has a weak subbasis of neighbourhoods at the origin of the form
    %
    \[ W = \{ x \in X : |\Lambda(x)| < r \} \]
    %
    for $r > 0$, $\Lambda \in X^*$. Thus we must verify that the set of $\mu$ for which $\left| \int \Lambda d\mu \right| < r$ is weak $*$ open. But $\Lambda|_K \in C(K)$, so this set is open almost by definition. Thus $\phi$ is weak $*$ continuous.
\end{proof}

\begin{theorem}
    If $\Omega$ is a compact Hausdorff space with a positive Borel measure $\mu$, $X$ is a Banach space, and $f: \Omega \to X$ is continuous, then
    %
    \[ \left\| \int f d\mu \right\| \leq \int \| f \| d\mu \]
\end{theorem}
\begin{proof}
    For each $\Lambda \in X^*$,
    %
    \[ \left| \Lambda\left(\int f d\mu\right) \right| = \left| \int \Lambda f d\mu \right| \leq \int | \Lambda f | d\mu \leq \| \Lambda \| \int | f | d\mu \]
    %
    If $\Lambda$ is chosen (by the Hahn Banach theorem) such that $\Lambda(\int f d\mu) = \| \int f d\mu \|$, and such that $\| \Lambda \| = 1$, then we obtain the needed inequality.
\end{proof}

If $A$ is a Banach algebra, then $\int f d\mu$ has an additional property, namely, for each $M \in A$,
%
\[ M \int f d\mu = \int Mf d\mu\ \ \ \ \ \ \ \ \ \ \left(\int f d\mu\right) M = \int fM d\mu \]
%
This follows since multiplication on the left and right by $x$ is a bounded linear function. If we let $L: N \mapsto MN$ be the left multiplication operator, and fix $\Lambda \in X^*$, then
%
\[ \Lambda \left( M \left( \int f d\mu \right) \right) = (\Lambda \circ L) \left( \int f d\mu \right) = \int (\Lambda \circ L) f d\mu = \int \Lambda(Mf) d\mu \]
%
the right case is similar.


\newpage

 A \emph{weakly analytic function} is $f: \mathbf{C} \to A$ for which $\langle \phi, f \rangle$ is analytic for any choice of $\phi \in A^*$. It is clear that all strongly analytic functions are weakly analytic, which follows because
%
\[ \lim_{w \to 0} \phi \left( \frac{f(z + w) - f(z)}{w} \right) = \phi \left( \lim_{w \to 0} \frac{f(z + w) - f(z)}{w} \right) \]
%
For fun, we shall also prove that all weakly analytic functions are strongly analytic.

\begin{theorem}
    Every weakly analytic function $f: D \to X$ is strongly analytic.
\end{theorem}
\begin{proof}
    Fix $\phi \in X^*$. Consider a particular contour winding counterclockwise around a point $w$ in the domain, which is at least a unit distance away from $w$ at any point on the contour. If $h,k \in \mathbf{C}$ are small enough that $w + h$ and $w + k$ are contained within the contour, then by the Cauchy integral theorem,
    %
    \begin{align*}
        &\phi\left( \frac{1}{h-k} \left[ \frac{f(w + h) - f(w)}{h} - \frac{f(w + k) - f(w)}{k} \right] \right)\\
        &\ \ \ \ \ =  \phi \left( \frac{f(w)}{hk} + \frac{f(w + h)}{(h - k)h} - \frac{f(w + k)]}{(h - k)k} \right)\\
        &\ \ \ \ \ = \frac{1}{2\pi i} \int_C \frac{\phi[f(z)]\ dz}{[z - (w + h)][z - (w + k)][z - w]}
    \end{align*}
    %
    Find $\delta$ such that if $\| h \| < \delta$, the distance between any point on $C$ and $w + h$ is greater than $1/2$. Then, if $M$ is the length of $C$, and $K$ is the supremum of $f$ on $C$, then
    %
    \[ \left| \frac{1}{2\pi i} \int_C \frac{\phi[f(z)]\ dz}{[z - (w + h)][z - (w + k)][z - w]}\right| \leq \frac{4MK}{2 \pi} \| \phi \| = \frac{2MK}{\pi} \| \phi \| \]
    %
    Applying the Banach Steinhaus theorem (on $X^*$, viewing elements of $X$ as elements of $X^{**}$), we conclude that for all $h,k$ sufficiently small, there exists $K$ such that
    %
    \[ \left| \frac{f(w + h) - f(w)}{h} - \frac{f(w + k) - f(k)}{k} \right| \leq K |h - k| \]
    %
    By the completeness of $X$, the quotients of $h$ and $k$ converge to a well defined quantity as $h - k$ converges to zero.
\end{proof}











\part{Linear Analysis}

\chapter{Topological Vector Spaces}

Basic functional analysis deals with norm spaces. But in many problems, more qualitative notions of convergence are encountered that cannot be induced by a norm structure. Here are some examples:
%
\begin{itemize}
    \item We say a sequence of functions $\{ f_i: X \to Y \}$ converges \emph{pointwise} to a function $f$ if $f_i(x) \to f(x)$ for each $x \in X$.

    \item If $X$ is a locally compact, but non-compact topological space, then we say a sequence of functions $\{ f_i: X \to \CC \}$ converges \emph{locally uniformly} to $f: X \to \CC$ if for any compact set $K \subset X$, $f_i$ converges to $f$ uniformly on $K$.

    \item Given a norm space $X$, we say a sequence $\{ x_i \}$ in $X$ converges \emph{weakly} to some $x$ if for each linear functional $\phi \in X^*$, $\phi(x_i) \to \phi(x)$. Similarily, we say $\{ \phi_i \}$ in $X^*$ converges in the \emph{weak $*$ topology} to some $\phi$ if for any $x \in X$, $\phi_i(x) \to \phi(x)$.
\end{itemize}
%
The notions of convergence considered in these examples cannot be induced by a norm, but they can be induced by a more qualitative `topological structure'. Our goal in this part of notes is to study vector spaces equipped with this more general topological structure.

In order to be completely general, we begin by making a framework to study function spaces with a topology under the weakest assumptions. A \emph{topological vector space} is a vector space equipped with a topology making both addition and scalar multiplication continuous. In terms of nets, this continuity means exactly that if $x_\alpha \to x$, $y_\beta \to y$, and $\lambda_\gamma \to \lambda$, then $\lambda_\gamma (x_\alpha + y_\beta) \to \lambda (x + y)$. In terms of neighbourhoods, the continuity says that if $V$ is an open subset containing $\lambda(x + y)$, then there exists $\varepsilon > 0$, and neighbourhoods $W$ of $x$ and $U$ of $y$ such that if $|\lambda - \gamma| < \varepsilon$, then $\gamma(W + U) \subset V$.

For each $x' \in X$, and $\lambda \neq 0$, the maps $T_{x'}(x) = x + x'$ and $M_\lambda(x) = \lambda x$ are homeomorphisms of $X$, as a consequence of the continuity of addition and multiplication. As a consequence, every neighbourhood of a point $x$ can be written as $x + W$, where $W$ is a neighbourhood of the origin. Thus most of the topological structure of a space can be understood by looking at the structure around the origin. Another special case of the continuity of addition and multiplication is that, since $1 \cdot (0 + 0) = 0$, for each neighbourhood $V$ of the origin, we can find a subneighbourhood $W$ with $W + W \subset V$. We can repeat this process to find neighbourhoods $W$ such that $W + W + \dots + W \subset V$ for any fixed, finite number of additions.

\begin{remark}
    A topological vector space is, of course, an abelian topological group. However, unlike in the case of topological groups, all but the finite dimensional topological vector spaces fail to be locally compact. This is why these two theories proceed down very different paths.
\end{remark}

%Algebraically, a vector space arised from a representation of a field $\mathbf{F}$ over the automorphisms of an abelian group. The topological vector spaces can also be characterized by such a structure. If $G$ is an abelian topological group, and $\rho: \mathbf{F} \to \text{Aut}(G)$ is a map into the continuous automorphisms of $G$, then the conditions which guarantee that this representation gives a topological vector space structure to $G$ is that if $g = \rho(\lambda) h$, then for any neighbourhood of the origin $W$ there is $\varepsilon > 0$ and $U$ such that if $|\lambda - \gamma| < \varepsilon$ then $\rho(\gamma) U \subset gW$. This is sufficiently satisfied if the representation is continuous with respect to the topology on $\text{Aut}(G)$ generated by neighbourhoods of the origin of the form
%
%\[ W_{UV} = \{ \varphi \in \text{Aut}(G) : \varphi(U) \subset V  \} \]
%
%where $U$ and $V$ are neighbourhoods of the origin, which can be seen as a topology analogous to the topology of functions converging locally uniformly.

\begin{example}
    If $X$ is a set, consider the space $\mathbf{F}^X$ of functions from $X$ to $\mathbf{F}$, under the product topology. Then $\mathbf{F}^X$ is a vector space, which we can make topological if we equip the space with the topology of pointwise convergence. The continuity of the operations follows because if $f_\alpha \to f$, $g_\beta \to g$, and $\lambda_\gamma \to \lambda$, then for each $x \in X$,
    %
    \[ \lambda_\alpha (f_\alpha(x) + g_\beta(x)) \to \lambda( f(x) + g(x)) \]
    %
    because addition and multiplication is continuous on $\mathbf{F}$, and this shows that the functions $\lambda_\gamma (f_\alpha + g_\beta)$ converges pointwise to $\lambda(f + g)$. The natural neighbourhood base around the origin are the sets
    %
    \[ \varepsilon B_{x_1, \dots, x_n} = \{ f \in \mathbf{F}^X : |f(x_1)|, \dots, |f(x_n)| < \varepsilon \}\ \]
    %
    for $x_1, \dots, x_n \in X$, and $\varepsilon > 0$. This space is only first countable if $X$ is countable.
\end{example}

\begin{example}
    Consider the space $L_0(X)$ of {\it all} measurable functions on a measure space $X$ with the topology induced by convergence of measure. That is, a net $f_\alpha$ converges to $f$ if, for any $\varepsilon > 0$, $\mu ( |f_\alpha - f| \geq \varepsilon ) \to 0$. Under a probabilistic interpretation, the probability that the two functions differ by more than $\varepsilon$ converges to zero for every $\varepsilon$. The neighbourhoods of the origin with respect to this topology are of the form
    %
    \[ \varepsilon U_\delta = \{ f \in L_0(X): \mu(|f| < \varepsilon) \leq \delta \} \]
    %
    The space is therefore first countable.
\end{example}

\begin{example}
    We would expect the space $L_0(X)$ to have an additional topological structure given by pointwise convergence almost everywhere. That is, we would like to have a topology such that $f_\alpha \to f$ if the set of points $x$ where $f_\alpha(x)$ does not converge to $f(x)$ has zero measure. Tempting a notion as it is, there is no topological structure giving this notion of convergence on $L_0(X)$. To see why, consider the space $L_0[0,1]$, induced by the Lebesgue measure on $[0,1]$. Consider the typewrite sequence of characteristic functions $\chi_n$, defined in terms of the sets $[H_n, H_{n+1}]$ modulo 1, where $H_n$ is the $n$th Harmonic number. Since $H_n \to \infty$, every point intersects infinitely many of the intervals, so that $\chi_n$ does not converge anywhere to zero. But $\chi_n$ does converge in measure to 0, so that for every subsequence of $\chi_n$, there is a further subsequence consisting of functions which converge pointwise almost everywhere to 0. But this contradicts the topological fact that a net $x_\alpha$ converges to a point $x$ if and only if every subnet of $x_\alpha$ has a further subnet which converges to $x$. Thus there can be no topology whose convergence agrees with almost everywhere convergence.
\end{example}

\begin{example}
    Consider the space $\mathbf{F}[[X]]$ of formal power series in a single variable. Define a topology on $\mathbf{F}[[X]]$ by letting $f_\alpha \to f$ if, eventually, the lower order coefficients in the power series expansion of $f_\alpha - f$ vanish. Thus a neighbourhood basis about the origin consists of the decreasing family $\mathfrak{m}$, $\mathfrak{m}^2$, and so on, where $\mathfrak{m}$ is the ideal consisting of power series with vanishing constant coefficient. It is easy to see that addition is continuous. Multiplication of two power series is also continuous, for if $f_\alpha \to f$ and $g_\beta \to g$, then
    %
    \[ f_\alpha g_\beta - fg = f_\alpha (g_\beta - g) + (f_\alpha - f) g \]
    %
    and because each $\mathfrak{m}^n$ is an ideal, if $g_\beta - g$ and $f_\alpha - f$ are in $\mathfrak{m}^n$, then $f_\alpha g_\beta$ is also in $\mathfrak{m}^n$. However, scalar multiplication is {\it not} continuous, for the convergence properties of this space are `too discrete'. Indeed, if we consider $\lambda_n \neq 0$ with $\lambda_n \neq 0$, then $\lambda_n X$ does {\it not} converge to 0, because $\lambda_n X \not \in \mathfrak{m}^2$. Thus $\mathbf{F}[[X]]$ is a topological ring (over any field), but is not a topological vector space. It is a useful space in algebra, which favours the discrete properties of the topological structure, but it is not so useful in analysis. We can weaken the topology on $\mathbf{C}[[X]]$ by taking the topology of pointwise convergence of the coefficients, and this gives $\mathbf{C}[[X]]$ a vector space structure, but it no longer reflects the algebraic structure of the space as strongly.
\end{example}

\section{Basic Theorems}

We now introduce some terminology from analytical linear algebra, which will become even more prevalent in the theory of topological vector spaces.
%
\begin{itemize}
    \item A \emph{convex} subset $C$ of a vector space $X$ is a set such that if $x, y \in C$ imply $tx + (1 - t) y \in C$ for $0 \leq t \leq 1$, so $C$ contains line segments between each of its points, or in set notation, $tC + (1 - t)C \subset C$ for all $0 \leq t \leq 1$. For any $t, u \in \mathbf{R}$, we have $tC + uC \subset (t + u) C$ which reduces to the ordinary convex equation by dividing both sides by $t + u$.

    \item A subset $B$ is \emph{balanced} if $\lambda B \subset B$ for $|\lambda| \leq 1$. For any scalar $\lambda$, $\lambda B$ is balanced, and if $|\lambda| = 1$, then $\lambda B = B$, since $B = \lambda^{-1}(\lambda B) \subset \lambda B \subset B$
    %
    which implies $B = \lambda B$.

    \item A subset $A$ is \emph{absorbing} if
    %
    \[ X = \bigcup_{t > 0} tA \]
    %
    so every $x \in X$ is equal to $ty$ for some scalar $t > 0$ and $y \in A$.

    \item A set $K$ is \emph{(Von Neumann) bounded} if, for every neighbourhood $U$ of the origin, there is $u > 0$ such that if $t > u$, $tU \supset K$.

    % As an example, compact sets are bounded. If $x \neq 0$, then the set $\{ x, 2x, \dots \}$ is {\it never} boundedness, because otherwise if $W$ is a balanced neighbourhood, with $nx \in tW$ for all $n$, then $x \in (t/n)W$ for all $n$, which for $t < n$ implies $x \in W$. But this means $x$ is in every neighbourhood of the origin
\end{itemize}
%
One of the cornerstones of the basis theory of topological vector spaces is that analytic properties of a space can be established from the existence of open sets with the geometric properties above.

\begin{theorem}
    Every neighbourhood of the origin is absorbing.
\end{theorem}
\begin{proof}
    Given a topological vector space $X$, and a neighbourhood $U$ of the origin. For any point $x$, by continuity,
    %
    \[ \lim_{\lambda \downarrow 0} \lambda x = \left( \lim_{\lambda \downarrow 0} \lambda \right) x = 0 \cdot x = 0 \]
    %
    Thus, eventually, $\lambda x \in U$, which implies $x \in \lambda^{-1} U$.
\end{proof}

\begin{theorem}
    Every topological vector space has a basis of balanced sets.
\end{theorem}
\begin{proof}
    Given a neighbourhood $U$ of the origin in a topological vector space $X$, note that by continuity of multiplication there is $\varepsilon > 0$ and $V \subset U$ such that if $|\lambda| < \varepsilon$, $\lambda V \subset U$. Then $\bigcup_{|\lambda| < \varepsilon} \lambda V \subset U$ is a balanced open neighbourhood of the origin contained in $U$. But this implies that the balanced open neighbourhoods form a basis of the entire topology at the origin.
\end{proof}

Note that now if $0 < t_1 < t_2 < \dots \to \infty$, and $V$ is a balanced neighbourhood, then $t_n V$ is balanced, hence contains $uV$ for all $|\lambda| < t_n$ and therefore, since $V$ is absorbing,
%
\[ \bigcup t_n V = \bigcup_{u > 0} uV = X \]
%
The previous theorem says that all balanced neighbourhoods contain absorbing neighbourhoods, so this statements remains true for any neighbourhood $V$, not just the balanced ones.

\begin{prop}
    If a space has a bounded open set, it is first countable.
\end{prop}
\begin{proof}
    Assume the bounded open set $V$ lies at the origin. Then if $t_n$ are a sequence of scalars tending to zero, then $t_n V$ is a neighbourhood basis of the origin, bcause if $W$ is an arbitrary neighbourhood, then $V \subset t_n^{-1} W$ for some $t_n$, so $t_n V \subset W$. Thus the $t_n V$ provide a countable neighbourhood base around the origin.
\end{proof}

\begin{lemma}
    If $U$ is a neighbourhood of the origin such that $x + U$ does not contain $y$, then there is a neighbourhood $V$ of the origin such that $x + V$ does not intersect $y + V$.
\end{lemma}
\begin{proof}
    Find a balanced subset $U_0$ of $U$ such that $U_0 + U_0 \subset U$. If there is $u,w \in U_0$ such that $x + u = y + w$, then
    %
    \[ y = x + u - w \in x + U_0 - U_0 = x + U_0 + U_0 \subset x + U \]
    %
    hence $x + U_0$ is disjoint from $y + U_0$.
\end{proof}

\begin{corollary}
    $T_1$ topological spaces are Hausdorff.
\end{corollary}

From now on, we will assume all the vector spaces we consider are Hausdorff. To see that a particular vector space is Hausdorff, it suffices to show that the intersection of a neighbourhood basis of the origin consists of only the origin, so that $\overline{0} = 0$. In most cases, any topological vector space can be made Hausdorff by considering an appropriate quotient space, ala identifying functions almost everywhere in the theory of $L^p$ spaces.

\begin{corollary}
    If $K$ is a compact set disjoint from $C$, then there is a neighbourhood $W$ such that $K + W$ is disjoint from $C + W$.
\end{corollary}
\begin{proof}
    For each $x \in K$, we may find a balanced set $U_x$ such that $x + U_x + U_x$ is disjoint from $C + U_x$. By compactness, finitely many $U_{x_1}, \dots, U_{x_n}$ cover $K$, and then if $W = U_{x_1} \cap \dots \cap U_{x_n}$, we find $K + W$ is disjoint from $C + W$.
\end{proof}

A corollary of this is that Hasudorff topological spaces are automatically regular. Since $C + W$ is open, we find that, in fact, $\overline{K + W}$ does not intersect $C + W$. If we choose $K = \{ 0 \}$, and $C = V^c$ for $V$ a neighbourhood of the origin, we find a neighbourhood $W$ with $\smash{\overline{W}} \subset V$. Thus for any neighborhood $V$ we can find a subneighbourhood whose closure is contained in $V$.

\begin{theorem}
    Let $X$ be a topological vector space.
    %
    \begin{enumerate}
        \item[(i)] If $V$ is a neighbourhood of the origin, and $A$ is any set, then $\overline{A} \subset A + V$, and in fact $\overline{A} = \bigcap_V A + V$.
        \item[(ii)] If $A,B \subset X$, then $\overline{A} + \overline{B} \subset \overline{A + B}$.
        \item[(iii)] The closure of a subspace is a subspace.
        \item[(iv)] If $C$ is a convex, then $C^\circ$ and $\overline{C}$ are convex subsets.
        \item[(v)] If $B$ is balanced, then so is $\overline{B}$, and if $0 \in B^\circ$, then $B^\circ$ is balanced.
        \item[(vi)] If $E$ is a bounded subset of $X$, then so is $\overline{E}$.
        \item[(vii)] If $A$ and $B$ are bounded, then so is $A + B$.
        \item[(viii)] If $A$ and $B$ are compact, so is $A + B$.
        \item[(ix)] If $A$ is compact, and $B$ is closed, $A + B$ is closed.
    \end{enumerate}
\end{theorem}
\begin{proof}
    $x \in \overline{A}$ if and only if $x + V$ intersects $A$ for every neighbourhood $V$ of the origin, hence $x \in A - V$, and $-V$ is a neighbourhood of the origin if and only if $V$ is. This proves (i). The continuity of addition essentially proves (ii), for if $x \in \overline{A}$, and $y \in \overline{B}$, then we find $x_\alpha \to x$, $y_\alpha \to y$ with $x_\alpha, y_\alpha \in X$, then $x_\alpha + y_\alpha \to x + y$, and $x_\alpha + y_\alpha \in A + B$. If $Y$ is a subspace, then (ii) implies $\overline{Y} + \overline{Y} \subset \overline{Y + Y} = \overline{Y}$, and $\lambda \overline{Y} = \overline{\lambda Y} = \overline{Y}$, so $\overline{Y}$ is closed under addition and multiplication, and is therefore a subspace. Similarily, if $C$ is convex, then
    %
    \[ \lambda \overline{C} + (1 - \lambda) \overline{C} = \overline{\lambda C + (1 - \lambda) C} \subset \overline{C} \]
    %
    and if $x,y \in C^\circ$, we can find a neighbourhood $U$ such that $x + U, y + U \subset C$, and then for any $\lambda$, by convexity
    %
    \[ (\lambda x + (1 - \lambda) y) + (\lambda U + (1 - \lambda) U) = \lambda(x + U) + (1 - \lambda)(y + U) \subset C \]
    %
    which implies $\lambda x + (1 - \lambda) y \in C^\circ$, hence (iv) is shown. If $\lambda B \subset B$ for $|\lambda| < 1$, then $\lambda \overline{B} = \overline{\lambda B} \subset \overline{B}$, so $\overline{B}$ is balanced. Conversely, $\lambda B^\circ$ is open for each $\lambda \neq 0$, so for nonzero $|\lambda| < 1$, $\lambda B^\circ \subset B^\circ$, and provided $0 \in B^\circ$, we find that $\lambda B^\circ \subset B^\circ$ for all $|\lambda| < 1$. If $E$ is a bounded subset, and $V$ is some neighbourhood, then there is some $W$ such that $\overline{W} \subset V$, and if we find $t$ such that $E \subset uW$ for all $u > t$, then $\overline{E} \subset u\overline{W} \subset uV$, hence $\overline{E}$ is bounded. If $A$ and $B$ are bounded, then $A + B$ is bounded, because if $W$ is fixed, we can find $U$ with $U + U \subset W$, and if $A,B \subset \lambda U$, then
%
\[ A + B \subset \lambda(U + U) \subset \lambda W \]
%
If $A$ and $B$ are compact, then $A + B$ is compact, as it is the image of $A \times B$ under the continuous addition map. If $A$ is compact, and $B$ is closed, then $A + B$ is closed, because if $x_\alpha + y_\alpha \to z$ in $A + B$, then $x_\alpha$ has a subnet converging to some $x \in A$, and then $y_\alpha \to z - x$, hence $z - x \in B$, and therefore $z = x + (z - x) \in A + B$.
\end{proof}




\section{Convexity and Metrizability}

We say a space is \emph{locally convex} if it has a locally convex base.

\begin{theorem}
    Every convex neighbourhood contains a subneighbourhood which is convex and balanced.
\end{theorem}
\begin{proof}
    If $U$ is a convex neighbourhood, consider the set $A = \bigcap_{|\lambda| = 1} \lambda U$, which is, convex, and balanced because if $|\gamma| < 1$,
    %
    \[ \gamma A = \gamma \bigcap_{|\lambda| = 1} \lambda U = \bigcap_{|\lambda| = 1} \gamma \lambda U = \bigcap_{|\lambda| < |\gamma|} \lambda U \subset A \]
    %
    If $V \subset U$ is balanced, then $V \subset A$, so $0 \in A^\circ$, and in particular, $A^\circ$ is a balanced, convex neighbourhood of the origin.
\end{proof}

Given a set $A$, we let $\text{Conv}(A)$ denote the \emph{convex hull} of $A$, the smallest convex set containing $A$. It can be written as
%
\[ \text{Conv}(A) = \bigcup_{n = 1}^\infty \bigcup_{t_1 + \dots + t_n = 1} (t_1A + \dots + t_nA) \]
%
It follows that the convex hull of an open set is open.

\begin{theorem}
    In a locally convex space, the convex hull of a bounded set is bounded.
\end{theorem}
\begin{proof}
    If $W$ is a convex neighbourhood, and $A$ is bounded, then $A \subset tW$ for some $t$, and so $\text{Conv}(A) \subset tW$.
\end{proof}

We now move on to a very important point of the basis theory of topological vector spaces: When can we metrize the topology of a vector space. The most useful metrics on a vector space are the \emph{translation invariant} ones, which satisfy $d(a + x, a + y) = d(x,y)$ for all points $a,x,y$ in the vector space. It turns out that every first countable vector space has such a metrization.

\begin{theorem}
    If $X$ is a first countable vector space with a countable base, then $X$ is metrizable by an invariant metric $d$ whose open balls are balanced. If $X$ is locally convex, the metric can be chosen so the open balls are convex.
\end{theorem}
\begin{proof}
    We consider a balanced neighbourhood base of the origin $V_1, V_2, \dots$ with $V_{n+1} + V_{n+1} + V_{n+1} \subset V_n$. If $X$ is locally convex, choose the $V_n$ to be convex as well. With each Dyadic rational number $r = \sum c_n 2^{-n}$ in $[0,1]$, we can associate the interval $V_r = \sum c_n V_n$, with $V_1 = X$. These neighbourhoods are monotonic because of the inclusion properties of these neighbourhoods, and satisfy $V_r + V_s \subset V_{r+s}$ (this is most easily proved when $r = s$, in which case the general case is proved). Thus we cam define
    %
    \[ f(x) = \inf \{ r \in [0,1] : x \in V_r \} \]
    %
    and $d(x,y) = f(x-y)$. It is clear $d$ is invariant, and satisfies the triangle inequality, because if $x - y \in V_r$ and $y - z \in V_s$, then $x - z \in V_r + V_s \subset V_{r + s}$. Since the $V_r$ is balanced if the $V_n$ are, the open balls of $d$ are balanced, and if the $V_r$ are convex, the open balls of $d$ are convex.
\end{proof}

\begin{remark}
    The metric $d$ obtained in the proof above is always bounded, i.e. $0 \leq d \leq 1$, and so we cannot use the same techniques to show that certain topological vector spaces are normable. We will describe the technique to obtain a norm very shortly.
\end{remark}

The notion of Cauchy sequences can be used to determine if the metric $d$ is complete. But even if we don't have a metric, we can still define the notion of a Cauchy sequence. We say $x_\alpha$ is a Cauchy net in a topological vector space if, for every neighbourhood $U$ of the origin, eventually we have $x_\alpha - x_\beta \in U$. If $x_\alpha$ converges, then it is obviously Cauchy. Of course, if $d$ is an invariant metric for the topological vector space, these notions agree exactly, which gives the surprising fact that if a single metric for a metrizable topological vector space is complete, then {\it any} metric for the vector space is complete.

\begin{theorem}
    Cauchy sequences are bounded.
\end{theorem}
\begin{proof}
    Let $x_1, x_2, \dots$ be Cauchy. If $U$ is a balanced neighbourhood of the origin, then eventually for $n \geq N$, $x_n - X_N \in U$. We know that for some $\lambda$, $x_1, \dots, X_N \in \lambda U$, hence all of the $x_n$ are in $(\lambda + 1)U$.
\end{proof}

\begin{theorem}
    A complete metrizable subspace of a topological vector space is closed.
\end{theorem}
\begin{proof}
    If $Y$ is complete and metrizable, and $y_\alpha \to x$, then $y_\alpha$ is Cauchy, hence converges in $Y$, and since $X$ is Hausdorff, $Y$ is closed.
\end{proof}

A \emph{seminorm} on a space $X$ is a positive function $\| \cdot \|$ on $X$ such that $\| x + y \| \leq \| x \| + \| y \|$, and $\| \alpha x \| \leq |\alpha| \| x \|$. These seminorms would give $X$ a metric by setting $d(x,y) = \| x - y \|$, except that we might have $d(x,y) = 0$ with $x \neq y$. One way to fix this is to consider the set $Y$ of all $x$ with $\| x \| = 0$. Then $Y$ forms a subspace of $X$, and if $y \in Y$, then $\| x + y \| \leq \| x \|$, and also $\| x \| = \| x + y - y \| \leq \| x + y \|$, hence $\| x + Y \| = \| x \|$, and so the seminorm descends to $X/Y$, and is now a norm. This is the perspective taken in the $L^p$ spaces, where $X$ is the space of all $p$ integrable functions, and $Y$ is the space of $p$ integrable functions equal to zero almost everywhere.

We shall now describe another way to give $X$ a Hausdorff topological structure if, instead of a single seminorm, we have a {\it family} of seminorms. Given such a family, we can give $X$ a topological structure by letting $x_\alpha \to 0$ if $\| x_\alpha \| \to 0$ for every seminorm $\| \cdot \|$ in the family. A family of seminorms is called \emph{separating} if for every $x \neq 0$, there is a seminorm $\| \cdot \|$ with $\| x \| \neq 0$. This implies that the topological structure is Hausdorff, for if $x_\alpha$ converges to two points $x$ and $x'$, then for any seminorm $\| \cdot \|$
%
\[ \| x - x' \| \leq \| x - x_\alpha \| + \| x_\alpha - x' \| \to 0 \]
%
hence $\| x - x' \| = 0$, and since this is true for every seminorm, $x = x'$. Every space of this form is locally convex, because a neighbourhood basis is given by the family of convex sets
%
\[ \varepsilon B_{\rho_1 \dots \rho_n} = \{ x: \rho_1(x), \dots, \rho_n(x) < \varepsilon \} = \varepsilon(B_{\rho_1} \cap \dots \cap B_{\rho_n}) \]
%
and each of these neighbourhoods is convex, since they are the intersections of convex balls with respect to an individual seminorm. In other words, the family of balls $\varepsilon B_\rho = \{ x : \rho(x) < \varepsilon \}$ form a subbase for a topology. If the family of seminorms defining the topology is closed under taking the maximum operation, then these balls actually form a base for the topology.

If $\| \cdot \|$ is a seminorm, then the `unit ball' with respect to this seminorm is convex, balanced, and absorbing. Conversely, suppose $A$ is a convex subset of a topological vector space containing the origin. Then we can define the \emph{Minkowski functional}
%   
\[ \mu_A(x) = \inf \{ t \geq 0: x \in tA \} \]
%
If $x \in \alpha A$ and $y \in \beta A$, then by convexity,
%
\[ \lambda x + \gamma y \in \lambda \alpha A + \gamma \beta A \subset (\lambda \alpha + \gamma \beta) A \]
%
Taking infima, we find $\mu_A(\lambda x + \gamma y) \leq \lambda \mu_A(x) + \gamma \mu_A(y)$, and so, as a special case, we find $\mu_A(x + y) \leq \mu_A(x) + \mu_A(y)$. If $A$ is an absorbing set, $\mu_A$ is always finite, and if, in addition, $A$ is balanced, then $\mu_A(\lambda x) = |\lambda| \mu_A(x)$, so $\mu_A$ is a seminorm. If $A_0 = \mu_A^{-1}([0,1))$ and $A_1 = \mu_A^{-1}([0,1])$, then $A_0 \subset A \subset A_1$, and $\mu_{A_0} = \mu_A = \mu_{A_1}$. Thus every {\it continuous} Minkowski functional can be given in terms of an open or a closed set.

The connection between convex sets and Minkowski functionals gives a close correspondence between locally convex spaces and spaces with metrics given by seminorms. If $\| \cdot \|$ is any continuous seminorm on $X$, we let $A$ consist of the points $x$ with $\| \cdot \| \leq 1$. Then $A$ is convex, because if $\| x \|, \| y \| \leq 1$, then
%
\[ \| \lambda x + (1 - \lambda) y \| \leq \lambda \| x \| + (1 - \lambda) \| y \| \leq \lambda + (1 - \lambda) = 1 \]
%
It is absorbing, since $x \in \| x \| A$, and balanced, since $\| \lambda x \| = |\lambda| \| x \|$. We find
%
\[ \mu_A(x) = \inf \{ \lambda \geq 0: x \in \lambda A \} = \inf \{ \lambda \geq 0: \| x \| \leq \lambda \} = \| x \| \]
%
so every seminorm is given by a Minkowski functional.

The previous paragraphs hint that the topology of {\it every} locally convex space is given by a family of seminorms. Indeed, suppose that a space has a convex balanced neighbourhood basis $U_\alpha$. If $\rho_\alpha = \mu_{U_\alpha}$, then each $\rho_\alpha$ is continuous, because if $x_\beta \to x$, then eventually $x_\beta - x \in \varepsilon U_\alpha$ for every $\varepsilon > 0$, hence eventually $\rho_\alpha(x_\beta - x) < \varepsilon$. This implies
%
\[ \rho_\alpha(x_\beta) \leq \rho_\alpha(x_\beta - x) + \rho_\alpha(x) \leq \rho_\alpha(x) + \varepsilon \]
\[ \rho_\alpha(x_\beta) \geq \rho_\alpha(x) - \rho_\alpha(x - x_\beta) \geq \rho_\alpha(x) - \varepsilon \]
%
So $\rho_\alpha(x_\beta) \to \rho_\alpha(x)$. Conversely, if $\rho_\alpha(x_\beta) \to 0$ for every fixed $\alpha$, then eventually $\rho_\alpha(x_\beta) \leq 1$, so $x_\beta \in U_\alpha$, so $x_\beta$ is eventually in $U_\alpha$ for every $\alpha$, so $x_\beta \to 0$. This shows that the topology of the vector space is exactly the same as the one formed from the family of seminorms $\rho_\alpha$.

If the topology of a space $X$ is specified by a countable family of seminorms, then the space is first countable, and therefore metrizable. However, in this situation we can come up with a natural metric to use, rather than appealing to the theorem we just came up with. If $\rho_1, \rho_2, \dots$ is an ordering of the seminorms, then the functions
%
\[ d_n(x,y) = \frac{\rho_n(x - y)}{1 + \rho_n(x-y)} \]
%
are bounded and satisfy the triangle inequality, and the metric for the space can be given by
%
\[ d(x,y) = \sum_{n = 1}^\infty \frac{d_n(x,y)}{2^n} = \sum_{n = 1}^\infty \frac{\rho_n(x-y)}{2^n (1 + \rho_n(x-y))} \]
%
Since {\it any} invariant metric on a complete, metrizable space is complete, there is normally not a need to switch to a different metric when doing general calculations on metric spaces, unless it is possible to switch to a single norm for the entire space.

\begin{theorem}
    Let $X$ be a locally convex, specified by a family of seminorms $\rho_\alpha$. Then a set $E$ is bounded if and only if $\rho_\alpha$ is bounded on $E$ for each $\alpha$.
\end{theorem}
\begin{proof}
    Suppose $E$ is bounded. If $U_\alpha$ is the unit ball with respect to $\rho_\alpha$, then for some $t > 0$, $E \in t U_\alpha$, so $\rho_\alpha(E) \leq t$. Conversely, suppose that $\rho_\alpha(E) \leq t_\alpha$ for each $\alpha$. Then we consider a neighbourhood basis of the elements $\varepsilon U_{\rho_1 \dots \rho_N}$, as introduced above, and for each such element we find
    %
    \[ E \in \max(t_1, \dots, t_N) \varepsilon U_{\rho_1 \dots \rho_N \varepsilon} \]
    %
    so $E$ is bounded.
\end{proof}

To finish our understanding of locally convex spaces, we ask when the topology of a locally convex space can be given by a single norm. If $\| \cdot \|$ is a norm for the space, then the unit ball with respect to this norm is bounded by the theorem above, and convex. It turns out this is sufficient for a locally convex space to be normable.

\begin{theorem}
    A space is normable if and only if it has a bounded, convex neighbourhood.
\end{theorem}
\begin{proof}
    If $U$ is a bounded, convex neighbourhood about the origin, then the $\varepsilon U$ form a neighbourhood basis around the origin. It follows that the topology of the space is specified by the single Minkowski functional $\mu_U$. The fact that $\mu_U$ is actually a norm, rather than a seminorm, follows from the fact that the space is Hausdorff.
\end{proof}

\begin{example}
    Consider the class $C(X)$ of continuous functions on a locally compact space $X$, under the topology of locally uniform convergence (uniform convergence on compact sets). Then $C(X)$ is a topological vector space. For each compact set $K$, we have the seminorms $\| \cdot \|_{L^\infty(K)}$, which define a seminorms which show $C(X)$ and $H(X)$ have the topology of a locally convex space. If $X$ is {\it $\sigma$ compact}, then the topology can be given by a countable family of seminorms, and so $C(X)$ is metrizable. If we write $X = \lim_{n \to \infty} K_m$, and $f_n$ is Cauchy, then the $f_n$ converge uniformly to some continuous function $g_m$ on $K_m$, and $g_{m+1}$ agrees with $g_m$ on $K_m$, hence we can consider the function $g$ defined everywhere by letting $g(x) = g_m(x)$ for all $x \in K_m$, and then $f_n \to g$. Thus $C(X)$ is Fr\'{e}chet. However, $C(X)$ is not normable if $X$ is not compact. We know a set $E \subset C(X)$ is bounded if and only if there is $M_K$ such that $\| f \|_{L^\infty(K)} \leq M_K$ for each $f \in E$. But we have a neighbourhood consisting of $U_{K_1 \dots K_N \varepsilon_1 \dots \varepsilon_N}$. And since $X$ is not compact, there is some $x \not \in K_1 \cup \dots \cup K_N$, and since $X$ is completely regular, we can find a continuous function $f$ with $f(x) = 1$, but $f$ vanishing on $K_1 \cup \dots \cup K_N$. It follows that $nf \in U_{K_1 \dots K_N \varepsilon_1 \dots \varepsilon_N}$ for all integers $n$, and the are not bounded $nf$. Thus $C(X)$ is not normable unless $X$ is compact.
\end{example}

\begin{example}
    If $X$ is an open subset of $\mathbf{C}$, then the space $H(X)$ of holomorphic functions on $X$ is also a topological vector space under locally uniform convergence. Since the local uniform limit of a holomorphic function is a holomorphic function, $H(X)$ is a closed subspace of $C(X)$, and is therefore a Fr\'{e}chet space. Montel's theorem in the theory of complex variables says that $H(X)$ has the Heine-Borel property: Every closed, bounded subset of $H(X)$ is compact. But since $H(X)$ is never finite dimensional, $H(X)$ cannot be locally compact, hence $H(X)$ cannot be locally bounded. It follows that $H(X)$ is also not normable.
\end{example}

\begin{example}
    Let $X$ be an open subset of $\mathbf{R}^n$. Then we can give $C^\infty(X)$ the structure of a topological vector space by letting $f_\alpha \to f$ if all the partial derivatives of $f_\alpha$ converge to the partial derivatives of $f$ locally uniformly. Arguing essentially the same as with $C(X)$ and $H(X)$, this shows $C^\infty(X)$ is a metrizable locally convex space. If $f_\alpha$ is a Cauchy sequence in this space, then $f_\alpha$ is Cauchy on each compact set $K$, hence $f_\alpha$ and all it's partial derivatives converges locally uniformly on $K$ to some $C^\infty$ function $g_K$. Putting these things together gives that $C^\infty(X)$ is a Fr\'{e}chet space. Surprisingly $C^\infty(X)$ also satisfies the Heine-Borel property. This is easily proven using the Arzela-Ascoli theorem. Since $C^\infty(X)$ is never finite dimensional, this space cannot be locally bounded, hence $C^\infty(X)$ isn't normable.
\end{example}




\section{Linear Maps}

As in the functional analysis of Banach spaces, linear maps play an important role in the theory. In particular, we are interested in those linear maps between topological vector spaces which are continuous. Continuous maps are exactly those which are uniformly continuous, because if $T: X \to Y$ is continuous, then for every neighbourhood $V$ of the origin in $Y$, there is a neighbourhood $U$ of the origin in $X$ such that if $x - y \in U$, then $Tx - TY \in V$.

\begin{lemma}
    If $T$ is continuous at $0$, then $T$ is continuous everywhere.
\end{lemma}
\begin{proof}
    Suppose $T$ is continuous at the origin. If $x_\alpha \to x$, then $x_\alpha - x \to 0$, hence $T(x_\alpha - x) = T(x_\alpha) - T(x) \to 0$, so $T(x_\alpha) \to T(x)$. Thus $T$ is continuous everywhere.
\end{proof}

The theory of linear functions is difficult to classify in the general case, but linear {\it functionals} are easier to understand. Given $X$, we let $X^\sharp$ denote the class of linear functionals, and $X^*$ the class of {\it continuous} linear functionals.

\begin{theorem}
    If $f \in X^\sharp$ is a non-zero linear functional, then the following are equivalent:
    %
    \begin{enumerate}
        \item $f$ is continuous.
        \item The nullspace of $f$ is closed.
        \item The nullspace of $f$ is not dense in $X$.
        \item $f$ is bounded in some neighbourhood of the origin.
    \end{enumerate}
\end{theorem}
\begin{proof}
    (1) implies (2) implies (3) is obvious. If (3) holds, so the nullspace of $f$ is not dense in $X$, we can find $x \in X$ and a balanced set $U$ such that $0 \not \in f(x + U) = f(x) + f(U)$, hence $f(u) \neq - f(x)$ for any $u \in U$. Since $U$ is balanced, this must imply that $f(u) \neq \lambda f(x)$ for any $|\lambda| \geq 1$, so $|f(u)| \leq |f(x)|$ for all $u \in U$, so $f$ is bounded on $U$, implying (4). If $f$ is bounded in some neighbourhood of the origin, then $|f(u)| \leq M$ for all $u \in U$, and if $x_\alpha \to 0$, then eventually for all $\varepsilon > 0$, $x_\alpha \in \varepsilon U$, hence $|f(x_\alpha)| \leq \varepsilon M$, implying $f(x_\alpha) \to 0$. This means $f$ is continuous at the origin. The general statement now follows from the fact that a linear function is continuous if and only if it is continuous at the origin.
\end{proof}

\begin{example}
    Suppose $X$ is a locally convex space, with the topology specified by a family of seminorms closed under the maximum operation. Then the balls $\varepsilon U_\rho$ form a basis for the space. It follows that if $f \in X^*$ is a continuous linear functional, then $f$ is bounded on a neighbourhood on the origin, so there exists $\rho, \varepsilon$, and $M$ such that if $\rho(x) \leq \varepsilon$, then $|f(x)| \leq M$. It then follows that for any $x \in X$,
    %
    \[ |f(x)| = \frac{\rho(x)}{\varepsilon} \left| f \left( \frac{\varepsilon x}{\rho(x)} \right) \right| \leq (M/\varepsilon) \rho(x) \]
    %
    so the functional is directly bounded above by a seminorm.
\end{example}

For finite dimensional topological vector spaces, the continuous linear maps are particularly easy to consider.

\begin{lemma}
    Every linear map $T: \mathbf{F}^n \to X$ is continuous.
\end{lemma}
\begin{proof}
    If we write $x_i = Te_i$, where $e_i$ is the $i$'th element of canonical basis of $\mathbf{F}^n$, then $T(a) = \sum a_i x_i$, and the continuity follows because addition and scalar multiplication is continuous.
\end{proof}

\begin{corollary}
    Every finite dimensional vector space has a unique topology making it into a topological vector space.
\end{corollary}
\begin{proof}
    if $\tau_0$ and $\tau_1$ are two topologies on $\mathbf{F}^n$ turning it into a topological vector space, then the identity map on $\mathbf{F}^n$ is a continuous map from $(\mathbf{F}^n, \tau_0)$ to $(\mathbf{F}^n, \tau_1)$, and from $(\mathbf{F}^n, \tau_1)$ to $(\mathbf{F}^n, \tau_0)$, hence we conclude the identity map is a homeomorphism.
\end{proof}

\begin{corollary}
    Every finite dimensional subspace of a Hausdorff topological vector space is closed.
\end{corollary}
\begin{proof}
    If $Y \subset X$ is a subspace of $X$, let $T: \mathbf{F}^n \to Y$ be an isomorphism. Then we know $S = T(S_{\mathbf{F}^n})$ is compact in $X$, and $B = T(B_{\mathbf{F}^n})$ is open. By compactness, there is an open neighbourhood $V$ of the origin in $X$ which does not intersect $S$. Then $W = T^{-1}(V \cap Y)$ is an open neighbourhood of the origin in $\mathbf{F}^n$ disjoint from $S_{\mathbf{F}^n}$, so that it only contains elements in $B$, and so $\overline{W}$ is compact, hence $V \cap Y \subset T(\overline{W}) \subset Y$, and so the closure of each $V \cap Y$ lies in $Y$. Now if $z \in \overline{Y}$ is arbitrary, then $z = tx$ for $x \in V$, and since $\overline{Y}$ is a subspace we find $x$ lies in $\overline{Y}$. But if $y_\alpha \to x$, with $y_\alpha \in Y$, then $y_\alpha$ is eventually in $Y \cap V$, which is a closed subset of $Y$, hence we find $x \in Y$, hence $z \in Y$.
\end{proof}

\begin{theorem}
    Every locally compact vector space $X$ has finite dimension.
\end{theorem}
\begin{proof}
    If a vector space has a precompact neighbourhood $V$, then that neighbourhood is bounded, so $V/2^n$ form a local base for $X$. Now there are $x_1, \dots, x_n \in V$ such that
    %
    \[ \overline{V} \subset (x_1 + V/2) \cup \dots \cup (x_n + V/2) \]
    %
    Then the span of the $x_i$ is a closed subspace $Y$ of $X$, and $\overline{V} \subset Y + V/2$. Then, of course, $V \subset Y + V/2$, hence, dividing by two, we find $V/2 \subset Y + V/4$, and so $\overline{V} \subset Y + V/4$. Continuing this process, we find $\overline{V} \subset \bigcap (Y + V/2^n)$, and since $V/2^n$ form a local base, we find $\overline{V} \subset \overline{Y} = Y$. We conclude that $Y$ contains an absorbing set for $X$, hence $Y = X$.
\end{proof}

Since we have a definition of boundedness in any topological vector space $X$, we can ask if a version of the Heine Borel theorem holds in $X$. That is, are closed, bounded subsets of $X$ compact.

\begin{corollary}
    No infinite dimensional space can be locally bounded and satisfy the Heine-Borel theorem.
\end{corollary}
\begin{proof}
    If $V$ is a bounded neighbourhood, then it is precompact, hence the space is locally compact, so finite dimensional.
\end{proof}

In the context of norm spaces, we found a linear map was continuous if and only if it was bounded. An analogous definition of a bounded operator $T: X \to Y$ between topological vector spaces is an operator that maps bounded sets to bounded sets. It is easy to prove that a continuous map is bounded, but the converse is not always true. However, in a metrizable space, it is true.

\begin{lemma}
    if $X$ is a metrizable space, and $x_n \to 0$, then there are constants $\lambda_n \to \infty$ with $\lambda_n x_n \to 0$.
\end{lemma}
\begin{proof}
    If $d$ is translation invariant, it is easy to prove that for any $x$, $d(nx,0) \leq n d(x,0)$. If $d(x_n,0) \to 0$, there are an increasing sequence of positive integers $N_m$ with $d(x_n,0) \leq 1/m^2$ for $n \geq N_m$. Then $d(mx_{n_m},0) \leq 1/m$, so if $\lambda_n$ is the largest $m$ with $n_m \leq n$, then $\lambda_n x_{n_m} \to 0$.
\end{proof}

\begin{example}
    If $X$ is non-metrizable, this need not be true. Consider the space $\mathbf{C}^{[0,1]}$ of all complex functions on $[0,1]$, under the topology of pointwise convergence. Since $[0,1]$ has the same cardinality as the space $\mathbf{C}^{\mathbf{N}}$ of all complex-valued sequences converging to zero pointwise, we can define a map $F: [0,1] \to \mathbf{C}^{\mathbf{N}}$, and then define a sequence $f_n$ of functions converging pointwise to zero by letting $f_n(x) = F(x)_n$. For any sequence of constants $\lambda_1, \lambda_2, \dots$ converging to $\infty$, the sequence $1/\lambda_1, 1/\lambda_2, \dots$ converges to zero, hence there is some $x \in [0,1]$ with $F(x)_n = 1/\lambda_n$. Then $\lambda_n f_n(x) = \lambda_n/\lambda_n = 1$, so $\lambda_n f_n$ does not converge pointwise to zero.
\end{example}

\begin{theorem}
    If $X$ is a metrizable space, every bounded operator with $X$ as a domain is continuous.
\end{theorem}
\begin{proof}
    Since $X$ is first countable, it suffices to prove that if $x_n$ is a sequence converging to zero, and $T: X \to Y$ is bounded, then $T$ is continuous. Certainly $x_n$ is bounded, so $Tx_n$ is bounded. If we pick $\lambda_n$ as in the last lemma, so $\lambda_n x_n \to 0$, then $\lambda_n x_n$ is bounded, so $\lambda_n Tx_n$ is bounded, and since $\lambda_n^{-1} \to 0$, $Tx_n = \lambda_n^{-1} (\lambda_n Tx_n) \to 0$.
\end{proof}

\begin{example}
    A quasinorm space is a vector space $X$ equipped with a non-negative real-valued function $\| \cdot \|$ such that $\| x \| = 0$ if and only if $x = 0$, $\| \lambda x \| = |\lambda| \| x \|$, and $\| x + y \| \lesssim \|x\| + \|y\|$, rather than the stronger inequality $\| x + y \| \leq \| x \| + \| y \|$. The most precient examples of quasinorm spaces are the $L^p(X)$ spaces over some measure $\mu$, where $p < 1$. Since the unit ball in these spaces are not convex, we know that $\| \cdot \|_p$ is not a norm. However, the norms corresponding to these spaces {\it are} quasinorms. To see this, we use the fairly trivial inequality $(a + b)^p \leq 2^p(a^p + b^p)$, for $a,b,p > 0$, which follows because
    %
    \[ (a + b)^p \leq (2 \max(a,b))^p = 2^p \max(a,b)^p \leq 2^p(a^p + b^p) \]
    %
    so that $\| f + g \|_p^p \leq 2^p ( \| f \|_p^p + \| g \|_p^p )$, and therefore
    %
    \[ \| f + g \|_p \leq 2 ( \| f \|_p^p + \| g \|_p^p )^{1/p} \leq 2^{1 + 1/p} ( \| f \|_p + \| g \|_p ) \]
    %
    So the `$L^p$ norm' is a quasinorm. This quasinorm gives $L^p(X)$ the structure of a complete metric space, the proof of completeness being exactly the same as in the case where $p \geq 1$. The fact that only a single quasinorm is defined in the definition of the topology shows the space is locally bounded.  However, the space is not locally convex, hence not a Fr\'{e}chet space. In fact, as an example, $L^p[0,1]$ contains no convex open sets other than $\emptyset$ and $L^p[0,1]$. To see this, let $W$ be an non-empty, open, convex set, and without loss of generality, let $0 \in W$, and suppose $W$ contains all functions $f$ with $\| f \|_p < \varepsilon$. Given any $f \in L^p[0,1]$, and any integer $N$, we can divide $[0,1]$ into disjoint intervals $I_1, I_2, \dots, I_N$ with
    %
    \[ \| f \|_{L^p(I_n)} = \frac{\| f \|_{L^p[0,1]}}{N^{1/p}} \]
    %
    If $f_n = N \chi_{I_n} f$, then $\| f_n \|_{L^p[0,1]} = N^{1-1/p} \| f \|_{L^p[0,1]}$. Since $p < 1$, we can choose $N$ large enough that $\| f_n \|_{L^p[0,1]} < \varepsilon$, hence $f_n \in W$, and then by convexity,
    %
    \[ f = \frac{f_1 + \dots + f_N}{N} \in W \]
    %
    Thus $W = L^p[0,1]$. Now a strange result of this is that if $T: L^p[0,1] \to X$ is a continuous linear transformation into a locally convex space $X$, then $T = 0$. This follows because if $W$ is an open, convex neighbourhood, then $T^{-1}(W)$ is open and convex, hence $T^{-1}(W) = L^p[0,1]$. But then taking $W$ to be an arbitrary convex neighbourhood of the origin,
    %
    \[ T^{-1}(0) = T^{-1} \left( \bigcap W \right) = \bigcap T^{-1}(W) = L^p[0,1] \]
    %
    Thus there are {\it no} nonzero continuous linear functions on $L^p[0,1]$.
\end{example}

For non-metrizable locally convex spaces, we still have a nice analytical criterion for continuity in terms of seminorms.

\begin{theorem}
    Let $T: X \to Y$ be a map between convex spaces. Then $T$ is continuous if and only if for any continuous seminorm $\| \cdot \|_Y$ on $Y$, there is a continuous seminorm $\| \cdot \|_X$ on $X$ such that $\| Tx \|_Y \leq \| x \|_X$.
\end{theorem}
\begin{proof}
    Suppose $T$ is continuous. Then the unit ball $B$ in the $Y$ norm is open, so $T^{-1}(B)$ is an open neighbourhood of the origin in $X$, and there therefore contains a convex, balanced subset about the origin which is the unit ball with respect to some continuous seminorm $\| \cdot \|_X$. Thus $\| Tx \|_Y \leq 1$ if $\| x \|_X \leq 1$, which implies that
    %
    \[ \| Tx \|_Y = \| x \|_X \left\| T \left( x/\|x \|_X \right) \right\|_Y \leq \| x \|_X \]
    %
    Conversely, if the other condition is satisfied and $U$ is an open convex set about the origin in $Y$, then it is the unit ball with respect to some norm $\| \cdot \|_Y$, and so there is $\| \cdot \|_X$ such that $\| Tx \|_Y \leq \| x \|_X$, hence the unit ball with respect to the $X$ norm is an open neighbourhood which maps into $U$, so $T$ is continuous at the origin, hence continuous everywhere.
\end{proof}

If $X$ and $Y$ are generated by a family of seminorms closed under maxima, we can restrict the conditions of the theorem to only the seminorms contained in this group, if we weaken the condition $\| Tx \|_Y \leq \| x \|_Y$ to $\| Tx \|_Y \lesssim \| x \|_X$.

\section{Quotient Spaces}

If $Y$ is a subspace of a topological vector space $X$, then $X/Y$ can be given the quotient topology, and one easily verifies that addition and multiplication is continuous, so the quotient of a topological vector space is a topological vector space. Since the neighbourhood of $0 + Y$ in $X/Y$ is an open set containing $Y$,
%
\[ \overline{0 + Y} = \bigcap_{U + Y} (0 + Y) + (U + Y) = \bigcap_{U} (U + Y) = \overline{Y} + Y \]
%
So $X/Y$ is Hausdorff if and only if $Y$ is closed.

We can now argue why assuming a space is Hausdorff isn't too strong a statement. Let $X$ be a (not necessarily Hausdorff) topological vector space. Then $0$ is a subspace of $X$, and so the closure of $\overline{0}$ is also a closed subspace. But now if we consider the space $X/\overline{0}$, we obtain a Hausdorff topological space. Thus the techniques of Hausdorff topological spaces can normally be used to obtain results about non Hausdorff spaces by means of quotienting.

\begin{theorem}
    The quotient map $\pi: X \to X/Y$ is open, and a neighbourhood base for $X/Y$ is given by taking $\pi(U)$, where $U$ ranges over a neighbourhood base.
\end{theorem}
\begin{proof}
    The fact that $\pi(U)$ is open when $U$ is open follows because
    %
    \[ \pi^{-1}(\pi(U)) = U + Y \]
    %
    is obviously a union of open neighbourhoods. If $V$ is an open neighbourhood of the origin in $X/Y$, then $\pi^{-1}(V)$ is a neighbourhood of the origin, hence contains some $U$ in a neighbourhood base, and then $\pi(U) \subset V$.
\end{proof}

\begin{theorem}
    The quotient of a locally convex / locally bounded / metrizable / normable / complete metrizable space also has these properties.
\end{theorem}
\begin{proof}
    The image of a convex / balanced / absorbing / bounded set under a quotient map is also convex / balanced / absorbing / bounded. This shows that the quotient of a locally convex / bounded space is locally convex / bounded. Since the quotient of a first countable space is first countable, this shows that the quotient of a metrizable space is metrizable. The fact that the quotient of a normable space is normable follows because a normable is precisely a locally convex and locally bounded space. The only remaining fact is to show that the quotient of a complete metrizable space is complete. If $d$ is a complete invariant metric for the space, with $f(x) = d(0,x)$, then the metric for the quotient is given by
    %
    \[ d(x_0 + Y, x_1 + Y) = \inf \{ f((x_1 - x_0) + y) : y \in Y \} \]
    %
    The triangle inequality follows because if $f((x_1 - x_0) + y_0) \leq \alpha$ and $f((x_2 - x_1) + y_1) \leq \beta$, then $d(x_1 + y_0, x_0) \leq \alpha$, and $d(x_2 + y_1 + y_0, x_1 + y_0) \leq \beta$, and so the triangle inequality on $X$ gives
    %
    \[ d(x_0, x_2 + y_1 + y_0) \leq \alpha + \beta \]
    %
    so $d(x_0 + Y, x_2 + Y) \leq \alpha + \beta$, and taking infima gives the triangle inequality. If $x_\alpha + Y \to 0$ in $X/Y$, then we can pick $y_\alpha$ with $x_\alpha + y_\alpha \to 0$ in $X$, hence $d(0, x_\alpha + y_\alpha) \to 0$, so $d(0,x_\alpha + Y) \to 0$. Conversely, if $d(0,x_\alpha + Y) \to 0$, then there are $y_\alpha$ with $d(0, x_\alpha + y_\alpha) \to 0$, so $x_\alpha + y_\alpha \to 0$, hence $x_\alpha + Y \to 0$. Thus $d$ is a metric for the topological structure of $X/Y$. Now if $d$ is complete on $X$, it remains to show $d$ is complete on $X/Y$. Suppose $x_n + Y$ is Cauchy. Then we can inductively, for each $n$, pick $k_n$ and $y_n$ such that $d(x_{k_{n+1}} + y_{n+1}, x_{k_n} + y_n) \leq 1/2^n$. This means $x_{k_n} + y_n$ is Cauchy, hence converges, hence $x_{k_n} + Y$ converges, and because of the Cauchy property it follows that $x_n + Y$ converges to the same value.
\end{proof}

\begin{corollary}
    If $Y$ is a closed subspace of $X$, and $Z$ is finite dimensional, then $Y + Z$ is closed.
\end{corollary}
\begin{proof}
    $Z/Y$ is finite dimension in $X/Y$, hence is closed. But $Y + Z$ is the inverse image of $Z/Y$ under the quotient map, which is continuous, so $Y + Z$ is closed.
\end{proof}






\section{Inductive Limits}

We have a theory of topological vector spaces, and maps between them, so we have a category. Let us study inductive limits in this space. The canonical example of this is the test function space $\DD(\Omega)$ on an open subset $\Omega$ of $\RR^d$, which is the inductive limit of the spaces $C_c^\infty(K)$ of smooth functions with support on a compact set $K \subset \Omega$. For general (not necessarily Hausdorff) topological spaces, inductive limits exist. Given a system $\{ f_{ij}: X_i \to X_j \}$ of linear maps, we can form the topological inductive limit $X$, together with the family of maps $f_i: X_i \to X$ such that $U \subset X$ is open if and only if $f_i^{-1}(U)$ is open in $X_i$ for each $i$. The set $X$ is defined such that $X = \bigcup f_i(X_i)$, and $f_i(x) = f_j(x)$ if and only if there exists $k \succ i,j$ such that $f_{ik}(x) = f_{jk}(y)$. This is precisely the topology with the most open sets, such that each of the maps $f_i$ is continuous. The algebraic operations on each of the spaces $X_i$ induces algebraic operations on $X$, and it is simple to see that these operations are continuous. Thus $X$ is a topological vector space. There are several problems with this construction that make this not so nice, however, because topological properties do not play quite so nicely with direct limits (the direct limit of Hausdorff topological vector spaces, for instance, need not be Hausdorff).

Our construction can be made a bit nicer if we work in the subcategory of \emph{locally convex topological spaces}. Working in this subcategory, we require less functions to be continuous, and so the direct limit can be defined with less open sets. In particular, if each of the spaces $\{ X_i \}$ is locally convex, then to form an direct limit in this subcategory, then we obtain an direct limit in the category of locally convex topological vector spaces by declaring a \emph{convex} set $U \subset X$ to be an open neighborhood of the origin if and only if $f_i^{-1}(U)$ is open for each $i$, and then using these sets as a basis for the overall topology. It is easy to see this is a basis, because the intersection of convex sets is convex, and thus we get a topology. Even in this subcategory, the direct limit of Hausdorff locally convex spaces need not be Hausdorff.

\begin{lemma}
    Consider a countable direct system $X_1 \to X_2 \to \dots$, where each $X_i$ is a locally convex $T1$ Hausdorff space, and such that each map $f_i: X_i \to X_{i+1}$ is injective. Then the direct limit $X$ is $T1$ (and thus Hausdorff).
\end{lemma}
\begin{proof}
    Consider $z,w \in X$. Suppose $i$ is the smallest index such that $z,w \in X_i$ and set $U_{i-1} = \emptyset$. Starting with $k = i$, define a convex set $U_k$, which is open in $X_k$, such that $U_{k-1} \subset U_k$, $z \in U_k$, but $w$ is not an element of $\overline{U_k}$. To do this, we start by finding a convex, balanced set $V$ such that $\overline{w + V}$ is disjoint from $\overline{U_{k-1}}$ by assumption. Then $U_k = U_{k-1} + V$ is convex, open, contains $z$, and it's closure is disjoint from $w$. Then the set $\bigcup_k U_k$ is a convex, open neighborhood of $z$ in $X$, not containing $w$, so $X$ is $T1$.
\end{proof}

A similar method to the proof above, combined with the following lemma, shows that if each of the maps $X_i \to X_{i+1}$ is am embedding, then the maps $X_i \to X$ will also be embeddings. A space obtained from the limit of countably many Fre\'{e}chet spaces embedded in one another is called an \emph{LF Space}.

\begin{lemma}
    Suppose $X$ and $Y$ are locally convex vector spaces, with $Y$ a subspace of $X$. Then for any convex open set $V \subset Y$, there exists a convex open set $U \subset X$ such that $U \cap Y = V$.
\end{lemma}
\begin{proof}
    By the definition of the subspace topology, we can write $V = V' \cap Y$ for some open set $V'$ in $X$. Let $U$ be the convex hull of $V'$. Because $V$ is convex, $U \cap Y = V$. But $U$ is also open in $X$.
\end{proof}

A direct limit of a countable family of Fr\'{e}chet spaces as in the Lemma above is called an \emph{LF space}. Most interesting results about direct limits are reserved for LF spaces, like the following result. For instance, that every LF space is complete.

These notes are probably worth looking into if I ever want to learn more about limits of convex spaces: Bierstedt, Klaus-Dieter (1988). An Introduction to Locally Convex Inductive Limits. Functional Analysis and Applications. Singapore-New Jersey-Hong Kong: Universittsbibliothek. pp. 35133. MR 0046004. Retrieved 20 September 2020.








\chapter{Weak Topologies}

\begin{example}
    In Banach theory, the most important examples of topological spaces are those obtain by placing other topologies on a norm space than the original norm topology. Given a norm space $X$, we have a space $X^*$ consisting of continuous linear functionals on $X$. We say that a net $x_\alpha$ converges weakly to $x$ if $f(x_\alpha) \to f(x)$ for every $f \in X^*$. This defines the \emph{weak topology} on $X$. Similarily, on $X^*$ we may define the \emph{weak $*$ topology}, by letting $f_\alpha \to f$ if $f_\alpha(x) \to f(x)$ for every $x \in X$. Note that we may also put a weak topology on $X^*$, since it is also a norm space, but the weak and weak $*$ topologies on $X^*$ rarely correspond (the weak topology has more stringent notions of continuity). These topologies are effectively topologies induced by pointwise convergence, because the weak topology is obtained by embedding $X$ in $\mathbf{F}^{X^*}$, and the weak $*$ topology is obtained by considering $X^*$ as a subspace of $\mathbf{F}^X$. The weak topology on $X$ is rarely equal to the original topology on $X$, except in degenerate circumstances. For instance, if we consider $e_n \in l_p$, for $1 < p < \infty$, then $\| e_n - e_m \| = 1$, so $e_n$ does not converge, yet if we consider any element $f \in l_q$ of the dual space, then $\langle f, e_n \rangle = f(n)$, which converges to zero as $n \to \infty$. Thus $e_n$ converges to zero in the weak topology. In $l_1$, $e_n$ does not converge at all, because the function $f(n) = (-1)^n$ is in $l_\infty$, and $\langle f, e_n \rangle = (-1)^n$ does not converge. It is important to note that the weak $*$ topology depends on the predual we are using. If we consider $l_1 = c_0^*$, then the $e_n$ converges to zero in the weak $*$ topology, yet if we consider $l_1$ as $c^*$, then the $e_n$ do not converge in the induced weak $*$ topology.

    The weak topology on a space is rarely first countable. If $A = \{ \sqrt{n} e_n : n \in \mathbf{N} \}$ is viewed as a subset of $l_2$, then 0 is contained in the weak closure of $A$, because if $\varepsilon > 0$ and we are given a finite set of sequences $\{ a_n^k \}_{n \in \mathbf{N}}$, for $1 \leq k \leq K$ and, for any $n$, there is $k_n$ such that $|a_n^{k_n}| \sqrt{n} > \varepsilon$, and if we consider the sum $\sum_k |a_n^k| \in l^2$, then
    %
    \[ \sum_n \left|\sum_k |a_n^k| \right|^2 \geq \sum_n |a_n^{k_n}|^2 \geq \varepsilon \sum \frac{1}{n} = \infty \]
    %
    so there must be an element of $A$ in each $U_{\varepsilon, \{ a_n^1 \}, \dots, \{ a_n^K \}}$, and hence $0$ is in the weak closure of $A$. However, 0 is not the weak limit of any sequence of elements in $A$, for
    %
    \[ \sum_{n = 0}^\infty \frac{e_n}{n} \in l_2 \]
    %
    and if we consider any sequence $\sqrt{n_i} e_{n_i}$ that converges weakly to zero, then we find that $(n_i)^{-1/2}$ converges to zero, hence $n_i \to \infty$. But then the sequence is not norm bounded, and hence cannot converge!
\end{example}








\part{Operator Theory}





\chapter{Banach Algebras}

In this chapter, we develop the machinery to study the various classes of bounded operators which occur when classifying transformations on a space. To do this, we employ tools from abstract algebra. Recall that an algebra over a field $\mathbf{F}$ is a (not necessarily unital) ring $A$ together with a fixed embedding of $\mathbf{F}$ into $A$, which gives $A$ a vector space structure. A consistant norm attached to an algebra is a nice situation to study operators over a Banach space. What's more, the general theory gives light to many other circumstance  which would not have been apparent were we just analyzing concrete operators. We shall use capital letters, like $M$ and $N$, to denote abstract elements of these algebras, and we denote algebras by capital letters near the beginning of the alphabet, such as $A$ or $B$. A \emph{Banach Algebra} is a Banach space $A$ which is also an algebra, and satisfies $\| MN \| \leq \| M \| \| N \|$ for all $M,N \in A$. A \emph{unital Banach Algebra} is a Banach algebra with an identity $1 \neq 0$, which we will assume also satisfies $\| 1 \| = 1$. Thus multiplication is a continuous operation, and the norm is normalized to give the multiplicative identity unit norm. We shall pretty much only consider Banach algebras over the complex numbers, because here we can apply the unique properties of complex analysis.

\begin{example}
    Let $X$ be a locally compact topological space. Then the space $C_b(X)$ of continuous, bounded functions on $X$ forms a unital commutative Banach algebra under the pointwise product, and equipped with the $L^\infty$ norm. The space $C_0(X)$ of continuous functions vanishing at infinity forms a subalgebra of $C_b(X)$, and is unital precisely when $X$ is compact, in which case $C_0(X) = C_b(X) = C(X)$. Regardless, we can add an identity by consider the family of all functions of the form
    %
    \[ C_0(X)^\# = \{ \lambda + f : \lambda \in \CC, f \in C_0(X) \}, \]
    %
    which can be viewed as the space of all continuous functions which converge to a common value at $\infty$, which can thus be naturally identified with $C(X \cup \{ \infty \})$, where $X \cup \{ \infty \}$ is the one point compactification of $X$.

    As a simple example, if $X = \{ x_1, \dots, x_n \}$ is a discrete topological space, then $C(K) \cong \CC^n$, where the right hand side is a Banach algebra if we equip it with the standard norm, and the pointwise product, since the Cauchy-Schwartz inequality then tells us that $\| xy \| \leq \| x \| \| y \|$ for all $x,y \in \CC^n$.
\end{example}

\begin{example}
    The space $L^\infty(X)$ of essentially bounded functions on a measure space $X$ is a Banach algebra, and it is unital except in the trivial case where $|X| = 0$, in which case $L^\infty(X) = 0$.
\end{example}

\begin{example}
    If $\Omega$ is a compact set in $\CC$, then we define $A(\Omega)$ to be the subset of $C(\Omega)$ consisting of all functions which are analytic on the interior of $\Omega$. Since uniform convergence preserves holomorphicity, $A(\Omega)$ is a closed subalgebra of $C(\Omega)$, and is therefore a Banach algebra. $A(\mathbf{D})$ is known as the \emph{disk algebra}.
\end{example}

\begin{example}
    Let $X$ be a Banach space. Then $X$ has the structure of a somewhat trivial, commutative Banach algebra if we define $x_1 x_2 = 0$ for any $x_1,x_2 \in X$. This is often a useful family of spaces to construct counterexamples, or to show why certain assumptions are necessary in Banach algebra theory.
\end{example}

A Banach algebra $A$ is \emph{generated} by a set $S \subset A$ if there is no proper closed subalgebra of $A$ containing $S$. In this language, the Stone-Weirstrass theorem says that, for any locally compact Hausdorff space $X$, a family of functions $S \subset C_0(X)$ generates $C_0(X)$ if and only if $S$ separates all points in $X$, $S$ has no common zero set in $X$, and if we are working with complex-valued functions, $S$ is closed under conjugation.

\begin{example}
    Let $G$ be a locally compact group, with Haar measure $\mu$, and consider the space of functions $L^1(G)$, where multiplication is convolution,
    %
    \[ (f * g)(x) = \int f(y) g(y^{-1}x) d\mu(y) \]
    %
    One can then verify that
    %
    \[ \| f * g \|_{L^1(G)} \leq \| f \|_{L^1(G)} \| g \|_{L^1(G)}. \]
    %
    Thus $L^1(G)$ is a Banach algebra, commutative when $G$ is commutative. It does not always possess a unit, e.g. $L^1(\RR)$ is non-unital, but $L^1(\ZZ)$ is unital. But we can always enlarge the space so it becomes a unital Banach algebra. Let $M(G)$ be the space of complex-valued finite Borel measures on $G$, and define convolution on $M(G)$ by letting
    %
    \[ \int f d (\eta * \nu) = \int \int f(xy) d\eta(x) d\nu(y), \]
    %
    then $M(G)$ forms a unital Banach algebra, and the Dirac delta function $\delta_0$ at the identity element of $G$ is then a unit for $M(G)$. Thus one can consider the set
    %
    \[ L^1(G)^\# = \{ \delta_0 + f : f \in L^1(G) \}, \]
    %
    which is the smallest unital Banach algebra containing $L^1(G)$ in $M(G)$.

    The space $M(\ZZ) = L^1(\ZZ)$ is a fairly concrete example. It can be taken as the space of integer valued sequences $c = \{ c(n) \}$ (where $\sum |c(n)| < \infty$), with convolution
    %
    \[ (a * b)(n) = \sum_{k \in \mathbf{Z}} a(k) b(n-k) \]
    %
    The Dirac delta function here is just the sequence $\delta_0$, where
    %
    \[ \delta_i(k) = \begin{cases} 1 & k = i \\ 0 & \text{elsewise} \end{cases} \]
    %
    Since $\delta_i = (\delta^1)^i$, $L^1(\ZZ)$ is generated by $\delta^1$ and it's inverse.
\end{example}

One of the prime reasons to study Banach algebras is to study spaces of operators on a Banach space, and this is our primary example of a non-commutative Banach algebra.

\begin{example}
    Let $E$ be a Banach space. The space $B(E)$ of all bounded linear operators from $E$ to itself is a Banach algebra with respect to the operator norm. It is a unital algebra, since it possesses the identity operator. The subset $K(E)$ of compact linear operators is a closed (double-sided) ideal of $B(E)$, and so is also a Banach algebra. $K(E)$ is unital if and only if $E$ is finite dimensional.
\end{example}

Really, all that distinguishes a Banach space from a Banach algebra is a continuous multiplication structure, modulo the norm we use to define the topology of the space.

\begin{prop}
    Let $X$ be a Banach space equipped with a continuous multiplication structure. Then there is an equivalent norm on $X$ which makes the space into a Banach algebra.
\end{prop}
\begin{proof}
    Embed $X$ in $B(X)$ by defining $T_M(N) = MN$ (since multiplication on the right is continuous, $T_M$ truly is in $B(X)$ rather than just being a linear map). If $M_i \to M$, and $T_{M_i} \to T$, then we claim $T_M = T$. Indeed, since multiplication is continuous on the left,
    %
    \[ T(N) = \lim_{i \to \infty} T_{M_i}(N) = \lim_{i \to \infty} M_i N = MN = T_M(N). \]
    %
    Thus the closed graph theorem implies that $M \to T_M$ is a continuous embedding of $X$ in $B(X)$. If we define a norm $\| \cdot \|_A$ on $X$ by setting $\| M \|_A = \| T_M \|$, then it follows that $\| M \|_A \sim \| M \|$, and $\| MN \|_A \leq \| M \|_A \| N \|_A$, so $X$ has a Banach algebra structure with the norm $\| \cdot \|_A$.
\end{proof}

The class of non-unital Banach algebras is not often that different from the class of unital Banach algebras. If $A$ is a Banach algebra without unit, then we can always consider it's unitization
%
\[ A^\# = \{ x + \lambda : x \in A, \lambda \in K \} \]
%
which will also be a Banach algebra by setting
%
\[ (x_1 + \lambda_1)(x_2 + \lambda_2) = (x_1x_2 + \lambda_1 x_2 + \lambda_2 x_1) + \lambda_1 \lambda_2 \]
%
and defining
%
\[ \| x + \lambda \| = \| x \| + |\lambda|. \]
%
A statement is often true about $A$ if and only if it is true about $A^\#$, so that it suffices to solely study unital Banach algebras.

As we saw in the examples above, if $A = C_0(X)$, then we can identify $A^\#$ with $C(X \cup \{ \infty \})$, where $X \cup \{ \infty \}$ is the one-point compactification of $X$. There is a general school of Banach algebra theory known as \emph{non commutative topology}, which studies Banach algebras $A$ heuristically as if they were rings of continuous functions on some `non-commutative space'. Thus one can think of the unitization of a non-unital algebra as the `one-point compactification' of this underlying non commutative space.

\section{Involutions}

An \emph{involution} on a Banach algebra $A$ is an antilinear map $M \mapsto M^*$, which satisfies
%
\[ M^{**} = M\ \ \ \ \ (MN)^* = N^*M^*. \]
%
One can think of an involution as the generalization of the conjugation operator $z \mapsto \overline{z}$ on $\CC$, or of taking the adjoint of an operator on a Hilbert space. A \emph{Banach $*$ Algebra} is a Banach algebra with a fixed involution. A \emph{$C^*$ algebra} is a Banach $*$ algebra $A$ which satisfies
%
\[ \| M^* M \| = \| M \|^2 \]
%
for all $M \in A$.

An arbitrary involution on a Banach algebra can be rather discontinuous, which makes the general study of Banach $*$ algebras not too interesting. But most involutions in Banach $*$ algebra theory turn out to be continuous, in particular, often being isometries, i.e. satisfying $\| M^* \| = \| M \|$. This is true of any $C^*$ algebra $A$, since if $M \in A$, then
%
\[ \| M \|^2 = \| M^* M \| \leq \| M^* \| \| M \| \]
%
implies $\| M \| \leq \| M^* \|$, and
%
\[ \| M^* \|^2 = \| M M^* \| \leq \| M^* \| \| M \| \]
%
implies $\| M^* \| \leq \| M \|$. The next result (a curiosity that can be ignored on a first reading) shows that any involution on a commutative, semisimple Banach algebra is continuous (an algebra $A$ is semisimple if the intersection of all maximal ideals is trivial).

\begin{prop}
    Let $A$ be a commutative, semisimple Banach algebra. Then every involution on $A$ is continuous.
\end{prop}
\begin{proof}
    We rely on a fact (to be proved later), that every algebra homomorphism $\phi: A \to K$ is \emph{automatically continuous}. The semisimplicity of $A$ implies that for any $M_1,M_2 \in A$, $M_1 = M_2$ if and only if for every such algebra homomorphism $\phi: A \to K$, $\phi(M_1) = \phi(M_2)$. Now if $T: A \to A$ is an involution on $A$, and $\phi: A \to K$ is a homomorphism, then $\overline{\phi \circ T}: A \to K$ is also an algebra homomorphism, and thus continuous. Thus if $M_i \to M$, and $TM_i \to N$, then the continuity of $\overline{\phi \circ T}$ implies that
    %
    \[ \overline{\phi(TM)} = \overline{\phi(N)}, \]
    %
    i.e. $\phi(TM) = \phi(N)$. Thus $TM - N$ is in the kernel of every character $\phi$. Since $A$ is semisimple, this implies that $TM = N$. Thus by the closed graph theorem, $T$ is continuous.
\end{proof}

\begin{remark}
    A similar proof shows that every homomorphism $T: A \to B$ from a Banach algebra $A$ into a semisimple commutative Banach algebra $B$ is continuous.
\end{remark}

\begin{example}
    Let $H$ be a Hilbert space. Then for any bounded operator $T: H \to H$, we define the adjoint operator $T^*: H \to H$ by the equation
    %
    \[ \langle Tx, y \rangle = \langle x, T^* y \rangle. \]
    %
    Now if $\| x \|, \| y \| \leq 1$, then
    %
    \[ | \langle T^* T x, y \rangle | = | \langle Tx, Ty \rangle | \leq \| T \|^2 \]
    %
    and this is attained, for if there are $\| x_i \| \leq 1$ such that $\| Tx_i \| \to \| T \|$, then
    %
    \[ \langle T^* T x_i, x_i \rangle = \| Tx_i \|^2 \to \| T \|^2. \]
    %
    Thus $\| T^* T \| = \| T \|^2$, and so $B(H)$ is a $C^*$ algebra. If we are working over $\mathbf{C}^n$, then each element of $B(\CC^n)$ can be expressed as a matrix in $M_n(\mathbf{C})$, and the involution in $B(\mathbf{C}^n)$ is then equivalent to taking the complex transpose on sets of matrices, which gives a finite dimensional example. In particular, $M_n(\CC)$ is also a $C^*$ algebra.
\end{example}

\begin{example}
    Other examples of $C^*$ algebras can be obtained by taking closed involutive subalgebras of $B(H)$. For instance, the algebra $K(H)$ of \emph{compact operators} on a Hilbert space forms a $C^*$ algebra. Another example, given a family of operators $S \subset B(H)$, is the space $C^*(S)$, which is the smallest closed involutive unital subalgebra of $B(H)$ containing $S$. As a special case, for an operator $T \in B(H)$, is the algebra $C^*(T)$, which can be seen as the closure of non-commutative polynomial expressions in $T$ and $T^*$.
\end{example}

\begin{example}
    The pointwise conjugation map $f \mapsto \overline{f}$ is an involution on $L^\infty(X)$, and for any $f \in L^\infty(X)$,
    %
    \[ \| f \overline{f} \|_\infty = \| |f|^2 \|_\infty = \| f \|^2_\infty. \]
    %
    Thus $L^\infty(X)$ is a $C^*$ algebra. Similarily, $C_0(X)$ and $C_b(X)$ are $C^*$ algebras with the same involution. The central result of the study of commutative $C^*$ algebras will show that all such algebras are isometric to $C_0(X)$ for some $X$.
\end{example}

\begin{example}
    For $f \in A(\mathbf{D})$, if we define $f^*(z) = \overline{f(\overline{z})}$, then $*$ is an isometric involution on $A(\mathbf{D})$. But $A(\mathbf{D})$ is \emph{not} a $C^*$ algebra with this involution. To show this, let $f(z) = e^{iz}$. Then
    %
    \[ (ff^*)(z) = e^{iz} \overline{e^{i\overline{z}}} = e^{iz} e^{-iz} = 1 \]
    %
    Thus $\| f f^* \|_\infty = 1$, yet $f(-i) = f^*(i) = e > 1$, so
    %
    \[ \| f \|_\infty \| f^* \|_\infty > \| ff^* \|_\infty. \]
\end{example}

\begin{example}
    For any locally compact group $G$, the convolution algebra $L^1(G)$ has an involution $f^*(g) = \overline{f(g^{-1})}$. It also has the involution $\overline{f}(g) = \overline{f(g)}$. The first one turns out to be much more important to the theory of harmonic analysis on such groups. But neither give $L^1(G)$ the structure of a $C^*$ algebra. As a characteristic example, if $G = \ZZ$, if $f = \delta_1 + \delta_0 - \delta_{-1}$, then
    %
    \[ \overline{f} * f = f * f = \delta_2 + 2 \delta_1 - \delta_0 - 2 \delta_{-1} + \delta_{-2} \]
    %
    and
    %
    \[ f * f^* = - \delta_2 + 3 \delta_0 - \delta{-2}. \]
    %
    Thus $\| f \|_{L^1(\ZZ)} = 3$, whereas $\| \overline{f} * f \|_{L^1(\ZZ)} = 7$ and $\| f * f^* \|_{L^1(G)} = 5$, and neither of these quantities are equal to $\| f \|_{L^1(\ZZ)}^2 = 9$. Similar examples can be constructed on general locally compact groups by using bump functions.
\end{example}

The next result is clearly not true in an arbitrary non-unital Banach algebra (e.g. if $MN = 0$ for all $M$ and $N$).

\begin{prop}
    Let $A$ be a $C^*$ algebra. Then for any $M \in A$,
    %
    \[ \| M \| = \sup \{ \| MN \| : \| N \| \leq 1 \} = \sup \{ \| NM \| : \| N \| \leq 1 \}. \]
\end{prop}
\begin{proof}
    If $N = M^* \|M\|^{-1}$, $\| N \| = 1$, and
    %
    \[ \| MN \| = \| MM^* \| \| M \|^{-1} = \| M \| \]
    %
    Thus the suprema on the right is greater than or equal to $\| M \|$. But if $\| N \| \leq 1$, then
    %
    \[ \| MN \| \leq \| M \| \| N \| \leq \| M \| \]
    %
    so the suprema is also less than or equal to $\| M \|$.
\end{proof}

It follows that we may isometrically embed any $C^*$-algebra $A$ into $B(A)$, by either considering the left or right multiplications. This is known as the \emph{left} or \emph{right regular representation}. Thus if $A$ is a $C^*$ algebra without identity, then we may embed $A$ in $B(A)$, and then consider the smallest closed $C^*$-subalgebra of $B(A)$ which contains $A$ and the identity. The general representation theory of $C^*$ algebras, to be returned to at a later time. In particular, we will learn about the Gelfand Naimark Segal theorem, which gives rise to a universal representation of $A$ as a subalgebra of operators on a Hilbert space.

Given a non-unital Banach $*$ algebra $A$, there is a natural involution on $A^\#$ obtain by defining
%
\[ (\lambda + M)^* = \overline{\lambda} + M^* \]
%
If $A$ is a $C^*$ algebra, so is $A^\#$, provided that we give it the norm
%
\[ \| \lambda + M \| = \sup \{ \| (M + \lambda) N \| : N \in A, \| N \| \leq 1 \}, \]
%
i.e. the norm of $\lambda + M$ is the operator norm of $\lambda + M$ obtained by embedding $A^\#$ in $B(A)$ by the left regular representation. 
%We then calculate that
%
%\[ \| (\lambda + M)^* \| = \sup_N \| (\lambda + M)^* N \| = \sup_N \| N^* (\lambda + M) \| = \sup_N \| N (\lambda + M) \|. \]
%
%Now we have
%
%\[ \sup_N \| N (\lambda + M) \| \leq \| \lambda + M \|. \]
%
%Thus $\| (\lambda + M)^* \| \leq \| \lambda + M \|$. But now symmetry gives the opposite result, so that we have proved
%
%\[ \| (\lambda + M)^* \| = \| \lambda + M \|. \]
%
%Now to prove this gives a $C^*$ norm, we calculate that
%
%\[ \| (A + \lambda)^* (A + \lambda) \| \geq \| (A + \lambda)^* \| \| A + \lambda \| = \| A + \lambda \|^2. \]
%
%The converse follows because
%
%\[ \| (A + \lambda)^* (A + \lambda) N \| \leq \| (A + \lambda)^* \]
%
%\begin{align*}
%    \| (A + \lambda)^* (A + \lambda) \| &= \sup_{\| N \| \leq 1} (A^* A + \overline{\lambda} A + \lambda A + |\lambda|^2) N\\
%    &\geq \sup_{\| N \| \leq 1} N^* (A^* A + \overline{\lambda} A + \lambda A + |\lambda|^2) N\\
%    &= \sup_{\| N \| \leq 1} \| (AN + \lambda N)^* (AN + \lambda N) \|\\
%    &= \sup_{\| N \| \leq 1} \| (A + \lambda) N \|^2\\
%    &= \| A + \lambda \|^2.
%\end{align*}
%
%But the converse follows trivially since
%
%\[ (A + \lambda)^* (A + \lambda) \| \geq \| (A + \lambda)^* \| \| A + \lambda \| \]
%
The above proposition verifies that the embedding of $A$ in $A^\#$ is an isometry under this norm.

The theory of $C^*$ algebras is closely related to operator theory. The Gelfand Naimark Segal construction shows that all $C^*$ algebras are isometric to some $C^*$ subalgebra of bounded operators on a Hilbert space. Thus it makes sense to extend terminology from Hilbert space theory to the $C^*$ domain. We say $M \in A$ is \emph{self-adjoint} or \emph{hermitian} if $M^* = M$. The set of all such elements forms a real subalgebra of $A$, analogous to the inclusion of the real numbers in the complex numbers. Here is a result which provides further evidence that this analogy is apt.

\begin{prop}
    In any Banach $*$ algebra $A$, there is a unique way to write any $M \in A$ as $M = T + iS$, where $T$ and $S$ are self-adjoint elements of $A$.
\end{prop}
\begin{proof}
    Write
    %
    \[ T = \frac{M + M^*}{2}\ \ \ \ \ S = \frac{M - M^*}{2i} \]
    %
    Then $T + iS = M$, and they are trivially verified to be self-adjoint. Now suppose $M = N + iL$, where $N$ and $L$ are self-adjoint. Then
    %
    \[ 0 = (N - T) + i(L - S) \]
    %
    Taking adjoints on both sides thus gives
    %
    \[ (N - T) + i(L - S) = (N - T) - i(L - S) \]
    %
    And so $i(L - S) = -i(L - S)$, which can only occur when $L - S = 0$. But then $N - T = 0$ also.
\end{proof}

An element $M$ of a Banach $*$ algebra is \emph{normal} if
%
\[ M^* M = MM^* \]
%
The importance of this property results because if $M$ is normal, then the smallest involutive subalgebra of $A$ containing $M$ will be commutative. An element $M$ of a Banach $*$ algebra is \emph{unitary} if
%
\[ MM^* = M^*M = 1, \]
%
and the set of all such elements forms a closed subgroup $U(A)$ of $GL(A)$. A \emph{projection} in a Banach $*$ algebra is an element $P$ such that $P^2 = P$.






\chapter{Basic Spectral Theory of Banach Algebras}

We shall begin our study into Banach algebras by analyzing criteria for invertibility, which coincides with the spectral theory of these algebras. For obvious reasons, we restrict our attention to unital algebras, though one can extend all concepts involved to a non-unital algebra $A$ by embedding $A$ in $A^\#$. The set of all units in a unital algebra $A$ will be denoted $GL(A)$, and called the general linear group of $A$. The \emph{spectrum} and \emph{resolvent} of an element $M$ of a Banach algebra $A$ are defined respectively as
%
\[ \sigma_{A}(M) = \{ \lambda \in \mathbf{C} : \lambda - M \not \in GL(A) \} \]
%
and
%
\[ \rho_{A}(M) = \{ \lambda \in \mathbf{C} : \lambda - M \in GL(A) \} \]
%
The resolvent is the complement of the spectrum. When the underlying algebra is canonical, we just use $\sigma(M)$ and $\rho(M)$ to denote the spectrum. %One way to view the addition of a complex number to an operator as an `infinitisimal shift' in the effects of the operator. The spectrum tells us in which directions the operator goes bad under infinitisimal changes, and we shall find that knowledge of the spectrum will allow us to perturb operators more finely. A large number of theorems are based on relating these perturbations to the original operator.

\begin{example}
    Let $X$ be a compact topological space, and consider $f \in C(X)$. Then $\sigma(f) = f(X)$, because the function
    %
    \[ \frac{1}{\lambda - f(x)} \]
    %
    is well defined, bounded, and continuous if and only if $\lambda \not \in f(X)$. If $\Omega$ is a domain in $\CC$, then $\sigma_{A(\Omega)}(f) = \sigma_{C(\Omega)}(f)$, since under the assumptions of this example, the function $(\lambda - f(x))^{-1}$ will also be an analytic function. Similarily, if $X$ is a measure space, and $f \in L^\infty(X)$, then $\sigma(f) = \text{ess supp}(f)$, the \emph{essential support} of $f$.
\end{example}

\begin{example}
    Consider the algebra of $n \times n$ matrices $M_n$. An $n \times n$ matrix is invertible if and only if it is injective, so for an $n \times n$ matrix $M$, $\sigma(M)$ is \emph{precisely} the set of eigenvalues of $M$. On the other hand, in a Banach space $E$, it is no longer true that a bounded operator $T: E \to E$ is invertible if and only if it is injective. Thus the \emph{point spectra} $\sigma_p(T)$ of eigenvalues for $T$ is a proper subset of the spectrum $\sigma(T)$.
\end{example}

The next lemma is incredibly important, and is an extension of the power series formula
%
\[ \frac{1}{1 - z} = \sum_{k = 0}^\infty z^k \]
%
whose conclusion relies solely on the product and addition structure on the complex numbers, which all Banach algebras possess.

\begin{lemma}[Neumann Series]
    Let $A$ be a Banach algebra. If $\|M\| < 1$, then $1 - M \in GL(A)$, and
    %
    \[ (1 - M)^{-1} = \sum_{k = 0}^\infty M^k. \]
\end{lemma}
\begin{proof}
    The right side converges absolutely by the comparison test, since $\| M^k \| \leq \| M \|^k$, and $A$ is complete. This justifies the manipulation
    %
    \[ (1 - M) \sum_{k = 0}^\infty M^k = \sum_{k = 0}^\infty (1 - M)M^k = \sum_{k = 0}^\infty M^k - M^{k+1} = \lim_{n \to \infty} 1 - M^{n+1} \]
    %
    As $n \to \infty$, $M^{n+1} \to 0$, so the limit above tends to one. But $(1 - M)$ commutes with $\sum_{k = 0}^\infty M^k$ (work with limits), since $\sum_{k = 0}^\infty M^k$ is both a left and right inverse for $1 - M$.
\end{proof}

\begin{corollary}
    Let $A$ be a Banach algebra. If $M \in A$ and $\| 1 - M \| < 1$, then $M \in GL(A)$, and
    %
    \[ M^{-1} = \sum_{k = 0}^\infty (1 - M)^k \]
\end{corollary}

\begin{corollary}
    For any Banach algebra $A$, $GL(A)$ is an open subset of $A$.
\end{corollary}
\begin{proof}
    If $M \in GL(A)$, and if $\| M - N \| < 1/\| M^{-1} \|$, then
    %
    \[ \| 1 - M^{-1}N \| \leq \| M^{-1} \| \| M - N \|  < 1 \]
    %
    so $M^{-1}N \in GL(A)$, and thus $N \in GL(A)$.
\end{proof}

\begin{corollary}
    $\sigma(M)$ is a closed and bounded subset of $\mathbf{C}$, and $\rho(M)$ is open
\end{corollary}
\begin{proof}
    The map $f: \lambda \mapsto \lambda - M$ is a continuous operation, for
    %
    \[ \| (\lambda - M) - (\mu - M) \| = \| \lambda - \mu \| = | \lambda - \mu | \]
    %
    Since $GL(A)$ is open, $f^{-1}(GL(A)) = \rho(M)$ is open, hence $\sigma(M)$ is closed. If $|\lambda| > \|M\|$, then $\| M/\lambda \| < 1$, so $(1 - M/\lambda) \in GL(A)$, which means $\lambda - M$ is also invertible. Thus $\sigma(A)$ is closed and bounded, hence compact.
\end{proof}

If we define the \emph{spectral radius} $r(M)$ to be the maximum modulus of an element of $\sigma(M)$, then the last corollary proves that $r(M) \leq \| M \|$, though we need not have equality here (take a trivial Banach algebra $X$ and equip it with a unit, in which it is then true that $\sigma(x) = \{ 0 \}$ for each $x \in X$).

We shall see that the spectra of complex Banach algebras are never empty. This is why we mainly study complex algebras, rather than real algebras; there are even finite dimensional real operators with empty spectra.

\begin{example}
    Consider the matrix
    %
    \[ M = \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} \]
    %
    as an element of the Banach algebra $M_2(\mathbf{R})$. The characteristic polynomial is calculated to be $\lambda^2 + 1$, so the matrix has no eigenvalues in the real numbers, and correspondingly, $\sigma(M) = \emptyset$. Over $M_2(\mathbf{C})$, we find $\sigma(M) = \{ i, -i \}$, so the spectrum is non-empty in the complex extension of the Banach algebra.
\end{example}

\begin{lemma}
    Inversion in an operator algebra $A$ is continuous.
\end{lemma}
\begin{proof}
    Let $(M_n)$ be a sequence in $GL(A)$ converging to an invertible element $M$. Then, by continuity, $M_nM^{-1} \to 1$. If $\| 1 - M_n M^{-1} \| < 1/2$, then
    %
    \[ M_n^{-1} M = (M^{-1}M_n)^{-1} = \sum_{k = 0}^\infty (1 - M^{-1}M_n)^k \]
    %
    It follows that
    %
    \begin{align*}
        \| M_n^{-1} \| &\leq \| M^{-1} \| \| M_n^{-1} M \| \leq \| M^{-1} \| \sum_{k = 0}^\infty \| (1 - M^{-1} M_n)^k \|\\
        &\leq \| M^{-1} \| \sum 2^{-k} = 2 \| M^{-1} \|
    \end{align*}
    %
    Finally, we obtain convergence of inverses,
    %
    \[ \| M_n^{-1} - M^{-1} \| = \| M_n^{-1} (M - M_n) M^{-1} \| \leq \| M_n^{-1} \| \| M - M_n \| \| M^{-1} \| \]
    %
    which tends to zero, since the first and third values are bounded, and the second converges to zero. Thus inversion is continuous.
\end{proof}

The invertible elements $GL(A)$ cannot form a closed set of $A$, for $A$ is path-connected, so there is a sequence of invertible elements $x_i$ which converge to a non-invertible element. Fortunately, Banach algebras have a way of telling us when things are about to go wrong; the norm of the operator blows up. If $A$ was an algebra of operators on a Banach space, one could prove this result from the uniform boundedness principle, and despite the fact we could prove the general result by embedding any Banach algebra into a space of operators of this form by taking an equivalent norm, we work more abstractly.

\begin{lemma}
    Let $A$ be a Banach algebra containing a convergent sequence $M_i \to M$, such that $M_i \in GL(A)$ for each $i$, and $M \not \in GL(A)$. Then $\| M_i^{-1} \| \to \infty$.
\end{lemma}
\begin{proof}
    If $\| M_n^{-1} \| \leq C$ for all $n$, then
    %
    \[ \| 1 - M_n^{-1} M \| \leq \| M_n^{-1} \| \| M_n - M \| \leq C \| M_n - M \|. \]
    %
    If we choose $n$ large enough that $\| M_n - M \| < 1/C$, then $\| 1 - M_n^{-1} M \| < 1$, which means $M_n^{-1} M \in GL(A)$, and thus $M \in GL(A)$.
\end{proof}

\begin{theorem}
    If $B$ is a closed subalgebra of $A$, and $M \in GL(B)$, then the entire connected component of $M$ in $B \cap GL(A)$ is contained in $GL(B)$.
\end{theorem}
\begin{proof}
    $GL(A)$ is open, so $B \cap GL(A)$ is open in $B$. So too is $GL(B)$. If $M_n \to M$, with $M_n \in GL(B)$, and $M \in GL(A)$, then $\| M_n^{-1} \| \to \| M^{-1} \| < \infty$, so by the last lemma, $M$ must be invertible in $B$. Thus we have argued that $GL(B)$ is a closed subset of $B \cap GL(A)$. But it is also open, and therefore must be a union of connected components of $B \cap GL(A)$.
\end{proof}

\begin{corollary}
    If $B$ is a closed subalgebra of $A$, then $\sigma_B(M)$ is obtained from $\sigma_A(M)$ by adding certain components of $\rho_A(M)$.
\end{corollary}

\begin{corollary}
    If $A \subset B$ are algebras, and $\sigma_B(M) \subset \mathbf{R}$, then $\sigma_A(M) = \sigma_A(M)$.
\end{corollary}
\begin{proof}
    $\sigma_B(M)$ is a bounded subset of $\mathbf{R}$, so $\rho_B(M)$ is connected in $\mathbf{C}$. Hence $\sigma_A(M) = \sigma_B(M)$, since $\sigma_A(M) \neq \mathbf{C}$, and if we added any more points to the spectrum we would have to add the entire component, which would have to be all of $\rho_B(M)$.
\end{proof}

\section{Resolvents}

The fundamental theorem of spectral theory relies on heavy complex analysis, hence its restricted application to Banach algebras over the complex numbers. Define the resolvent of $M$, defined on $\rho(M)$ by
%
\[ R(z; M) = (z - M)^{-1} \]
%
Fixing $M$, we obtain a function $R: \rho(M) \to A$. Formally speaking, we should expcet $R$ to be an analytic function with derivative $-(z - M)^{-2}$. This turns out to be the case.

\begin{lemma}
    $R: \rho(M) \to A$ is analytic, in the sense that
    %
    \[ R'(z) = \lim_{w \to 0} \frac{R(z + w) - R(z)}{w} \]
    %
    is a well defined, convergent limit for all $z \in \rho(M)$.
\end{lemma}
\begin{proof}
    The proof is a pure computation.
    %
    \begin{align*}
        \lim_{w \to 0} &\frac{R(z + w, M) - R(z,M)}{w}\\
        &= \lim_{w \to 0} \frac{(z + w - M)^{-1} - (z - M)^{-1}}{w}\\
        &= \lim_{w \to 0} (z + w - M)^{-1} \frac{(z - M) - (z + w - M)}{w} (z - M)^{-1}\\
        &= \lim_{w \to 0} -(z + w - M)^{-1} (z - M)^{-1}\\
        &= -(z - M)^{-2}. \qedhere
    \end{align*}
\end{proof}

In functional analysis, we call such a mapping \emph{strongly analytic}. A \emph{weakly analytic} function $f: \CC \to X$ is a map such that for each $\lambda \in X^*$, $\lambda \circ f$ is analytic. These notions are equivalent if $X$ is a Banach space (proved via methods such as the Banach-Steinhaus theorem). Applying Louiville's theorem to the spectrum, we shall now prove that the spectrum of any element of a Banach algebra is non-empty.

\begin{lemma}
    A bounded weakly analytic function $f: \mathbf{C} \to X$ is constant.
\end{lemma}
\begin{proof}
    Let $\phi \in X^*$. Then $\phi \circ f$ is an analytic function, and
    %
    \[ | (\phi \circ f)(z) | \leq \| \phi \| \| f \|_\infty \]
    %
    Louiville tells us there is $w \in \mathbf{C}$ such that $\phi \circ f = w$. Fix $x,y \in \mathbf{C}$. Then $\phi[f(x) - f(y)] = 0$ for all $\phi \in X^*$. By the Hahn Banach theorem, since $\phi$ was arbitrary, we must have $f(x) - f(y) = 0$, so $f(x) = f(y)$. Thus $f$ is a constant function.
\end{proof}

There is a deep relationship between complex analysis and the spectral theory of Banach algebras. We shall return to `holomorphic functional analysis' later.

\begin{theorem}[Gelfand-Mazur] If $A$ is a complex Banach algebra, then for any $M \in A$, $\sigma(M) \neq \emptyset$.
\end{theorem}
\begin{proof}
    Assume $\sigma(M)$ is empty. Then $R(z)$ is an analytic, entire function of $z$, and tends to zero at infinity, since if $|z| > N \| M \|$,
    %
    \begin{align*}
        \| R(z) \| &= \| (z - M)^{-1} \| = \frac{1}{|z|} \left\| \sum_{k = 0}^\infty \frac{M^k}{z^k} \right\| \leq \sum_{k = 0}^\infty \frac{\| M \|^k}{|z|^{k+1}}\\
        &\leq \frac{1}{|z|} \sum_{k = 0}^\infty \frac{1}{N^{k+1}} = \frac{1}{N(N - 1)\|M\|}
    \end{align*}
    %
    But this implies $R = 0$. But then
    %
    \[ R(z) = (z - M)^{-1} = 0, \]
    %
    and this is clearly impossible for any particular value of $z$.
\end{proof}

\begin{remark}
    We note how non-constructive this theorem is. In particular, this reflects the fact that, for a given explicit element $M$ of a Banach algebra, it is often very difficult to compute $\sigma(M)$ explicitly.
\end{remark}

A cute little theorem arises from this property of Banach algebras that will surprisingly find great use in the analysis of commutative Banach algebras.

\begin{corollary}
    Every complex Banach division algebra is isometric to $\mathbf{C}$.
\end{corollary}
\begin{proof}
    In any unital Banach algebra $A$, $\mathbf{C} \cdot 1$ is isometric to $\mathbf{C}$, for
    %
    \[ \| \lambda \cdot 1 \| = |\lambda| \| 1 \| = |\lambda| \]
    %
    Let $A$ be a complex division algebra, and fix $M \in A$. Pick some $\lambda \in \sigma(A)$. Then $\lambda - M \not \in GL(A)$, hence $\lambda - M = 0$, i.e. $M = \lambda$. Thus $A = \mathbf{C} \cdot 1 \cong \mathbf{C}$.
\end{proof}

The real case is much more complicated. There are three Banach division algebras over the real numbers, namely $\mathbf{R}$, $\mathbf{C}$, and $\mathbf{Q}$ (the quaternions), and it is much more difficult to show that these are the only three.

\begin{theorem}
    If $A$ is a Banach algebra for which $M$ exists such that
    %
    \[ \| x \| \| y \| \leq M \| x y \| \]
    %
    for all $x,y \in \mathbf{C}$, then $A$ is isometric to $\mathbf{C}$.
\end{theorem}
\begin{proof}
    Let $y \in \partial GL(A)$. Then there are $y_i \to y$ with $y_i \in GL(A)$. Thus $\| y_i^{-1} \| \to \infty$. But since
    %
    \[ \| y_i \| \| y_i^{-1} \| \leq M \]
    %
    we must have $\| y_i \| \to 0$, so $y = 0$. Suppose $z \not \in GL(A)$. Consider the line between $z$ and 1. Consider
    %
    \[ \lambda = \inf \{ \gamma \in [0,1] : \gamma + (1 - \gamma) z \in GL(A) \} \]
    %
    then $\gamma + (1 - \gamma) z \in \partial GL(A)$, so $\gamma + (1 - \gamma) z = 0$, and since $\gamma \neq 1$ (since $GL(A)$ is open), we conclude $z = \gamma/(1-\gamma)$, and since $z$ is not invertible, we must have $z = 0$. Thus $A$ is a division algebra, so $A$ is isometric to $\mathbf{C}$.
\end{proof}

\begin{theorem}
    $\sigma$ is `continuous', in the sense that for any open set $U \subset \mathbf{C}$ containing $\sigma(M)$, there is an open neighbourhood $V$ of $M$ such that if $N \in V$, $\sigma(N) \subset U$.
\end{theorem}
\begin{proof}
    The map $\lambda \mapsto \| (\lambda - M)^{-1} \|$ is a bounded continous function in $U^c$, with some bound $K$. If $\| N \| < 1/K$, and $\lambda \in U^c$, then
    %
    \[ \lambda - (M + N) = (\lambda - M)(1 - (\lambda - M)^{-1}N) \]
    %
    is invertible, since $(\lambda - M)$ is invertible, since $\| (\lambda - M)^{-1} N \| < 1$. It follows that $\sigma(M + N) \subset U$.
\end{proof}

\section{Spectral Radii}

The \emph{spectral radius} of an element $M \in A$ is defined to be
%
\[ r(M) = \sup \{ |\lambda| : \lambda \in \sigma(M) \} \]
%
It bounds where to look for the spectrum of $M$ occurs. What is amazing is that we can define the spectral radius without any algebraic reference; this is crazy, since if we enlarge our Banach algebra, more elements become invertible, and thus the spectrum shrinks in size. The radius formula says that there still exists points on the boundary of the spectrum.

\begin{lemma}
    Let $M \in A$, $n \in \mathbf{N}$. Then, if $\lambda \in \sigma(M)$, $\lambda^n \in \sigma(M^n)$.
\end{lemma}
\begin{proof}
    Suppose $\lambda \in \sigma(M)$. Then
    %
    \[ \lambda^n - M^n = (\lambda - M) \left(\sum \lambda^{n-1-k} M^k \right) = \left(\sum \lambda^{n-1-k} M^k \right) (\lambda - M) \]
    %
    If $\lambda - M$ was invertible, then $\lambda^n - M^n$ would also be invertible.
\end{proof}

\begin{theorem}[Spectral Radius Theorem]
    \[ r(M) = \lim_{n \to \infty} \| M^n \|^{1/n} \]
\end{theorem}
\begin{proof}
    If $\lambda \in \sigma(M)$, then $\lambda^n \in \sigma(M^n)$, and therefore by Neumann's lemma, $|\lambda|^n \leq \| M^n \|$. We conclude
    %
    \[ |\lambda| \leq \| M^n \|^{1/n} \]
    %
    taking extrema,
    %
    \[ r(M) = \sup_{\lambda \in \sigma(M)} |\lambda| \leq \liminf_{n \to \infty} \|M^n\|^{1/n} \]
    %
    Set $R = r(M)^{-1}$ (which can be $\infty$, if $r(M) = 0$), and $r = \|M\|^{-1}$. Let $\lambda$ be a complex number with modulus less than $R$. Then $1/|\lambda| > r(M)$, so $1 - \lambda M \in GL(A)$. If $\phi \in A^*$, define
    %
    \[ f: \lambda \mapsto \langle \phi, (1 - \lambda M)^{-1} \rangle \]
    %
    Then $f$ is holomorphic in the disk of radius $R$. If $|\lambda| < r$, then $\| \lambda M \| < 1$, $1 - \lambda M \in GL(A)$, and
    %
    \[ \phi \left( (1 - \lambda M)^{-1} \right) = \sum_{k = 0}^\infty \phi( \lambda^k M^k) \]
    %
    power series expansions are unique, hence this expansion should work in the whole disk of radius $R$. But $\phi$ was arbitrary, so the sequence $\lambda^k M^k$ must be bounded, by Banach Steinhaus. If $\lambda$ is fixed, then there is $C$ such that
    %
    \[ |\lambda^n| \|M^n\| \leq C \]
    %
    for all $n$, so
    %
    \[ \|M^n\|^{1/n} \leq \frac{C^{1/n}}{|\lambda|} \]
    %
    Hence
    %
    \[ \limsup_{n \to \infty} \|M^n\|^{1/n} \leq \lim_{n \to \infty} \frac{C^{1/n}}{\lambda} = \frac{1}{\lambda} \]
    %
    Letting $\lambda \to R$, we obtain that $\limsup \|M^k\|^{1/k} \leq r(a)$. We have shown
    %
    \[ \liminf \|M^k\|^{1/k} \geq r(M) \geq \limsup \|M^k\|^{1/k} \]
    %
    from which the theorem follows.
\end{proof}

\begin{corollary}
    The spectral radius of a Banach algebra element is invariant of which Banach algebra the element is in. If $B$ is a Banach subalgebra of $A$, with $M \in B$, then $r_{A}(M) = r_B(a)$.
\end{corollary}

\begin{example}
    We can isometrically embed $A(\mathbf{D})$ in $C(\mathbf{T})$ via the map $f \mapsto f|_\mathbf{T}$, so that we may view $A(\mathbf{D})$ as a closed subspace of $C(\mathbf{T})$. These properties follows simply from the maximum modulus principle. Let $z: \mathbf{T} \to \mathbf{C}$ be the identity map. Then
    %
    \[ \sigma_{A(\mathbf{D})}(z) = \mathbf{D} \supsetneqq \mathbf{T} = \sigma_{C_0(\mathbf{T})}(z|_\mathbf{T}) \]
    %
    while the spectrum are different, the spectral radius is the same. Note that enlarging the spectrum in this way is the \emph{only} possible change one can have in the spectrum, since we have to add a connected component of the resolvent when enlarging the algebra, and the interior of the unit disk is the only bounded connected component of the resolvent.
\end{example}

\begin{corollary}
    If $A$ is a $C^*$ algebra, and $M \in A$ is normal, then $r(M) = \| M \|$.
\end{corollary}
\begin{proof}
    We calculate that
    %
    \[ \| M^2 \| = \| (M^*)^2 M^2 \|^{1/2} = \| (M^* M) (M^* M)^* \|^{1/2} = \| M^* M \| = \| M \|^2. \]
    %
    More general, by induction we can prove that
    %
    \[ \| M^{2^n} \| = \| M \|^{2^n}. \]
    %
    But this means that
    %
    \[ r(M) = \lim_{n \to \infty} \| M^{2^n} \|^{1/2^n} = \| M \|. \]
    %
    Since $r(M)$ is defined completely algebraically, without any reference to the norm of $A$, this shows $\| M \|$ depends solely on the algebraic structure of $A$.
\end{proof}

\begin{corollary}
    Every $C^*$ algebra $A$ has a unique norm making it a $C^*$ algebra.
\end{corollary}
\begin{proof}
    For any $M \in A$, $M^* M$ is self-adjoint, so
    %
    \[ \| M \|^2 = \| M^*M \| = r(M^*M). \]
    %
    Thus the norm of $M$ is defined by the algebraic structure of $A$.
\end{proof}

\section{Bounded Approximate Identities}

We may not have an identity in a non-unital Banach algebra, but we may be able to `approximate' an identity in some sense. An \emph{approximate identity} for an algebra $A$ is a net $\{ E_\alpha \}$ such that for any $N \in A$,
%
\[ \lim E_\alpha N = N\ \ \ \ \ \ \ \ \lim N E_\alpha = N \]
%
Nets for which one of these equations hold are known as \emph{left} or \emph{right} approximate identities. A \emph{bounded approximate identity} is an approximate identity for which $\sup \| E_\alpha \| < \infty$.

\begin{example}
    Let $X$ be locally compact and Hausdorff. The set of all compact subsets is a directed, exhausting set. Using Urysohn's lemma, find $f_K$, for each compact $K$, such that $f_K |_K = 1$, and $\| f_K \|_\infty \leq 1$. Fix $g \in C_0(X)$. Pick $K$ such that $|g| \leq \varepsilon$ outside of $K$. Then, in $K$, $|f_K g - g| = 0$, and outside of $K$, $|f_K g - g| < 2 \varepsilon$. Thus $\| f_K g - g \|_\infty < 2 \varepsilon$. Thus $\lim_{K \to \infty} f_K g = g$, and so $\{ f_K \}$ is a bounded approximate identity in $C_0(X)$.
\end{example}

\begin{example}
    Consider the net $P_r(z) = \sum_\mathbf{Z} r^{|n|} z^n$ in the group algebra $L^1(S^1)$, for $0 < r < 1$. Given a continuous function $g$, it is well known that $(P_r * g) \to g$ uniformly. Since, for any $g \in L^1(S^1)$, $\| P_r * g \|_{L^1} \lesssim \| g \|_{L^1}$, uniformly in $r$, it follows that $g * P_r \to g$ in $L^1(S^1)$ for any $g \in L^1(S^1)$. Thus $\{ P_r \}$ is a bounded approximate identity.
\end{example}

\begin{example}
    Bounded approximate identities appear in advanced Banach space theory. For instance, they arise in the study of compact operators. Let $X$ be a Banach space, and let $A(X)$ be the closure of the family of all bounded finite rank operators on $X$. Then $A(X)$ is a right ideal in $B(X)$ contained in $K(X)$, the subalgebra of compact operators on $X$. We say $X$ has the \emph{approximation property} if $K(X) = A(X)$, i.e. all compact operators can be approximated in the operator norm by finite rank operators. We say $X$ has the \emph{bounded approximation property} if there exists a family of uniformly bounded finite rank operators $\{ E_\alpha \}$ converging pointwise to the identity map on $X$. Under these assumptions, it then follows that the family $\{ E_\alpha \}$ actually converges \emph{uniformly} on compact subsets of $X$, from which it follows that for any compact operator $T \in K(X)$, $E_\alpha T$ is a family of finite rank operators converging in the operator topology to $T$. Thus if $X$ has the bounded approximation property, then $X$ has the approximation property. If a Banach space is reflexive, it is a result of Grothendieck that a space has the bounded approximation property if and only if $A(X) = K(X)$, i.e. all compact operators on $X$ can be approximated by finite rank operators. We claim that $X$ has the bounded approximation property if and only if $A(X)$ has a bounded left approximate identity.

    If $X$ has the bounded approximation property, and $\{ E_\alpha \}$ are the uniformly bounded, finite rank operators converging uniformly to the identity on compact subsets of $X$, then it is simple to see that for any finite rank operator $T: X \to X$, $E_\alpha T$ converges in the operator norm to $T$. Indeed, if $Y$ is the finite dimensional image of $T$, and $B_Y$ is the closed unit ball in $Y$, then $B_Y$ is compact, so $E_\alpha$ converges to the identity uniformly on $B_Y$, so $E_\alpha|_Y$ converges in the norm topology to $\text{id}|_Y$, and thus means that
    %
    \[ \| E_\alpha T - T \|_{B(X)} = \| (E_\alpha - 1) T \|_{B(X)} \leq \| E_\alpha - 1 \|_{B(Y)} \| T \|_{B(X)} \to 0. \]
    %
    A density argument shows the same is true for any $T \in A(X)$, so $\{ E_\alpha \}$ is a bounded approximate identity for $A(X)$.

    Conversely, suppose $\{ E_\alpha \}$ is a bounded left approximate identity for $A(X)$. Without loss of generality, by a density argument we may assume each $E_\alpha$ is of finite rank. For each $x_0 \in X$, and $\phi_0 \in X^*$, the operator $x_0 \otimes \phi_0: X \to X$ defined by setting
    %
    \[ (x_0 \otimes \phi_0)(x) = \phi(x) \cdot x_0 \]
    %
    is clearly a finite rank operator. Thus we conclude that $E_\alpha (x_0 \otimes \phi_0)$ converges to $x_0 \times \phi_0$ in $B(X)$. But this means that
    %
    \[ |\phi_0(x)| \| E_\alpha x_0 - x_0 \| = o \left( \| x \| \right). \]
    %
    But this clearly means that $\| E_\alpha x_0 - x_0 \| \to 0$. Thus $\{ E_\alpha \}$ is a uniformly bounded family of operators converging pointwise to the identity, so $X$ has the bounded approximation property.

    Finding a Banach space without the approximation property proved to be a very challenging problem in 20th century mathematics. For instance, if $H$ is a Hilbert space, then $B(H)$ always has the bounded approximation property (consider the bounded approximate identity given by orthogonal projections onto finite dimensional subspaces), as do the classical sequence spaces $c_0$ and $l_p$. The problem of proving or disproving that all Banach spaces have the approximation property was proposed by Stanislaw Mazur in 1936, promising a reward of a live goose as a prize for the solution to this problem. Forty years later, the problem was solved by the Swedish mathematician Per Enflo in 1972, who finally recieved a live goose as a reward.
\end{example}

\begin{example}
    Let $X$ be a Banach space with the bounded approximation property. Let $\{ T_\alpha \}$ be a bounded net. If $S$ is a compact operator, then $S(\overline{B_X})$ is precompact, and
    %
    \[ \| T_\alpha S - S \| = \sup \{ \| T_\alpha Sx - Sx \| : x \in B_X \} \leq \sup \{ \| T_\alpha y - y \| : y \in \overline{S(B_X)} \} \]
    %
    The right side is the supremum over a compact set, and since $\{ T_\alpha \}$ uniformly tends to the identity on compact sets, $\| T_\alpha S - S \| \to 0$. This shows $\{ T_\alpha \}$ is a bounded left approximate identity, and that $A(X) = K(X)$.

    Now suppose $A(X)$ has a bounded left approximate identity $\{ T_\alpha \}$. Without loss of generality, we may assume each $T_\alpha$ is of finite rank, because if we choose, for each $\alpha$, a bounded net $W_{\alpha, \beta}$ of finite rank operators such that $\lim_\beta W_{\alpha, \beta} = T_\alpha$, then $\{ W_{\alpha, \beta} \}$ is a bounded left approximate identity. For $x \in X$, $\phi \in X^*$, let $x \otimes \phi : X \to X$ be defined by $(x \otimes \phi)(y) = \phi(y) x$. Then $x \otimes \phi$ obviously has finite rank. Pick $y$ for which $\langle \phi, y \rangle = 1$. Then
    %
    \[ \| T_\alpha x - x \| = \| T_\alpha (x \otimes \phi)(y) - (x \otimes \phi)(y) \| \leq \| y \| \| T_\alpha (x \otimes \phi) - (x \otimes \phi) \| \to 0 \]
    %
    So the nets converge pointwise, which implies convergence on compact sets. To summarize, $X$ has the bounded approximxation property if and only if $A(X)$ has a bounded left approximate identity if and only if $K(X)$ has a bounded left approximate identity belonging to $A(X)$.
\end{example}

\begin{lemma}
    If a space has the bounded left and right approximation properties then it has the two sided approximation property.
\end{lemma}
\begin{proof}
    Let $\{ M_\alpha \}$ be a left approximation identity, and $\{ N_\beta \}$ a right approximation identity. We contend $\{ M_\alpha + N_\beta - M_\alpha N_\beta \}$ is a two sided approximator. The limits below certainly converge, and the iterated limits must therefore equal the convergent factor, which is
    %
    \[ \lim_\alpha \lim_\beta L(M_\alpha + N_\beta - M_\alpha N_\beta) = \lim_\alpha LM_\alpha + L - LM_\alpha = L \]
    %
    \[ \lim_\beta \lim_\alpha (M_\alpha + N_\beta - M_\alpha N_\beta)L = \lim_\beta L + N_\beta L - N_\beta L = L \]
    %
    So twe have a two sided approximator.
\end{proof}

Before the logician Paul Cohen got into logic, he was a functional analyst who contributed to the theory of approximation identities. We shall prove the theorem he contributed to the field, generalized to work over arbitrary modules. Let $A$ be a Banach algebra. A \emph{left Banach $A$-module} is a Banach space $X$, which is a module over $A$, such that for any $M \in A$, and $x \in X$,
%
\[ \| Mx \| \leq \| M \| \| x \| \]
%
This makes the module operations continuous. As with Banach algebras, if module operations are continuous, then a Banach space can be made into a Banch $A$-module.

Now if $A$ is a unital Banach algebra, and $X$ is a left Banach $A$-module, then every $x \in A$ can be trivially written as $My$ for some $M \in A$ (just choose $M$ to be the identity). If $A$ is a non-unital Banach algebra, and $x \in \overline{A X}$, then we can write $x$ approximately as $My$. Cohen found that in an algebra with a bounded left approximate identity, we have $AX = \overline{AX}$, i.e. we can write $x$ precisely as $My$ for some $M \in A$ and $y \in X$.

\begin{theorem}[Cohen's Factorization Theorem]
    Let $A$ be a Banach algebra with a bounded left approximation identity $\{ E_\alpha \}$, bounded by some quantity $R > 0$. If $X$ is a Banach $A$-module, let $x \in \overline{AX}$, and let $\varepsilon > 0$. Then there is $M \in A$ with $\| M \| \leq R$, $y \in \overline{AE}$ with $\| y - x \| < \varepsilon$, for which $x = My$.
\end{theorem}
\begin{proof}
    If $A$ has an identity, then the proof is trivial. Since $\overline{AX}$ is a closed subset of $X$, we might as well assume $\overline{AX} = X$. We may extend $X$ to be an module over $A^\#$, by defining
    %
    \[ (M + \lambda) x = Mx + \lambda x \]
    %
    Pick $\lambda > 0$ small enough such that
    %
    \[ 0 < \frac{\lambda}{1 - \lambda} K < 1 \]
    %
    Define a net $\{ L_\alpha \}$ in $A^\#$ by letting
    %
    \[ L_\alpha = \lambda E_\alpha + (1 - \lambda) = (1 - \lambda) \left( 1 + \frac{\lambda}{1 - \lambda} E_\alpha \right) \]
    %
    Then $L_\alpha N \to N$ for all $N \in A$, so $\{ L_\alpha \}$ is a BLAI, and each $L_\alpha$ is invertible in $A^\#$ by the choice of $\lambda$, so
    %
    \[ L_\alpha^{-1} = \frac{1}{1 - \lambda} \sum_{k = 0}^\infty \left(- \frac{\lambda}{1 - \lambda} L_\alpha \right)^k \]
    %
    which implies
    %
    \begin{align*}
        \| L_\alpha^{-1} N - N \| &= \| L_\alpha^{-1} N - L_\alpha^{-1} L_\alpha N \| \leq \| L_\alpha^{-1} \| \| N - L_\alpha N \|\\
        &\leq \left( \frac{1}{1 - \lambda} \sum_{k = 0}^\infty \left( \frac{\lambda K}{1 - \lambda} \right)^k \right) \| N - L_\alpha N \| \to 0
    \end{align*}
    %
    Therefore $L_\alpha^{-1}$ is also a BLAI. Fix $x \in X$, and let
    %
    \[ \delta < 1, \frac{\varepsilon}{2 + \|x\|} \]
    %
    We will inductively construct a sequence $\alpha_n$ of indices such that the sequence $\{ L_{\alpha_n} \dots L_{\alpha_1} \}$ and $\{ L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} \}$ are convergent subnets. Choose $\alpha_1$ such that
    %
    \[ \| L_{\alpha_1}^{-1} x - x \| < \delta/2 \]
    %
    If $\alpha_1, \dots, \alpha_n$ has been chosen. There is a unique element $T_n \in A$ such that
    %
    \[  L_{\alpha_n} \dots L_{\alpha_1} = (1 - \lambda)^n + T_n \]
    %
    Pick $\alpha_{n+1}$ such that
    %
    \[ \| L_{\alpha_{n+1}} x - x \| < \frac{\delta}{\| L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} \| 2^{n+2}}\ \ \ \ \ \ \ \ \ \ \| L_{\alpha_{n+1}} T_n - T_n \| < 1/2^n \]
    %
    Then
    %
    \[ \| L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} L_{\alpha_{n+1}}^{-1} x - L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} x \| \leq \| L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} \| \| x - L_{\alpha_{n+1}}^{-1} x \| < \frac{\delta}{2^{n+2}} \]
    %
    This implies $\lim_{n \to \infty} L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} x = y$ exists, and
    %
    \begin{align*}
    \| y - x \| &= \left\| \sum_{n = 0}^\infty (L_{\alpha_1}^{-1} \dots L_{\alpha_{n+1}^{-1}} x - L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} x) \right\|\\
    &\leq \sum_{n = 0}^\infty \| L_{\alpha_1}^{-1} \dots L_{\alpha_{n+1}^{-1}} x - L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} x \| < \sum_{n = 0}^\infty \frac{\delta}{2^{n+2}} < \delta/2
    \end{align*}
    %
    By construction,
    %
    \[ L_{\alpha_{n+1}} (L_{\alpha_n} \dots L_{\alpha_1}) = (1 - \lambda)^n L_{\alpha_{n+1}} + L_{\alpha_{n+1}} T_n \]
    %
    Thus
    %
    \begin{align*}
        \| L_{\alpha_{n+1}} L_{\alpha_n} \dots L_{\alpha_1} - L_{\alpha_n} \dots L_{\alpha_1} \| &= \| (1 - \lambda)^n L_{\alpha_{n+1}} + L_{\alpha_{n+1}} T_n - T_n - (1-  \lambda)^n \|\\
        &\leq (1 - \lambda)^n \| L_{\alpha_{n+1}} - 1 \| + \frac{1}{2^n}
    \end{align*}
    %
    Thus $L_{\alpha_n} \dots L_{\alpha_1}$ converge to some element $M$. Since $A$ is closed in $A^\#$, $M \in A$, and moreover,
    %
    \[ x = \lim_{n \to \infty} (L_{\alpha_1} \dots L_{\alpha_n}) (L_{\alpha_1}^{-1} \dots L_{\alpha_n}^{-1} x) = My \]
    %
    Also, observe that
    %
    \begin{align*}
        T_{n+1} &= L_{\alpha_{n+1}} \dots L_{\alpha_1} - (1 - \lambda)^{n+1}\\
        &= L_{\alpha_{n+1}} T_n + L_{\alpha_{n+1}} (1 - \lambda)^n - (1 - \lambda)^{n+1}\\
        &= L_{\alpha_{n+1}} T_n + (1 - \lambda)^n \lambda e_{\alpha_{n+1}}
    \end{align*}
    %
    Thus
    %
    \[ \| T_{n+1} - T_n \| = \| (L_{\alpha_{n+1}} T_n - T_n + (1 - \lambda)^n \lambda e_{\alpha_{n+1}} \| \leq 1/2^n + (1 - \lambda)^n \lambda K \]
    %
    Since $M = \lim T_n$,
    %
    \[ \| M \| \leq \| T_1 \| + \left(\sum_{n = 1}^\infty (1 - \lambda)^n \lambda K \right) + \delta \leq \lambda K + (1 - \lambda) K + \delta = K + \delta \]
    %
    Let $M' = \frac{K}{K + \delta} M$, $y' = \frac{K + \delta}{K} y$. Then $M'y' = My = x$, and by the choice of $\delta$ (kept hidden all this time),
    %
    \[ \| x - y' \| \leq \frac{\| Kx - Ky \| + \| \delta y \|}{K} < \delta + \delta \| x \| + \delta^2 \leq \delta(2 + \|x\|) = \varepsilon \]
    %
    And we have verified what was needed.
\end{proof}

\begin{corollary}
    If $A$ is a Banach algebra with a bounded left approximate identity, then each $M \in A$ may be written $M = NL$, with $N,L \in A$.
\end{corollary}

Thus, for instance, for any locally compact group $G$, since $L^1(G)$ has an approximate identity, any $f \in L^1(G)$ can be written as $f = g * h$ for some $g,h \in L^1(G)$. Moreover, for any $\varepsilon > 0$, we can pick $g$ and $h$ such that $\| g \|_{L^1(G)} \leq 1$, and $\| f - h \|_{L^1(G)} < \varepsilon$, or vice versa.

\begin{corollary}
    Let $A$ be a Banach algebra with a BLAI, and let $\{ M_n \}$ be a sequence in $A$ converging to 0. Then there is $M \in A$ and $\{ N_m \}$ in $A$ tending to zero such that $M_k = M N_k$.
\end{corollary}
\begin{proof}
    Let $X$ be the set of all sequences in $A$ that converge to zero, with the $\| \cdot \|_\infty$ norm. Then $X$ is a left $A$ module, and $X = \overline{AX}$, since $A$ has a BLAI. Applying Cohen's theorem, we find that we may write
    %
    \[ (M_1, M_2, \dots) = M (N_1, N_2, \dots) \]
    %
    hence $M_i = M N_i$ for each $i$.
\end{proof}






\section{The Holomorphic Functional Calculus}

Given a polynomial $P(x) = \sum a_i x^i$, a Banach algebra $A$, and $M \in A$, it is natural to overload the definition of $P$ by setting $P(M) = \sum a_i M^i$. This does not really require any topological info about $A$. In this section, we use this topology to extend this so that we can consider $f(M)$, for a large family of analytic functions $f$. As a basic example of this, in matrix theory it is useful to define the exponential of $M \in A$ by
%
\[ e^M = \sum_{k = 0}^\infty \frac{M^k}{k!} \]
%
We may define $\sin(M)$ and $\cos(M)$ similarily. More generally, for any power series $f = \sum_{k = 0}^\infty c_k (X - \alpha)^k$ with a radius of convergence $R$, we may define
%
\[ f(M) = \sum_{k = 0}^\infty c_k (M - \alpha)^k \]
%
And this function is defined for any $M$ satisfying $\|M - \alpha \| < R$. For analytic functions not given in a power series representation, it is non-trivial to define them for elements of a Banach algebra, but very useful.

To do this, we utilize the Cauchy integral formula
%
\[ f(w) = \frac{1}{2\pi i} \int_\gamma \frac{f(z)}{z - w} \; dz, \]
%
where $\gamma$ is a simple positively oriented curve containing $w$ in it's interior. We use this formula to overload the function $f$. Given a Banach algebra $A$ containing an element $M$, a domain $\Omega \subset \CC$ containing $\sigma(M)$, an analytic function $f: \Omega \to A$, and a positively oriented curve $\gamma$ containing $\sigma(M)$ in it's interior, we define
%
\[ f(M) = \frac{1}{2 \pi i} \int_\gamma f(z) (z - M)^{-1}\; dz. \]
%
The right hand side is a vector-valued integral, whose integrand is smooth on it's compact domain. Thus we can define this integral using Riemann sums (i.e. using the \emph{Bochner integral}). We can reduce the study of such quantities to standard complex contour integrals by the fact that for any linear functional $\Lambda: A \to \CC$,
%
\[ \Lambda \left( \frac{1}{2 \pi i} \int_\gamma f(z) (z - M)^{-1}\; dz \right) = \frac{1}{2 \pi i} \int_\gamma \Lambda \left( f(z) (z - M)^{-1} \right)\; dz. \]
%
In particular, it follows from such a reduction that $f(M)$ is actually independent of the contour $\gamma$ used. We have thus laid the foundations for the holomorphic functional calculus.

\begin{theorem}
    The map $f \mapsto f(M)$ is the unique algebra homomorphism from the algebra $\mathcal{O}(\sigma(M))$ into $A$ extending the evaluation of polynomials, and which is continuous under the topology of locally uniform convergence.
\end{theorem}
\begin{proof}
    If the integrands of a Bochner integral converge uniformly, then the integrals converge. This gives continuity of the map $f \mapsto f(M)$. The map $f \mapsto f(M)$ is obviously linear. Next, we show that for any polynomial $f$, and any contour integral $\gamma$ around $\sigma(M)$,
    %
    \[ f(M) = \frac{1}{2 \pi i} \int_\gamma f(z) (z - M)^{-1}\; dz. \]
    %
    By linearity, we may assume $f(z) = z^k$. We may assume our contour is large enough that $\| (z - M)^{-1} \| < 1$ on $\gamma$. Then
    %
    \begin{align*}
        \frac{1}{2 \pi i} \int_\gamma z^n (z - M)^{-1} dz &= \frac{1}{2 \pi i} \int_\gamma z^{n-1} \sum_{k = 0}^\infty \frac{M^k}{z^k} dz\\
        &= \frac{1}{2 \pi i} \sum_{k = 0}^\infty M^k \int_\gamma z^{n - 1 - k} dz = M^n,
    \end{align*}
    %
    since $\int_\gamma z^{n-1-k} dz \neq 0$ only when $n - 1 - k = -1$ ($n = k$). Now we need to show the multiplicity of the evaluation map. This is done by brute calculation. Let $f,g \in \mathcal{O}(D)$ be given. Pick $\gamma$ be as required, and consider another $\tilde{\gamma}$ satisfying $\text{Int}\ \tilde{\gamma} \supset \overline{\text{Int}\ \gamma}$, $\mathbf{C} - D \subset \text{ext}\ \tilde{\gamma}$. Then
    %
    \begin{align*}
        f(M) g(M) &= \frac{-1}{4 \pi^2} \left( \int_\gamma f(z) (z - M)^{-1} dz \right) \left( \int_{\tilde{\gamma}} g(w) (w - M)^{-1} \right)\\
        &= \frac{-1}{4 \pi^2} \int_\gamma \int_{\tilde{\gamma}} f(z) g(w) (z - M)^{-1} (w - M)^{-1} dw\ dz\\
        &= \frac{-1}{4 \pi^2} \int_\gamma \int_{\tilde{\gamma}} f(z) g(w) \left( \frac{1}{w - z} \left((z - M)^{-1} - (w - M)^{-1} \right) \right) dw\ dz\\
        &= \frac{-1}{4 \pi^2} \int_\gamma f(z) \left( \int_{\tilde{\gamma}} \frac{g(w)}{w - z} dw \right) (z - M)^{-1} dz\\
        &\ \ \ + \frac{1}{4 \pi^2} \int_{\tilde{\gamma}} g(w) \left( \int_\gamma \frac{f(z)}{w - z} dz \right) (w - M)^{-1} dw\\
        &= \frac{1}{2 \pi i} \int_\gamma f(z) \left( \frac{1}{2 \pi i} \int_{\tilde{\gamma}} \frac{g(w)}{w - z} dw \right) (z - M)^{-1} dz\\
        &= \frac{1}{2 \pi i} \int_\gamma f(z) g(z) (z - M)^{-1} dz\\
        &= (fg)(M)
    \end{align*}
    %
    and thus we have an algebra homomorphism.

    Finally, we prove uniqueness. This would be trivial if $\Omega = \mathbf{C}$, since all functions are limits of polynomials. More generally, we apply Runge's theorem, which says that for any compact set $K$, if $S$ is a set containing at least one point from each bounded connected component of $\CC - K$, then every analytic function on $K$ is the uniform limit of a family of rational functions with poles solely in $S$. Now suppose $\Lambda: \mathcal{O}(\sigma(M)) \to A$ is another homorphism satisfying the properties above. Then for any two polynomials $P$ and $Q$, such that the zeroes of $Q$ are disjoint from $\sigma(M)$, $1/Q \in \mathcal{O}(\sigma(M))$, and so $\Lambda(1/Q) = \Lambda(Q)^{-1}$. Thus we calculate that
    %
    \[ \Lambda(P/Q) = \Lambda(P) \Lambda(1/Q) = \Lambda(P) \Lambda(Q)^{-1} = P(M) Q(M)^{-1} = (P/Q)(M). \]
    %
    Thus $\Lambda$ agrees with the holomorphic functional calculus on rational functions, which shows $\Lambda(f) = f(M)$ for all $f \in \mathcal{O}(\sigma(M))$ by continuity and Runge's theorem.
\end{proof}

\begin{example}
    Let $K$ be compact, and let $f \in C(K)$. Let $\Omega$ be an open neighbourhood of $\sigma(f) = f(K)$. Consider the map from $\mathcal{O}(\Omega) \to C(K)$ mapping $g$ to $g \circ f$. This map satisfies the properties of the holomorphic functional calculus, so it really is the holomorphic calculus in disguise.
\end{example}

\begin{theorem}
    Let $F: A \to B$ be a homomorphism between two Banach algebras, and suppose $M \in A$. Then $\sigma(F(M)) \subset \sigma(M)$, and if $g$ is holomorphic in a neighbourhood of $\sigma(M)$, then $(g \circ F)(M) = (F \circ g)(M)$.
\end{theorem}
\begin{proof}
    That $\sigma(f(M)) \subset \sigma(M)$ is trivial, for if $\alpha - M$ is invertible, then $f(\alpha - M) = \alpha - f(M)$ is invertible. If $g$ is a polynomial, then the theorem follows from the multiplicative property. But then the theorem is true for limits of polynomials, and hence for all $g$.
\end{proof}

The ultimatum of the holomorphic functional calculus is the proof of the spectral mapping theorem, that asserts that the `operation' of the spectrum commutes with holomorphic functions. To extend this theorem to non-commutative algebras, we need an algebraic trick. We introduce the center $Z(A)$ of an algebra, which is defined exactly how it is defined in all other algebraic structures. It is a closed subalgebra of $A$, for if $M_i \to M$, and each $M_i \in A$, then
%
\[ MN = \lim M_iN = \lim NM_i = NM \]
%
If $S$ is a subset of $A$, then we may consider
%
\[ Z(S) = \{ M \in A : (\forall N \in S: MN = NM) \} \]
%
which is a commutative subalgebra of $A$. For any subset $S$, the double centralizer $Z(Z(S))$ also contains $S$. $Z(Z(S))$ is commutative if $S \subset Z(S)$, for then $Z(Z(S)) \subset Z(S)$, and thus commutes with itself by definition.

Now consider the commutative subalgebra $B = Z(Z(\{ M \}))$ of an algbera $A$. If $\lambda - M$ is invertible in $A$, there is $N = (\lambda - M)^{-1}$. But then if $K \in Z(\{ M \})$, then $K$ commutes with $\lambda - M$, and
%
\[ KN = N(\lambda - M) K N = NK (\lambda - M) N = NK \]
%
which implies that $\lambda - M$ is invertible in $Z(Z(\{M\}))$, so $\sigma_A(M) = \sigma_B(M)$.

\begin{theorem}[Spectral Mapping Theorem]
    If $\sigma(M) \subset \Omega$, where $\Omega$ is open, and $f \in \mathcal{O}(\Omega)$, then $\sigma(f(M)) = f(\sigma(M))$.
\end{theorem}
\begin{proof}
    First, suppose $A$ is commutative. By Gelfand theory,
    %
    \[ \sigma(f(M)) = \widehat{f(M)}(\Phi_A) = f(\widehat{M}(\Phi_A)) = f(\sigma(M)) \]
    %
    If $A$ is not commutative, consider the commutative subalgebra
    %
    \[ B = Z(Z(\{M\})). \]
    %
    If $f$ is analytic in a neighbourhood of $\sigma_A(M)$, then $f(M) \in B$, for there is surely a homomorphism from analytic functions in a neighbourhood of $\sigma_A(M)$ into $B$, and the embedding of $B$ in $A$ produces the unique homomorphism required. Thus we have justified the computation
    %
    \[ \sigma_A(f(M)) = \sigma_B(f(M)) = f(\sigma_B(M)) = f(\sigma_A(M)) \]
    %
    and the spectral mapping theorem is proved in general.
\end{proof}

The holomorphic functional calculus is incredibly useful for it allows us to apply calculations on the complex plane to arbitary algebras. Here are some immediate uses.

\begin{theorem}
    Suppose $A$ is a Banach algebra, $M \in GL(A)$, and $\sigma(M)$ does not separate the origin from $\infty$. Then
    %
    \begin{itemize}
        \item For each $m$, there is $N$ such that $M = N^m$. If $\sigma(M) \subset \RR^+$, then we may choose the $N$ such that $\sigma(N) \subset \mathbf{R}^+$.
        \item There is $N$ such that $M = e^N$.
        \item if $B$ is the closed subalgebra of $A$ generated by $M$, then $M^{-1} \in B$.
    \end{itemize}
\end{theorem}
\begin{proof}
    By assumption, we may choose a branch $f(z)$ of $z^{1/m}$ which is holomorphic on a neighborhood of $\sigma(M)$, and if $\sigma(M) \subset \mathbf{R}^+$, we may choose $f(z)$ to be the principal branch. Thus we can define $N = f(M)$. Since $f^m(z) = z$ for all $z$ on a neighborhood of $\sigma(M)$, it follows that $N^m = f(M)^n = f^n(M) = M$. The spectral mapping theorem shows that $\sigma(N) = \sigma(f(M)) = f(\sigma(M))$, so if $f$ is the principal branch, and $\sigma(M) \subset \mathbf{R}^+$, then $\sigma(N) \subset \RR^+$. Similar calculations involving the logarithm allow us to define $N$ such that $M = e^N$. Finally, by Runge's theorem, for each $\varepsilon > 0$, we can find a polynomial $f(z)$ such that $|f(z) - 1/z| \leq \varepsilon$ on $\sigma(M)$. Then $\| f(M) - M^{-1} \| \leq \varepsilon$. Taking $\varepsilon \to 0$ gives the final point.
\end{proof}

One can apply this result, for instance, for unitary, or self adjoint elements, of $C^*$ algebras.

\begin{prop}
    In a $C^*$ algebra, if $M$ is unitary, then $\sigma(M) \subset \mathbf{T}$.
\end{prop}
\begin{proof}
    Because $M$ is normal, $r(M) = \| M \| = 1$. But $M^{-1} = M^*$ is also unitary, so $r(M^{-1}) = 1$, and by the spectral mapping theorem,
    %
    \[ \sigma(M^{-1}) = \sigma(M)^{-1} \]
    %
    which implies that both spectra lie on $\mathbf{T}$.
\end{proof}

\begin{prop}
    If $M$ is self-adjoint, then $\sigma(M) \subset \RR$.
\end{prop}
\begin{proof}
    The operator $e^{iM}$ is unitary, for
    %
    \[ e^{-iM} = \sum_{k = 0}^\infty \frac{(-i)^k M^k}{k!} = \sum_{k = 0}^\infty \left( \frac{(iM)^k}{k!} \right)^* = (e^{iM})^* \]
    %
    The spectral mapping theorem implies that $\sigma(e^{iM}) = e^{i \sigma(M)} \subset \mathbf{T}$, which implies $\sigma(M) \subset \mathbf{R}$.
\end{proof}

\begin{corollary}
    Let $A$ be a $C^*$ algebra, and let $B$ be a $C^*$ subalgebra. Then $GL(B) = B \cap GL(A)$.
\end{corollary}
\begin{proof}
    Suppose $N \in B \cap GL(A)$. Then $N^* \in B \cap GL(A)$, for $(N^{-1})^* = (N^*)^{-1}$. Thus $NN^* \in B \cap GL(A)$. Moreover, $NN^*$ is invertible, so $\sigma_A(NN^*) \subset \RR - \{ 0 \}$. Now $\sigma_B(NN^*)$ is obtained by adding bounded connected components of $\rho_A(NN^*)$ to $\sigma_A(NN^*)$, and since $\rho_A(NN^*)$ has no bounded connected components, it follows that $\sigma_B(NN^*) = \sigma_A(NN^*)$. But this means that $NN^* \in GL(B)$. But then $N$ has a right inverse in $B$. By symmetry $N^*N \in GL(B)$, so $N$ has a left inverse in $B$. But if $N$ has a left and right inverse, then $N \in GL(B)$.
\end{proof}

\begin{corollary}
    If $A$ is a $C^*$ algebra, and $B$ is a $C^*$-subalgebra, then for any $M \in B$, $\sigma_A(M) = \sigma_B(M)$.
\end{corollary}

\begin{corollary}
    If $A$ is a $C^*$ algebra, and $M \in GL(A)$ is normal, then $M^{-1}$ is approximable by expressions of the form
    %
    \[ N = \sum_{\alpha, \beta} a_{\alpha \beta} M^\alpha (M^*)^\beta, \]
    %
    i.e. for any $\varepsilon > 0$, we can find $N$ as above such that $\| M^{-1} - N \| \leq \varepsilon$.
\end{corollary}
\begin{proof}
    Let $B$ be the smallest $C^*$ subalgebra of $A$ containing $M$. Then the family of expressions of the form above is dense in $B$. By the result we have just proven, $M \in GL(B)$, and so the result immediately follows.
\end{proof}

Even for finite dimensional matrix algebras, the holomorphic functional calculus has nontrivial repercussions.

\begin{corollary}
    If $M \in GL_n(\mathbf{C})$, then for each $m$, there is $N \in GL_n(\mathbf{C})$ such that $M = N^m$, and there is $N$ such that $M = e^N$.
\end{corollary}

\begin{example}
    Now consider the exponential function $\exp: A \to A$. If $M$ and $N$ commute, it is easy to see from the power series representation that
    %
    \[ \exp(M + N) = \exp(M) \exp(N). \]
    %
    In particular, this implies that $\exp(M)$ is invertible, and $\exp(-M) = \exp(M)^{-1}$. Thus for each $M$, the image of the map
    %
    \[ t \mapsto \exp(tM) \]
    %
    is a one-parameter subgroup of $G(A)$, which gives us a path from the identity $\exp(0)$ to $\exp(M)$. The connected component of $G(A)$ containing the identity is the \emph{principal component}, denoted $G_0(A)$. Since $N \mapsto MNM^{-1}$ is a continuous map leaving the identity fixed, it maps $G_0(A)$ to itself, so $G_0(A)$ is a normal subgroup. The quotient group $G(A)/G_0(A)$ is sometimes called the \emph{index group}.
\end{example}

\begin{theorem}
    If $P(X) = (X - \alpha_1)^{m_1} \dots (X - \alpha_s)^{m_s}$, and $P(M) = 0$, then
    %
    \[ \sigma(M) \subset \{ \alpha_1, \dots, \alpha_n \}, \]
    %
    and if $\Omega$ is an open subset of the plane containing $\alpha_1, \dots, \alpha_n$, then for any $f \in \mathcal{O}(\Omega)$, there is a polynomial $Q$ of degree less than $m_1 + \dots + m_s$, such that $f - Q = gP$, for some $g \in \mathcal{O} (\Omega)$, so $f(M) = Q(M)$.
\end{theorem}
\begin{proof}
    Applying the spectral theorem, we find $\{ 0 \} = \sigma(P(M)) = P(\sigma(M))$, from which the spectrum of $M$ is restricted to lie in the roots of $P$. The Laurent series about each $\alpha_i$ gives constants $c_{it}$ such that
    %
    \[ g(z) = f(z)/P(z) - \sum_{i = 1}^s \sum_{k = 1}^{m_i} \frac{c_{it}}{(z - \alpha_i)^k} \]
    %
    is holomorphic in $\Omega$, and
    %
    \[ gP = f - \sum_{i = 1}^s \sum_{k = 1}^{m_i} c_{it} P (z - \alpha_i)^{-k} \]
    %
    constructing $Q$ with degree less than $n$.
\end{proof}

In non-unital algebras, we cannot evaluate any polynomial of the form $\sum a_i z^i$, since $a_0 \in \mathbf{C}$ does not necessarily have an interpretation in the algebra. If $a_0 = 0$, we can evaluate $\sum a_i z^i$, and thus any holomorphic function $f$, provided $f(0) = 0$. To verify this, one need only use the simple trick of switching from a non-unital algebra $A$ to a unital algebra $A^\#$.

For a Banach space $X$, a weaker version of the spectral mapping theorem applies to the \emph{point spectrum} $\sigma_p(T)$ of bounded operators $T: X \to X$.

\begin{theorem}
    Suppose $T: X \to X$ is a bounded operator, and $f \in \mathcal{O}(\sigma(T))$. Then $f(\sigma_p(T)) \subset \sigma_p(f(T))$, with equality if $f$ is not constant on any connected component of the domain of $f$.
\end{theorem}
\begin{proof}
    Suppose $Tx = \lambda x$. The function $g(z) = (f(z) - f(\lambda)) / (z - \lambda)$ is analytic, and so
    %
    \[ [f(T) x - f(\lambda) x] = [g(T) \circ (T - \lambda)] x = g(T) 0 = 0. \]
    %
    Thus $f(T) x = f(\lambda) x$. Now if $f(T) x = \gamma x$, and $f - \gamma$ does not vanish in any connected component of the domain of $f$, then $f(z) - \gamma$ has finitely many zeroes $\xi_1, \dots, \xi_n$, counted up to multiplicity. Thus the function
    %
    \[ g(z) = \frac{(z - \xi_1) \dots (z - \xi_n)}{f(z) - \gamma} \]
    %
    is analytic and non-vanishing on the domain of $f$, and so
    %
    \[ (T - \xi_1) \dots (T - \xi_n) x = g(T) [f(T) - \gamma] x = 0. \]
    %
    But this means that there is some nonzero $y$ with $(T - \xi_i) y = 0$, and so $\xi_i \in \sigma_p(T)$. Since $f(\xi_i) = \gamma$, this shows that $f(\sigma_p(T)) = \sigma_p(f(T))$ if $f$ is non constant on any connected component of it's domain.
\end{proof}

As mentioned briefly at the beginning of this section, given a non-unital algebra $A$, we extend the concepts of this chapter to elements of $A$ by embedding $A$ in $A^\#$. Thus, for instance, if $M \in A$, then
%
\[ \sigma_A(M) = \{ \lambda : \lambda - M\ \text{is not invertible in $A^\#$} \}. \]
%
The spectral radius formula remains true in this setting, as does the result that $\sigma(M)$ is non-empty (though it is rather trivial in this setting, since $0 \in \sigma(M)$ for any $M \in A$). If $M \in A$, and $f$ is holomorphic on a neighborhood of $\sigma(M)$, then we can define $f(M) \in A^\#$. Moreover, we have $f(M) \in A$ precisely when $f(0) = 0$, because if we consider the continuous linear functional $\Lambda(\lambda + M) = \lambda$ on $A^\#$, then $\Lambda(f(M)) = f(0)$ for any polynomial $f$, and we can apply a density argument. Thus we have a holomorphic functional calculus on $A$ provided we consider only holomorphic functions vanishing at the origin.








\chapter{Gelfand Theory}

Gelfand found a very powerful way of transforming commutative Banach algebras into Banach algebras of continuous functions over a compact space, which generalizes the spectral theory of commuting operators, as well as the Fourier transform. The ingenious trick to Gelfand theory is that one can recover the points in the set $K$ via the algebraic structure of $C(K)$ by studying the maximal ideals of $C(K)$. Thus given a general commutative Banach algebra $A$, we can study the set $K$ of maximal ideals of $A$, equipped this set with a topology, and then consider a natural homomorphism of $A$ into $C(K)$ which has powerful algebraic properties. For reasons which might become clear from the last chapter (the main reason being that the only complex Banach division algebras are fields), in this chapter we solely work over algebras defined on the complex numbers.

\section{Algebra Homomorphisms and Ideals}

Given an algebra $A$ containing an ideal $\IA$, we can consider the quotient ring $A/ \IA$. We can consider left, right, and two-sided ideals, and we'll denote them by gaudy letters such as $\IA$ and $\IB$. If $\IA$ is a \emph{closed} ideal in a Banach algebra, then $A/ \IA$ naturally has the structure of a Banach algebra, equipped with the norm defined, for any coset $S \in A/\IA$,
%
\[ \| S \|_{A/\IA} = \inf_{s \in S} \| s \|_A. \]
%It is simple to see that a proper left ideal cannot contain any left invertible elements, and a right ideal cannot contain any right invertible elements. It is also easy to verify that in a Banach algebra, the closure of any ideal is an ideal. In the commutative case, the quotient of an algebra by a maximal ideal is a field. Furthermore, Zorn's Lemma can be applied to show every left, right, or double sided ideal can be extended to a maximal ideal of the same type.
Ideals are naturally connected with homomorphisms $f: A \to B$ between algebras. Every ideal is the kernel of some homomorphism, and the kernel of every homomorphism is an ideal. Similarily, \emph{closed ideals} in a Banach algebra correspond to continuous homomorphisms. The most tractable homomorphisms to study are the \emph{characters}, homomorphisms from a ring $A$ to $\CC$. In this section, we will deduce their structure.

\begin{lemma}
    Let $A$ be a unital Banach algebra and let $\phi: A \to \CC$ be a character. Then $\| \phi \| \leq 1$.
\end{lemma}
\begin{proof}
    Let $\IA$ be the kernel of $\phi$. Then $\IA$ cannot be all of $A$. Thus $\IA$ does not contain any invertible elements of $A$. If $f(M) = \lambda$, then $\lambda - M \in \IA$, so $\lambda - M \in \sigma(M)$. This means $|\lambda| \leq r(M) \leq \| M \|$.
\end{proof}

\begin{corollary}
    Every character is a continuous linear map.
\end{corollary}

\begin{lemma}
    Every maximal ideal of a unital Banach algebra is closed.
\end{lemma}
\begin{proof}
    Let $\mathfrak{a}$ be a maximal ideal of an algebra $A$. It is easy to show the closure of any ideal is an ideal. It follows that either $\overline{\mathfrak{a}} = \mathfrak{a}$ (so that $\mathfrak{a}$ is closed), or $\mathfrak{a}$ is dense in $A$. Suppose the second option holds. Let $M \in GL(A)$ be chosen. Then there is $M_i \in \mathfrak{a}$ converging to $M$. But then the $M_i$ are eventually invertible, since $GL(A)$ is open, from which we conclude $\mathfrak{a} = A$, a contradiction.
\end{proof}

\begin{corollary}
    If $\mathfrak{a}$ is a maximal ideal in a commutative, unital Banach algebra $A$, then $A/\IA$ is isometric to $\CC$.
\end{corollary}
\begin{proof}
    For then $A/\mathfrak{a}$ is a Banach division algebra.
\end{proof}

Thus it follows that the kernel of every character on a commutative, unital Banach algebra $A$ is a maximal ideal in $A$, and conversely, every maximal ideal corresponds to the kernel of some character. Moreover, this character is uniquely determined.

\begin{lemma}
    If $\phi_1: A \to \CC$ and $\phi_2: A \to \CC$ have the same kernel, then $\phi_1 = \phi_2$.
\end{lemma}
\begin{proof}
    Fix $M \in A$. Then
    %
    \[ \phi_1(M - \phi_1(M)) = \phi_1(M) - \phi_1(M) = 0. \]
    %
    Thus $M - \phi_1(M)$ is in the kernel of $\phi_1$. But this means $M - \phi_1(M)$ is also in the kernel of $\phi_2$, so
    %
    \[ \phi_2(M - \phi_1(M)) = \phi_2(M) - \phi_1(M) = 0. \]
    %
    Thus $\phi_1(M) = \phi_2(M)$.
\end{proof}

We denote the set of characters of a Banach algebra by $A$ by $\Phi_A$, and call it the \emph{character space} of $A$. Gelfand's theory is the study of $\Phi_A$, and its relation to $A$, especially when $A$ is a commutative Banach algebra.

\begin{example}
    Let $K$ be a compact space, and consider the algebra $C(K)$ of continuous functions. Given a closed subset $C$ of $K$, the set
    %
    \[ \{ f \in C(K) : f|_C = 0 \} \]
    %
    is an ideal of $C(K)$. We contend these are all such closed ideals. Let $\IA$ be an arbitrary closed ideal of $C(K)$. It is easy to see that the set
    %
    \[ C = \{ x \in K : f(x) = 0\ \text{for all $f \in \IA$} \}. \]
    %
    are closed. Conversely, suppose $g \in C(K)$ and $g|_C = 0$. Fix $\varepsilon > 0$, and let $V = g^{-1}(B_\varepsilon(0))$. For each $y \in K - C$, there is a function $f_y \in \IA$ with $f_y(y) = g(y)$. Let $U_y = (f_y - g)^{-1}(B_\varepsilon(0))$. Then $\{ V \} \cup \{ U_y \}$ is an open cover of $K$, and thus has a finite subcover $V, U_{y_1}, \dots, U_{y_n}$. Let $h_V, h_{y_1}, \dots, h_{y_n}$ be a partition of unity subordinate to the cover. Consider the function $\tilde{g} = \sum h_{y_i} f_{y_i} \in \IA$. For $x \in K - V$,
    %
    \[ |\tilde{g}(x) - g(x)| = | \sum h_{y_i}(x) (f(x) - f_{y_i}(x)) | \leq \sum h_{y_i}(x) |f(x) - f_{y_i}(x)| < \varepsilon \]
    %
    For $x \in V$,
    %
    \[ |\tilde{g}(x) - g(x)| = | \sum h_{y_i}(x) (f(x) - f_{y_i}(x)) - h_V(x) f(x) | < \varepsilon + h_V(x) f(x) \leq 2 \varepsilon \]
    %
    Thus $\| \tilde{g} - g \|_\infty \leq 2 \varepsilon$. It follows that $g$ can be approximated to arbitrary precision by elements of $\IA$, so $g \in \IA$, since $\IA$ is closed. We conclude $\IA$ consists of all functions which vanish on $C$. Thus closed ideals of $C(K)$ are in one-to-one correspondence with closed sets of $K$. But this means that the maximal ideals are precisely in one to one correspondence with the points of $K$. Thus the points in the character space of $C(K)$ is in one-to-one correspondence with the points in $K$.
\end{example}

Given a unital Banach algebra $A$, and $M \in A$, by duality we obtain a function $\widehat{M}: \Phi_A \to \CC$, given by $\widehat{M}(\phi) = \phi(M)$. It is natural to equip $\Phi_A$ with the weakest topology such that each of the functions $\widehat{M}$ is continuous. Thus we obtain an algebra homomorphism $\Gamma: A \to C(\Phi_A)$, given by $\Gamma(M) = \widehat{M}$.

\begin{theorem}
    For any unital Banach algebra $A$, $\Phi_A$ is a compact, Hausdorff space.
\end{theorem}
\begin{proof}
    Let us first verify the Hausdorff condition. Given $\phi, \psi \in \Phi_A$, there is $M \in A$ such that $\phi(M) \neq \psi(M)$. If we pick disjoint neighborhoods $U_0$ and $V_0$ of $\phi(x)$ and $\psi(x)$, then
    %
    \[ U = \widehat{M}^{-1}(U_0)  \quad\text{and}\quad V = \widehat{M}^{-1}(V_0) \]
    %
    are disjoint open sets in $\Phi_A$ separating $\phi$ and $\psi$. Thus $\Phi_A$ is a Hausdorff space.

    Compactness is a little trickier. The space $\Phi_A$ can be viewed as a subset of $A^*$, since characters are linear maps, and the topology on $\Phi_A$ is the relative topology on $A^*$ when $A^*$ is equipped with the weak $*$ topology. Since $\| \phi \| \leq 1$ for each $\phi \in \Phi_A$, $\Phi_A$ is a bounded subset of $A^*$. If we can show it is also weak $*$ closed, then the Banach-Alaoglu theorem will imply that $\Phi_A$ is compact.

    To show $\Phi_A$ is weak-$*$ closed, it suffices to show any functional $\alpha$ in the weak $*$ closure of $\Phi_A$ is a character. Fix $M,N \in A$, and $\varepsilon > 0$. Consider
    %
    \[ W = \{ \psi \in A^* : | \psi - \alpha | (z) < \varepsilon\ \text{for}\ z \in \{ 1, M, N, MN \} \} \]
    %
    Then $W$ is a weak-$*$ neighbourhood of $\alpha$, and thus contains some $\phi \in \Phi_A$. Thus
    %
    \[ |\phi(1) - \alpha(1)| = | 1 - \alpha(1) | < \varepsilon. \]
    %
    Thus we find that $\alpha(1) = 1$, since $\varepsilon$ was arbitrary. Furthermore,
    %
    \begin{align*}
        \alpha(MN) -   \alpha(M) \alpha(N) &= [\alpha(MN) - \phi(MN)] + [\phi(M)\phi(N) - \alpha(M)\alpha(N)]\\
        &= [\alpha(MN) - \phi(MN)] + [\phi(N) - \alpha(N)] \phi(M)\\
        &\ \ \ + [\phi(M) - \alpha(M)] \alpha(N)
    \end{align*}
    %
    Hence, since $\phi$ is a complex homomorphism,
    %
    \[ | \alpha(MN) - \alpha(M) \alpha(N) | < (1 + |\phi(M)| + |\alpha(N)|) \varepsilon \leq (1 + \| M \| + \| \alpha \| \| N \|) \varepsilon \]
    %
    Letting $\varepsilon \to 0$, we find $\alpha(MN) = \alpha(M) \alpha(N)$. Thus $\alpha$ is a character, so $\Phi_A$ is closed, and thus compact.
\end{proof}

\begin{theorem}
    If $f: A \to B$ is an algebra homomorphism, then the map $f^*: \Phi_B \to \Phi_A$ defined such that for any $M \in A$,
    %
    \[ f^*(\phi)(M) = \phi(f(M)) \]
    %
    is continuous.
\end{theorem}
\begin{proof}
    The open sets in $\Phi_A$ are generated for $M \in A$, $\lambda \in \CC$, and $\varepsilon > 0$, by sets of the form
    %
    \[ U = \{ \phi \in \Phi_A: |\phi(M) - \lambda| < \varepsilon \} = \widehat{M}^{-1} \left( B_\varepsilon(\lambda) \right). \]
    %
    The inverse image of $U$ under $f^*$ is precisely
    %
    \[ \{ \psi \in \Phi_B : |(\psi \circ f)(M) - \lambda| < \varepsilon \} = \widehat{f(M)}^{-1} \left( B_\varepsilon(\lambda) \right). \]
    %
    The map is therefore continuous.
\end{proof}

Let us now list the main properties of the Gelfand transform, which make it so useful.

\begin{theorem}
    Let $A$ be a unital Banach algebra. Then for any $M \in A$,
    %
    \[ \widehat{M}(\Phi_A) \subset \sigma(M). \]
    %
    If $A$ is commutative, then
    %
    \[ \widehat{M}(\Phi_A) = \sigma(M). \]
\end{theorem}
\begin{proof}
    If $\phi: A \to \CC$, and $\phi(M) = \lambda$, then $\lambda - M$ lies in some maximal ideal of $A$, and thus cannot be invertible, so $\lambda \in \sigma(M)$. Conversely, if $A$ is commutative, and $\lambda \in \sigma(M)$, then $\lambda - M$ lies in some maximal ideal of $A$, and so there is some character $\phi: A \to \CC$ with $\phi(\lambda - M) = 0$, i.e. $\phi(M) = \lambda$.
\end{proof}

\begin{example}
    The Gelfand transform can be quite useless when studying a noncommutative algebra $A$. For instance, the algebra $M_n(\CC)$ of $n \times n$ matrices has only a single ideal, namely the set $\{ 0 \}$. To see this, suppose $\IA$ is an ideal of $M_n(\CC)$ containing some non-zero matrix $M$. It follows from the elementary theory of matrices that there are invertible matrices $N$ and $L$ such that $NML \in \IA$ is a diagonal matrix, non-zero somewhere on the diagonal. Multiplying on the left by an appropriate matrix, we may assume that there is only a single entry on the diagonal. Multiplying on the left by permutation matrices and then considering linera combinations of what we get then shows that $\IA$ contains all diagonal matrices in $M_n(\CC)$. But as we have seen above, this implies that $\IA$ contains \emph{all} matrices in $M_n(\CC)$. Thus $M_n(\mathbf{C})$ is a {\it simple} algebra, it contains no non-trivial ideals. Consequently, we find that every non-zero algebra homomorphism $F: M_n(\CC) \to A$ must be injective, for the kernel is a proper ideal for $M_n(\CC)$. Thus the character space of $M_n(\CC)$, for $n > 1$, must be $\emptyset$, because there is no injective algebra homomorphism from $M_n(\mathbf{C})$ to $\mathbf{C}$ (there is not even an injective linear map).
\end{example}

Since $\widehat{M}(\Phi_A) \subset \sigma(M)$ for any $M$ in a unital Banach algebra $A$, it follows that
%
\[ \| \Gamma(M) \|_{L^\infty(\Phi_A)} = \rho(M) \leq \| M \|. \]
%
Thus $\Gamma$ is a contractive algebra homomorphism from $A$ into $C(\Phi_A)$, whose kernel is the Jacobson radical of $A$, the intersection of all it's maximal ideals. Thus $\Gamma$ is injective if and only if $A$ is semisimple.

\begin{example}
    An example of a commutative Banach algebra which is not semisimple is the ring $A$ of all matrices of the form
    %
    \[ \begin{pmatrix} a & b \\ 0 & a \end{pmatrix}. \]
    %
    Any matrix of the form above, where $a \neq 0$, is invertible in $A$, and the complement of this set is an ideal. Thus this ring is local. The Gelfand space $\Phi_A$ in this case is just a single point, and a matrix of the form above is mapped to the function taking the value $a$ at this point.
\end{example}

For general Banach $*$ algebras, Gelfand theory does not necessarily react well with involution. We would want to have the property that
%
\[ \widehat{M^*} = \overline{\widehat{M}}, \]
%
for all $M \in A$. This condition is equivalent to $\Gamma: A \to C(\Phi_A)$ being a homomorphism of Banach $*$ algebras. A Banach $*$ algebra with this property is called \emph{symmetric}. An example consequence is that for any $M \in A$,
%
\[ \widehat{M^* M} = |\widehat{M}|^2, \]
%
and if $M$ is unitary, then $|\widehat{M}| = 1$.

\begin{lemma}
    Any unital $C^*$ algebra $A$ is symmetric.
\end{lemma}
\begin{proof}
    We have already seen that $\sigma(M) \subset \RR^+$ for any self-adjoint $M \in A$, so the theorem follows immediately from the holomorphic functional calculus and the fact that $\widehat{M}(\Phi_A) \subset \sigma(M)$. Alternatively, we can give a more elementary proof. Consider a self-adjoint element $M \in A$. If $\phi: A \to \CC$ is a character, and $\phi(M) = a + i b$, then $\phi(M + i t) = a + i(b + t)$. But we have
    %
    \begin{align*}
        |\phi(M + i t)|^2 &= a^2 + (b + t)^2\\
        &\leq \| M + it \|^2\\
        &= \| (M + it)(M - it) \|\\
        &= \| M^2 + t^2 \| \leq \| M \|^2 + t^2.
    \end{align*}
    %
    Subtracting $t^2$ from each side of the equation gives a uniform bound on $a^2 + b^2 + 2bt$ for all $t$, which is only possible if $b = 0$.
\end{proof}

\begin{remark}
    The algebra $A(\mathbf{D})$ with involution $f^*(z) = \overline{f}(\overline{z})$, is not symmetric. Neither is $L^1(\mathbf{Z})$, where $(a^*)_n = \overline{a}_n$. But if we instead consider the convolution $(a^*)_n = \overline{a_{-n}}$, then $L^1(\mathbf{Z})$ \emph{is} a symmetric algebra, which is one of the reaons why this involution is so much more useful than pointwise conjugation.
\end{remark}

\begin{theorem}
    If $A$ is a commutative, symmetric Banach $*$ algebra, then the image of the Gelfand transform is a dense subset of $C(\Phi_A)$.
\end{theorem}
\begin{proof}
    Let $B = \Gamma(A)$. Then $B$ is closed under conjugation because $A$ is symmetric. Since characters are determined by their values on elements of $A$, elements of $B$ separate points in $\Phi_A$. It also contains constants since $\widehat{1} = 1$. Thus by the Stone-Weirstrass theorem, $B$ is dense in $C(\Phi_A)$.
\end{proof}

If $A$ is a \emph{commutative} unital Banach algebra, the spectral radius formula implies that $\Gamma$ is an isometry if and only if for any $M \in A$,
%
\[ \| M^2 \| = \| M \|^2. \]
%
This is true, in particular, if $A$ is a commutative $C^*$ algebra. To see this, using the fact that $A$ is symmetric, we calculate that
%
\[ \| M \|^2 = \| M^* M \| = \| \widehat{M^* M} \|_{L^\infty(\Phi_A)} = \| |\widehat{M}|^2 \|_{L^\infty(\Phi_A)} = \| (\widehat{M})^2 \|_{L^\infty(\Phi_A)} = \| M^2 \|. \]
%
Thus \emph{every commutative, unital $C^*$ algebra is semisimple}. Moreover, the Gelfand transform $\Gamma: A \to C(\Phi_A)$ is then an \emph{isometric $*$-isomorphism} between $A$ and $C(\Phi_A)$. Thus \emph{every commutative $C^*$ algebra is naturally isomorphic to $C(K)$ for some compact space $K$}. This is the commutative case of the \emph{Gelfand-Naimark theorem}.

The commutative Gelfand Naimark theorem has two important applications. The first is a proof of the existence of the \emph{Stone-Cech compactification} of a completely regular topological space. Recall that a space $X$ is \emph{completely regular} if it is $T1$, and if for each closed $C$ and $x \in X - C$, there is $f \in C(X)$ which satisfies $f(x) = 1$, but vanishes on $C$. Urysohn's lemma tells us all normal spaces are completely regular.

\begin{theorem}
    Let $X$ be a completely regular space. Then there is a compact Hausdorff space $\beta X$ with an embedding $i: X \to \beta X$ onto a dense subset of $\beta X$ satisfying the following universal property: For any continuous map $j: X \to K$ into a compact Hausdorf space, there is a unique $F: \beta X \to K$ such that $j = F \circ i$. The universal property implies $\beta X$ is unique up to a homeomorphism, and it is called the \emph{Stone-Cech compactification of $X$}.
\end{theorem}
\begin{proof}
    The space $C_b(X)$ is a commutative unital $C^*$ algebra, so the Gelfand transform gives an isomorphism of $C_b(X)$ with $C(\beta X)$, where $\beta X = \Phi_{C_b(X)}$ is the Character space of $C_b(X)$. For each $x \in X$, the map $\phi_x(f) = f(x)$ is a character on $C_b(X)$, and thus corresponds to a unique point $i(x) \in \beta X$. We thus obtain an injective map $i: X \to \beta X$. We claim it is also continuous. Indeed, the open sets of $\beta X$ are generated, for each $f \in C_b(X)$, $\lambda \in \CC$, and $\varepsilon > 0$, by sets of the form
    %
    \[ U = \{ x \in \beta X: |\widehat{f}(x) - \lambda| < \varepsilon \}. \]
    %
    The inverse image of $U$ by $i$ is precisely
    %
    \[ \{ x \in X : |f(x) - \lambda| < \varepsilon \}, \]
    %
    which is certainly open. Thus $i$ is continuous. We will now show $i: X \to \beta X$ satisfies the required universal properties.

    To begin with, note that $\widehat{f} \circ i = f$ for any $f \in C_b(X)$. Since $C_b(X)$ is a $C^*$ algebra, $\Gamma: C_b(X) \to C(\beta X)$ is an isomorphism, so every continuous, scalar-valued function on $\beta X$ is the extension of a unique bounded, continuous function on $X$ with the same $L^\infty$ norm. It follows that $i(X)$ is dense in $\beta(X)$, e.g. by Urysohn's lemma.

    Next, we show $i: X \to \beta X$ is an embedding. Fix a net $\{ x_\alpha \}$ in $X$, let $x \in X$, and suppose $\{ x_\alpha \}$ does not converge to $x$. Thinning this net if necessary, we may find an open set $U$ containing $x$, but no elements of the net $\{ x_\alpha \}$. Since $X$ is completely regular, we may find $f \in C_b(X)$ whcih vanishes outside of $U$, but with $f(x) = 1$. Then $\widehat{f}(i(x_\alpha)) = 0$, but $\widehat{f}(I(x)) = 1$. Thus $\{ i(x_\alpha) \}$ cannot converge to $i(x)$. Thus we have shown $i$ is an embedding.

    Finally, let $K$ be any compact Hausdorff space, and let $j: X \to K$ be a continuous map. Then $j$ induces an algebra homomorphism $j^*: C(K) \to C_b(X)$, and thus a continuous map from the character space of $C_b(X)$ to the character space of $C(K)$, i.e. a continuous map $F: \beta X \to K$ such that if $x \in \beta X$ corresponds to a character $\phi: C_b(X) \to \CC$, then for any $g \in C(K)$,
    %
    \[ g(F(x)) = \phi(j^*(g)). \]
    %
    In particular, if $x \in X$, then
    %
    \[ g(F(i(x))) = \phi_x(j^*(g)) = j^*(g)(x) = g(j(x)). \]
    %
    Since $g$ was arbirary, it follows that $F \circ i = j$. That $F$ is the unique continuous map making the diagram commute follows because $i(X)$ is dense in $\beta X$. Thus we have verified the universal property.
\end{proof}

For normal elements of a $C^*$ algebra, we now use the Gelfand-Naimark theorem to extend the holomorphic functional calculus to a \emph{continuous functional calculus}. To begin with, note that $A$ is a commutative, unital Banach $*$ algebra containing an element $M$ such that one of three things is true:
%
\begin{itemize}
    \item $A$ is generatedf as a unital algebra by $M$.
    \item $M$ is invertible, and $A$ is generated as an algebra by $M$ and $M^{-1}$.
    \item $A$ is a symmetric algebra, and $A$ is generated as a unital algebra by $M$ and $M^*$.
\end{itemize}
%
Then $\widehat{M}: \Phi_A \to \sigma(M)$ is a homeomorphism. Since $\Phi_A$ is compact, it suffices to show that $\widehat{M}$ is injective. But this follows because, in each of the three cases above, if two characters agree at $M$, they agree on the entirety of $M$. A particular example of importance to us is, for an arbitrary $C^*$ algebra $A$ and a normal element $M \in A$, is $C^*(M)$, the smallest $C^*$ subalgebra generated by $M$. Since $M$ is normal, $C^*(M)$ will be commutative, and generated as a unital algebra by $M$ and $M^*$.

\begin{example}
    Consider $\delta^1 \in L^1(\ZZ)$. Then $\sigma(\delta^1) = \mathbf{T}$. We have $\sigma(\delta^1) \subset \mathbf{D}$ because $\| \delta^1 \|_{L^1(\ZZ)} = 1$. The function $\delta^1$ has an inverse $\delta^{-1}$, and by the spectral theorem and the fact that $\| \delta^{-1} \|_{L^1(\ZZ)} = 1$, $\sigma(\delta^1)^{-1} = \sigma(\delta^{-1}) \subset \mathbf{D}$, so we conclude $\sigma(\delta^1) \subset \mathbf{T}$. In fact, $\sigma(\delta^1)$ is equal to $\mathbf{T}$. To see this, let us try and invert $\lambda \delta^0 - \delta^1$, for some $|\lambda| = 1$. If $c * (\lambda \delta^0 - \delta^1) = \delta^0$, then
    %
    \[ \lambda c_n - c_{n-1} = \begin{cases} 1 & n = 0 \\ 0 & n \neq 0 \end{cases} \]
    %
    Solving these equations recursively, we find $c_n = \lambda^{-n} c_0$ for $n \geq 0$, and $c_{-n} = \lambda^{n-1} c_{-1}$. We must have $c \in L^1(\mathbf{Z})$, so that
    %
    \[ |c_0| \sum_{k = 0}^\infty 1 + |c_{-1}| \sum_{k = 1}^\infty 1 < \infty \]
    %
    Hence $c_0 = c_{-1} = 0$, so that $c = 0$, which is impossible if we also want $c * (\lambda \delta^0 - \delta^1) = \delta^0$ to hold. Thus $\sigma(\delta^1) = \mathbf{T}$.

    Since $\delta^1$ generates $L^1(\ZZ)$, it follows that the Gelfand space of $L^1(\ZZ)$ is homeomorphic to $\TT$. We have seen that $\Gamma(\sum a_n \delta^n) = \sum a_n z^n$. Taking uniform limits of this result gives that $\Gamma: L^1(\ZZ) \to C(\mathbf{T})$ is precisely the inverse Fourier transform on the Torus. Conversely, more sophisticated arguments show that for any locally compact abelian group $G$, the space $L^1(G)$, equipped with convolution (against the Haar measure) as multiplication has Gelfand space equal to $\widehat{G}$, the dual group of complex-valued characters on $G$, and $\Gamma: L^1(G) \to C(\widehat{G})$ is precisely the abstract Fourier transform of functions on $G$. Thus the Gelfand transform is one way to think of the Fourier transform.
\end{example}

Now suppose that $A$ is a commutative unital $C^*$ algebra of the form above. Then $\widehat{M}: \Phi_A \to \sigma(M)$ is a homeomorphism. We thus have an isometric $*$ isomorphism
%
\[ A \cong C(\Phi_A) \cong C(\sigma(M)). \]
%
For $f \in C(\sigma(M))$, we let $f(M) \in A$ denote the image of this map. Thus for any character $\phi: A \to \CC$,
%
\[ \phi(f(M)) = f(\phi(M)). \]
%
This equation implies that $\sigma(f(M)) = f(\sigma(M))$, so we have a continuous functional calculus. Thus we have a continuous functional calculus on $A$. It is simple to see that $z(M) = M$, and $1(M) = 1$, and $f \mapsto f(M)$ is the unique $*$ algebra homomorphism with this property, since functions of the form
%
\[ f(z) = \sum c_{\alpha \beta} z^\alpha \overline{z}^\beta \]
%
are dense in $C(\sigma(M))$, and we see that $f(M) = \sum c_{\alpha \beta} M^\alpha (M^*)^\beta$. In particular, we see that if $f(z) = \sum c_k z^k$, then $f(M) = \sum c_k M^k$, and so this calculus extends the holomorphic functional calculus.

The key to Gelfand theory is noticing that characters of Banach algebras naturally reflect the structure of the Banach algebra in question. Understanding the character space leads to a natural understanding of the invertibility of the elements of the algebra. For instance, here is a result on the invertibility of Fourier series initially due to Wiener, whose proof was incredibly difficult without the technology that Gelfand introduced.

\begin{example}
    Consider a formal trigonometric series on $\TT$ of the form
    %
    \[ f(z) = \sum a_n z^n \]
    %
    where $\sum |a_n| < \infty$. Then $f = \Gamma(a)$, where $a \in L^1(\ZZ)$ is given by the sequence $\{ a_n \}$. Now suppose $f$ is non-vanishing on $\TT$. Since $\sigma(a) = f(\TT)$, this means that $a$ is invertible in $L^1(\ZZ)$. Thus there exists $b \in L^1(\ZZ)$ such that $a * b = \delta$. Thus $\Gamma(b) = 1/f$, i.e.
    %
    \[ \frac{1}{f(z)} = \sum b_n z^n. \]
    %
    Similar results can be applied to non-continous functions by approximation, and to higher dimensional trigonometric series, in which case the Gelfand space are the higher dimensional torii $\TT^n$.
\end{example}

Here's another example from the complex analysis of several variables.

\begin{example}
    Consider the commutative algebra $A(\mathbf{D})$. We also contend that $\Phi_{A(\mathbf{D})}$ can be identified with $\mathbf{D}$. The identity function $z$ has norm 1 in this space, implying that if $\phi: A(\mathbf{D}) \to \mathbf{C}$ is any character, then $\phi(z) = w \in \mathbf{D}$. Then
    %
    \[ \phi(\sum_{k = 0}^N a_k z^k) = \sum_{k = 0}^N a_k w^k \]
    %
    and these polynomials are dense in $A(\mathbf{D})$, from which we conclude $\phi(f) = f(w)$. Thus any character is given by evaluation at a point in $\mathbf{D}$.

    Let us use this calculation to obtain an analytic version of the nullstellensatz in algebraic geometry. Consider $n$ functions $f_1, \dots, f_n \in A(\mathbf{D})$ whose common nullset $Z(f_1,\dots,f_n)$ is empty. Then we claim there are $g_1,\dots,g_n \in A(\mathbf{D})$ such that $f_1 g_1 + \dots + f_n g_n = 1$. It is clear that this is equivalent to the ideal relation
    %
    \[ (f_1, \dots, f_n) = A(\mathbf{D}) \]
    %
    If this were not true, then $(f_1, \dots, f_n)$ would be contained in a closed, maximal ideal, and would therefore be annihilated by some $\phi \in \Phi_{A(\mathbf{D})}$. But $\phi$ corresponds to evaluation at some $w \in \mathbf{D}$, so $f_i(w) = 0$ for all $i$, which gives a contradiction. One can apply Runge's theorem to classify the character spaces of arbitrary spaces of the form $A(\Omega)$, but we leave this as an exercise to the reader.
\end{example}

If $M$ and $N$ are operators such that $MN = NM$, then certainly $M^*N^* = N^*M^*$, but it is not necessarily true that $MN^* = N^* M$ or $M^* N = N M^*$. For instance, if $M$ is not a normal operator, and we take $M = N$. But if $M$ and $N$ are normal, then the result is true. In fact, much more is true.

\begin{theorem}[Fuglede-Putnam-Rosenblum]
    Let $A$ be a $C^*$ algebra, and consider normal elements $M,N \in A$, and a third element $L \in A$ such that $ML = LM$. Then $M^* L = L N^*$.
\end{theorem}
\begin{proof}
    Without loss of generality, assume $A$ is unital. If $ML = LN$, then for all $k > 0$, $M^kL = LN^k$, and so by taking power series, we conclude that for any $\lambda \in \CC$,
    %
    \[ e^{\lambda M} L = L e^{\lambda N}, \]
    %
    so that $L = e^{\lambda M} L e^{- \lambda N}$. Thus
    %
    \[ e^{\lambda M^*} L e^{- \lambda N^*} = e^{\lambda (M^* - M)} L e^{\lambda (N - N^*)}. \]
    %
    Note that $e^{\lambda(M^* - M)}$ and $e^{\lambda (N - N^*)}$ are both unitary, and so if we set
    %
    \[ f(\lambda) = e^{\lambda M^*} L e^{- \lambda N^*} = L + \lambda (M^* L - L N^*) + O(\lambda^2), \]
    %
    then we see $f: \CC \to A$ is an entire function of $\lambda$, and $\| f \|_{L^\infty(\CC)} \leq \| L \|$ is uniformly bounded. Thus we conclude $f$ is a constant function. But this means that the first order term of the power series vanishes, i.e. $M^* L = LN^*$.
\end{proof}

\section{The Non-Unital Gelfand Space}

Let us also address the non-unital case of Gelfand theory. In the Gelfand theory, we have a little trouble defining ideals. We call an ideal $\mathfrak{a}$ (an additive subgroup closed under multiplication) for a non-unital algebra $A$ \emph{modular} if there is $N \in A$ such that $MN - M, NM - M \in \mathfrak{a}$ for all $M \in A$. If $\mathfrak{a}$ is modular, it follows that $A/\mathfrak{a}$ contains an identity. Zorn can show us maximal modular ideals exist in any non-unital algebra. We need to edit the proof which shows a maximal ideal is closed, which relies on an algebraic trick.

\begin{lemma}
    A maximal modular ideal in an algebra $A$ is closed.
\end{lemma}
\begin{proof}
    If a maximal ideal $\mathfrak{a}$ was not closed, then we would have $\overline{\mathfrak{a}} = A$. Let $N$ be a right modular identity for $\mathfrak{a}$. Then there is $M \in \mathfrak{a}$ with $\| M - N \| < 1$, so
    %
    \begin{align*}
        N &= (N - M) + M = \sum_{k = 1}^\infty (N - M)^k - \sum_{k = 2}^\infty (N - M)^k + M\\
        &= \sum_{k = 1}^\infty (N - M)^k - \left[ \sum_{k = 1}^\infty (N - M)^k \right] (N - M) + M\\
        &= \underbrace{\left[ \left( \sum_{k = 1}^\infty (N - M)^k \right) M + M \right]}_{\in \mathfrak{a}} - \underbrace{\left[ \left( \sum_{k = 1}^\infty (N - M)^k \right) N - \left( \sum_{k = 1}^\infty (N - M)^k \right) \right]}_{\in \mathfrak{a}}
    \end{align*}
    %
    Given any $L \in A$, $LM - M \in \mathfrak{a}$, implying $M \in \mathfrak{a}$. This implies $\mathfrak{a} = A$, an impossibility.
\end{proof}

\begin{lemma}
    The kernel of any {\it nonzero} algebra homomorphism from $A$ to $\mathbf{C}$ is a maximal modular ideal, and in a commutative non-unital algebra, any maximal modular ideal is the kernel of some non-zero algebra homomorphism.
\end{lemma}
\begin{proof}
    If $\phi: A \to \mathbf{C}$ is a non-zero algebra homomorphism, then $\phi$ is surjective, for if $\phi(M) \neq 0$, then $\phi(\mathbf{C} \cdot x) = \mathbf{C}$. We claim that if $\mathfrak{a} = \ker(\phi)$, and if $\phi(M) = 1$, then $M$ is a modular identify for $\mathfrak{a}$, because
    %
    \[ \phi(MN - N) = \phi(M)\phi(N) - \phi(N) = \phi(N) - \phi(N) = 0 \]
    %
    Implying $MN - N \in \mathfrak{a}$ for each $N$, so $\mathfrak{a}$ is a modular ideal. The first isomorphism theorem gives us an isomorphism from $A/\mathfrak{a}$ to $\mathbf{C}$, so $\mathfrak{a}$ is maximal, since $A/\mathfrak{a}$ is a field.

    If $A$ is commutative, and $\mathfrak{a}$ is a maximal modular ideal, then $A/\mathfrak{a}$ is an algebra with identity, whose only ideals consists of $(0)$ and $A/\mathfrak{a}$, since $\mathfrak{a}$ is maximal, so $A/\mathfrak{a}$ is a field, and is therefore isometric to $\mathbf{C}$, giving us an algebra homomorphism.
\end{proof}

Given this result, we may therefore consider the Gelfand transform of a non-unital algebra, into the character space of all nonzero non-unital algebra homomorphisms. Unitizing $A$ and considering the Gelfand theory on $A^\#$ only adds a single extra character, which normally does not introduce any complications.

\begin{lemma}
    If $A$ is an algebra without identity, and $\phi$ is a character on $A$, then there is a unique non-zero character $\tilde{\phi}$ defined on $A^\#$ which extends $\phi$.
\end{lemma}
\begin{proof}
    Define $\tilde{\phi}(M + \lambda) = \phi(M) + \lambda$. Then $\tilde{\phi}$ is linear, $\tilde{\phi}(1) = 1$, and
    %
    \begin{align*}
        \tilde{\phi}(M + \lambda) \tilde{\phi}(N + \gamma) &= [\phi(M) + \lambda][\phi(N) + \gamma]\\
        &= \phi(MN) + \phi(\lambda N) + \phi(\gamma M) + \lambda \gamma\\
        &= \tilde{\phi}((M + \lambda)(N + \gamma))
    \end{align*}
    %
    The uniqueness of the extension follows from the fact any maximal modular ideal of $A$ can be uniquely extended to a maximal ideal on $A^\#$, for the projection $M + \lambda \mapsto M$ maps ideals to ideals, and the only ideals of $\mathbf{C}$ are $(0)$ and $(1)$.
\end{proof}

\begin{corollary}
    We have
    %
    \[ \Phi_{A^\#} = \Phi_A \cup \{ \phi_\infty \}, \]
    %
    where
    %
    \[ \phi_\infty(M + \lambda) = \lambda. \]
    %
    We have $\sigma(M) \subset \widehat{M}(\Phi_A) \cup \{ 0 \}$, with equality if $A$ is commutative.
\end{corollary}

We can equip $\Phi_A$ with the weak topology in the same way that we introduce a topology in the unital case. In this situation, however, $\Phi_A$ is only \emph{locally compact}, not compact, with $\Phi_{A^\#}$ corresponding to the one point compactification.

\begin{theorem}
    The Gelfand topology on $\Phi_A$ is Hausdorff and locally compact, and we have
    %
    \[ \Gamma: A \to C_0(\Phi_A). \]
\end{theorem}
\begin{proof}
    This follows from the fact that $\Phi_{A^\#}$ is Hausdorff compact, and $\Phi_A$ is obtained from $\Phi_{A^\#}$ by removing a single point. Certainly it follows from this that $\Phi_A$ is Hausdorff. Moreover, for any character $\phi$, we can find an open set $U \subset \Phi_{A^\#}$ containing $\phi$ and an open set $V \subset \Phi_{A^\#}$ containing $\phi_\infty$ such that the closures of $U$ and $V$ are disjoint. But this means that $\overline{U} \subset \Phi_A$ is a compact neighborhood of $\phi$. Thus $\Phi_A$ is locally compact.
%    Let $\psi_0 \in \Phi_A$ be arbitrary, and fix $M \in A$ such that $\psi_0(M) = 1$. We shall verify that
    %
%    \[ K = \{ \psi \in \Phi_A : |\psi(M)| \geq 1/2 \} \]
    %
%    is compact, in which case it's interior will be a compact neighborhood of $\psi_0$, proving that $\Phi_A$ is locally compact. Since characters on $A$ extended to characters on $A^\#$, it follows that $\| \psi(M) \| \leq \| M \|$ for any $M \in A$, and thus $\Phi_A$, and thus $K$ is bounded in $A^*$. It therefore suffices to show $K$ is weak-$*$ closed in $A^*$. Certainly $K$ is closed in $\Phi_A$ because $\widehat{M}: \Phi_A \to \CC$ is continuous. But $K$ is also closed in $\Phi_{A^\#}$ for the same reasons, since $\phi_\infty \not \in K$. Since $\Phi_{A^\#}$ is closed in $A^*$, it follows $K$ is closed in $A^*$.
%
%    But $\Phi_{A^\#} = $
%
%    the corresponding  $K$ is closed in $\Phi_{A^\#}$
%
%    Since $K = \psi_0^{-1}([1/2, \infty))$, where $\Lambda: A^* \to \mathbf{C}$ is the map $\phi \mapsto |\phi(M)|$, then $\Lambda$ is weak $*$ continuous, so $K$ is closed, hence compact. $K$ contains an open neighbourhood
    %
%    \[ U = \{ \psi \in \Phi_A : |\psi(M)| > 1/2 \} \]
    %
%    so $\Phi_A$ is locally compact. If $M \in A$, $\widehat{M} \in C_0(\Phi_A)$, since
    %
%    \[ \{ \phi \in \Phi_A : |\phi(M)| \geq \varepsilon \} \]
    %
%    is compact, and outside of this set $\widehat{M} \leq \varepsilon$.
\end{proof}

\begin{example}
    Suppose $X$ is a locally compact, but not compact, space. Then $C_0(X)$ is a non-unital $C^*$ algebra. It's unitization is then a unital $C^*$ algebra, and thus corresponds to $C(X^*)$ for some compact set $X^*$. We have already seen that $X^*$ is equal to the one point compactification of $X$.
\end{example}

As with the holomorphic functional calculus on non unital Banach algebras, given a normal element $M$ of a non-unital $C*$ algebra $A$, we can define $f(M)$ for any $f \in C(\sigma(M))$, provided that $f(0) = 0$.







\chapter{Positivity}

The model example of this chapter is a positive semidefinite operator on a Hilbert space.

\begin{theorem}
    Let $H$ be a Hilbert space, and suppose $T: H \to H$ is a bounded, self-adjoint operator. Then the following two conditions are equivalent:
    %
    \begin{itemize}
        \item $\sigma(T) \subset [0,\infty)$.
        \item For any $x \in H$, $\langle Tx, x \rangle \geq 0$.
    \end{itemize}
    %
    If these properties are true, we say $T$ is \emph{positive semidefinite}.
\end{theorem}
\begin{proof}
    Suppose $\sigma(T) \subset [0,\infty)$. If we let $f: \sigma(T) \to [0,\infty)$ be defined by setting $f(x) = \sqrt{x}$, and we set $S = f(T)$, then $S$ is also self-adjoint, and $T = S^2$. It follows that for any $x \in H$,
    %
    \[ \langle Tx, x \rangle = \langle S^2x, x \rangle = \langle Sx, Sx \rangle \geq 0. \]
    %
    Conversely, suppose that for all $x \in H$,
    %
    \[ \langle Tx, x \rangle \geq 0. \]
    %
    Then for any $\lambda < 0$, we have
    %
    \[ \langle (T - \lambda)x, x \rangle = \langle Tx, x \rangle - \lambda \| x \|^2 \geq - \lambda \| x \|^2 \gtrsim \ |x \|^2. \]
    %
    Since $| \langle (T - \lambda) x, x \rangle | \lesssim \| (T - \lambda) x \| \| x \|$, it follows that $\| (T - \lambda) x \| \sim \| x \|$, so $T - \lambda$ is an isomorphism of $H$. Thus $\sigma(T) \subset [0,\infty)$.
\end{proof}

Now let $A$ be an arbitrary $C^*$ algebra. A self-adjoint element $M$ is \emph{positive} if $\sigma(M) \subset [0, \infty)$. In shorthand, we write $M \geq 0$. The set of all positive elements in an algebra $A$ is denoted $A_+$. We write $M \leq N$ if $N - M \geq 0$. Thus identifying positive elements gives us a partial ordering on the set of self-adjoint elements of $A$.

\begin{example}
    Let $X$ be a locally compact space. Then $f \in C_0(X)$ is self-adjoint if and only if $f$ is real-valued, and positive if and only if $f \geq 0$, since $\sigma(f) = \{ 0 \} \cup f(X)$. For a measure space $X$, $f \in L^\infty(X)$ is self-adjoint if and only if $f$ is almost-everywhere real valued, and positive if and only if $f \geq 0$ almost everywhere.
\end{example}

\begin{prop}
    Let $A$ be a $C^*$ algebra. If $M \in A_+$, there is a unique $N \in A_+$ for which $M = N^2$, which we denote by $\sqrt{M}$.
\end{prop}
\begin{proof}
    Consider the positive square root map $f(z) = \sqrt{z}$. This is well defined on $\sigma(M)$ since $\sigma(M) \subset [0,\infty)$, and $f \in C(\sigma(M))$, so we may consider $N = f(M)$. Now
    %
    \[ N^2 = f(M)^2 = (f^2)(M) = (\text{id}_{\sigma(M)})(M) = M. \]
    %
    Denote this element by $\sqrt{M}$. If $N^2 = M$ for any other $N \in A_+$, then
    %
    \[ NM = N^3 = (N^2)N = MN \]
    %
    Thus $N$ commutes with $M$, and so it follows that $N$ commutes with $f(M)$ for any $f \in C(\sigma(M))$, since $f(M)$ lies in the unital $C^*$ algebra generated by $M$. Thus the smallest $C*$ algebra $B$ containing $N$ and $f(M)$ is commutative. Applying the Gelfand transform, since $N \in A_+$, $\widehat{N}(\Phi_B) \geq 0$, and $\widehat{N}^2 = M$. This means that $\widehat{N} = \sqrt{\widehat{M}} = \widehat{f(M)}$. Thus $\widehat{f(M)} = \widehat{N}$, so $f(M) = N$.
\end{proof}

If self-adjoint operators behave somewhat like real numbers, positive operators behave like positive real numbers.

\begin{prop}
    Let $A$ be a $C^*$ algebra, and let $M \in A$ be self adjoint. Then there are unique $M_+$, $M_- \in A_+$ for which $M = M_+ - M_-$, and $M_+ M_- = 0$.
\end{prop}
\begin{proof}
    Let $f_+(t) = \text{max}(t,0)$, and $f_-(t) = -\text{min}(t,0)$. Then $f_+$ and $f_-$ are continuous maps, and we may consider $f_+(M)$, $f_-(M)$. Since
    %
    \[ f_+ - f_- = \text{id}_{\sigma(M)} \]
    %
    $f_+(M) - f_-(M) = M$. By the spectral mapping theorem,
    %
    \[ \sigma(f_+(M)) = f_+(\sigma(M)) \subset [0,\infty)\ \ \ \ \ \sigma(f_-) = f_-(\sigma(M)) \subset [0,\infty) \]
    %
    so $f_+(M), f_-(M) \geq 0$. Since $f_+ f_- = 0$, $f_+(M) f_-(M) = 0$. Uniqueness follows by a Gelfand transform calculation analogous to the proof of the uniqueness of square roots.
\end{proof}

%\begin{example}
%    Suppose $M$ is a positive element of $B(H)$. Then, for any $x \in H$,
    %
%    \[ \langle Mx,x \rangle = \langle \sqrt{M}\sqrt{M}x,x \rangle = \langle \sqrt{M}x, \sqrt{M}x \rangle \geq 0 \]
    %
%    Conversely, let $M \in B(H)$ be an operator such that, for any $x \in H$,
    %
%    \[ \langle Mx, x \rangle \geq 0 \]
    %
%    Write $M = N + iL$, with $N$ and $L$ self adjoint.Then
    %
%    \[ \langle Mx, x \rangle = \langle Nx, x \rangle + i \langle Lx, x \rangle \geq 0 \]
    %
%    implying $\langle Lx, x \rangle = 0$ for all $x$, so $L = 0$, and $M = N$ is self-adjoint. The last proposition implies that we may write $M = M_+ - M_-$. Then
    %
%    \[ 0 \leq \langle MM_-x, M_-x \rangle = - \langle M_-^2 x, M_- x \rangle \leq 0 \]
    %
%    Since $H = \overline{M_-H} \oplus \ker M_-$, we find that
    %
%    \[ \langle M_-x, x \rangle = 0 \]
    %
%    for all $x$, implying $M_- = 0$, so $M = M_+$ is positive. Thus positive operators have a nice characterization on Hilbert spaces.
%\end{example}

\begin{lemma}
    Let $A$ be a $C*$ algebra. If $M$ is self-adjoint, $t \geq 0$, and $\| M - t \| \leq t$, then $M$ is positive. If $M$ is positive, and $\| M \| \leq t$, then $\| M - t \| \leq t$. Thus the positive elements of $A$ are a relatively open subset of the self-adjoint elements of $A$.
\end{lemma}
\begin{proof}
    Suppose $\| M - t \| \leq t$. Then $\sigma(M - t) \in [-t,t]$, so
    %
    \[ \sigma(M) = \sigma(M - t) + t \in [0, 2t] \]
    %
    Thus $M \in A_+$. Conversely, if $M \in A_+$ and $\| M \| \leq t$, then $\sigma(M) \subset [0,t]$, and
    %
    \[ \sigma(M - t) = \sigma(M) - t \subset [-t,0] \]
    %
    which means $\| M - t \| = r(M - t) \leq t$.
\end{proof}

The next result shows that $A_+$ is a cone in $A$.

\begin{prop}
    If $A$ is a $C^*$ algebra, then
    %
    \begin{enumerate}
        \item[(a)] $A_+$ is closed.
        \item[(b)] If $M,N \in A_+$, then $M + N \in A_+$.
        \item[(c)] If $M \in A_+$, and $t \geq 0$, then $tM \in A_+$.
        \item[(d)] $A_+ \cap (-A_+) = (0)$.
    \end{enumerate}
\end{prop}
\begin{proof}
    Suppose that $N \in \overline{A_+}$, choose $K > \| N \|$. Fix $\varepsilon > 0$ and pick $M \in A_+$ with $\| N - M \| < \varepsilon$. Then if $\varepsilon$ is chosen small enough, then $\| M \| < K$, and
    %
    \[ \| N - K \| = \| N - M \| + \| M - K \| \leq \varepsilon + K \]
    %
    Letting $\varepsilon \to 0$, we find $N \in A_+$. To prove (b), we apply the inequality in the lemma to conclude
    %
    \[ \| M + N - (\| M \| + \| N \| ) \| \leq \| M - \| M \| \| + \| N - \| N \| \| \leq \| M \| + \| N \| \]
    %
    So $M + N \in A_+$. Since $\sigma(\lambda M) = \lambda \sigma(M)$, we obtain (c). To prove (d), suppose $M \in A_+ \cap -A_+$. Then $\sigma(M) = \{ 0 \}$, and since $M$ is normal, this means that
    %
    \[ \| M \| = r(M) = 0. \qedhere \]
\end{proof}

The next corollary is an analogy of the result over the real numbers that if $|x| \leq 0$, then $x = 0$.

\begin{lemma}
    Let $A$ be a $C^*$ algebra. If $M \in A$, and $-M^*M \in A_+$, then $M = 0$.
\end{lemma}
\begin{proof}
    Since
    %
    \[ \sigma(MM^*) \cup \{ 0 \} = \sigma(M^*M) \cup \{ 0 \} \]
    %
    which can be proved by some algebraic tricks, $-MM^* \in A_+$ as well. If we write $M = T + iS$, where $T$ and $S$ are self-adjoint, then
    %
    \[ M^*M + MM^* = (T - iS)(T + iS) + (T + iS)(T - iS) = 2(T^2 + S^2) \in A_+ \]
    %
    Thus
    %
    \[ M^*M = 2(T^2 + S^2) - MM^* \in A_+ \]
    %
    which implies $M^*M = 0$.
\end{proof}

\begin{prop}
    Let $A$ be a $C^*$ algebra. The following are equivalent:
    %
    \begin{enumerate}
        \item[(a)] $M \in A_+$.
        \item[(b)] There is $N \in A_+$ such that $M = N^2$.
        \item[(c)] There is $N \in A$ such that $N^*N = M$.
    \end{enumerate}
\end{prop}
\begin{proof}
    We have already show (a) implies (b). The proof of (c) from (b) is trivial. To prove (a) from (c), note that if $M = N^*N$, then $M$ is certainly self-adjoint, so we may write $M = M_+ - M_-$. Let $L = NM_-$. Then
    %
    \[ - L^*L = - M_-N^*NM_- = - M_- M M_- = M_-^3 \in A_+ \]
    %
    Implying $NM_- = 0$, hence
    %
    \[ 0 = N^*L = N^*NM_- = -M_-^2 \in A_+ \]
    %
    This implies $M_- = 0$, so $M = M_+ \in A_+$.
\end{proof}

For $M$ lying in a $C*$ algebra $A$, we are thus inclined to define $|M| = \sqrt{MM^*}$, for any $M \in A$, which is a positive element.

\begin{prop}
    Let $A$ be a $C^*$ algebra. If $M \leq N$, then
    %
    \begin{enumerate}
        \item[(a)] $M + L \leq N + L$.
        \item[(b)] $L^*ML \leq L^*NL$.
    \end{enumerate}
    %
    If in addition, $0 \leq M \leq N$, then
    %
    \begin{enumerate}
        \item[(c)] $\| M \| \leq \| N \|$.
        \item[(d)] $\sqrt{M} \leq \sqrt{N}$.
    \end{enumerate}
    %
    and if $M, N \in GL(A)$, then
    %
    \begin{enumerate}
        \item[(e)] $0 \leq N^{-1} \leq M^{-1}$
    \end{enumerate}
\end{prop}
\begin{proof}
    (a) is trivial. To prove (b), note that
    %
    \[ L^*(N - M)L = L^*\sqrt{N - M}\sqrt{N - M}L = (\sqrt{N - M} L)^* (\sqrt{N - M} L) \in A_+ \]
    %
    Let us prove (c). If $N$ is positive, then $N \leq \| N \|$, which follows by Gelfand theory. Thus if $M$ and $N$ are positive, then
    %
    \[ 0 \leq M \leq N \leq \| N \| \]
    %
    But then $\phi(M) \leq \| N \|$ for each $\phi$, so $\| M \| \leq \| N \|$.

    Fix $\varepsilon > 0$. Write
    %
    \[ (\varepsilon + \sqrt{N} + \sqrt{M})(\varepsilon + \sqrt{N} - \sqrt{M}) = T \]
    %
    where $T,U \in A$ are self adjoint. By calculation
    %
    \[ T = \varepsilon^2 + 2 \varepsilon \sqrt{N} + N - M \geq \varepsilon^2 \]
    %
    Thus $T$ is positive and invertible, so $\varepsilon + \sqrt{N} - \sqrt{M}$ is left invertible and therefore invertible. Thus $\varepsilon \not \in \sigma(\sqrt{M} - \sqrt{N})$, and thus
    %
    \[ \sigma(\sqrt{M} - \sqrt{N}) \subset (-\infty, 0) \]
    %
    But this implies $\sqrt{N} - \sqrt{M}$ is positive.

    If $M \geq \varepsilon$, then $M^{-1} \leq 1/\varepsilon$, which follows by Gelfand theory, since $\phi(M^{-1}) = \phi(M)^{-1}$. Since
    %
    \[ 1 = \sqrt{M}^{-1}M\sqrt{M}^{-1} \leq \sqrt{M}^{-1} N \sqrt{M}^{-1} \]
    %
    this yields
    %
    \[ \sqrt{M} N^{-1} \sqrt{M} \leq 1 \]
    %
    and by conjugation again,
    %
    \[ N^{-1} = \sqrt{M}^{-1} \sqrt{M} N^{-1} \sqrt{M} \sqrt{M}^{-1} \leq M^{-1}. \qedhere \]
\end{proof}

\section{Positive Approximate Units}

We now show that all $C^*$ algebras have \emph{approximate units}, which are bounded approximate identities which are also increasing nets, in the sense of the positive ordering on the $C^*$ algebra.

\begin{lemma}
    If $0 \leq M \leq N$, then $M(1 + M)^{-1} \leq N(1 + N)^{-1}$.
\end{lemma}
\begin{proof}
    Note that
    %
    \[ M(1 + M)^{-1} = 1 - (1 + M)^{-1}\ \ \ \ \ N(1 + N)^{-1} = 1 - (1 + N)^{-1} \]
    %
    We know $1 + M \leq 1 + N$, so $(1 + N)^{-1} \leq (1 + M)^{-1}$, so
    %
    \[ N(1 + N)^{-1} = 1-(1 + N)^{-1} \leq 1-(1 + M)^{-1} = M(1 + M)^{-1} \]
    %
    which is exactly the inequality we needed.
\end{proof}

\begin{prop}
    For a $C^*$ algebra $A$, the net
    %
    \[ \{ M \in A_+ : \| M \| < 1 \} \]
    %
    ordered by the positivity of the algebra, is a bounded approximate unit.
\end{prop}
\begin{proof}
    The set is a net, because any $M,N \in A_+$ are less than or equal to $\max(\|M\|,\|N\|)$. Fix a self adjoint $M \in A$, and let $\varepsilon > 0$. Let $B$ be the (non-unital) $C^*$ algebra generated by $M$. Then $B$ is commutative, and we can consider the continuous function $m: \Phi_B \to \CC$ given by the Gelfand transform of $M$. Pick a function $i \in C_0(\Phi_B)$ such that $0 \leq i < 1$ and $\| (1 - i) m \| < \varepsilon$, and let $E = i(M)$. Then $\| E \| \leq 1$, $E \geq 0$, and $\| M - ME \| = \| (1 - i) m \|_{L^\infty} < \varepsilon$. If $E \leq E' < 1$, then since $\sigma(\sqrt{1 - E'}) \in [0,1]$, $\| \sqrt{1 - E'} \| < 1$, and so
    %
    \begin{align*}
        \| M - E'M \|^2 &= \| \sqrt{1 - E'}^2 M \|^2 \leq \| \sqrt{1 - E'}\ M \|^2 = \| M(1 - E')M \|\\
        &\leq \| M(1 - E)M \| \leq \| M \| \| (1 - E)M \| < \| M \| \varepsilon.
    \end{align*}
    %
    Decreasing $\varepsilon$ is arbitrary, we find $\lim LM = M$. Similar results show $\lim ML = M$. But this proves the result in general, since any $M \in A$ and be written as $M_1 + i M_2$ for appropriate self-adjoint elements $M_1,M_2 \in A$.
\end{proof}

\begin{remark}
    If $A$ is separable, then we can take a subsequence of the net above which is also an approximate unit. To see this, for any self-adjoint $M \in A$, if $B$ is as in the last proof, then $B$ is separable, $C_0(\Phi_B)$ is separable, and so using the functional calculus, we can find a countable sequence $\{ F_i \in A_+ \}$ such that $M = \lim MF_i = \lim F_iM$. If we let $\{ M_j \}$ be a countable, dense subset of self-adjoint elements of $A$, and let $\{ F_{ji} \in A_+ \}$ be the elements such that $M_j = \lim_i F_{ji} M_j = \lim_i M_j F_{ji}$. If we pick some sequence $\{ E_k \in A_+ \}$ such that $E_k \geq E_{ji}$ for all $i,j \leq k$, then $M_j = \lim_k E_k M_j = \lim_k M_j E_k$ for all $j$, and by density, this implies that $M = \lim_k E_k M = \lim_k M E_k$ for all self-adjoint $M$. Thus any separable $C^*$ algebra has an approximate unit which is a sequence.
\end{remark}

If $A$ is an abelian $C^*$ algebra, then the family of self adjoint elements in $A$ forms a real Riesz lattice, which can be easily seen from an isometric representation $A \cong C(X)$. Thus if $0 \leq M \leq N + L$, where $N,L \in A_+$, then there are $N_0,L_0$ such that $N_0 \leq N$, $L_0 \leq L$, and such that $M = N_0 + L_0$. This theorem does not hold in general nonabelian $C^*$ algebras, but there is a weaker decomposition theorem which does hold.

\begin{prop}
    If $A$ is a $C^*$ algebra, and
    %
    \[ \sum_{i = 0}^m M_i^* M_i = \sum_{j = 0}^n N_i^* N_i \]
    %
    then there are $L_{i,j}$ such that
    %
    \[ M_i^* M_i = \sum_j L_{i,j}^* L_{i,j}\ \ \ \ \ \ N_j^* N_j = \sum_i L_{i,j}^* L_{i,j} \]
\end{prop}
\begin{proof}
    We may assume $A$ is unital. TODO
\end{proof}







\section{Ideals and Quotients of $C^*$ Algebras}

If we quotient a $C^*$ algebra by a closed ideal, we certainly get a Banach algebra. But does this algebra still have an involution? Or do we need to apply additional structure to our ideals? Such discussions will naturally lead to the Gelfand Naimark construction, establishing that every $C^*$ algebra is isometric to some subalgebra of bounded operators on a Hilbert space. Thus this endeavor will prove very fruitful. Unless stated otherwise, by an ideal of a $C^*$ algebra we mean a closed, two-sided ideal. Left and right ideals are also assumed to be closed unless stated otherwise.

\begin{lemma}
    If $\IA$ is a closed left/right ideal in a $C^*$ algebra $A$ containing a self-adjoint element $M$, and if $f \in C(\sigma(M))$ satisfies $f(0) = 0$, then $f(M) \in \mathfrak{a}$.
\end{lemma}
\begin{proof}
    We may approximate $f(M)$ on $C(\sigma(M))$ by polynomial expressions of the form $a_1 M + \dots + a_n M^n$. Such expressions all lie in $\IA$, and because $\IA$ is closed, this implies $f(M)$ is closed.
\end{proof}

\begin{corollary}
    If $M \in \IA$ is self adjoint, then $M_+$, $M_-$, $|M|$, and $\sqrt{M}$ are all in $\IA$.
\end{corollary}

\begin{lemma}
    Let $A$ be a $C^*$ algebra. Then every ideal of $A$ is self-adjoint.
\end{lemma}
\begin{proof}
    Let $\mathfrak{a}$ be an ideal of $A$. Then $\mathfrak{a}^*$ is also an ideal. Let $\mathfrak{b} = \mathfrak{a} \cap \mathfrak{a}^*$. Then $\mathfrak{b}$ is a $C^*$ subalgebra of $A$ containing $\mathfrak{a} \mathfrak{a}^*$. We therefore know from the last section that $\mathfrak{b}$ has an approximate unit $\{ E_\alpha \}$. But this means that for any $M \in \mathfrak{a}$,
    %
    \begin{align*}
        \| M^* - M^* E_\alpha \|^2 &= \| (M - E_\alpha M) (M^* - M^* E_\alpha) \|\\
        &= \| MM^*(1 - E_\alpha) + (1 - E_\alpha) MM^* E_\alpha \|\\
        &\leq \| MM^* (1 - E_\alpha) \| + \| (1 - E_\alpha) MM^* \|.
    \end{align*}
    %
    Both of these quantities converge to zero as $\alpha \to \infty$, since $MM^* \in \mathfrak{b}$. Thus we find that $M^* = \lim_\alpha M^* E_\alpha$. But $M^* E_\alpha \in \mathfrak{a}$, so $M^* \in \mathfrak{a}$. But this means $\mathfrak{a}$ is self-adjoint.
\end{proof}

It follows from this result that if $A$ is a $C^*$ algebra, and $\mathfrak{a}$ is an ideal, then $A / \mathfrak{a}$ will be a Banach-$*$ algebra, since the involution naturally respects equivalence classes, and moreover, because $\mathfrak{a}$ is self-adjoint,
%
\[ \| M + \mathfrak{a} \| = \inf_{N \in A} \| M + N \| = \inf_{N \in A} \| M^* + N^* \| = \inf_{N \in A} \| M^* + N \| = \| M^* + \mathfrak{a}. \]
%
Thus the involution is an isometry.

A subalgebra $B$ of a $C^*$ algebra $A$ is called \emph{hereditary} if whenever $M \in B_+$ and $M \geq N$ for some $N \in A_+$, we have $N \in B$. To show that quotients of $C^*$ algebras remain $C^*$ algebras, we shall now show that all ideals in a $C^*$ algebra are hereditary.

\begin{lemma}
    Let $A$ be a $C^*$ algebra. If $|M|^2 \leq N$, then there is $L \in A$ with $\| L \| \leq \| N \|^{1/4}$ such that $M = LN^{1/4}$.
\end{lemma}
\begin{proof}
    Let
    %
    \[ L_n = M(N + 1/n)^{-1/2} N^{1/4}, \]
    %
    which is well-defined in $A$ even if $A$ is non-unital. Nonetheless, the following calculation will be done in the unitization of $A$. If
    %
    \[ D_{nm} = (N + 1/n)^{-1/2} - (N + 1/m)^{-1/2}, \]
    %
    we find that
    %
    \begin{align*}
        \| L_n - L_m \|^2 &= \| M D_{nm} N^{1/4} \|^2\\
        &= \| N^{1/4} D_{nm} M^* M D_{nm} N^{1/4} \|\\
        &\leq \| N^{1/4} D_{nm} N D_{nm} N^{1/4} \|\\
        &= \| D_{nm} N^{3/4} \|^2\\
        &= \| f_n(N) - f_m(N) \|^2\\
        &\leq \| f_n - f_m \|_{L^\infty(\sigma(N))},
    \end{align*}
    %
    where
    %
    \[ f_n(t) = (t + 1/n)^{-1/2} t^{3/4}. \]
    %
    But $f_n$ converges locally uniformly on $[0,\infty)$ to $t^{1/4}$, which means that $\| L_n - L_m \|$ is Cauchy. Thus we have $L = \lim L_n$ for some $L \in A$. Similarily, we find that $(N + 1/n)^{-1/2} N^{1/2}$ converges locally uniformly to the identity, so that
    %
    \[ LN^{1/4} = \lim_n L_n N^{1/4} = \lim_n M (N + 1/n)^{-1/2} N^{1/2} = M. \qedhere \]
\end{proof}

\begin{theorem}
    Let $A$ be a $C^*$ algebra. Then any ideal $\mathfrak{a}$ of $A$ is hereditary.
\end{theorem}
\begin{proof}
    Suppose $0 \leq M \leq N$, and $N \in \mathfrak{a}$. Then we can write $M = T^*T$ for some $T \in A$. The Lemma above finds that $T = LN^{1/4}$ for some $L \in A$. Since $N^{1/4} \in \mathfrak{a}$, $T \in \mathfrak{a}$, and thus $M = T^*T \in \mathfrak{a}$.
\end{proof}

\begin{theorem}
    If $A$ is a $C^*$ algebra, and $\IA$ is an ideal, then $A / \IA$ is a $C^*$ algebra.
\end{theorem}
\begin{proof}
    All that remains to be checked is that for any $M \in A$,
    %
    \[ \| M^* M + \IA \| = \| M + \IA \|^2. \]
    %
    If $\{ E_\alpha \}$ is an approximate identity for $\IA$, then we claim that for any $N \in A$, $\lim_\alpha \| N(1 - E_\alpha) \|$ converges, and
    %
    \[ \| N + \IA \| = \lim_\alpha \| N(1 - E_\alpha) \|. \]
    %
    To see the limit exists, note that for $\alpha_1 \leq \alpha_2$, using the construction of the approximate identity using the functional calculus, we can write $(1 - E_{\alpha_2}) = (1 - E_{\alpha_1}) L$ for some $L \in A$ with $\| L \| \leq 1$, and then we conclude that
    %
    \[ \| N(1 - E_{\alpha_2}) \| = \| N (1 - E_{\alpha_1}) L \| \leq \| N (1 - E_{\alpha_1}) \|. \]
    %
    Thus the net is monotonically decreasing and bounded from below, and thus converges. Now we certainly have $\| N + \IA \| \leq \lim_\alpha \| N(1 - E_\alpha) \|$ since $N E_\alpha \in \IA$. On the other hand, for any $\varepsilon > 0$, we can find $L \in \IA$ such that
    %
    \[ \| N + \IA \| \geq \| N + L \| - \varepsilon. \]
    %
    But then
    %
    \begin{align*}
        \lim_\alpha \| N(1 - E_\alpha) \| &\leq \lim_\alpha \| (N - L)(1 - E_\alpha) \| + \| L(1 - E_\alpha) \|\\
        &\leq  \| N - L \| + 0\\
        &\leq \| N + \IA \| + \varepsilon.
    \end{align*}
    %
    Taking $\varepsilon \to 0$ completes the proof of the claim. And now we see that
    %
    \begin{align*}
        \| M^* M + \IA \|^2 = \lim_\alpha \| M^* M (1 - E_\alpha) \|^2\\
        &\geq \lim_\alpha \| (1 - E_\alpha) M^* M (1 - E_\alpha) \|^2\\
        &= \lim_\alpha \| M (1 - E_\alpha) \|^4\\
        &= \| M + \IA \|^4.
    \end{align*}
    %
    Taking square roots gives the required condition.
\end{proof}

Thus if $\mathfrak{a}$ is a closed ideal in a $C^*$-algebra $A$, then $A/\mathfrak{a}$ is verified to be a Banach $*$ algebra. It is only a little more work now to verify that $A/\mathfrak{a}$ is a $C^*$ algebra.

\begin{lemma}
    If $\mathfrak{a}$ is a closed ideal of $A$, and $\{ E_\alpha \}$ is the positive BAI for $\mathfrak{a}$, then $A/\mathfrak{a}$, then for any $M \in A$,
    %
    \[ \| M + \mathfrak{a} \| = \lim \| M - E_\alpha M \| = \lim \| M - M E_\alpha \| \]
\end{lemma}
\begin{proof}
    Fix $M \in A$, and let $\{ E_\alpha \}$ be the positive BAI for $\mathfrak{a}$. Choose $\varepsilon > 0$, and let $N \in \mathfrak{a}$ satisfy $\| M + N \| \leq \| M + \mathfrak{a} \| + \varepsilon$. Then
    %
    \begin{align*}
        \limsup_\alpha \| M - E_\alpha M \| &\leq \limsup_\alpha \| (1 - E_\alpha)(M + N) \| + \| E_\alpha N - N \|\\
        &\leq \limsup_\alpha \| (1 - E_\alpha)(M + N) \| + \limsup_\alpha \| N - E_\alpha N \|\\
        &= \limsup_\alpha \| (1 - E_\alpha) (M + N) \|\\
        &\leq \| M + N \| \leq \| M + \mathfrak{a} \| + \varepsilon
    \end{align*}
    %
    and $\varepsilon$ was arbitrary, so
    %
    \[ \limsup_\alpha \| M - E_\alpha M \| \leq \| M + \mathfrak{a} \| \]
    %
    But $E_\alpha M \in \mathfrak{a}$, so for each $\alpha$,
    %
    \[ \| M - E_\alpha M \| \geq \| M + \mathfrak{a} \| \]
    %
    and since we have bounded the $\limsup$ above and below by the same value, it is in fact a limit, and has value $\| M + \mathfrak{a} \|$. Similar results hold for $\| M - M E_\alpha \|$.
\end{proof}

The lemma makes sense, for $E_\alpha$ approximates elements of $\mathfrak{a}$ as best as possible, so subtracting $E_\alpha M$ subtracts the best approximation of $M$ in $\mathfrak{a}$, thus giving us the quotient norm.

\begin{theorem}
    If $\mathfrak{a}$ is a closed ideal of a $C^*$ algebra $A$, then $A/\mathfrak{a}$ is a $C^*$ algebra.
\end{theorem}
\begin{proof}
    Letting $\{ E_\alpha \}$ be the positive approximate identity for $\mathfrak{a}$, we find
    %
    \begin{align*}
        \| M + \mathfrak{a} \|^2 &= \lim_\alpha \| M (1 - E_\alpha) \|^2\\
        &= \lim_\alpha \| (1 - E_\alpha) M^*M (1 - E_\alpha) \|\\
        &\leq \lim_\alpha \| (1 - E_\alpha) M^*M \|\\
        &= \| M^*M + \mathfrak{a} \|\\
        &\leq \| M^* + \mathfrak{a} \| \| M + \mathfrak{a} \|
    \end{align*}
    %
    And it is easy to see that $\| M^* + \mathfrak{a} \| = \| M + \mathfrak{a} \|$, for $\mathfrak{a}$ is closed under involution, so we find
    %
    \[ \| M + \mathfrak{a} \|^2 = \| M^*M + \mathfrak{a} \| \]
    %
    and this is exactly the $C^*$ identity for the quotient algebra.
\end{proof}

Thus every $*$-morphism is continuous. We shall find that injective $*$-morphisms are isometries. To prove this, we must first verify a corresponding theorem about continuous functions on a locally compact space, which says that the uniform norm on $C(X)$ is the sharpest algebra norm we can have.

\begin{lemma}
    Let $X$ be a compact Hausdorff space, and let $\vvvert \cdot \vvvert$ be a submultiplicative norm on $C(X)$. Then for any $f \in C(X)$,
    %
    \[ \| f \|_{L^\infty(X)} \leq \vvvert f \vvvert. \]
\end{lemma}
\begin{proof}
    Let $A$ be the Banach algebra formed by completing $C(X)$ with respect to the norm $\vvvert \cdot \vvvert$. Then $A$ is a Banach algebra, and since $C(X) \subset A$, for any $f \in C(X)$, $r_{C(X)}(f) \leq r_A(f)$. Thus
    %
    \[ \| f \|_{L^\infty(X)} = r_{C(X)}(f) \leq r_A(f) \leq \vvvert f \vvvert. \qedhere \]
\end{proof}

\begin{lemma}
    Let $A$ and $B$ be $C^*$ algebras (possibly without unit), and let $\pi: A \to B$ be a nont-necessarily continuous non-zero $*$-algebra homomorphism (in particular, if $\pi$ is a unital $*$-algebra homomorphism). Then $\pi$ is continuous, $\| \pi \| = 1$, $\pi(A)$ is a $C^*$ subalgebra of $B$, and $\pi$ induces an isometry from $A/\IA$ to $B$, where $\IA$ is the kernel of $\pi$.
\end{lemma}
\begin{proof}
    For $M \in A$, we have
    %
    \[ \| \pi(M) \| = \sigma(\pi(M)) \leq \sigma(M) = \| M \|, \]
    %
    so $\| \pi \| \leq 1$. Thus $\pi$ is continuous. Thus the kernel $\IA$ of $\pi$ is closed, and $\pi$ factors through $A/\IA$. Thus for the remainder of the argument, we can switch $A$ with $A / \IA$ and assume $\pi$ is injective. If $\pi$ was not an isometry, there would be $M \in A$ such that $t = \| \pi(M) \| < \| M \| = r$. Then $\| \pi(M^*M) \| < \| M^*M \|$, so we may assume without loss of generality that $M \in A_+$. Let $f: \RR \to \RR$ is a continuous function vanishing on $[0, t]$ and with $f(r) = 1$. Then $f(\pi(M)) = 0$, but $f(M) \neq 0$ since $\sigma(f(M)) = f(\sigma(M)) \neq \{ 0 \}$, contradiction the fact that $\pi$ is injective. Thus $\pi$ is an isometry, from which it follows that $\pi(A)$ is closed, and thus a $C^*$ subalgebra of $B$, and that $\| \pi \| = 1$.
\end{proof}

Thus to calculate the norm on $A/\IA$, it is often easier to find a homomorphism $\pi: A \to B$ with $\IA$ the kernel of $\pi$, so that $\| M + \IA \| = \| \pi(M) \|$.

\begin{example}
    We have calculated that all closed ideals of $C(X)$ are of the form
    %
    \[ \mathfrak{a}_K = \{ f \in C(X) : (\forall x \in K: f(x) = 0) \} \]
    %
    for some closed set $K$. Then $C(X)/\mathfrak{a}_K$ is isometric to $C(K)$, because we have the $C^*$ homorphism $f \mapsto f|_K$, and $\mathfrak{a}_K$ is the kernel.
\end{example}

\begin{example}
    Let $H$ be a Hilbert space, and $\mathfrak{a}$ a closed ideal of $B(H)$. If $\mathfrak{a} \neq (0)$, we claim $K(H) \subset \mathfrak{a}$. For any $x,y \in H$, let $x \otimes y \in B(H)$ be the map
    %
    \[ z \mapsto \langle z, y \rangle x \]
    %
    Because $H$ satisfies the approximation property, $K(H)$ is the closed span of the family $\{ x \otimes y: x,y \in H \}$. If $T \in \mathfrak{a}$ and $T \neq 0$, then there are $v,w$ such that $\langle Tv, w \rangle = 1$. Then
    %
    \[ (x \otimes y) = (x \otimes w) \circ (Tv \otimes y) = (x \otimes w) \circ T \circ (v \otimes y) \in \mathfrak{a} \]
    %
    from which we obtain, since $x \otimes y$ was arbitrary, that $K(H) \subset \mathfrak{a}$. As a special case of this, if $H$ is finite dimensional, with some $n = \dim(H)$, we see that $B(H)$, which can be identified with the algebra $M_n(\CC)$ of $n \times n$ matrices, is simple, i.e. the algebra has no non-trivial ideals. The standard proof that $M_n(\CC)$ is simple, which we briefly described in the section on Gelfand theory in these notes, is essentially a version of this argument stated in the language of matrices.

    In a separable Hilbert space $H$, the \emph{only} closed ideals of $B(H)$ are $\{ 0 \}$, $K(H)$, and $B(H)$. To see this, let $\IA$ be an ideal properly containing $K(H)$, and let $T: H \to H$ be a non-compact operator in $\IA$. Without loss of generality, we may assume $T$ is positive semidefinite. TODO: WHEN BETTER AT SPECTRAL THEORY.

    Thus we can consider the \emph{Calkin Algebra} $C(H) = B(H)/K(H)$. This is a $C^*$ algebra that has no nontrivial closed ideals. What makes this algebra interesting is that it has no natural representation as a $C^*$ subalgebra of bounded operators on a Hilbert space (one cannot represent it as a $C^*$ subalgebra of operators on a separable Hilbert space), so it is some sense, an `abstract $C^*$ algebra'.
\end{example}



\begin{lemma}
    If $\pi: A \to B$ is an injective $*$-morphism between abelian $C^*$ algebras, then the dual map $\pi^*$ is surjective.
\end{lemma}
\begin{proof}
    Let
    %
    \[ K = \{ \phi|_A : \phi \in \Phi_B \]
    %
    If $K \neq \Phi_A$, then using the continuous functional calculus, we may find non-zero $f$ and $g$ which vanish at $K$, for which $f = fg$. Then $1 \in \sigma(g)$, so there is $\phi \in \Phi_B$ such that $\phi(g) = 1$. But this is clearly impossible.
\end{proof}

\begin{prop}
    An injective, continuous morphism $\pi: A \to B$ from a $C^*$ algebra to a Banach algebra satisfies
    %
    \[ \| M \| \leq \| \pi \| \| \pi(M) \| \]
\end{prop}
\begin{proof}
    Given $M$, let $A_0 = C^*(M^*M)$. Define a norm on $A_0$ by letting
    %
    \[ \vvvert{N} = \| \pi(N) \| \]
    %
    Then $\| \cdot \| \leq \vvvert{\cdot}$, and
    %
    \[ \| M \|^2 = \| M^*M \| \leq \vvvert{M^*M} = \| \pi(M^*M) \| \leq \| \pi \| \| M \| \| \pi(M) \| \]
    %
    which yields the claim.
\end{proof}

\begin{corollary}
    Let $\pi: A \to B$ be a $*$ homomorphism between $C^*$ algebras. Then $\pi(A)$ is a closed $C^*$ algebra, and $\pi$ is an isometry if it is injective.
\end{corollary}
\begin{proof}
    If $\pi$ is injective, it certainly has closed range by the last proposition. But in general, letting $\mathfrak{a} = \ker(\pi)$, $\pi$ induces an injective map
    %
    \begin{center}
    \begin{tikzcd}
        A \arrow{r}{\pi} \arrow{d}{} & B \\
        A/\mathfrak{a} \arrow{ru}{\tilde{\pi}}
    \end{tikzcd}
    \end{center}
    %
    and $\pi(A) = \tilde{\pi}(A)$ is closed. Thus if $\pi$ is injective we obtain an inverse $*$ homomorphism $\pi^{-1}: \pi(A) \to A$, and both must be contractible, hence isometries.
\end{proof}

\begin{prop}
    If $B$ is a $C^*$ subalgebra of $A$, and $\mathfrak{a}$ a closed ideal of $A$, then $B + \mathfrak{a}$ is a $C^*$ subalgebra of $A$.
\end{prop}
\begin{proof}
    Completeness is a three space property, and since $\mathfrak{a}$ is complete, we need only show that $(B + \mathfrak{a})/\mathfrak{a}$ is complete, and from this we will obtain completeness. Let $\pi: A \to A/\mathfrak{a}$ be the quotient map. But the composed $*$ morphism $\psi$ defined by
    %
    \[ B \to A \to A/\mathfrak{a} \]
    %
    tells us that the image of $B$ is closed, and
    %
    \[ \psi(B) = (B + \mathfrak{a})/\mathfrak{a} \]
    %
    so $(B + \mathfrak{a})/\mathfrak{a}$ is complete.
\end{proof}




\subsection{Positive Operators}

Every $C^*$ algebra is essentially a ring of bounded operators on a Hilbert space. The challenge is to construct a canonical Hilbert space from a $C^*$ algebra. The study of a certain subclass of operators will be essential. A \emph{positive} operator $\phi: A \to \mathbf{C}$ on a $C^*$ algebra maps $A_+$ into $[0,\infty)$. Certainly the set of positive maps form a real subspace of $A^*$.

\begin{example}
    If $\phi \in \Phi_A$, then $\phi$ is positive, for
    %
    \[ \phi(M^*M) = |\phi(M)|^2 \]
    %
    and every positive element can be written in the form $M^*M$.
\end{example}

\begin{example}
    If $X$ is locally compact and Hausdorff, and $\mu$ is a complex Borel measure on $X$, then the functional
    %
    \[ f \mapsto \int f d\mu \]
    %
    from $C_0(X)$ to $\mathbf{C}$ is positive if and only if $\mu$ is a positive measure.
\end{example}

\begin{example}
    Consider the trace map $\text{tr}: M_n(\mathbf{C}) \to \mathbf{C}$. Any positive matrix $M$ can be, by a change of basis, put into the form
    %
    \[ \begin{pmatrix} \lambda_1 & 0 & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ 0 & 0 & \ddots & 0 \\ 0 & 0 & \dots & \lambda_n \end{pmatrix} \]
    %
    where $\lambda_1, \dots, \lambda_n \geq 0$. The trace is invariant of a change in basis, and thus
    %
    \[ \text{tr}(M) = \sum \lambda_i \geq 0 \]
    %
    Thus the trace is positive.
\end{example}

\begin{example}
    For a fixed $x \in H$, the map $T \mapsto \langle Tx, x \rangle$ is positive.
\end{example}

One need not verify continuity for positive operators, for we obtain this automatically.

\begin{prop}
    A positive operator $\phi:A \to \mathbf{C}$ is continuous.
\end{prop}
\begin{proof}
    We claim the supremum
    %
    \[ K = \sup \{ \phi(M): M \in A_+, \| M \| \leq 1 \} \]
    %
    is finite. Otherwise, we may pick a sequence $M_1, M_2, \dots$ with $\| M_i \| \leq 1$ and $\phi(M_i) \geq 4^n$. Let
    %
    \[ M = \sum \frac{M_i}{2^i} \]
    %
    Then for each $n$, $2^n M \geq M_n$, so
    %
    \[ \phi(M) \geq \frac{\phi(M_n)}{2^n} \geq \frac{4^n}{2^n} = 2^n \]
    %
    which yields an immediate contradiction.

    Now suppose that $M$ is an arbitrary operator, choose self adjoint $N$ and $L$ in $A$ such that
    %
    \[ M = N + iL = N_+ - N_- + iL_+ - iL_- \]
    %
    Then if $\| M \| \leq 1$,
    %
    \[ |\phi(M)| = |\phi(N_+) - \phi(N_-) + i\phi(L_+) - i\phi(L_-)| \leq 4K \]
    %
    which shows that $\phi$ is continuous.
\end{proof}

\begin{theorem}
    The following are equivalent
    %
    \begin{enumerate}
        \item $\phi$ is positive operator.
        \item For every BAI $E_\alpha$ contained within the positive identity on $A$,
        %
        \[ \| \phi \| = \lim_\alpha \phi(E_\alpha) \]
        \item There is a BAI $E_\alpha$ in the positive identity on $A$ for which
        %
        \[ \| \phi \| = \lim_\alpha \phi(E_\alpha) \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| \phi \| = 1$. Suppose $\phi$ is positive. Fix an approximate identity $E_\alpha$. Then
    %
    \[ \limsup_\alpha \phi(E_\alpha) \leq 1 \]
    %
    On the other hand, when $\| M \| \leq 1$,
    %
    \[ |\phi(M)|^2 = \lim |\phi(E_\alpha M)|^2 \leq \liminf_\alpha \phi(E_\alpha^2) \phi(M^*M) \]
\end{proof}







\chapter{Spectral Theory for Normal Operators}

\section{Resolutions of the Identity}

If $X$ is a measure space and $H$ is a Hilbert space, then a \emph{resolution of the identity} on $X$ is a mapping $E$ from measurable subsets of $X$ to self-adjoint projections $B(H)$, such that $E(\emptyset) = 0$, $E(X) = I$, such that $E(S_1 \cap S_2) = E(S_1) E(S_2)$, if $S_1$ and $S_2$ are disjoint, $E(S_1 \cup S_2) = E(S_1) + E(S_2)$, and for any $x,y \in H$, the map $E_{x,y}(S) = \langle E(S) x, y \rangle$ is a complex measure. If $X$ is a topological space equipped with the measure space structure given by Borel sets, then we will implicitly assume that each $E_{x,y}$ is a regular Borel measure.

A consequence of these assumptions is that all projections in the image of $E$ commute with one another, and that if $S_1$ and $S_2$ are disjoint, $E(S_1)$ and $E(S_2)$ are orthogonal to one another. $E$ is certainly finitely additive, but except in trivial situations, is \emph{not} countably additive in the topology of $B(H)$, since projections have norm one. On the other hand, the measure \emph{is} countably additive in the strong operator topology on $B(H)$, i.e. for each $x \in H$, if $\{ S_n \}$ are disjoint, and $S = \bigcup S_n$, then
%
\[ \sum_{n = 1}^\infty E(S_n) x = E(S) x, \]
%
because the series converges absolutely, i.e. by the orthogonality of the projections $E(S_n)$,
%
\[ \sum_{n = 1}^\infty \| E(S_n) x \|^2 \leq \| x \|^2. \]
%
We will use resolutions of the identity to obtain a very general functional calculus on operators.

If $E$ is a resolution to the identity, we let $f: X \to \CC$ be a measurable function. The \emph{essential range} of $f$ is the complement of the set formed from the union of all open discs $D \subset \CC$ with $E(f^{-1}(D)) = 0$. The function $f$ is essentially bounded if it's range is bounded, and we can then define $\| f \|_{L^\infty(X,E)}$ to be the maximum modulus of an element of the essential range of $f$. The quotient of the family of essentially bounded functions by the closed ideal of functions $f$ with $\| f \|_{L^\infty(X,E)} = 0$ is a Banach algebra denote by $L^\infty(X,E)$. In this Banach algebra, $\sigma(f)$ is precisely the essential range of $f$. We now define a way to integrate elements of $L^\infty(X,E)$ against the resolution $E$. The integral will not only be linear, but even \emph{multiplicative}. Recall that a closed normal subalgebra of $B(H)$ is a commutative subalgebra closed under taking adjoints.

\begin{theorem}
    For any resolution of the identity $E$, there exists an isometric map $L^\infty(X,E) \to B(H)$ onto a closed normal subalgebra $A$ of $B(H)$, such that if we denote the image of $f \in L^\infty(X,E)$ under this map by
    %
    \[ \int_X f dE, \]
    %
    then for any $x,y \in H$,
    %
    \[ \left\langle \left(\int_X f dE \right) x, y \right\rangle = \int f dE_{x,y}, \]
    %
    and
    %
    \[ \left\| \left( \int_X f dE \right) x \right\|^2 = \int_X |f|^2 dE_{x,x}. \]
    %
    An operator $M \in B(H)$ commutes with every $E(S)$ if and only if $M$ commutes with every element of $A$, and
    %
    \[ \| f \|_{L^\infty(X,E)} = \sup_{\| x \| \leq 1} \left( \int_X |f|^2 dE_{x,x} \right)^{1/2}. \]
\end{theorem}
\begin{proof}
    TODO: Not that interesting.
\end{proof}

The spectral theorem for normal operators on a Hilbert space says that each normal $T \in B(H)$ induces a canonical resolution $E$ on Borel subsets of $\sigma(T)$ which allows us to reconstruct $T$. We can do things in a more general light, by simultaneously performing the spectral theorem for any subalgebra of $B(H)$, all of whose elements are normal.

\begin{theorem}
    Suppose that $A$ is a closed normal unital subalgebra of $B(H)$, and let $\Phi_A$ be the maximal ideal space of $A$. Then there exists a unique resolution $E$ on the Borel sets of $\Phi_A$ such that
    %
    \[ T = \int_{\Phi_A} \widehat{T}\; dE, \]
    %
    where $\widehat{T}$ is the Gelfand transform of $T$. The inverse of the Gelfand transform from $C(\Phi_A)$ to $A$ extends to an isometric $*$ isomorphism $\Phi$ of $L^\infty(X,E)$ onto a closed subalgebra $B$ of $B(H)$ containing $A$, where the inverse is given by
    %
    \[ f \mapsto \int_{\Phi_A} f dE. \]
    %
    The subalgebra $B$ is the closure (in the topology of $B(H)$) of all finite linear combinations of the projections in the image of $E$. Moreover, if $U$ is a nonempty open subset of $\Phi_A$, then $E(U) \neq 0$. An operator $S \in B(H)$ commutes with every element of $A$ if and only if $S$ commutes with every projection in the image of $E$.
\end{theorem}
\begin{proof}
    TODO
\end{proof}

In particular, if $T \in B(H)$ is a normal operator, then there exists a unique resolution of the identity on Borel subsets of $\sigma(T)$ such that
%
\[ T = \int_{\sigma(T)} \lambda dE(\lambda) \]
%
and if $S$ commutes with $T$, every projection in the image of $E$ commutes with $S$. We can extend $E$ to a resolution on $\CC$ by setting $E(S) = 0$ if $S \cap \sigma(T) = \emptyset$. We call $E$ in this case the \emph{spectral decomposition} of $T$. To obtain this result from the more general result, we consider the smallest closed subalgebra $A$ of $B(H)$ containing $T$, $T^*$ and the identity. Then $A$ is a normal (in fact, a commutative) algebra, and $\Phi_A$ can be identified with $\sigma(T)$ in such a way that $\widehat{T}(\lambda) = \lambda$ for each $\lambda \in \sigma(T)$. In this case, the inverse map from $L^\infty(\sigma(T),E)$ to $B(H)$ is denoted by $f \mapsto f(T)$. In this special case, we find that $\| f(T) \| \leq \| f \|_{L^\infty(X)}$ (defined by a pointwise supremum rather than an essential supremum), where this is an equality if $f \in C(\sigma(T))$, since then $\| f \|_{L^\infty(X,E)} = \| f \|_{L^\infty(X)}$ by virtue of the fact that if $U \subset \CC$ is open, then $E(U) \neq 0$. Intuitively, we can think of $dE(\lambda)$ as giving an `infinitisimal projection' onto the eigenspace corresponding to the eigenvalue $\lambda$. Let us consider some applications of this symbolic calculus.

\begin{theorem}
    If $T \in B(H)$ is normal, then
    %
    \[ \| T \| = \sup_{\|x\| \leq 1} |\langle Tx, x \rangle|. \]
\end{theorem}
\begin{proof}
    If scalars in $\sigma(T)$ always corresponded to eigenvectors, then this result would follow from the fact that $\| T \| = \sigma(T)$. But elements of $\sigma(T)$ do not always correspond to eigenvectors. On the other hand, we will use the spectral theorem to produce `almost eigenvectors' for $T$, which will suffice for our purposes. Since $T$ is normal, we know that $\| T \|$ is equal to the spectral radius of $T$. Thus for any $\lambda_0 \in \sigma(T)$ with $|\lambda_0| = \| T \|$. let $B_\varepsilon$ be a ball of radius $\varepsilon$ centred at $\lambda_0$. Then if $E$ is the resolution associated with $T$, we know that $E(B_\varepsilon) \neq 0$. Since $E(B_\varepsilon)$ is a projection, we may find $x \in H$ such that $E(B_\varepsilon) x = x$ and such that $\| x \| = 1$. If $f(\lambda) = (\lambda - \lambda_0) \mathbf{I}_{B_\varepsilon}$, then
    %
    \[ f(T) = (T - \lambda_0) E(B_\varepsilon) \]
    %
    and so $f(T) x = Tx - \lambda_0 x$. Now $\| f \|_{L^\infty} \leq \varepsilon$, so it follows that $\| f(T) x \| \leq \varepsilon$, which implies that
    %
    \[ |\langle Tx, x \rangle - \lambda_0| = |\langle f(T)x, x \rangle - \lambda_0| \leq \| f \|_{L^\infty} \leq \varepsilon. \]
    %
    This implies the required result.
\end{proof}

\begin{remark}
    If $T: \CC^2 \to \CC^2$ is given by $T(a,b) = (b,0)$, then $\langle T(a,b), (a,b) \rangle = ab$, and so $|\langle Tx, x \rangle| \leq 1/2$ if $\| x \| \leq 1$. But $\| T \| = 1$.
\end{remark}

Similar arguments, left as an exercise, show that a normal operator $T \in B(H)$ is self-adjoint if and only if $\sigma(T) \subset \RR$, and unitary if and only if $\sigma(T)$ is contained on the unit circle. This need not be true for general operators (e.g. non orthogonal projections are not self-adjoint).

\begin{theorem}
    Let $T \in B(H)$ be normal, and let $E$ be it's spectral decomposition. If $f \in C(\sigma(T))$ and $S = f^{-1}(0)$, then the kernel of $f(T)$ is equal to the range of $E(S)$.
\end{theorem}
\begin{proof}
    If $g = \mathbf{I}_S$, then $f \cdot g = 0$, and so $f(T) g(T) = f(T) E(S) = 0$, which shows the range of $E(S)$ is contained in the kernel of $f(T)$. Conversely, suppose $x \in H$ and $f(T) x = 0$. For each $\varepsilon > 0$, let
    %
    \[ g_\varepsilon(x) = \frac{1}{f(x)} \mathbf{I}_{S_\varepsilon^c}(x). \]
    %
    Since $f$ is continuous, $g_\varepsilon \in L^\infty(\sigma(T))$ for all $\varepsilon > 0$. And $f \cdot g_\varepsilon = \mathbf{I}_{S_\varepsilon^c}$, so that $E(S_\varepsilon^c) x = g_\varepsilon(T) f(T) x = 0$. Countable additivity shows that $E(S^c) x = 0$, which shows by orthogonality of $E(S)$ and $E(S^c)$ that $x$ is in the range of $E(S)$.
\end{proof}

It follows that if $\lambda \in \sigma(T)$, and $E = E(\lambda)$, then the range of $E$ is precisely the kernel of $T - \lambda_0$, i.e. the set of eigenvectors for $T$ with eigenvalue $\lambda$. Since $E(U) \neq 0$ for any open $U$, any isolated point of $\sigma(T)$ is an eigenvalue for some eigenvector. If $\sigma(T)$ is countable, $\sigma(T) = \{ \lambda_1, \lambda_2, \dots \}$ then we have, in the strong operator topology, an orthogonal decomposition $I = \sum_{n = 1}^\infty E_i$, where $E_i = E(\lambda_i)$, and $TE_i = \lambda E_i$.

Previously, we saw that for a compact normal operator $T$, $\sigma(T)$ was countable with no limit point but the origin, and $T - \lambda$ had a finite dimensional kernel for each $\lambda \in \sigma(T)$. Using the spectral theorem, we can now prove that this characterizes the compact normal operators from the family of all normal operators.

\begin{theorem}
    A normal operator $T \in B(H)$ is compact if and only if $\sigma(T)$ has no limit point but the origin (which implies $\sigma(T)$ is countable), and for any $\lambda \neq 0$, then $T - \lambda$ has finite dimensional kernel.
\end{theorem}
\begin{proof}
    To show this is sufficient, if $f_\varepsilon(x) = x \cdot \mathbf{I}(|x| \geq \varepsilon)$, then $f_\varepsilon(T)$ is a finite sum of finite rank operators. Thus $f_\varepsilon(T)$ is compact for each $\varepsilon > 0$. On the other hand,
    %
    \[ \| T - f_\varepsilon(T) \| \leq \| x - f_\varepsilon \|_{L^\infty} \leq \varepsilon, \]
    %
    which shows $T$ is the limit of a family of compact operators, and is therefore compact.
\end{proof}

It follows that if $T$ is normal and compact, then $T$ has an eigenvalue $\lambda$ with $\| T \| = |\lambda|$, and $f(T)$ is compact for any $f \in C(\sigma(T))$ with $f(0) = 0$, but $f(T)$ is not compact if $H$ is infinite dimensional and $f(0) \neq 0$.

\begin{theorem}
    If $T \in B(H)$, then $\langle Tx, x \rangle \geq 0$ for each $x \in H$ if and only if $T$ is self-adjoint, and $\sigma(T) \subset [0,\infty)$. We call such an operator \emph{positive semidefinite} and write $T \geq 0$. If $\sigma(T) \subset (0,\infty)$, we say $T$ is \emph{positive definite}, and then $\langle Tx, x \rangle > 0$ for $x \neq 0$, and if $\lambda_0$ is the smallest value in $\sigma(T)$, then $\langle Tx, x \rangle \geq \lambda_0 \| x \|^2$ (and $\lambda_0$ is the largest constant for which this bound holds), in which case we write $T \geq \lambda_0$.
\end{theorem}
\begin{proof}
    Suppose $\langle Tx,x \rangle \geq 0$ for each $x \in H$. Then because $\langle Tx, x \rangle$ is real-valued, $\langle Tx, x \rangle = \langle x, Tx \rangle = \langle T^* x, x \rangle$, so that $\langle (T - T^*) x, x \rangle = 0$ for all $x \in H$. Since $T - T^*$ is normal, it follows that $T - T^* = 0$, from which it follows that $T$ is self adjoint. For any $\lambda < 0$, for $x \neq 0$ we have
    %
    \[ -\lambda \| x \|^2 = \langle -\lambda x, x \rangle \leq \langle (T-\lambda) x, x \rangle \leq \| (T - \lambda) x \| \| x \|, \]
    %
    from which it follows that $\| (T - \lambda) x \| \geq - \lambda \| x \|$, so $T - \lambda$ is an isomorphism, hence $\lambda \not \in \sigma(T)$.

    Conversely, if $T$ is self adjoint, and $\sigma(T) \subset [0,\infty)$, then
    %
    \[ \langle Tx, x \rangle = \int_0^\infty \lambda dE_{x,x}. \]
    %
    Since $E_{x,x}$ is a positiev measure, and $\lambda \geq 0$, it follows that $\langle Tx,x\rangle \geq 0$. If $\sigma(T) \subset (0,\infty)$, and $\lambda_0$ is the smallest element of $\sigma(T)$, then $\sigma(T - \lambda_0) \subset [0,\infty)$, and is self adjoint, so $\langle (T - \lambda_0) x, x \rangle \geq 0$, which gives $\langle Tx, x \rangle \geq \lambda \| x \|^2$.
\end{proof}

If $T \in B(H)$ is positive-semidefinite, then we can let $f(t) = \sqrt{t}$ be a well defined continuous function on $\sigma(T)$, and so $f(T) = \sqrt{T}$ is well define. Thus every positive semidefinite function has a square root. Now $\sigma(f(T)) = \sqrt{\sigma(T)} \subset [0,\infty)$, and since $f$ is real valued, $\sqrt{T}$ is self adjoint. Thus $\sqrt{T}$ is a positive-semidefinite square root for $T$. This is actually the unique such positive semidefinite square root, because if $S \geq 0$ is a positive semidefinite square root for $T$, then we let $A$ be the smallest closed subalgebra of $B(H)$ containing $S$, $T$, and $\sqrt{T}$. Then $A$ is commutative, and is isomorphic to $C(\Phi_A)$ for some compact $\Phi_A$, in such a way that positive-semidefinite elements of $A$ are mapped onto non-negative functions in $C(\Phi_A)$. But since non-negative functions have unique square roots, it follows that $S = \sqrt{T}$.

For any operator $T$, $T^*T$ is a positive semidefinite self-adjoint operator, so we can consider the operator $|T| = \sqrt{T^*T}$. Then
%
\[ \| |T| x \|^2 = \langle \sqrt{T^* T} x, \sqrt{T^* T} x \rangle = \langle T^*T x, x \rangle = \| Tx \|^2. \]
%
This is the \emph{only} positive semidefinite operator with this property, since if $\| Sx \| = \| Tx \|$ for each $x \in H$, then $\langle (S^2 - T^* T) x, x \rangle = 0$ for all $x$, from which it follows that $S^2 = T^*T$.

Over the complex numbers, any $z \in \CC$ can be written as $r w$ for some $r \geq 0$ and $|w| = 1$. This leads to the problem of trying to factorize an operator $T$ into a product $U P$, where $P \geq 0$ and $U$ is unitary. We call $UP$ a \emph{polar decomposition} of $T$.




















\chapter{Unbounded Operators}

We often wish to describe a spectral theory of operators that are not necessarily bounded. For instance, in the spectral analysis of partial differential equations with non constant coefficients, one would like to consider a Banach space of functions $X$ supporting both derivative operators $D: X \to X$ given formally by $Df = f'$, and multiplier operators $M: X \to X$ given formally by $Mf = xf$. Applying the product rule would show that $[D,M] = DM - MD$ is the identity operator. But the following intriguing result shows that we \emph{cannot} find a Banach space of functions $X$ upon which this theory works.

\begin{lemma}
    There does not exist a unital normed algebra $A$ supporting $x,y \in A$ with $xy - yx = 1$.
\end{lemma}
\begin{proof}
    If $x,y \in A$ were found with $xy - yx = 1$, then it would follow that $x^n y - yx^n = nx^{n-1}$ (easily proved e.g. by induction). But this means that
    %
    \[ n \| x^{n-1} \| = \| x^n y - yx^n \| \leq 2 \| x^n \| \| y \| \leq 2 \| x^{n-1} \| \| x \| \| y \|, \]
    %
    so that $\| x \| \| y \| \geq n/2$ for every integer $n$, which is impossible.
\end{proof}

Thus we cannot find a common function space upon which to analyze differentiation and multiplication as bounded operators. Fortunately, we can obtain a theory of \emph{unbounded operators} which allow us to view $D$ and $M$ as operators with a common domain, e.g. $L^2(\RR)$. The key to this theory is to allow operators that are only defined on dense subsets of Banach spaces.

Let $X$ and $Y$ be Banach spaces. An \emph{unbounded operator} $T: X \to Y$ is a linear map $T: \mathcal{D}(T) \to Y$ defined on a subspace $\mathcal{D}(T) \subset X$, which we call the \emph{domain} of the operator. Two unbounded operators are equal if they have the same domain, and are equal as functions. We do not assume this operator has any topological properties in general - if the operator was bounded the Hahn-Banach theorem would imply that it was just the restriction of a bounded operator $T: X \to Y$, so there would be no real importance to consider the operator on a smaller subspace.

\begin{example}
    Consider the operator $\Delta$ on $L^2(\Omega)$, where $\Omega$ is some domain in $\RR^d$ which, for simplicity, we might as well assume has smooth boundary. One domain we could take for $\Delta$ is $C^\infty(\Omega)$, or the space of all smooth, periodic functions and these will be different unbounded operators. Of more relevance in what follows, we can consider $\Delta$ either as an operator with domain $\mathcal{D}_D$ (the space of functions with \emph{Dirichlet boundary conditions} boundary conditions) consisting of all functions $f \in C^2(\Omega)$ vanishing on the boundary, or the domain $\mathcal{D}_N$ of functions $f \in C^2(\Omega)$ such that $\nabla f \cdot \nu$ vanishes on the boundary, where $\nu$ is the normal vector to the boundary. Thus we obtain two different unbounded operators, $\Delta_D$, and $\Delta_N$. The spectral theory of operators on the two domains can certainly differ, e.g. for $\Omega = [0,1]$, the eigenfunctions of $\Delta_D$ are precisely scalar multipliers of the functions
    %
    \[ f_n(x) = \sin(2 \pi n x) \]
    %
    which have eigenvalues $- 4 \pi^2 n^2$, for $n > 0$. The eigenfunctions for $\Delta_N$, on the other hand, are scalar multiples of the functions
    %
    \[ f_n(x) = \cos(2 \pi n x) \]
    %
    which also have eigenvalues $- 4 \pi^2 n^2$, for $n \geq 0$. Thus $0$ is an eigenvalue for $\Delta_N$, but not for $\Delta_D$. The differences between Neumann and Dirichlet boundary conditions only get more distinct in higher dimensions.
\end{example}

For any unbounded operator $T: X \to Y$, we can consider the graph $\Gamma(T) = \{ (x,Tx): x \in \mathcal{D}(T) \}$. If $\Gamma(T)$ is a closed subset of $X \times Y$, we say that $T$ is \emph{closed}. The closed graph theorem implies that if $T$ is closed and $\mathcal{D}(T) = X$, then $T$ is actually a bounded operator. For any closed operator $T$, we can give $\mathcal{D}(T)$ the structure of a Banach space by defining
%
\[ \| x \|_T = \sqrt{\| x \|^2 + \| Tx \|^2}, \]
%
and in this topology $T$ will then be a bounded operator from $\mathcal{D}(T)$ to $Y$.

The importance of being closed is \emph{essential} to the spectral theory of unbounded operators. Given an unbounded operator $T: X \to Y$, we define the resolvent $\rho(T)$ of $T$ to be the set of all complex numbers $\lambda \in \CC$ such that $T - \lambda$ has a bounded everywhere defined inverse $S: X \to \mathcal{D}(T)$, i.e. such that $(T - \lambda) S = I_X$, and $S (T - \lambda) = I_{\mathcal{D}(T)}$, which we will denote by $(T - \lambda)^{-1}$. The spectrum $\sigma(T)$ is then the complement of the resolvent of $T$.

\begin{lemma}
    If $\sigma(T) \neq \CC$, then $T$ is closed.
\end{lemma}
\begin{proof}
    Suppose $\lambda \not \in \sigma(T)$, and assume without loss of generality that $\lambda = 0$. Let $S: X \to \mathcal{D}(T)$ be the inverse of $T$. If $x_i \to x$ in $\mathcal{D}(X)$, and $T x_i \to y$ in $X$, then by continuity, $x_i = STx_i \to Sy$, so $x = Sy$. But this means that $Tx = TSy = y$. Thus $T$ is closed.
\end{proof}

Like with bounded operators, $\sigma(T)$ is a closed set, but it need not be compact. The proof is roughly the same.

\begin{lemma}
    If $\lambda \in \rho(T)$, and $L^{-1} = \| (T - \lambda)^{-1} \|$, then $B(\lambda,L) \subset \rho(T)$.
\end{lemma}
\begin{proof}
    Assume without loss of generality that $\lambda = 0$. Let $S = T^{-1}$. Then
    %
    \[ (T - \lambda)^{-1} = \sum_{n = 0}^\infty (-\lambda)^n  \]
    %
    \[ (T - \lambda)^{-1} = \sum_{n = 0}^\infty (-\lambda)^n T^n \]
    %

\end{proof}

We wish to extend the natural operations on the class of operators to the class of unbounded operators. Given a scalar $\lambda$, and an unbounded operator $T: X \to Y$, we can define an unbounded operator $\lambda T: X \to Y$ with $\mathcal{D}(\lambda T) = \mathcal{D}(T)$. For two unbounded operators $T: \mathcal{D}(T) \to Y$ and $S: \mathcal{D}(S) \to Y$, we can define $T + S$ as an unbounded operator defined on $\mathcal{D}(T) \cap \mathcal{D}(S)$. Similarily, we can define $T - S$. If $T: \mathcal{D}(T) \to Y$ and $S: \mathcal{D}(S) \to Z$ are unbounded operators, we can define $ST$ as an unbounded operator defined on $\mathcal{D}(T) \cap T^{-1}(\mathcal{D}(S))$. The distributive law $(S + U)T = ST + UT$ continues to hold since
%
\[ \mathcal{D}(T) \cap T^{-1}(\mathcal{D}(S) \cap \mathcal{D}(U)) = \left[ \mathcal{D}(T) \cap T^{-1}(\mathcal{D}(S)) \right] \cap \left[ \mathcal{D}(T) \cap T^{-1}(\mathcal{D}(U)) \right], \]
%
but the distributive law $T(S + U) = TS + TU$ might \emph{not} hold in this scheme. If $T: X \to Y$ is an injective unbounded operator, we can define $T^{-1}: Y \to X$ to be the unbounded operator whose domain is the image of $T$.



An unbounded operator is \emph{densely defined} if $\mathcal{D}(T)$ is a dense subset of $X$. Given an unbounded densely defined operator $T: \mathcal{D}(X) \to Y$, we can define an unbounded operator $T^*$ with domain
%
\[ \mathcal{D}(T^*) = \{ \gamma \in Y^*: \gamma \circ T \in \mathcal{D}(T)^* \}, \]
%
where $\mathcal{D}(T)$ is given the subspace topology inherited from $X$. We then set $T^* \gamma$ to be the unique $\lambda \in X^*$ extending the continuous functional $\gamma \circ T$. In inner product notation, we then have
%
\[ \langle T^* \gamma, x \rangle = \langle \gamma, Tx \rangle \]
%
for any $x \in \mathcal{D}(T)$ and $\gamma \in \mathcal{D}(T^*)$. Note that if $T$ is not densely defined, this extension might not be unique, and so the adjoint is not well defined. If $T: X \to Y$ and $S: Y \to Z$ are densely defined unbounded operators such that $ST$ is also densely defined, then $(ST)^*$ is an extension of $T^* S^*$. If $S$ is bounded, then the domains are actually equal to one another, and so we get the familiar identity $T^* S^* = (ST)^*$. We also note that if $T: X \to Y$ is densely defined and unbounded, and $S: Y^* \to X^*$ is another unbounded operator such that $\gamma(Tx) = (S\gamma)(x)$ for any $x \in \mathcal{D}(T)$ and $\gamma \in \mathcal{D}(S)$, then $\mathcal{D}(S) \subset \mathcal{D}(T^*)$, because $\gamma \circ T$ is a bounded functional on $\mathcal{D}(T)$ for any $\gamma \in \mathcal{D}(S)$.

%If $T^* S^* \eta$ is well defined, then firstly, $|\eta(Sy)| \lesssim \| y \|_Y$ for $y \in \mathcal{D}(S)$. Thus there exists $\gamma \in Y^*$ such that $\gamma y = \eta(Sy)$ for all $y \in \mathcal{D}(S)$. Moreover, we know that $|\gamma(Tx)| \lesssim \| x \|$ for all $x \in \mathcal{D}(T)$. Thus we can find $\lambda \in X^*$ such that $\lambda x = \gamma(Tx)$. But then
%
%\[ |\eta(STx)| = |\gamma(Tx)| \lesssim \| x \| \]
%
% So \eta is in the domain of T^* S^*.

If $T: H_1 \to H_2$ is an unbounded operator between two Hilbert spaces $H_1$ and $H_2$, the unbounded adjoint can be naturally identified with an unbounded adjoint $T^*: H_2 \to H_1$, which we will do whenever we are talking about Hilbert spaces. If $T: H \to H$ is unbounded, and $T^*$ is an extension of $T$, then we say $T$ is \emph{symmetric}. This means that for any $x_1,x_2 \in \mathcal{D}(T)$, $\langle Tx_1, x_2 \rangle = \langle x_1, Tx_2 \rangle$. If we actually have $T^* = T$, which means that in addition to the previous property, $x \mapsto \langle Tx, y \rangle$ is continuous if and only if $y \in \mathcal{D}(X)$, then we say $T$ is \emph{self adjoint}. However, it is possible for $T$ to be a strict extension of $T^*$, as the next example shows, and we do not say this operator is symmetric nor self-adjoint. 

\begin{example}
    Let $T: L^2[0,1] \to L^2[0,1]$ be the unbounded operator whose domain consists of all absolutely continuous functions $f: [0,1] \to \CC$ such that $f' \in L^2[0,1]$, and for such functions, let
    %
    \[ Df = if'. \]
    %
    If $g \in L^2[0,1]$ satisfies
    %
    \[ \left| \int f'(x) g(x)\; dx \right| \lesssim \| f \|_{L^2[0,1]} \]
    %
    for all $f \in \mathcal{D}(T)$, then we claim that $g$ is absolutely continuous, and $g(0) = g(1) = 0$. Conversely, if $g$ is absolutely continuous, then
    %
    \[ \int f'(x) g(x)\; dx = f(1) g(1) - f(0) g(0) - \int f(x) g'(x)\; dx, \]
    %
    and we see that this quantity is $\lesssim \| f \|_{L^2[0,1]}$ precisely when $g(0) = g(1) = 0$. All that remains is to argue that $g$ is absolutely continuous, but this follows because $\mathcal{D}(T)$ contains the restriction of $C_c^\infty(0,1)$, so the boundedness equation above implies that the distributional derivative $g'$ of $g$ in $\mathcal{D}(0,1)^*$ is square integrable, which implies that $g$ lies in $\mathcal{D}(T)$, i.e. $g$ is absolutely continuous and $g' \in L^2[0,1]$. Thus we see that, even though we have $\langle Tx, y \rangle = \langle x, Ty \rangle$ for $x \in \mathcal{D}(T)$ and $y \in \mathcal{D}(T^*)$, $T^*$ is only defined on a proper subset of the domain of $T$. On the other hand, the operator $ S = T^*$, which extends $T$, is \emph{symmetric}, but not self adjoint, since one can verify that $S^* = T^{**} = T$, and that $S^*$ therefore extends $S$. The operator $T'$ defined as the restriction of $T$ to functions $f$ with $f(0) = f(1)$, is \emph{self adjoint}, since once can easily verify from the integration by parts formula that $\mathcal{D}((T')^*) = \mathcal{D}(T')$.
\end{example}

We now come to an interesting result which relates the graph of $T$ and $T^*$.

\begin{theorem}
    Let $T$ be a densely defined unbounded operator on a Hilbert space $H$. Then $\Gamma(T^*) = [V \Gamma(T)]^\perp$, where $V(x,y) = (-y,x)$, and $H \times H$ is viewed as a Hilbert space. In particular, $T^*$ is \emph{always} a closed unbounded operator, all self-adjoint operators are closed.
\end{theorem}
\begin{proof}
    The following four statements are equivalent to one another:
    %
    \begin{itemize}
        \item $(y,z) \in \Gamma(T^*)$
        \item $\langle y, Tx \rangle = \langle z, x \rangle$ for every $x \in \mathcal{D}(T)$.
        \item $\langle (y,z), V(x,Tx) \rangle = 0$ for every $x \in \mathcal{D}(T)$.
        \item $(y,z)$ lies in $V(\Gamma(T))^\perp$.
    \end{itemize}
    %
    Thus the proof is complete.
\end{proof}

Here are some corollaries for a symmetric unbounded operator $T: H \to H$:
%
\begin{itemize}
    \item If $\mathcal{D}(T) = H$, then $T$ is a bounded, self-adjoint operator.
    \item If $T$ is injective and self-adjoint, then it has dense image, and $T^{-1}$ is self adjoint.
    \item If the image of $T$ is dense, then $T$ is injective.
    \item If $T$ is surjective (so that (c) applies and $T$ is actually injective), then $T$ is self-adjoint, and $T^{-1}$ is bounded.
\end{itemize}
\begin{proof}
    To see (a), if $\mathcal{D}(T) = H$, then because $T^*$ extends $T$, $T^* = T$, and since $T^*$ is closed, it follows that $T$ is bounded and self-adjoint. 

    To obtain (b), to show the image is dense let $x$ be perpendicular to the image of $T$. Then $x \in \mathcal{D}(T^*)$ because $\langle x, Tx' \rangle = 0$ for all $x' \in \mathcal{D}(T)$, and is thus trivially continuous. But this implies that $x \in \mathcal{D}(T^*) = \mathcal{D}(T)$, and $Tx = T^*x = 0$. Thus $x = 0$, which shows the image of $T$ is dense. Thus $T^{-1}$ is a densely defined unbounded operator, and so we can consider it's adjoint. We claim that $[V\Gamma(T^{-1})]^\perp = \Gamma(T^{-1})$, which would show that $T^{-1}$ is self adjoint. But $V(\Gamma T^{-1}) = \Gamma(-T)$ and $V \Gamma(-T)$, and since $T$ is self-adjoint, $-T$ is self adjoint, and so $\Gamma(-T)^\perp = V \Gamma(-T) = \Gamma(T^{-1})$, which completes the argument.

    To prove (c), we suppose that $Tx = 0$. Then for any $x' \in \mathcal{D}(T)$, $\langle x, Tx' \rangle = \langle Tx, x' \rangle = 0$. Thus $x$ is orthogonal to the image of $T$. But this implies $x = 0$.

    To prove (d), we note that $T^{-1}$ is symmetric, because if $x_1,x_2 \in H$ then $x_i = Ty_i$ for some $y_i \in \mathcal{D}(T)$, and so applying the fact that $T$ is symmetric, we find that
    %
    \[ \langle T^{-1} x_1, x_2 \rangle = \langle y_1, Ty_2 \rangle = \langle Ty_1, y_2 \rangle = \langle x_1, T^{-1} x_2 \rangle. \]
    %
    Since $T^{-1}$ is self adjoint, injective, and has dense iamge, this implies $T = (T^{-1})^{-1}$ is self adjoint. But (a) also implies that $T^{-1}$ is bounded.
\end{proof}

A powerful consequence of this result is that if $T$ is a closed operator, then we have an orthogonal decomposition
%
\[ H \times H = V \Gamma(T) \oplus \Gamma(T^*) \]
%
Thus for any $a,b \in H$, there exists a unique pair $(x,y) \in \mathcal{D}(T) \times \mathcal{D}(T^*)$ such that $a = y - Tx$ and $b = x + T^* y$. Moreover, for this pair we have
%
\[ \| a \|^2 + \| b \|^2 = \| x \|^2 + \| Tx \|^2 + \| y \|^2 + \| T^* y \|^2. \]
%
In particular, setting $a = 0$, we find that with any closed, unbounded operator $T$, we can associate a pair of bounded operators $A_1: H \to \mathcal{D}(T)$ and $A_2: H \to \mathcal{D}(T^*)$, with $\| A_1 \| \leq 1$ and $\| A_2 \| \leq 1$, such that $TA_1 = A_2$, $I = A_1 + T^* A_2$, and for any $x \in H$,
%
\[ \| x \|^2 = \| A_1 x \|^2 + \| TA_1 x \|^2 + \| A_2 x \|^2 + \| T^* A_2 x \|^2. \]
%
In particular, if $Q = I + T^*T$, then $I = QA_1$, so $Q$ is surjective onto $H$. Moreover, $Q$ is also injective, since if $x \in \mathcal{D}(Q)$, $Tx \in \mathcal{D}(T^*)$, and so
%
\[ \langle x, x \rangle + \langle Tx, Tx \rangle = \langle x, x \rangle + \langle T^*Tx, x \rangle = \langle Qx, x \rangle \]
%
which shows by Cauchy-Schwartz that $\| x \|^2 \leq \| x \| \| Qx \|$, so that $\| Qx \| \geq \| x \|$, and thus $Q$ is injective. Thus $Q$ is a bijection from $\mathcal{D}(Q)$ to $H$, which means that $I$ is an extension of $A_1Q$. The fact that $\langle Qx, x \rangle \geq 0$ for all $x \in \mathcal{D}(Q)$, means $\langle A_1 x, x \rangle \geq 0$ for all $x \in H$, i.e. $A_1$ is positive semidefinite. Since $A_1$ is injective and self-adjoint, this implies $Q = A_1^{-1}$ is self-adjoint. And this means $T^*T = Q - I$ is self adjoint for any closed unbounded operator $T$.

\begin{theorem}
    If $T: H \to H$ is a densely defined closed unbounded operator, then $\mathcal{D}(T^*)$ is dense, and $T^{**} = T$.
\end{theorem}
\begin{proof}
    We use the fact that $H \times H = V \Gamma(T) \oplus \Gamma(T^*)$. Suppose $y \perp \mathcal{D}(T^*)$. Then $(y,0)$ is perpendicular to $\Gamma(T^*)$. This means that $(y,0) \in V \Gamma(T)$, so $(0,-y) \in \Gamma(T)$, which implies $y = 0$. Thus $\mathcal{D}(T^*)$ is dense. To show $T^{**} = T$, we simply note that we can also write $H \times H = V \Gamma(T^{**}) \oplus \Gamma(T^*)$, from which it follows that $V \Gamma(T^{**}) = V \Gamma(T)$, and so $T = T^{**}$.
\end{proof}

A symmetric operator $T$ is \emph{maximally symmetric} if it has no proper symmetric extension. Any self-adjoint operator $T$ is maximally symmetric, for if $S$ is symmetric and extends $T$, then $T = T^*$ extends $S^*$, which means $S$ extends $S^*$, and since $S$ is symmetric, $S^*$ extends $S$, hence we conclude $S = S^*$, and as a result, $S = T$. On the other hand, maximally symmetric operators need not be self-adjoint.

\section{The Cayley Transform}

One trick to understanding symmetric operators $T$ is to consider the operator $T + i$. This is because if $T$ is symmetric, a simple calculation shows that for $x \in \mathcal{D}(T)$,
%
\[ \| Tx + i x \|^2 = \| x \|^2 + \| Tx \|^2. \]
%
Thus $\Gamma(T)$ is isometric to the image of $T + i$. Thus $T + i$ is injective, $T$ is closed if and only if the range of $T + i$ is closed, and if $T + i$ is onto $H$, then $T$ is maximally symmetric, because otherwise $T + i$ would have a symmetric extension which was still injective, which is impossible. Exactly the same results are true if we replace $i$ with any other purely imaginary quantity.

The mapping
%
\[ t \mapsto \frac{t - i}{t + i} \]
%
is a one-to-one-correspondence between $\RR$ and the unit circle in $\CC$ (except for one). It follows from the continuous functional calculus that the map
%
\[ T \mapsto (T - i)(T + i)^{-1} \]
%
is a one-to-one-correspondence between the family of self-adjoint bounded operator $T$ on a Hilbert space $H$, and the family of unitary operators on $H$ which do not contain $1$ in their spectrum. We wish to work with `unbounded' isometries, which will extend the theory of the Cayley transform to unbounded symmetric operators. An unbounded isometry is an unbounded operator $U: H \to H$ such that $\| Ux \| = \| x \|$ for each $x \in \mathcal{D}(U)$. Equivalently, this holds if and only if $\langle Ux, Uy \rangle = \langle x, y \rangle$ for each $x,y \in \mathcal{D}(U)$. If $U$ is an unbounded isometry, and $I - U$ has dense range, then $I - U$ is injective, for if $Ux = x$, then for any $y \in \mathcal{D}(U)$,
%
\[ \langle x, (I - U)y \rangle = \langle x, y \rangle - \langle x, Uy \rangle = \langle x,y \rangle - \langle Ux, Uy \rangle = 0. \]
%
Because the range of $I - U$ is dense, $x = 0$. It is similarily easy to prove that the three sets $\mathcal{D}(U)$, $U(\mathcal{D}(U))$, and $\Gamma(U)$ are all closed, or all not closed.

Let us now show the Caylet transform gives a correspondence between symmetric unbounded operators on $H$, and unbounded isometries on $H$ (unbounded operators $U: H \to H$ such that $\| Ux \| = \| x \|$ for each $x \in \mathcal{D}(U)$), or equivalently, $\langle Ux, Uy \rangle = \langle x, y \rangle$ for $x,y \in \mathcal{D}(U)$). For any symmetric operator $T$, since $\| Tx + ix \|^2 = \| x \|^2 + \| Tx \|^2$, the map $U = (T - i)(T + i)^{-1}$ is an unbounded isometry with domain is the image of the map $T + i$. The following properties then holds

\begin{theorem}
    Suppose $U$ is the Cayley transform of $T$.
    %
    \begin{itemize}
        \item $U$ is closed if and only if $T$ is closed.
        \item The map $I - U$ is injective from $\mathcal{D}(U)$ onto $\mathcal{D}(T)$, and $T = i(I + U)(I - U)^{-1}$.
        \item $U$ is unitary if and only if $T$ is self-adjoint.
    \end{itemize}
    %
    Conversely, any unbounded isometry on $H$ such that $I - U$ is injective is the Cayley transform of a symmetric operator.
\end{theorem}
\begin{proof}
    TODO
\end{proof}

If $U_1$ and $U_2$ are Cayley transforms of symmetric operators $T_1$ and $T_2$, then $T_1$ extends $T_2$ if and only if $U_1$ extends $U_2$. Thus problems about extensions of symmetric operators reduce to problems about extensions of isometries. Given an unbounded symmetric closed operator $T$, the range of $T + i$ and $T - i$ are closed, and $U$ is an isometry from the image of the first map to the image of the second map. The dimensions of $(T + i)^\perp$ and $(T - i)^\perp$ are called the \emph{deficiency indices} of the map $T$. Then it follows from the properties above that $T$ is self-adjoint if and only if both of its deficiency indices are zero, $T$ is maximally symmetric if and only if at least one of its deficiency indices is zero, and $T$ has a self-adjoint extension if and only if its two deficiency indices are equal.

\begin{example}
    Let $V$ be the right shift operator on $l^2$. Then $V$ is an isometry, and $I - V$ is injective. Thus $V$ is the Cayley transform of a symmetric operator $T$ on $l^2$. Since $V$ has domain $l^2$, and its range has codimension one, the deficiency indices of $T$ are zero and one. Thus $T$ is an example of a maximally symmetric operator which is not self adjoint.
\end{example}

\section{The Spectral Theory of Unbounded Symmetric Operators}

s






\section{Operator Semigroups}

TODO






\chapter{Von Neumann Algebras}





\section{Spectral Theorem for Normal Operators}

In finite dimensional theory, a normal linear transformation $T: \mathbf{C}^n \to \mathbf{C}^n$ can be written
%
\[ T = \sum \lambda_i P_i \]
%
where $P_i$ is projection onto the eigenspace corresponding to the eigenvalue $\lambda_i$. In this section we apply the theory of $C^*$ algebras to extend this theorem to arbitrary normal bounded transformations from a Hilbert space to itself. The trick is to `integrate' rather than sum up the subspaces.

A \emph{spectral measure} on a measure space $(\Omega, \mathcal{F})$ is a function $E: \mathcal{F} \to B(H)$, for which
%
\[ E(\Omega) = \text{id}_H \]
%
such that $E(S)$ is a projection for each $S$, and such that for a disjoint family of sets $\{ S_1, S_2, \dots \}$ in $\mathcal{F}$, then
%
\[ E \left( \bigcup S_i \right) = \sum E(S_i) \]
%
with convergence pointwise (the strong operator topology), rather than in the operator norm. It follows that $E(\emptyset) = 0$.

\begin{lemma}
    If $S \subset W$, $E(S) \leq E(W)$.
\end{lemma}
\begin{proof}
    Since $E(W - S)$ is a projection, $E(W - S) \geq 0$, so
    %
    \[ E(W) = E(W - S) + E(S) \geq E(S) \]
    %
    Hence a spectral measure is monotone on projections.
\end{proof}

\begin{lemma}
    If $S$ and $W$ are disjoint sets, then $E(S)E(W) = 0$.
\end{lemma}
\begin{proof}
    $E(S \cup W) = E(S) + E(W)$, so
    %
    \[ E(S \cup W) = E(S \cup W) E(S \cup W) = E(S) + E(W) E(S) + E(S)E(W) + E(W) \]
    %
    which implies
    %
    \[ E(S) + E(W) = E(S) + E(W) E(S) + E(S) E(W) + E(W) \]
    %
    hence $E(W) E(S) + E(S) E(W) = 0$.
\end{proof}

\begin{lemma}
    $E(S \cap W) = E(S) \circ E(W)$.
\end{lemma}
\begin{proof}
    We have
    %
    \[ E(S \cap W) + E(S - W) = E(S)\ \ \ \ \ \ \ \ E(S \cap W) + E(W - S) = E(W) \]
    %
    and
    %
    \[ E(S \cup W) = E(S \cap W) + E(S - W) + E(W - S) \]
    %
    From which it follows that
    %
    \begin{align*}
        E(S) + E(W) &= 2E(S \cap W) + E(S - W) + E(W - S)\\
        &= E(S \cap W) + E(S \cup W)
    \end{align*}
    %
    Now multiply both sides of the equation on the right by $E(W)$ gives
    %
    \[ E(S) E(W) + E(W)^2 = E(S \cap W) E(W) + E(S \cup W) E(W) \]
    %
    Since $S \subset S \cup W$, $E(S) \leq E(S \cup W)$, and
    %
    \[ E(S \cup W) E(S) = E(S) \]

    Now $E(S \cup W) E(S) = E(S)^2 + E(W - S) E(S) = E(S)$
\end{proof}

\begin{example}
    If $H = \mathbf{C}$, then $B(H) \cong \mathbf{C}$, and any $\{ 0, 1 \}$ valued measure $\mu$ is a spectral measure, provided $\mu(\Omega) = 1$. If $\mu(S_1) = \mu(S_2) = 1$, then
    %
    \[ 1 = \mu(S_1) = \mu(S_1 \cap S_2) + \mu(S_1 - S_2) \]
    %
    \[ 1 = \mu(S_2) = \mu(S_1 \cap S_2) + \mu(S_2 - S_1) \]
    %
    If $\mu(S_1 \cap S_2) = 0$, then $\mu(S_1 - S_2) = \mu(S_2 - S_1) = 1$, which implies
    %
    \[ \mu((S_1 - S_2) \cup (S_2 - S_1)) = \mu(S_1 - S_2) + \mu(S_2 - S_1) = 2 \]
    %
    an impossibility. Thus $\mu(S_1 \cap S_2) = 1$. If $\mu(S_1) = 0$, then $S_1 \cap S_2 \subset S_1$, so $\mu(S_1 \cap S_2) \leq \mu(S_1) = 0$. The same holds if $\mu(S_2) = 0$. Thus we have verified that $\mu(S_1 \cap S_2) = \mu(S_1) \circ \mu(S_2)$ on a case by case basis. The countable summation property holds by the property of the measure itself.
\end{example}

\begin{example}
    If $H$ is infinite dimensional, and $N \in K(H)$, then
    %
    \[ \sigma(N) = \{ \lambda_0, \lambda_1, \dots \} \]
    %
    where $\lambda_0 = 0$, and each $\lambda_i$ is an eigenvalue. For each $n > 0$, let $P_n$ be orthogonal projection onto $\text{ker}(\lambda_n - N)$, and let $P_0$ project onto the orthogonal complement of the closed linear space of the images of $P_1, P_2, \dots$. For $S \subset \sigma(N)$, let
    %
    \[ E(S) = \sum_{\lambda_n \in S} P_n \]
    %
    In the sense that the sum on the right is interpreted pointwise. Then $E$ is a spectral measure on $(\sigma(N), \mathcal{P}(\sigma(N)))$. Surely
    %
    \[ E(\sigma(N)) = \sum_{n = 0}^\infty P_n = \text{id}_H \]
    %
    And since $P_i \circ P_j = 0$ if $i \neq j$,
    %
    \begin{align*}
        E(S_1) \circ E(S_2) &= \left( \sum_{\lambda_n \in S_1} P_n \right) \circ  \left( \sum_{\lambda_m \in S_2} P_m \right)\\
        &= \sum_{\lambda_n \in S_1, \lambda_m \in S_2} P_n P_m\\
        &= \sum_{\lambda_n \in S_1 \cap S_2} P_n = E(S_1 \cap S_2)
    \end{align*}
    %
    And the countable additivity follows by the pointwise definition of the sum of operators.
\end{example}

\begin{example}
    If $\Omega$ is a $\sigma$-finite measure space with measure $\mu$, and $H = L^2(\Omega)$, define
    %
    \[ E(S) \xi = \chi_S \xi \]
    %
    Then $E$ is a spectral measure. Surely $E(\Omega) = \text{id}_H$, $E(\emptyset) = 0$, because $\chi_\Omega = 1$, $\chi_\emptyset = 0$. Now $E(S_1 \cap S_2) = E(S_1) \circ E(S_2)$ follows because $\chi_{S_1 \cap S_2} = \chi_{S_1} \chi_{S_2}$. Similarily, $\chi_{\bigcup S_i} = \sum \chi_{S_i}$ pointwise if the $S_i$ are disjoint.
\end{example}

\end{document}
